<!DOCTYPE pdf2xml SYSTEM "pdf2xml.dtd">
<pdf2xml producer="poppler" version="23.04.0">
<page number="1" position="absolute" top="0" left="0" height="792" width="612">
	<fontspec id="font0" size="7" family="NimbusRomNo9L-Regu" color="#000000"/>
	<fontspec id="font1" size="24" family="NimbusRomNo9L-Regu" color="#000000"/>
	<fontspec id="font2" size="11" family="NimbusRomNo9L-Regu" color="#000000"/>
	<fontspec id="font3" size="9" family="NimbusRomNo9L-MediItal" color="#000000"/>
	<fontspec id="font4" size="9" family="NimbusRomNo9L-Medi" color="#000000"/>
	<fontspec id="font5" size="10" family="NimbusRomNo9L-Regu" color="#000000"/>
	<fontspec id="font6" size="8" family="NimbusRomNo9L-Regu" color="#000000"/>
	<fontspec id="font7" size="8" family="NimbusRomNo9L-Medi" color="#000000"/>
	<fontspec id="font8" size="8" family="NimbusRomNo9L-ReguItal" color="#000000"/>
	<fontspec id="font9" size="10" family="NimbusRomNo9L-MediItal" color="#000000"/>
	<fontspec id="font10" size="10" family="NimbusRomNo9L-ReguItal" color="#000000"/>
	<fontspec id="font11" size="10" family="CMMI10" color="#000000"/>
	<fontspec id="font12" size="7" family="CMR7" color="#000000"/>
	<fontspec id="font13" size="6" family="NimbusRomNo9L-Regu" color="#000000"/>
	<fontspec id="font14" size="20" family="Times" color="#7f7f7f"/>
<text top="26" left="560" width="3" height="6" font="font0" id="p1_t1" reading_order_no="1" segment_no="0" tag_type="text">1</text>
<text top="61" left="57" width="497" height="21" font="font1" id="p1_t2" reading_order_no="2" segment_no="1" tag_type="title">MIMIR: Deep Regression for Automated Analysis</text>
<text top="88" left="173" width="266" height="21" font="font1" id="p1_t3" reading_order_no="3" segment_no="1" tag_type="title">of UK Biobank Body MRI</text>
<text top="121" left="105" width="401" height="10" font="font2" id="p1_t4" reading_order_no="4" segment_no="2" tag_type="text">Taro Langner, Andr´es Mart´ınez Mora, Robin Strand, H˚akan Ahlstr¨om, and Joel Kullberg</text>
<text top="178" left="59" width="241" height="8" font="font3" id="p1_t5" reading_order_no="5" segment_no="4" tag_type="text">Abstract —UK Biobank (UKB) is conducting a large-scale</text>
<text top="188" left="49" width="251" height="8" font="font4" id="p1_t6" reading_order_no="6" segment_no="4" tag_type="text">study of more than half a million volunteers, collecting health-</text>
<text top="198" left="49" width="251" height="8" font="font4" id="p1_t7" reading_order_no="7" segment_no="4" tag_type="text">related information on genetics, lifestyle, blood biochemistry, and</text>
<text top="208" left="49" width="251" height="8" font="font4" id="p1_t8" reading_order_no="8" segment_no="4" tag_type="text">more. Medical imaging furthermore targets 100,000 subjects,</text>
<text top="218" left="49" width="251" height="8" font="font4" id="p1_t9" reading_order_no="9" segment_no="4" tag_type="text">with 70,000 follow-up sessions, enabling measurements of organs,</text>
<text top="228" left="49" width="251" height="8" font="font4" id="p1_t10" reading_order_no="10" segment_no="4" tag_type="text">muscle, and body composition. With up to 170,000 mounting</text>
<text top="238" left="49" width="251" height="8" font="font4" id="p1_t11" reading_order_no="11" segment_no="4" tag_type="text">MR images, various methodologies are accordingly engaged in</text>
<text top="248" left="49" width="251" height="8" font="font4" id="p1_t12" reading_order_no="12" segment_no="4" tag_type="text">large-scale image analysis. This work presents an experimental</text>
<text top="258" left="49" width="251" height="8" font="font4" id="p1_t13" reading_order_no="13" segment_no="4" tag_type="text">inference engine that can automatically predict a comprehensive</text>
<text top="267" left="49" width="251" height="8" font="font4" id="p1_t14" reading_order_no="14" segment_no="4" tag_type="text">profile of subject metadata from UKB neck-to-knee body MRI.</text>
<text top="277" left="49" width="251" height="8" font="font4" id="p1_t15" reading_order_no="15" segment_no="4" tag_type="text">In cross-validation, it accurately inferred baseline characteristics</text>
<text top="287" left="49" width="251" height="8" font="font4" id="p1_t16" reading_order_no="16" segment_no="4" tag_type="text">such as age, height, weight, and sex, but also emulated mea-</text>
<text top="297" left="49" width="251" height="8" font="font4" id="p1_t17" reading_order_no="17" segment_no="4" tag_type="text">surements of body composition by DXA, organ volumes, and</text>
<text top="307" left="49" width="251" height="8" font="font4" id="p1_t18" reading_order_no="18" segment_no="4" tag_type="text">abstract properties like grip strength, pulse rate, and type 2</text>
<text top="317" left="49" width="251" height="8" font="font4" id="p1_t19" reading_order_no="19" segment_no="4" tag_type="text">diabetic status (AUC: 0.866). The proposed system can automat-</text>
<text top="327" left="49" width="251" height="8" font="font4" id="p1_t20" reading_order_no="20" segment_no="4" tag_type="text">ically analyze thousands of subjects within hours and provide</text>
<text top="337" left="49" width="251" height="8" font="font4" id="p1_t21" reading_order_no="21" segment_no="4" tag_type="text">individual confidence intervals. The underlying methodology is</text>
<text top="347" left="49" width="251" height="8" font="font4" id="p1_t22" reading_order_no="22" segment_no="4" tag_type="text">based on convolutional neural networks for image-based mean-</text>
<text top="357" left="49" width="251" height="8" font="font4" id="p1_t23" reading_order_no="23" segment_no="4" tag_type="text">variance regression on two-dimensional representations of the</text>
<text top="367" left="49" width="251" height="8" font="font4" id="p1_t24" reading_order_no="24" segment_no="4" tag_type="text">MRI data. This work aims to make the proposed system available</text>
<text top="377" left="49" width="251" height="8" font="font4" id="p1_t25" reading_order_no="25" segment_no="4" tag_type="text">for free to researchers, who can use it to obtain fast and fully-</text>
<text top="387" left="49" width="251" height="8" font="font4" id="p1_t26" reading_order_no="26" segment_no="4" tag_type="text">automated estimates of 72 different measurements immediately</text>
<text top="397" left="49" width="180" height="8" font="font4" id="p1_t27" reading_order_no="27" segment_no="4" tag_type="text">upon release of new UK Biobank image data.</text>
<text top="432" left="136" width="77" height="9" font="font5" id="p1_t28" reading_order_no="28" segment_no="6" tag_type="title">I. I NTRODUCTION</text>
<text top="450" left="59" width="241" height="9" font="font5" id="p1_t29" reading_order_no="29" segment_no="7" tag_type="text">UK Biobank (UKB) has shared an extensive record of</text>
<text top="462" left="49" width="251" height="9" font="font5" id="p1_t30" reading_order_no="30" segment_no="7" tag_type="text">health-related data for more than half a million volunteers</text>
<text top="474" left="49" width="251" height="9" font="font5" id="p1_t31" reading_order_no="31" segment_no="7" tag_type="text">with over 2,000 research projects. Starting in 2014, medical</text>
<text top="486" left="49" width="251" height="9" font="font5" id="p1_t32" reading_order_no="32" segment_no="7" tag_type="text">imaging was initiated for 100,000 participants with several</text>
<text top="498" left="49" width="251" height="9" font="font5" id="p1_t33" reading_order_no="33" segment_no="7" tag_type="text">modalities such as DXA, ultrasound, and MRI [1]. Beyond</text>
<text top="510" left="49" width="251" height="9" font="font5" id="p1_t34" reading_order_no="34" segment_no="7" tag_type="text">collecting data on genetics, lifestyle, and biochemistry of</text>
<text top="522" left="49" width="251" height="9" font="font5" id="p1_t35" reading_order_no="35" segment_no="7" tag_type="text">blood and urine, ongoing research is accordingly engaged in<a href="deeplearning_paper12.html#3">[1]. </a>Beyond</text>
<text top="534" left="49" width="243" height="9" font="font5" id="p1_t36" reading_order_no="36" segment_no="7" tag_type="text">large-scale analysis of the extensive acquired imaging data.</text>
<text top="547" left="59" width="241" height="9" font="font5" id="p1_t37" reading_order_no="37" segment_no="10" tag_type="text">Information on body composition [2] and liver fat con-</text>
<text top="559" left="49" width="251" height="9" font="font5" id="p1_t38" reading_order_no="38" segment_no="10" tag_type="text">tent [3] can be extracted from these images, with important</text>
<text top="571" left="49" width="251" height="9" font="font5" id="p1_t39" reading_order_no="39" segment_no="10" tag_type="text">implications for metabolic and cardiovascular disease [4].<a href="deeplearning_paper12.html#3">[2] </a>and liver fat con-</text>
<text top="583" left="49" width="251" height="9" font="font5" id="p1_t40" reading_order_no="40" segment_no="10" tag_type="text">Although the required image analysis can involve human labor,<a href="deeplearning_paper12.html#3">[3] </a>can be extracted from these images, with important</text>
<text top="594" left="49" width="251" height="9" font="font5" id="p1_t41" reading_order_no="41" segment_no="10" tag_type="text">fully-automated approaches more recently introduced neural<a href="deeplearning_paper12.html#3">[4].</a></text>
<text top="606" left="49" width="251" height="9" font="font5" id="p1_t42" reading_order_no="42" segment_no="10" tag_type="text">networks for segmentation of the liver [5], pancreas [6], [7],</text>
<text top="618" left="49" width="251" height="9" font="font5" id="p1_t43" reading_order_no="43" segment_no="10" tag_type="text">kidneys [8], and various other muscles, organs, and tissues</text>
<text top="630" left="49" width="251" height="9" font="font5" id="p1_t44" reading_order_no="44" segment_no="10" tag_type="text">within this study [9], [10]. Many of these techniques target<a href="deeplearning_paper12.html#3">[5], </a>pancreas <a href="deeplearning_paper12.html#3">[6], [7],</a></text>
<text top="642" left="49" width="251" height="9" font="font5" id="p1_t45" reading_order_no="45" segment_no="10" tag_type="text">the UKB neck-to-knee body MRI, which can represent almost<a href="deeplearning_paper12.html#3">[8], </a>and various other muscles, organs, and tissues</text>
<text top="654" left="49" width="251" height="9" font="font5" id="p1_t46" reading_order_no="46" segment_no="10" tag_type="text">all of human anatomy in one comprehensive image. Lean and<a href="deeplearning_paper12.html#3">[9], [10]. </a>Many of these techniques target</text>
<text top="666" left="49" width="251" height="9" font="font5" id="p1_t47" reading_order_no="47" segment_no="10" tag_type="text">adipose tissue can be clearly distinguished in these images,</text>
<text top="678" left="49" width="251" height="9" font="font5" id="p1_t48" reading_order_no="48" segment_no="10" tag_type="text">based on a two-point Dixon technique that acquires separate,</text>
<text top="690" left="49" width="162" height="9" font="font5" id="p1_t49" reading_order_no="49" segment_no="10" tag_type="text">volumetric water and fat signal images.</text>
<text top="714" left="57" width="243" height="7" font="font6" id="p1_t50" reading_order_no="95" segment_no="13" tag_type="footnote">Department of Surgical Sciences, Uppsala University, Sweden (T.L., AM.M.</text>
<text top="723" left="49" width="251" height="7" font="font6" id="p1_t51" reading_order_no="96" segment_no="13" tag_type="footnote">R.S., H.A., J.K.); Department of Information Technology, Uppsala University,</text>
<text top="732" left="49" width="208" height="7" font="font6" id="p1_t52" reading_order_no="97" segment_no="13" tag_type="footnote">Sweden (R.S.); and Antaros Medical AB, Sweden (H.A., J.K.).</text>
<text top="740" left="57" width="234" height="8" font="font7" id="p1_t53" reading_order_no="98" segment_no="15" tag_type="footnote">Address correspondence to T.L. (e-mail: taro.langner@surgsci.uu.se ).</text>
<text top="177" left="322" width="241" height="9" font="font5" id="p1_t54" reading_order_no="50" segment_no="3" tag_type="text">Despite these developments, many relevant measurements</text>
<text top="189" left="312" width="251" height="9" font="font5" id="p1_t55" reading_order_no="51" segment_no="3" tag_type="text">only cover a small fraction of the 40,000 images that have been</text>
<text top="201" left="312" width="251" height="9" font="font5" id="p1_t56" reading_order_no="52" segment_no="3" tag_type="text">available for more than a year. The evaluation of the image</text>
<text top="213" left="312" width="251" height="9" font="font5" id="p1_t57" reading_order_no="53" segment_no="3" tag_type="text">data, quality control, and sharing of measurements is accord-</text>
<text top="225" left="312" width="251" height="9" font="font5" id="p1_t58" reading_order_no="54" segment_no="3" tag_type="text">ingly lagging far behind the image acquisition. Researchers</text>
<text top="237" left="312" width="251" height="9" font="font5" id="p1_t59" reading_order_no="55" segment_no="3" tag_type="text">with access to the data, who are conducting correlation anal-</text>
<text top="249" left="312" width="251" height="9" font="font5" id="p1_t60" reading_order_no="56" segment_no="3" tag_type="text">yses to genetics, lifestyle, and blood biochemistry, but also</text>
<text top="261" left="312" width="251" height="9" font="font5" id="p1_t61" reading_order_no="57" segment_no="3" tag_type="text">longitudinal developments related to aging, are accordingly</text>
<text top="273" left="312" width="251" height="9" font="font5" id="p1_t62" reading_order_no="58" segment_no="3" tag_type="text">confined to comparably small sample sizes. Months or years</text>
<text top="285" left="312" width="251" height="9" font="font5" id="p1_t63" reading_order_no="59" segment_no="3" tag_type="text">can pass until measurements for newly released images be-</text>
<text top="297" left="312" width="251" height="9" font="font5" id="p1_t64" reading_order_no="60" segment_no="3" tag_type="text">come available, and this backlog can only be expected to grow</text>
<text top="309" left="312" width="175" height="9" font="font5" id="p1_t65" reading_order_no="61" segment_no="3" tag_type="text">over time as more images are released [1].</text>
<text top="321" left="322" width="241" height="9" font="font5" id="p1_t66" reading_order_no="62" segment_no="5" tag_type="text">This work presents a freely available software tool that</text>
<text top="333" left="312" width="251" height="9" font="font5" id="p1_t67" reading_order_no="63" segment_no="5" tag_type="text">can infer a wide range of these measurements automatically</text>
<text top="343" left="312" width="252" height="11" font="font5" id="p1_t68" reading_order_no="64" segment_no="5" tag_type="text">within hours. 1 It can process UKB neck-to-knee body MRI, or</text>
<text top="357" left="312" width="251" height="9" font="font5" id="p1_t69" reading_order_no="65" segment_no="5" tag_type="text">image data from other studies that reproduce the protocol on</text>
<text top="368" left="312" width="251" height="9" font="font5" id="p1_t70" reading_order_no="66" segment_no="5" tag_type="text">similar demographics, and predict 72 measurements together<a href="deeplearning_paper12.html#3">[1].</a></text>
<text top="380" left="312" width="251" height="9" font="font5" id="p1_t71" reading_order_no="67" segment_no="5" tag_type="text">with individual confidence intervals. In this work, the predic-</text>
<text top="392" left="312" width="251" height="9" font="font5" id="p1_t72" reading_order_no="68" segment_no="5" tag_type="text">tion model was created and retrospectively validated against</text>
<text top="404" left="312" width="251" height="9" font="font5" id="p1_t73" reading_order_no="69" segment_no="5" tag_type="text">existing data. The value of this system consists in making au-<a href="deeplearning_paper12.html#1">hours.</a></text>
<text top="416" left="312" width="251" height="9" font="font5" id="p1_t74" reading_order_no="70" segment_no="5" tag_type="text">tomated measurements conveniently available to researchers,<a href="deeplearning_paper12.html#1">1</a></text>
<text top="428" left="312" width="251" height="9" font="font5" id="p1_t75" reading_order_no="71" segment_no="5" tag_type="text">months or years ahead of time, almost immediately whenever</text>
<text top="440" left="312" width="127" height="9" font="font5" id="p1_t76" reading_order_no="72" segment_no="5" tag_type="text">new UKB images are released.</text>
<text top="465" left="408" width="59" height="9" font="font5" id="p1_t77" reading_order_no="73" segment_no="8" tag_type="title">II. M ETHODS</text>
<text top="480" left="322" width="241" height="9" font="font5" id="p1_t78" reading_order_no="74" segment_no="9" tag_type="text">Based on convolutional neural networks, M edical I nference</text>
<text top="492" left="312" width="251" height="9" font="font10" id="p1_t79" reading_order_no="75" segment_no="9" tag_type="text">on M agnetic resonance images with I mage-based R egression</text>
<text top="504" left="312" width="251" height="9" font="font5" id="p1_t80" reading_order_no="76" segment_no="9" tag_type="text">(MIMIR) performs an image-based, deep regression [11]. A</text>
<text top="516" left="312" width="251" height="9" font="font5" id="p1_t81" reading_order_no="77" segment_no="9" tag_type="text">similar methodology was independently proposed for UKB</text>
<text top="528" left="312" width="251" height="9" font="font5" id="p1_t82" reading_order_no="78" segment_no="9" tag_type="text">brain MRI to estimate human age, which subsequently enabled</text>
<text top="540" left="312" width="164" height="9" font="font5" id="p1_t83" reading_order_no="79" segment_no="9" tag_type="text">correlation studies to genetics data [12].</text>
<text top="552" left="322" width="241" height="9" font="font5" id="p1_t84" reading_order_no="80" segment_no="11" tag_type="text">The neural networks process UKB neck-to-knee body MRI,</text>
<text top="564" left="312" width="251" height="9" font="font5" id="p1_t85" reading_order_no="81" segment_no="11" tag_type="text">compressed into a two-dimensional format as seen in Fig. 1,</text>
<text top="576" left="312" width="251" height="9" font="font5" id="p1_t86" reading_order_no="82" segment_no="11" tag_type="text">and predicts the mean and variance of a Gaussian probability</text>
<text top="588" left="312" width="251" height="9" font="font5" id="p1_t87" reading_order_no="83" segment_no="11" tag_type="text">distribution over each given target measurement [13]. As a re-</text>
<text top="600" left="312" width="251" height="9" font="font5" id="p1_t88" reading_order_no="84" segment_no="11" tag_type="text">sult, it can provide both a point estimate µ for the measurement</text>
<text top="610" left="312" width="251" height="11" font="font5" id="p1_t89" reading_order_no="85" segment_no="11" tag_type="text">itself and a heteroscedastic variance σ 2 , which can expresses</text>
<text top="624" left="312" width="251" height="9" font="font5" id="p1_t90" reading_order_no="86" segment_no="11" tag_type="text">aleatoric uncertainty and describe confidence- or prediction</text>
<text top="636" left="312" width="251" height="9" font="font5" id="p1_t91" reading_order_no="87" segment_no="11" tag_type="text">intervals [14]. This methodology was previously proposed</text>
<text top="647" left="312" width="251" height="9" font="font5" id="p1_t92" reading_order_no="88" segment_no="11" tag_type="text">for six measurements of body composition on the same data</text>
<text top="659" left="312" width="251" height="9" font="font5" id="p1_t93" reading_order_no="89" segment_no="11" tag_type="text">[15]. Here, neural network instances were not formed into</text>
<text top="671" left="312" width="251" height="9" font="font5" id="p1_t94" reading_order_no="90" segment_no="11" tag_type="text">ensembles, however, in favor of speed and convenience. The</text>
<text top="683" left="312" width="251" height="9" font="font5" id="p1_t95" reading_order_no="91" segment_no="11" tag_type="text">targets were furthermore expanded to 72 different measure-</text>
<text top="695" left="312" width="251" height="9" font="font5" id="p1_t96" reading_order_no="92" segment_no="11" tag_type="text">ments, ranging from age, height, weight, and sex over body</text>
<text top="707" left="312" width="251" height="9" font="font5" id="p1_t97" reading_order_no="93" segment_no="11" tag_type="text">composition and organ volumes to experimental properties like</text>
<text top="719" left="312" width="230" height="9" font="font5" id="p1_t98" reading_order_no="94" segment_no="11" tag_type="text">grip strength, pulse rate, and type 2 diabetic status [16].<a href="deeplearning_paper12.html#3">[11]. </a>A</text>
<text top="739" left="320" width="115" height="8" font="font6" id="p1_t99" reading_order_no="99" segment_no="14" tag_type="footnote">1 github.com/tarolangner/ukb mimir</text>
<text top="556" left="32" width="0" height="18" font="font14" id="p1_t100" reading_order_no="0" segment_no="12" tag_type="title">arXiv:2106.11731v1  [eess.IV]  22 Jun 2021</text>
</page>
<page number="2" position="absolute" top="0" left="0" height="792" width="612">
	<fontspec id="font15" size="10" family="CMR10" color="#000000"/>
	<fontspec id="font16" size="10" family="CMSY10" color="#000000"/>
<text top="26" left="560" width="3" height="6" font="font0" id="p2_t1" reading_order_no="0" segment_no="0" tag_type="text">2</text>
<text top="274" left="49" width="514" height="7" font="font6" id="p2_t2" reading_order_no="1" segment_no="1" tag_type="text">Fig. 1. MIMIR is an experimental inference engine for prediction of measurements and metadata from UKB neck-to-knee body MRI with image-based deep</text>
<text top="283" left="49" width="514" height="7" font="font6" id="p2_t3" reading_order_no="2" segment_no="1" tag_type="text">regression. Here, image data for one subject (left) was compressed and processed as part of the validation set. The listed measurements were inferred, together</text>
<text top="292" left="49" width="436" height="7" font="font6" id="p2_t4" reading_order_no="3" segment_no="1" tag_type="text">with 95% confidence intervals based on the mean and variance predicted by a ResNet50 convolutional neural network (bottom part).</text>
<text top="323" left="59" width="241" height="9" font="font5" id="p2_t5" reading_order_no="4" segment_no="2" tag_type="text">Neck-to-knee body MRI was shared by UKB for about</text>
<text top="335" left="49" width="251" height="9" font="font5" id="p2_t6" reading_order_no="5" segment_no="2" tag_type="text">40,000 men and women aged 44-82 (mean 63) years, BMI</text>
<text top="345" left="49" width="251" height="11" font="font5" id="p2_t7" reading_order_no="6" segment_no="2" tag_type="text">14-62 (mean 27) kg/m 2 and 95% self-reported white British</text>
<text top="359" left="49" width="251" height="9" font="font5" id="p2_t8" reading_order_no="7" segment_no="2" tag_type="text">ethnicity (see also [1], [2]). Following visual inspection for</text>
<text top="371" left="49" width="251" height="9" font="font5" id="p2_t9" reading_order_no="8" segment_no="2" tag_type="text">exclusion of artifacts, severe pathologies, and other anomalies,</text>
<text top="383" left="49" width="209" height="9" font="font5" id="p2_t10" reading_order_no="9" segment_no="2" tag_type="text">38,916 subjects remained for the experiments [15].<a href="deeplearning_paper12.html#3">[1], [2]). </a>Following visual inspection for</text>
<text top="398" left="59" width="241" height="9" font="font5" id="p2_t11" reading_order_no="10" segment_no="4" tag_type="text">From the UKB metadata, 72 fields were selected as regres-</text>
<text top="410" left="49" width="251" height="9" font="font5" id="p2_t12" reading_order_no="11" segment_no="4" tag_type="text">sion targets. They were grouped into four modules, for each<a href="deeplearning_paper12.html#3">[15].</a></text>
<text top="422" left="49" width="251" height="9" font="font5" id="p2_t13" reading_order_no="12" segment_no="4" tag_type="text">of which one network instance with one or more outputs was</text>
<text top="434" left="49" width="251" height="9" font="font5" id="p2_t14" reading_order_no="13" segment_no="4" tag_type="text">trained: Body composition, abdominal organs, anthropomet-</text>
<text top="446" left="49" width="251" height="9" font="font5" id="p2_t15" reading_order_no="14" segment_no="4" tag_type="text">ric/experimental estimates, and age. The available reference</text>
<text top="458" left="49" width="251" height="9" font="font5" id="p2_t16" reading_order_no="15" segment_no="4" tag_type="text">values for these regression targets originate from previously</text>
<text top="470" left="49" width="251" height="9" font="font5" id="p2_t17" reading_order_no="16" segment_no="4" tag_type="text">shared atlas-based segmentation results [2], manual analyses</text>
<text top="482" left="49" width="251" height="9" font="font5" id="p2_t18" reading_order_no="17" segment_no="4" tag_type="text">[3], DXA imaging [1], and prior neural network segmentations</text>
<text top="493" left="49" width="251" height="10" font="font5" id="p2_t19" reading_order_no="18" segment_no="4" tag_type="text">of the liver and kidneys [8]. Across all subjects, 73% of<a href="deeplearning_paper12.html#3">[2], </a>manual analyses</text>
<text top="506" left="49" width="251" height="9" font="font5" id="p2_t20" reading_order_no="19" segment_no="4" tag_type="text">these values were not available through UKB. Estimating these<a href="deeplearning_paper12.html#3">[3], </a>DXA imaging <a href="deeplearning_paper12.html#3">[1], </a>and prior neural network segmentations</text>
<text top="518" left="49" width="251" height="9" font="font5" id="p2_t21" reading_order_no="20" segment_no="4" tag_type="text">missing measurements and providing them automatically for<a href="deeplearning_paper12.html#3">[8]. </a>Across all subjects,</text>
<text top="529" left="49" width="243" height="9" font="font5" id="p2_t22" reading_order_no="21" segment_no="4" tag_type="text">future UKB images was the main motivation for this work.</text>
<text top="545" left="59" width="241" height="9" font="font5" id="p2_t23" reading_order_no="22" segment_no="7" tag_type="text">A stratified, 10-fold cross-validation split was generated by</text>
<text top="557" left="49" width="251" height="9" font="font5" id="p2_t24" reading_order_no="23" segment_no="7" tag_type="text">grouping all subjects into ten even subsets, each of which in</text>
<text top="569" left="49" width="251" height="9" font="font5" id="p2_t25" reading_order_no="24" segment_no="7" tag_type="text">turn served for validation of a neural network trained on the</text>
<text top="580" left="49" width="251" height="9" font="font5" id="p2_t26" reading_order_no="25" segment_no="7" tag_type="text">data of all remaining sets. This pretrained ResNet50 [17] with</text>
<text top="592" left="49" width="251" height="9" font="font5" id="p2_t27" reading_order_no="26" segment_no="7" tag_type="text">a specialized mean-variance loss function [14] is visualized</text>
<text top="604" left="49" width="251" height="9" font="font5" id="p2_t28" reading_order_no="27" segment_no="7" tag_type="text">in Fig. 1. All samples with at least one known ground truth</text>
<text top="616" left="49" width="251" height="9" font="font5" id="p2_t29" reading_order_no="28" segment_no="7" tag_type="text">value were used by setting the loss for missing values to zero.</text>
<text top="628" left="49" width="251" height="9" font="font5" id="p2_t30" reading_order_no="29" segment_no="7" tag_type="text">The network was trained in PyTorch with the Adam optimizer,<a href="deeplearning_paper12.html#3">[17] </a>with</text>
<text top="640" left="49" width="251" height="9" font="font5" id="p2_t31" reading_order_no="30" segment_no="7" tag_type="text">batch size 32, and augmentation by random translations. After<a href="deeplearning_paper12.html#3">[14] </a>is visualized</text>
<text top="652" left="49" width="251" height="9" font="font5" id="p2_t32" reading_order_no="31" segment_no="7" tag_type="text">training for 8,000 iterations, the learning rate was reduced<a href="deeplearning_paper12.html#2">1. </a>All samples with at least one known ground truth</text>
<text top="663" left="49" width="209" height="10" font="font5" id="p2_t33" reading_order_no="32" segment_no="7" tag_type="text">from 5 e − 5 to 5 e − 6 for another 2,000 iterations.</text>
<text top="679" left="59" width="241" height="9" font="font5" id="p2_t34" reading_order_no="33" segment_no="9" tag_type="text">The predictions were evaluated with the intraclass cor-</text>
<text top="691" left="49" width="251" height="9" font="font5" id="p2_t35" reading_order_no="34" segment_no="9" tag_type="text">relation coefficient (ICC) using a two-way random, single</text>
<text top="703" left="49" width="251" height="9" font="font5" id="p2_t36" reading_order_no="35" segment_no="9" tag_type="text">measures, absolute agreement definition. For this metric, the</text>
<text top="715" left="49" width="251" height="9" font="font5" id="p2_t37" reading_order_no="36" segment_no="9" tag_type="text">reliability can be considered good for values above 0 . 75</text>
<text top="727" left="49" width="251" height="9" font="font5" id="p2_t38" reading_order_no="37" segment_no="9" tag_type="text">and excellent for those above 0 . 90 , with a maximum of</text>
<text top="737" left="49" width="251" height="11" font="font15" id="p2_t39" reading_order_no="38" segment_no="9" tag_type="text">1 . 0 [18]. Additionally, the coefficient of determination (R 2 ),</text>
<text top="323" left="312" width="251" height="9" font="font5" id="p2_t40" reading_order_no="39" segment_no="3" tag_type="text">mean absolute error (MAE), mean absolute percentage error</text>
<text top="335" left="312" width="251" height="9" font="font5" id="p2_t41" reading_order_no="40" segment_no="3" tag_type="text">(MAPE) and the area under curve of the receiver operating</text>
<text top="347" left="312" width="251" height="9" font="font5" id="p2_t42" reading_order_no="41" segment_no="3" tag_type="text">characteristic curve (AUC-ROC) are provided. The uncertainty</text>
<text top="359" left="312" width="251" height="9" font="font5" id="p2_t43" reading_order_no="42" segment_no="3" tag_type="text">estimates are known to often underestimate the true prediction</text>
<text top="371" left="312" width="251" height="9" font="font5" id="p2_t44" reading_order_no="43" segment_no="3" tag_type="text">errors [19], and were therefore calibrated post-hoc with scaling</text>
<text top="383" left="312" width="190" height="9" font="font5" id="p2_t45" reading_order_no="44" segment_no="3" tag_type="text">factors determined on the validation data [15].</text>
<text top="406" left="370" width="135" height="9" font="font5" id="p2_t46" reading_order_no="45" segment_no="5" tag_type="title">III. R ESULTS AND D ISCUSSION</text>
<text top="421" left="322" width="241" height="9" font="font5" id="p2_t47" reading_order_no="46" segment_no="6" tag_type="text">The cross-validation results are summarized in Fig. 2. The</text>
<text top="433" left="312" width="251" height="9" font="font5" id="p2_t48" reading_order_no="47" segment_no="6" tag_type="text">evaluation yielded mean absolute errors (MAE) of 2.6 years</text>
<text top="445" left="312" width="251" height="9" font="font5" id="p2_t49" reading_order_no="48" segment_no="6" tag_type="text">for estimation of chronological age, 1.8 cm for height, 0.9</text>
<text top="457" left="312" width="251" height="9" font="font5" id="p2_t50" reading_order_no="49" segment_no="6" tag_type="text">kg for bodyweight, and correct identification of sex in all but</text>
<text top="469" left="312" width="251" height="9" font="font5" id="p2_t51" reading_order_no="50" segment_no="6" tag_type="text">14 of 38,874 subjects (of whom five differed in registered vs</text>
<text top="481" left="312" width="251" height="9" font="font5" id="p2_t52" reading_order_no="51" segment_no="6" tag_type="text">genetic sex). Relative errors of 7% for parenchymal kidney</text>
<text top="493" left="312" width="251" height="9" font="font5" id="p2_t53" reading_order_no="52" segment_no="6" tag_type="text">volume, less than 5% for several body composition measure-</text>
<text top="505" left="312" width="251" height="9" font="font5" id="p2_t54" reading_order_no="53" segment_no="6" tag_type="text">ments, and 3% for total liver volume were incurred. Liver fat</text>
<text top="515" left="312" width="251" height="11" font="font5" id="p2_t55" reading_order_no="54" segment_no="6" tag_type="text">content was predicted with R 2 = 0 . 955 and probable type</text>
<text top="529" left="312" width="251" height="9" font="font5" id="p2_t56" reading_order_no="55" segment_no="6" tag_type="text">2 diabetics [16] were identified with an AUC-ROC of 0.866.</text>
<text top="541" left="312" width="251" height="9" font="font5" id="p2_t57" reading_order_no="56" segment_no="6" tag_type="text">The inference engine can process thousands of subjects within</text>
<text top="553" left="312" width="251" height="9" font="font5" id="p2_t58" reading_order_no="57" segment_no="6" tag_type="text">minutes on an Nvidia RTX 2080 Ti with 11GB, and extensive</text>
<text top="563" left="312" width="213" height="10" font="font5" id="p2_t59" reading_order_no="58" segment_no="6" tag_type="text">tables list detailed metrics for all 72 targets online 2 .</text>
<text top="576" left="322" width="241" height="9" font="font5" id="p2_t60" reading_order_no="59" segment_no="8" tag_type="text">Several limitations apply. No independent test set was ex-</text>
<text top="588" left="312" width="251" height="9" font="font5" id="p2_t61" reading_order_no="60" segment_no="8" tag_type="text">amined, and so the trained networks should not be expected to</text>
<text top="600" left="312" width="251" height="9" font="font5" id="p2_t62" reading_order_no="61" segment_no="8" tag_type="text">correctly process arbitrary MRI data. Generalization is likely</text>
<text top="612" left="312" width="251" height="9" font="font5" id="p2_t63" reading_order_no="62" segment_no="8" tag_type="text">restricted to images that resemble the UKB training data in<a href="deeplearning_paper12.html#3">[18]. </a>Additionally, the coefficient of determination (R</text>
<text top="624" left="312" width="251" height="9" font="font5" id="p2_t64" reading_order_no="63" segment_no="8" tag_type="text">protocol, imaging device, and demographics. Out-of-domain</text>
<text top="636" left="312" width="251" height="9" font="font5" id="p2_t65" reading_order_no="64" segment_no="8" tag_type="text">tasks would likely require hundreds of subjects for renewed</text>
<text top="648" left="312" width="251" height="9" font="font5" id="p2_t66" reading_order_no="65" segment_no="8" tag_type="text">training [11]. However, robust performance within UKB can</text>
<text top="660" left="312" width="251" height="9" font="font5" id="p2_t67" reading_order_no="66" segment_no="8" tag_type="text">likely be expected, as prior work saw similar systems match</text>
<text top="672" left="312" width="251" height="9" font="font5" id="p2_t68" reading_order_no="67" segment_no="8" tag_type="text">or exceed the cross-validation performance on withheld UKB</text>
<text top="684" left="312" width="251" height="9" font="font5" id="p2_t69" reading_order_no="68" segment_no="8" tag_type="text">subjects [15]. The predicted uncertainties underestimate the</text>
<text top="696" left="312" width="251" height="9" font="font5" id="p2_t70" reading_order_no="69" segment_no="8" tag_type="text">prediction errors, especially since no ensembling was used.<a href="deeplearning_paper12.html#3">[19], </a>and were therefore calibrated post-hoc with scaling</text>
<text top="708" left="312" width="251" height="9" font="font5" id="p2_t71" reading_order_no="70" segment_no="8" tag_type="text">However, the scaling factors likely resolve this issue, and may<a href="deeplearning_paper12.html#3">[15].</a></text>
<text top="720" left="312" width="233" height="9" font="font5" id="p2_t72" reading_order_no="71" segment_no="8" tag_type="text">indeed yield somewhat conservative confidence intervals.</text>
<text top="739" left="320" width="115" height="8" font="font6" id="p2_t73" reading_order_no="72" segment_no="10" tag_type="footnote">2 github.com/tarolangner/ukb mimir</text>
</page>
<page number="3" position="absolute" top="0" left="0" height="792" width="612">
	<fontspec id="font17" size="9" family="Times" color="#000000"/>
	<fontspec id="font18" size="9" family="Times" color="#000000"/>
	<fontspec id="font19" size="9" family="Times" color="#000000"/>
	<fontspec id="font20" size="9" family="Times" color="#7f7f7f"/>
	<fontspec id="font21" size="11" family="Times" color="#000000"/>
<text top="26" left="560" width="3" height="6" font="font0" id="p3_t1" reading_order_no="0" segment_no="0" tag_type="text">3</text>
<text top="197" left="100" width="11" height="21" font="font17" id="p3_t2" reading_order_no="32" segment_no="1" tag_type="figure">Anthr</text>
<text top="208" left="110" width="11" height="19" font="font17" id="p3_t3" reading_order_no="33" segment_no="1" tag_type="figure">opom</text>
<text top="219" left="121" width="8" height="17" font="font17" id="p3_t4" reading_order_no="34" segment_no="1" tag_type="figure">etry</text>
<text top="197" left="147" width="12" height="21" font="font17" id="p3_t5" reading_order_no="35" segment_no="1" tag_type="figure">Organ</text>
<text top="209" left="159" width="2" height="12" font="font17" id="p3_t6" reading_order_no="36" segment_no="1" tag_type="figure">s</text>
<text top="197" left="195" width="11" height="22" font="font17" id="p3_t7" reading_order_no="37" segment_no="1" tag_type="figure">Atlas</text>
<text top="208" left="206" width="12" height="22" font="font17" id="p3_t8" reading_order_no="38" segment_no="1" tag_type="figure">Bodyc</text>
<text top="220" left="218" width="9" height="18" font="font17" id="p3_t9" reading_order_no="39" segment_no="1" tag_type="figure">omp</text>
<text top="197" left="243" width="14" height="21" font="font17" id="p3_t10" reading_order_no="40" segment_no="1" tag_type="figure">DXA Bo</text>
<text top="212" left="258" width="13" height="21" font="font17" id="p3_t11" reading_order_no="41" segment_no="1" tag_type="figure">dycom</text>
<text top="225" left="271" width="2" height="12" font="font17" id="p3_t12" reading_order_no="42" segment_no="1" tag_type="figure">p</text>
<text top="193" left="63" width="12" height="12" font="font18" id="p3_t13" reading_order_no="13" segment_no="1" tag_type="figure">0.88</text>
<text top="174" left="63" width="12" height="12" font="font18" id="p3_t14" reading_order_no="12" segment_no="1" tag_type="figure">0.90</text>
<text top="156" left="63" width="12" height="12" font="font18" id="p3_t15" reading_order_no="11" segment_no="1" tag_type="figure">0.92</text>
<text top="137" left="63" width="12" height="12" font="font18" id="p3_t16" reading_order_no="10" segment_no="1" tag_type="figure">0.94</text>
<text top="119" left="63" width="12" height="12" font="font18" id="p3_t17" reading_order_no="9" segment_no="1" tag_type="figure">0.96</text>
<text top="100" left="63" width="12" height="12" font="font18" id="p3_t18" reading_order_no="8" segment_no="1" tag_type="figure">0.98</text>
<text top="82" left="63" width="12" height="12" font="font18" id="p3_t19" reading_order_no="7" segment_no="1" tag_type="figure">1.00</text>
<text top="136" left="59" width="0" height="39" font="font19" id="p3_t20" reading_order_no="2" segment_no="1" tag_type="figure">Va lid ati on ag</text>
<text top="127" left="59" width="0" height="12" font="font19" id="p3_t21" reading_order_no="3" segment_no="1" tag_type="figure">ree</text>
<text top="118" left="59" width="0" height="12" font="font19" id="p3_t22" reading_order_no="4" segment_no="1" tag_type="figure">me</text>
<text top="110" left="59" width="0" height="12" font="font19" id="p3_t23" reading_order_no="5" segment_no="1" tag_type="figure">nt</text>
<text top="95" left="59" width="0" height="19" font="font19" id="p3_t24" reading_order_no="6" segment_no="1" tag_type="figure">(IC C)</text>
<text top="164" left="248" width="7" height="12" font="font20" id="p3_t25" reading_order_no="30" segment_no="1" tag_type="figure">gyn</text>
<text top="135" left="255" width="28" height="33" font="font20" id="p3_t26" reading_order_no="31" segment_no="1" tag_type="figure">oid bon e m ass</text>
<text top="106" left="200" width="14" height="18" font="font20" id="p3_t27" reading_order_no="19" segment_no="1" tag_type="figure">mu scle</text>
<text top="98" left="214" width="6" height="12" font="font20" id="p3_t28" reading_order_no="20" segment_no="1" tag_type="figure">fat</text>
<text top="174" left="104" width="7" height="12" font="font20" id="p3_t29" reading_order_no="25" segment_no="1" tag_type="figure">age</text>
<text top="78" left="116" width="7" height="12" font="font20" id="p3_t30" reading_order_no="14" segment_no="1" tag_type="figure">sex</text>
<text top="110" left="104" width="8" height="12" font="font20" id="p3_t31" reading_order_no="21" segment_no="1" tag_type="figure">heig</text>
<text top="102" left="113" width="4" height="12" font="font20" id="p3_t32" reading_order_no="22" segment_no="1" tag_type="figure">ht</text>
<text top="74" left="104" width="13" height="18" font="font20" id="p3_t33" reading_order_no="15" segment_no="1" tag_type="figure">wei ght</text>
<text top="129" left="116" width="11" height="19" font="font20" id="p3_t34" reading_order_no="23" segment_no="1" tag_type="figure">wai st</text>
<text top="155" left="116" width="6" height="12" font="font20" id="p3_t35" reading_order_no="24" segment_no="1" tag_type="figure">hip</text>
<text top="84" left="152" width="14" height="18" font="font20" id="p3_t36" reading_order_no="17" segment_no="1" tag_type="figure">live r vo</text>
<text top="69" left="166" width="10" height="19" font="font20" id="p3_t37" reading_order_no="18" segment_no="1" tag_type="figure">lum e</text>
<text top="159" left="152" width="8" height="12" font="font20" id="p3_t38" reading_order_no="26" segment_no="1" tag_type="figure">kidn</text>
<text top="151" left="160" width="8" height="12" font="font20" id="p3_t39" reading_order_no="27" segment_no="1" tag_type="figure">ey v</text>
<text top="143" left="169" width="10" height="12" font="font20" id="p3_t40" reading_order_no="28" segment_no="1" tag_type="figure">olum</text>
<text top="133" left="178" width="2" height="12" font="font20" id="p3_t41" reading_order_no="29" segment_no="1" tag_type="figure">e</text>
<text top="85" left="152" width="16" height="26" font="font20" id="p3_t42" reading_order_no="16" segment_no="1" tag_type="figure">live r fa t</text>
<text top="56" left="148" width="77" height="14" font="font21" id="p3_t43" reading_order_no="1" segment_no="1" tag_type="figure">Cross-validation results</text>
<text top="257" left="49" width="22" height="7" font="font6" id="p3_t44" reading_order_no="43" segment_no="8" tag_type="text">Fig. 2.</text>
<text top="257" left="79" width="221" height="7" font="font6" id="p3_t45" reading_order_no="44" segment_no="8" tag_type="text">Agreement between predictions and reference in cross-validation,</text>
<text top="266" left="49" width="251" height="7" font="font6" id="p3_t46" reading_order_no="45" segment_no="8" tag_type="text">expressed as intraclass correlation coefficient (ICC). Note that not all targets</text>
<text top="275" left="49" width="113" height="7" font="font6" id="p3_t47" reading_order_no="46" segment_no="8" tag_type="text">fall within the bounds of this plot.</text>
<text top="305" left="59" width="241" height="9" font="font5" id="p3_t48" reading_order_no="47" segment_no="11" tag_type="text">Not all metadata can be inferred with the proposed ap-</text>
<text top="317" left="49" width="251" height="9" font="font5" id="p3_t49" reading_order_no="48" segment_no="11" tag_type="text">proach, as the required information may be lost by prepro-</text>
<text top="329" left="49" width="251" height="9" font="font5" id="p3_t50" reading_order_no="49" segment_no="11" tag_type="text">cessing or absent from the MRI data. Other measurements are</text>
<text top="341" left="49" width="251" height="9" font="font5" id="p3_t51" reading_order_no="50" segment_no="11" tag_type="text">clinically trivial, such as age, sex, and weight. For some, alter-</text>
<text top="353" left="49" width="251" height="9" font="font5" id="p3_t52" reading_order_no="51" segment_no="11" tag_type="text">native techniques may be superior, such as liver fat measure-</text>
<text top="365" left="49" width="251" height="9" font="font5" id="p3_t53" reading_order_no="52" segment_no="11" tag_type="text">ments from the dedicated UKB liver MRI with more accurate</text>
<text top="377" left="49" width="251" height="9" font="font5" id="p3_t54" reading_order_no="53" segment_no="11" tag_type="text">fat fraction values. Here, the projected, two-dimensional input</text>
<text top="389" left="49" width="251" height="9" font="font5" id="p3_t55" reading_order_no="54" segment_no="11" tag_type="text">format also limits the accuracy of organ measurements, with</text>
<text top="401" left="49" width="251" height="9" font="font5" id="p3_t56" reading_order_no="55" segment_no="11" tag_type="text">the proposed kidney volume measurements almost doubling</text>
<text top="413" left="49" width="251" height="9" font="font5" id="p3_t57" reading_order_no="56" segment_no="11" tag_type="text">the error previously achieved by segmentation of axial slices</text>
<text top="425" left="49" width="251" height="9" font="font5" id="p3_t58" reading_order_no="57" segment_no="11" tag_type="text">[8]. Finally, MRI-based diagnosis of type 2 diabetic status</text>
<text top="437" left="49" width="251" height="9" font="font5" id="p3_t59" reading_order_no="58" segment_no="11" tag_type="text">may not be clinically viable, with a specificity of 0.965 and</text>
<text top="449" left="49" width="251" height="9" font="font5" id="p3_t60" reading_order_no="59" segment_no="11" tag_type="text">sensitivity of only 0.250 here. Prior work classified it using</text>
<text top="461" left="49" width="236" height="9" font="font5" id="p3_t61" reading_order_no="60" segment_no="11" tag_type="text">convolutional neural networks with similar accuracy [20].</text>
<text top="472" left="59" width="241" height="9" font="font5" id="p3_t62" reading_order_no="61" segment_no="17" tag_type="text">Future work may explore fully volumetric processing and</text>
<text top="484" left="49" width="251" height="9" font="font5" id="p3_t63" reading_order_no="62" segment_no="17" tag_type="text">other imaging protocols, which could leverage more, po-</text>
<text top="496" left="49" width="251" height="9" font="font5" id="p3_t64" reading_order_no="63" segment_no="17" tag_type="text">tentially critical information. However, several metrics can</text>
<text top="508" left="49" width="251" height="9" font="font5" id="p3_t65" reading_order_no="64" segment_no="17" tag_type="text">already be accurately inferred in the proposed way, such as</text>
<text top="520" left="49" width="251" height="9" font="font5" id="p3_t66" reading_order_no="65" segment_no="17" tag_type="text">liver volume and body composition metrics with estimated</text>
<text top="532" left="49" width="251" height="9" font="font5" id="p3_t67" reading_order_no="66" segment_no="17" tag_type="text">errors below 5%. With additional metadata becoming avail-</text>
<text top="544" left="49" width="251" height="9" font="font5" id="p3_t68" reading_order_no="67" segment_no="17" tag_type="text">able, such as hormone levels, disease outcomes, and mortality</text>
<text top="556" left="49" width="251" height="9" font="font5" id="p3_t69" reading_order_no="68" segment_no="17" tag_type="text">statistics, more modules could be added in the future. The</text>
<text top="568" left="49" width="251" height="9" font="font5" id="p3_t70" reading_order_no="69" segment_no="17" tag_type="text">networks already trained in this work may provide benefit for</text>
<text top="580" left="49" width="251" height="9" font="font5" id="p3_t71" reading_order_no="70" segment_no="17" tag_type="text">independent studies that replicate the used imaging protocol,</text>
<text top="592" left="49" width="179" height="9" font="font5" id="p3_t72" reading_order_no="71" segment_no="17" tag_type="text">but also hold potential for transfer learning.</text>
<text top="604" left="59" width="241" height="9" font="font5" id="p3_t73" reading_order_no="72" segment_no="22" tag_type="text">This work provides an implementation that can conveniently<a href="deeplearning_paper12.html#3">[8]. </a>Finally, MRI-based diagnosis of type 2 diabetic status</text>
<text top="616" left="49" width="251" height="9" font="font5" id="p3_t74" reading_order_no="73" segment_no="22" tag_type="text">provide image-derived phenotypes at large scale for prototyp-</text>
<text top="628" left="49" width="251" height="9" font="font5" id="p3_t75" reading_order_no="74" segment_no="22" tag_type="text">ing in correlation studies, months or years before the reference</text>
<text top="640" left="49" width="251" height="9" font="font5" id="p3_t76" reading_order_no="75" segment_no="22" tag_type="text">measurements will be available. Over the coming years, it will<a href="deeplearning_paper12.html#3">[20].</a></text>
<text top="652" left="49" width="251" height="9" font="font5" id="p3_t77" reading_order_no="76" segment_no="22" tag_type="text">stand ready for fully-automated analysis of more than 100,000</text>
<text top="664" left="49" width="209" height="9" font="font5" id="p3_t78" reading_order_no="77" segment_no="22" tag_type="text">upcoming UKB images that are yet to be released.</text>
<text top="688" left="119" width="110" height="9" font="font5" id="p3_t79" reading_order_no="78" segment_no="25" tag_type="title">IV. A CKNOWLEDGMENTS</text>
<text top="703" left="59" width="241" height="9" font="font5" id="p3_t80" reading_order_no="79" segment_no="27" tag_type="text">This research was enabled by grants from the Swedish</text>
<text top="715" left="49" width="251" height="9" font="font5" id="p3_t81" reading_order_no="80" segment_no="27" tag_type="text">Heart-Lung Foundation and the Swedish Research Council</text>
<text top="727" left="49" width="251" height="9" font="font5" id="p3_t82" reading_order_no="81" segment_no="27" tag_type="text">(2016-01040, 2019-04756, 2020-0500, 2021-70492) and the</text>
<text top="739" left="49" width="213" height="9" font="font5" id="p3_t83" reading_order_no="82" segment_no="27" tag_type="text">UK Biobank Resource under application no. 14237.</text>
<text top="58" left="410" width="56" height="9" font="font5" id="p3_t84" reading_order_no="83" segment_no="2" tag_type="title">R EFERENCES</text>
<text top="74" left="316" width="247" height="7" font="font6" id="p3_t85" reading_order_no="84" segment_no="3" tag_type="text">[1] T. J. Littlejohns, J. Holliday, L. M. Gibson, S. Garratt, N. Oesingmann,</text>
<text top="83" left="330" width="233" height="7" font="font6" id="p3_t86" reading_order_no="85" segment_no="3" tag_type="text">F. Alfaro-Almagro, J. D. Bell, C. Boultwood, R. Collins, M. C. Conroy,</text>
<text top="92" left="330" width="233" height="7" font="font8" id="p3_t87" reading_order_no="86" segment_no="3" tag_type="text">et al. , “The uk biobank imaging enhancement of 100,000 participants:</text>
<text top="101" left="330" width="233" height="7" font="font6" id="p3_t88" reading_order_no="87" segment_no="3" tag_type="text">rationale, data collection, management and future directions,” Nature</text>
<text top="110" left="330" width="159" height="7" font="font8" id="p3_t89" reading_order_no="88" segment_no="3" tag_type="text">Communications , vol. 11, no. 1, pp. 1–12, 2020.</text>
<text top="119" left="316" width="247" height="7" font="font6" id="p3_t90" reading_order_no="89" segment_no="4" tag_type="text">[2] J. West, O. Dahlqvist Leinhard, T. Romu, R. Collins, S. Garratt,</text>
<text top="128" left="330" width="233" height="7" font="font6" id="p3_t91" reading_order_no="90" segment_no="4" tag_type="text">J. D. Bell, M. Borga, and L. Thomas, “Feasibility of MR-Based Body</text>
<text top="137" left="330" width="233" height="7" font="font6" id="p3_t92" reading_order_no="91" segment_no="4" tag_type="text">Composition Analysis in Large Scale Population Studies,” PLoS ONE ,</text>
<text top="146" left="330" width="64" height="7" font="font6" id="p3_t93" reading_order_no="92" segment_no="4" tag_type="text">vol. 11, Sept. 2016.</text>
<text top="155" left="316" width="247" height="7" font="font6" id="p3_t94" reading_order_no="93" segment_no="5" tag_type="text">[3] H. R. Wilman, M. Kelly, S. Garratt, P. M. Matthews, M. Milanesi,</text>
<text top="163" left="330" width="233" height="8" font="font6" id="p3_t95" reading_order_no="94" segment_no="5" tag_type="text">A. Herlihy, M. Gyngell, S. Neubauer, J. D. Bell, R. Banerjee, et al. ,</text>
<text top="172" left="330" width="233" height="8" font="font6" id="p3_t96" reading_order_no="95" segment_no="5" tag_type="text">“Characterisation of liver fat in the uk biobank cohort,” PloS one , vol. 12,</text>
<text top="181" left="330" width="84" height="7" font="font6" id="p3_t97" reading_order_no="96" segment_no="5" tag_type="text">no. 2, p. e0172921, 2017.</text>
<text top="190" left="316" width="247" height="7" font="font6" id="p3_t98" reading_order_no="97" segment_no="6" tag_type="text">[4] J. Linge, M. Borga, J. West, T. Tuthill, M. R. Miller, A. Dumitriu,</text>
<text top="199" left="330" width="233" height="7" font="font6" id="p3_t99" reading_order_no="98" segment_no="6" tag_type="text">E. L. Thomas, T. Romu, P. Tun´on, J. D. Bell, et al. , “Body composition</text>
<text top="208" left="330" width="233" height="7" font="font6" id="p3_t100" reading_order_no="99" segment_no="6" tag_type="text">profiling in the uk biobank imaging study,” Obesity , vol. 26, no. 11,</text>
<text top="217" left="330" width="71" height="7" font="font6" id="p3_t101" reading_order_no="100" segment_no="6" tag_type="text">pp. 1785–1795, 2018.</text>
<text top="226" left="316" width="247" height="7" font="font6" id="p3_t102" reading_order_no="101" segment_no="7" tag_type="text">[5] B. Irving, C. Hutton, A. Dennis, S. Vikal, M. Mavar, M. Kelly, and</text>
<text top="235" left="330" width="233" height="7" font="font6" id="p3_t103" reading_order_no="102" segment_no="7" tag_type="text">J. M. Brady, “Deep quantitative liver segmentation and vessel exclusion</text>
<text top="244" left="330" width="233" height="7" font="font6" id="p3_t104" reading_order_no="103" segment_no="7" tag_type="text">to assist in liver assessment,” in Annual Conference on Medical Image</text>
<text top="253" left="330" width="193" height="7" font="font8" id="p3_t105" reading_order_no="104" segment_no="7" tag_type="text">Understanding and Analysis , pp. 663–673, Springer, 2017.</text>
<text top="262" left="316" width="247" height="7" font="font6" id="p3_t106" reading_order_no="105" segment_no="9" tag_type="text">[6] N. Basty, Y. Liu, M. Cule, E. L. Thomas, J. D. Bell, and B. Whitcher,</text>
<text top="271" left="330" width="233" height="7" font="font6" id="p3_t107" reading_order_no="106" segment_no="9" tag_type="text">“Automated measurement of pancreatic fat and iron concentration using</text>
<text top="280" left="330" width="233" height="7" font="font6" id="p3_t108" reading_order_no="107" segment_no="9" tag_type="text">multi-echo and t1-weighted mri data,” in 2020 IEEE 17th International</text>
<text top="289" left="330" width="228" height="7" font="font8" id="p3_t109" reading_order_no="108" segment_no="9" tag_type="text">Symposium on Biomedical Imaging (ISBI) , pp. 345–348, IEEE, 2020.</text>
<text top="298" left="316" width="247" height="7" font="font6" id="p3_t110" reading_order_no="109" segment_no="10" tag_type="text">[7] A. T. Bagur, G. Ridgway, J. McGonigle, M. Brady, and D. Bulte,</text>
<text top="307" left="330" width="233" height="7" font="font6" id="p3_t111" reading_order_no="110" segment_no="10" tag_type="text">“Pancreas segmentation-derived biomarkers: Volume and shape metrics</text>
<text top="316" left="330" width="233" height="7" font="font6" id="p3_t112" reading_order_no="111" segment_no="10" tag_type="text">in the uk biobank imaging study,” in Annual Conference on Medical</text>
<text top="325" left="330" width="215" height="7" font="font8" id="p3_t113" reading_order_no="112" segment_no="10" tag_type="text">Image Understanding and Analysis , pp. 131–142, Springer, 2020.</text>
<text top="334" left="316" width="247" height="7" font="font6" id="p3_t114" reading_order_no="113" segment_no="12" tag_type="text">[8] T. Langner, A. ¨ Ostling, L. Maldonis, A. Karlsson, D. Olmo, D. Lindgren,</text>
<text top="343" left="330" width="233" height="7" font="font6" id="p3_t115" reading_order_no="114" segment_no="12" tag_type="text">A. Wallin, L. Lundin, R. Strand, H. Ahlstr¨om, et al. , “Kidney segmen-</text>
<text top="352" left="330" width="233" height="7" font="font6" id="p3_t116" reading_order_no="115" segment_no="12" tag_type="text">tation in neck-to-knee body mri of 40,000 uk biobank participants,”</text>
<text top="361" left="330" width="160" height="7" font="font8" id="p3_t117" reading_order_no="116" segment_no="12" tag_type="text">Scientific reports , vol. 10, no. 1, pp. 1–10, 2020.</text>
<text top="370" left="316" width="247" height="7" font="font6" id="p3_t118" reading_order_no="117" segment_no="13" tag_type="text">[9] Y. Liu, N. Basty, B. Whitcher, J. Bell, E. Sorokin, N. van Bruggen, E. L.</text>
<text top="379" left="330" width="233" height="7" font="font6" id="p3_t119" reading_order_no="118" segment_no="13" tag_type="text">Thomas, and M. Cule, “Genetic architecture of 11 organ traits derived</text>
<text top="388" left="330" width="228" height="7" font="font6" id="p3_t120" reading_order_no="119" segment_no="13" tag_type="text">from abdominal mri using deep learning,” ELife , p. 10:e65554, 2021.</text>
<text top="397" left="312" width="251" height="7" font="font6" id="p3_t121" reading_order_no="120" segment_no="14" tag_type="text">[10] T. Kart, M. Fischer, T. K¨ustner, T. Hepp, F. Bamberg, S. Winzeck,</text>
<text top="406" left="330" width="233" height="7" font="font6" id="p3_t122" reading_order_no="121" segment_no="14" tag_type="text">B. Glocker, D. Rueckert, and S. Gatidis, “Deep learning–based auto-</text>
<text top="415" left="330" width="233" height="7" font="font6" id="p3_t123" reading_order_no="122" segment_no="14" tag_type="text">mated abdominal organ segmentation in the uk biobank and german</text>
<text top="424" left="330" width="233" height="7" font="font6" id="p3_t124" reading_order_no="123" segment_no="14" tag_type="text">national cohort magnetic resonance imaging studies,” Investigative Ra-</text>
<text top="432" left="330" width="47" height="8" font="font8" id="p3_t125" reading_order_no="124" segment_no="14" tag_type="text">diology , 2021.</text>
<text top="441" left="312" width="251" height="7" font="font6" id="p3_t126" reading_order_no="125" segment_no="15" tag_type="text">[11] T. Langner, R. Strand, H. Ahlstr¨om, and J. Kullberg, “Deep regression</text>
<text top="450" left="330" width="233" height="7" font="font6" id="p3_t127" reading_order_no="126" segment_no="15" tag_type="text">for uncertainty-aware and interpretable analysis of large-scale body mri,”</text>
<text top="459" left="330" width="18" height="7" font="font6" id="p3_t128" reading_order_no="127" segment_no="15" tag_type="text">2021.</text>
<text top="468" left="312" width="251" height="7" font="font6" id="p3_t129" reading_order_no="128" segment_no="16" tag_type="text">[12] B. A. J´onsson, G. Bjornsdottir, T. Thorgeirsson, L. M. Ellingsen, G. B.</text>
<text top="477" left="330" width="233" height="7" font="font6" id="p3_t130" reading_order_no="129" segment_no="16" tag_type="text">Walters, D. Gudbjartsson, H. Stefansson, K. Stefansson, and M. Ul-</text>
<text top="486" left="330" width="233" height="7" font="font6" id="p3_t131" reading_order_no="130" segment_no="16" tag_type="text">farsson, “Brain age prediction using deep learning uncovers associated</text>
<text top="495" left="330" width="233" height="7" font="font6" id="p3_t132" reading_order_no="131" segment_no="16" tag_type="text">sequence variants,” Nature communications , vol. 10, no. 1, pp. 1–10,</text>
<text top="504" left="330" width="18" height="7" font="font6" id="p3_t133" reading_order_no="132" segment_no="16" tag_type="text">2019.</text>
<text top="513" left="312" width="251" height="7" font="font6" id="p3_t134" reading_order_no="133" segment_no="18" tag_type="text">[13] B. Lakshminarayanan, A. Pritzel, and C. Blundell, “Simple and scalable</text>
<text top="522" left="330" width="233" height="7" font="font6" id="p3_t135" reading_order_no="134" segment_no="18" tag_type="text">predictive uncertainty estimation using deep ensembles,” in Advances in</text>
<text top="531" left="330" width="201" height="7" font="font8" id="p3_t136" reading_order_no="135" segment_no="18" tag_type="text">neural information processing systems , pp. 6402–6413, 2017.</text>
<text top="540" left="312" width="251" height="7" font="font6" id="p3_t137" reading_order_no="136" segment_no="19" tag_type="text">[14] A. Kendall and Y. Gal, “What uncertainties do we need in bayesian</text>
<text top="549" left="330" width="233" height="7" font="font6" id="p3_t138" reading_order_no="137" segment_no="19" tag_type="text">deep learning for computer vision?,” in Advances in neural information</text>
<text top="558" left="330" width="138" height="7" font="font8" id="p3_t139" reading_order_no="138" segment_no="19" tag_type="text">processing systems , pp. 5574–5584, 2017.</text>
<text top="567" left="312" width="251" height="7" font="font6" id="p3_t140" reading_order_no="139" segment_no="20" tag_type="text">[15] T. Langner, F. K. Gustafsson, B. Avelin, R. Strand, H. Ahlstr¨om,</text>
<text top="576" left="330" width="233" height="7" font="font6" id="p3_t141" reading_order_no="140" segment_no="20" tag_type="text">and J. Kullberg, “Uncertainty-aware body composition analysis with</text>
<text top="585" left="330" width="233" height="7" font="font6" id="p3_t142" reading_order_no="141" segment_no="20" tag_type="text">deep regression ensembles on uk biobank mri,” arXiv preprint</text>
<text top="594" left="330" width="81" height="7" font="font8" id="p3_t143" reading_order_no="142" segment_no="20" tag_type="text">arXiv:2101.06963 , 2021.</text>
<text top="603" left="312" width="251" height="7" font="font6" id="p3_t144" reading_order_no="143" segment_no="21" tag_type="text">[16] S. V. Eastwood, R. Mathur, M. Atkinson, S. Brophy, C. Sudlow, R. Flaig,</text>
<text top="612" left="330" width="233" height="7" font="font6" id="p3_t145" reading_order_no="144" segment_no="21" tag_type="text">S. de Lusignan, N. Allen, and N. Chaturvedi, “Algorithms for the capture</text>
<text top="621" left="330" width="233" height="7" font="font6" id="p3_t146" reading_order_no="145" segment_no="21" tag_type="text">and adjudication of prevalent and incident diabetes in uk biobank,” PloS</text>
<text top="630" left="330" width="129" height="7" font="font8" id="p3_t147" reading_order_no="146" segment_no="21" tag_type="text">one , vol. 11, no. 9, p. e0162388, 2016.</text>
<text top="639" left="312" width="251" height="7" font="font6" id="p3_t148" reading_order_no="147" segment_no="23" tag_type="text">[17] K. He, X. Zhang, S. Ren, and J. Sun, “Deep Residual Learning for</text>
<text top="648" left="330" width="233" height="7" font="font6" id="p3_t149" reading_order_no="148" segment_no="23" tag_type="text">Image Recognition,” in 2016 IEEE Conference on Computer Vision and</text>
<text top="657" left="330" width="179" height="7" font="font8" id="p3_t150" reading_order_no="149" segment_no="23" tag_type="text">Pattern Recognition (CVPR) , pp. 770–778, June 2016.</text>
<text top="666" left="312" width="251" height="7" font="font6" id="p3_t151" reading_order_no="150" segment_no="24" tag_type="text">[18] T. K. Koo and M. Y. Li, “A guideline of selecting and reporting intraclass</text>
<text top="675" left="330" width="233" height="7" font="font6" id="p3_t152" reading_order_no="151" segment_no="24" tag_type="text">correlation coefficients for reliability research,” Journal of chiropractic</text>
<text top="684" left="330" width="146" height="7" font="font8" id="p3_t153" reading_order_no="152" segment_no="24" tag_type="text">medicine , vol. 15, no. 2, pp. 155–163, 2016.</text>
<text top="693" left="312" width="251" height="7" font="font6" id="p3_t154" reading_order_no="153" segment_no="26" tag_type="text">[19] C. Guo, G. Pleiss, Y. Sun, and K. Q. Weinberger, “On calibration of</text>
<text top="701" left="330" width="217" height="8" font="font6" id="p3_t155" reading_order_no="154" segment_no="26" tag_type="text">modern neural networks,” arXiv preprint arXiv:1706.04599 , 2017.</text>
<text top="710" left="312" width="251" height="7" font="font6" id="p3_t156" reading_order_no="155" segment_no="28" tag_type="text">[20] R. Wagner, B. Dietz, J. Machann, P. Schwab, J. K. Dienes, S. Reichert,</text>
<text top="719" left="330" width="233" height="7" font="font6" id="p3_t157" reading_order_no="156" segment_no="28" tag_type="text">A. L. Birkenfeld, H.-U. Haering, F. Schick, N. Stefan, et al. , “102-</text>
<text top="728" left="330" width="233" height="7" font="font6" id="p3_t158" reading_order_no="157" segment_no="28" tag_type="text">or: Detection of diabetes from whole-body magnetic resonance imaging</text>
<text top="737" left="330" width="90" height="7" font="font6" id="p3_t159" reading_order_no="158" segment_no="28" tag_type="text">using deep learning,” 2020.</text>
</page>
<outline>
<item page="1">I Introduction</item>
<item page="1">II Methods</item>
<item page="2">III Results and Discussion</item>
<item page="3">IV Acknowledgments</item>
<item page="3">References</item>
</outline>
</pdf2xml>
