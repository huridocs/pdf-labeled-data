<!DOCTYPE pdf2xml SYSTEM "pdf2xml.dtd">
<pdf2xml producer="poppler" version="23.04.0">
<page number="1" position="absolute" top="0" left="0" height="3210" width="2260">
	<fontspec id="font0" size="38" family="GlyphLessFont" color="#000000"/>
	<fontspec id="font1" size="20" family="GlyphLessFont" color="#000000"/>
	<fontspec id="font2" size="3" family="GlyphLessFont" color="#000000"/>
	<fontspec id="font3" size="36" family="GlyphLessFont" color="#000000"/>
	<fontspec id="font4" size="31" family="GlyphLessFont" color="#000000"/>
	<fontspec id="font5" size="42" family="GlyphLessFont" color="#000000"/>
	<fontspec id="font6" size="40" family="GlyphLessFont" color="#000000"/>
	<fontspec id="font7" size="39" family="GlyphLessFont" color="#000000"/>
	<fontspec id="font8" size="47" family="GlyphLessFont" color="#000000"/>
	<fontspec id="font9" size="37" family="GlyphLessFont" color="#000000"/>
	<fontspec id="font10" size="41" family="GlyphLessFont" color="#000000"/>
	<fontspec id="font11" size="33" family="GlyphLessFont" color="#000000"/>
	<fontspec id="font12" size="48" family="GlyphLessFont" color="#000000"/>
	<fontspec id="font13" size="43" family="GlyphLessFont" color="#000000"/>
	<fontspec id="font14" size="2" family="GlyphLessFont" color="#000000"/>
<text top="202" left="505" width="782" height="54" font="font0" id="p1_t1" reading_order_no="0" segment_no="0" tag_type="title">Table  {.  Typical  lexicon,  with  the  word  fhe  having  two</text>
<text top="250" left="506" width="234" height="51" font="font0" id="p1_t2" reading_order_no="1" segment_no="0" tag_type="title">pronunciations.</text>
<text top="250" left="820" width="28" height="51" font="font0" id="p1_t3" reading_order_no="2" segment_no="0" tag_type="title">a</text>
<text top="325" left="581" width="78" height="49" font="font3" id="p1_t4" reading_order_no="3" segment_no="1" tag_type="table">Word</text>
<text top="326" left="858" width="362" height="49" font="font3" id="p1_t5" reading_order_no="4" segment_no="1" tag_type="table">Phonetic  representation</text>
<text top="379" left="580" width="47" height="42" font="font4" id="p1_t6" reading_order_no="5" segment_no="1" tag_type="table">The</text>
<text top="379" left="859" width="83" height="42" font="font4" id="p1_t7" reading_order_no="6" segment_no="1" tag_type="table">DH  AH</text>
<text top="427" left="580" width="47" height="42" font="font4" id="p1_t8" reading_order_no="7" segment_no="1" tag_type="table">The</text>
<text top="427" left="859" width="74" height="42" font="font4" id="p1_t9" reading_order_no="8" segment_no="1" tag_type="table">DH  IY</text>
<text top="475" left="567" width="56" height="42" font="font4" id="p1_t10" reading_order_no="9" segment_no="1" tag_type="table">Cat</text>
<text top="475" left="858" width="86" height="42" font="font4" id="p1_t11" reading_order_no="11" segment_no="1" tag_type="table">K  AET</text>
<text top="515" left="571" width="50" height="51" font="font0" id="p1_t12" reading_order_no="10" segment_no="1" tag_type="table">Pig</text>
<text top="517" left="859" width="80" height="51" font="font0" id="p1_t13" reading_order_no="12" segment_no="1" tag_type="table">PIHG</text>
<text top="570" left="580" width="53" height="42" font="font4" id="p1_t14" reading_order_no="13" segment_no="1" tag_type="table">Two</text>
<text top="572" left="857" width="72" height="42" font="font4" id="p1_t15" reading_order_no="14" segment_no="1" tag_type="table">TUW</text>
<text top="704" left="484" width="376" height="57" font="font5" id="p1_t16" reading_order_no="15" segment_no="3" tag_type="title">HYPOTHESIS  SEARCH</text>
<text top="754" left="520" width="792" height="56" font="font6" id="p1_t17" reading_order_no="16" segment_no="5" tag_type="text">Three  basic  components  comprise  the  hypothe-</text>
<text top="803" left="483" width="829" height="56" font="font7" id="p1_t18" reading_order_no="17" segment_no="5" tag_type="text">sis  search:  a  lexicon,  a  language  model,  and  an</text>
<text top="851" left="484" width="257" height="54" font="font6" id="p1_t19" reading_order_no="18" segment_no="5" tag_type="text">acoustic  model.</text>
<text top="939" left="483" width="138" height="63" font="font8" id="p1_t20" reading_order_no="19" segment_no="7" tag_type="title">Lexicon</text>
<text top="994" left="520" width="792" height="57" font="font6" id="p1_t21" reading_order_no="20" segment_no="9" tag_type="text">The  typical  lexicon  shown  in  Table 1  lists  each</text>
<text top="1042" left="483" width="829" height="56" font="font6" id="p1_t22" reading_order_no="21" segment_no="9" tag_type="text">word’s  possible  pronunciations,  constructed  from</text>
<text top="1090" left="483" width="827" height="56" font="font6" id="p1_t23" reading_order_no="22" segment_no="9" tag_type="text">phonemes,  of  which  English  uses  approximately  50.</text>
<text top="1138" left="483" width="828" height="56" font="font6" id="p1_t24" reading_order_no="23" segment_no="9" tag_type="text">An  individual  word  can  have  multiple  pronuncia-</text>
<text top="1190" left="483" width="828" height="51" font="font9" id="p1_t25" reading_order_no="24" segment_no="9" tag_type="text">tions,  however,  which  complicates  recognition</text>
<text top="1236" left="483" width="828" height="53" font="font7" id="p1_t26" reading_order_no="25" segment_no="9" tag_type="text">tasks.  The  system  chooses  the  lexicon  on  a  task-</text>
<text top="1282" left="483" width="829" height="56" font="font6" id="p1_t27" reading_order_no="26" segment_no="9" tag_type="text">dependent  basis,  trading  off  vocabulary  size  with</text>
<text top="1330" left="483" width="828" height="56" font="font6" id="p1_t28" reading_order_no="27" segment_no="9" tag_type="text">word  coverage.  Although  a  search  can  easily  find</text>
<text top="1379" left="483" width="828" height="54" font="font7" id="p1_t29" reading_order_no="28" segment_no="9" tag_type="text">phonetic  representations  for  commonly  used  words</text>
<text top="1427" left="483" width="829" height="54" font="font7" id="p1_t30" reading_order_no="29" segment_no="9" tag_type="text">in  various  sources,  task-dependent  jargon  often</text>
<text top="1475" left="483" width="740" height="54" font="font7" id="p1_t31" reading_order_no="30" segment_no="9" tag_type="text">requires  writing  out  pronunciations  by  hand.</text>
<text top="1568" left="483" width="294" height="57" font="font5" id="p1_t32" reading_order_no="31" segment_no="11" tag_type="title">Language  model</text>
<text top="1617" left="520" width="792" height="57" font="font10" id="p1_t33" reading_order_no="32" segment_no="12" tag_type="text">The  search  for  the  most  likely  word  sequence  in</text>
<text top="1666" left="483" width="828" height="56" font="font6" id="p1_t34" reading_order_no="33" segment_no="12" tag_type="text">Equation  1  requires  the  computation  of  two  terms,</text>
<text top="1716" left="482" width="830" height="53" font="font0" id="p1_t35" reading_order_no="34" segment_no="12" tag_type="text">p(ytlw)  and  p(w).  The  second  of  these  computa-</text>
<text top="1762" left="482" width="829" height="56" font="font6" id="p1_t36" reading_order_no="35" segment_no="12" tag_type="text">tions  is  called  the  Janguage  model.  Its  function  is</text>
<text top="1810" left="483" width="827" height="56" font="font6" id="p1_t37" reading_order_no="36" segment_no="12" tag_type="text">to  assign  a  probability  to  a  sequence  of  words  w¥.</text>
<text top="1859" left="528" width="784" height="54" font="font7" id="p1_t38" reading_order_no="37" segment_no="14" tag_type="text">The  simplest  way  to  determine  such  a  probabil-</text>
<text top="1907" left="483" width="831" height="55" font="font7" id="p1_t39" reading_order_no="38" segment_no="14" tag_type="text">ity  would  be  to  compute  the  relative  frequencies  of</text>
<text top="1954" left="483" width="831" height="56" font="font6" id="p1_t40" reading_order_no="39" segment_no="14" tag_type="text">different  word  sequences.  However,  the  number  of</text>
<text top="2002" left="484" width="828" height="55" font="font7" id="p1_t41" reading_order_no="40" segment_no="14" tag_type="text">different  sequences  grows  exponentially  with  the</text>
<text top="2051" left="483" width="828" height="53" font="font7" id="p1_t42" reading_order_no="41" segment_no="14" tag_type="text">length  of  the  sequence,  making  this  approach  infea-</text>
<text top="2097" left="483" width="83" height="54" font="font6" id="p1_t43" reading_order_no="42" segment_no="14" tag_type="text">sible.</text>
<text top="2145" left="520" width="792" height="56" font="font6" id="p1_t44" reading_order_no="43" segment_no="15" tag_type="text">A  typical  approximation  assumes  that  the  prob-</text>
<text top="2194" left="483" width="828" height="54" font="font7" id="p1_t45" reading_order_no="44" segment_no="15" tag_type="text">ability  of  the  current  word  depends  on  the  previ-</text>
<text top="2243" left="483" width="829" height="55" font="font7" id="p1_t46" reading_order_no="45" segment_no="15" tag_type="text">ous  two  words  only,  so  that  the  computation  can</text>
<text top="2289" left="484" width="828" height="57" font="font10" id="p1_t47" reading_order_no="46" segment_no="15" tag_type="text">approximate  the  probability  of  the  word  sequence</text>
<text top="2337" left="483" width="41" height="55" font="font10" id="p1_t48" reading_order_no="47" segment_no="15" tag_type="text">as:</text>
<text top="2580" left="520" width="792" height="52" font="font9" id="p1_t49" reading_order_no="48" segment_no="16" tag_type="text">The  computation  can  estimate  p(wjlw;_,,  w;-»)  by</text>
<text top="2625" left="482" width="829" height="56" font="font6" id="p1_t50" reading_order_no="49" segment_no="16" tag_type="text">counting  the  relative  frequencies  of  word  trigrams,</text>
<text top="2674" left="483" width="180" height="53" font="font7" id="p1_t51" reading_order_no="50" segment_no="16" tag_type="text">or  triplets:</text>
<text top="2796" left="513" width="590" height="54" font="font6" id="p1_t52" reading_order_no="51" segment_no="18" tag_type="formula">p(w;  |w; 4,02)  =  N(w;,W1,W-  )/</text>
<text top="2796" left="1256" width="41" height="54" font="font6" id="p1_t53" reading_order_no="53" segment_no="18" tag_type="text">(3)</text>
<text top="2869" left="529" width="205" height="49" font="font3" id="p1_t54" reading_order_no="52" segment_no="18" tag_type="formula">N (w;15  W;»)</text>
<text top="2964" left="482" width="829" height="51" font="font9" id="p1_t55" reading_order_no="54" segment_no="19" tag_type="text">where N  refers  to  the  associated  event’s  relative  fre-</text>
<text top="3009" left="484" width="828" height="55" font="font6" id="p1_t56" reading_order_no="55" segment_no="19" tag_type="text">quency.  Typically,  training  such  a  language  model</text>
<text top="3112" left="395" width="128" height="45" font="font11" id="p1_t57" reading_order_no="109" segment_no="20" tag_type="text">Computer</text>
<text top="468" left="1369" width="829" height="57" font="font6" id="p1_t58" reading_order_no="56" segment_no="2" tag_type="text">requires  using  hundreds  of  millions  of  words  to</text>
<text top="520" left="1370" width="827" height="51" font="font3" id="p1_t59" reading_order_no="57" segment_no="2" tag_type="text">estimate  p(wjlw;,_,,  W;).  Even  then,  many  trigrams</text>
<text top="566" left="1370" width="828" height="54" font="font0" id="p1_t60" reading_order_no="58" segment_no="2" tag_type="text">do  not  occur  in  the  training  text,  so  the  computa-</text>
<text top="614" left="1370" width="827" height="55" font="font7" id="p1_t61" reading_order_no="59" segment_no="2" tag_type="text">tion  must  smooth  the  probability  estimates  to  avoid</text>
<text top="660" left="1370" width="606" height="56" font="font6" id="p1_t62" reading_order_no="60" segment_no="2" tag_type="text">zeros  in  the  probability  assignment.’</text>
<text top="748" left="1369" width="302" height="66" font="font12" id="p1_t63" reading_order_no="61" segment_no="4" tag_type="title">Acoustic  models</text>
<text top="805" left="1407" width="792" height="57" font="font6" id="p1_t64" reading_order_no="62" segment_no="6" tag_type="text">An  acoustic  model  computes  the  probability  of</text>
<text top="853" left="1370" width="828" height="57" font="font6" id="p1_t65" reading_order_no="63" segment_no="6" tag_type="text">feature  vector  sequences  under  the  assumption  that</text>
<text top="901" left="1369" width="820" height="57" font="font6" id="p1_t66" reading_order_no="64" segment_no="6" tag_type="text">a  particular  word  sequence  produced  the  vectors.</text>
<text top="949" left="1408" width="789" height="57" font="font6" id="p1_t67" reading_order_no="65" segment_no="8" tag_type="text">Given  speech’s  inherently  stochastic  nature,</text>
<text top="997" left="1370" width="828" height="56" font="font6" id="p1_t68" reading_order_no="66" segment_no="8" tag_type="text">speakers  usually  do  not  utter  a  word  the  same  way</text>
<text top="1047" left="1370" width="827" height="53" font="font0" id="p1_t69" reading_order_no="67" segment_no="8" tag_type="text">twice.  The  variation  in  a  word’s  or  phoneme’s</text>
<text top="1092" left="1369" width="828" height="57" font="font6" id="p1_t70" reading_order_no="68" segment_no="8" tag_type="text">pronunciation  manifests  itself  in  two  ways:  dura-</text>
<text top="1142" left="1369" width="828" height="55" font="font7" id="p1_t71" reading_order_no="69" segment_no="8" tag_type="text">tion  and  spectral  content,  also  known  as  acoustic</text>
<text top="1189" left="1369" width="827" height="56" font="font6" id="p1_t72" reading_order_no="70" segment_no="8" tag_type="text">observations.  Further,  phonemes  in  the  surround-</text>
<text top="1238" left="1369" width="829" height="54" font="font0" id="p1_t73" reading_order_no="71" segment_no="8" tag_type="text">ing  context  can  cause  variations  in  a  particular</text>
<text top="1285" left="1370" width="828" height="56" font="font6" id="p1_t74" reading_order_no="72" segment_no="8" tag_type="text">phoneme’s  spectral  content,  a  phenomenon  called</text>
<text top="1334" left="1370" width="240" height="53" font="font7" id="p1_t75" reading_order_no="73" segment_no="8" tag_type="text">coarticulation.</text>
<text top="1377" left="1406" width="793" height="61" font="font13" id="p1_t76" reading_order_no="74" segment_no="10" tag_type="text">Hidden  Markov  models.  A  hidden  Markov  model</text>
<text top="1428" left="1370" width="828" height="57" font="font6" id="p1_t77" reading_order_no="75" segment_no="10" tag_type="text">offers  a  natural  choice  for  modeling  speech’s  sto-</text>
<text top="1477" left="1369" width="829" height="55" font="font7" id="p1_t78" reading_order_no="76" segment_no="10" tag_type="text">chastic  aspects.  HMMs  function  as  probabilistic</text>
<text top="1524" left="1370" width="830" height="56" font="font6" id="p1_t79" reading_order_no="77" segment_no="10" tag_type="text">finite  state  machines:  The  model  consists  of  a  set  of</text>
<text top="1573" left="1370" width="828" height="55" font="font7" id="p1_t80" reading_order_no="78" segment_no="10" tag_type="text">states,  and  its  topology  specifies  the  allowed  tran-</text>
<text top="1620" left="1370" width="828" height="57" font="font6" id="p1_t81" reading_order_no="79" segment_no="10" tag_type="text">sitions  between  them.  At  every  time  frame,  an</text>
<text top="1669" left="1369" width="829" height="55" font="font7" id="p1_t82" reading_order_no="80" segment_no="10" tag_type="text">HMM  makes  a  probabilistic  transition  from  one</text>
<text top="1716" left="1370" width="828" height="56" font="font6" id="p1_t83" reading_order_no="81" segment_no="10" tag_type="text">state  to  another  and  emits  a  feature  vector  with</text>
<text top="1764" left="1369" width="259" height="54" font="font6" id="p1_t84" reading_order_no="82" segment_no="10" tag_type="text">each  transition.</text>
<text top="1813" left="1407" width="791" height="55" font="font7" id="p1_t85" reading_order_no="83" segment_no="13" tag_type="text">Figure  2  shows  an  HMM  for  a  phoneme.  A  set</text>
<text top="1861" left="1370" width="828" height="55" font="font7" id="p1_t86" reading_order_no="84" segment_no="13" tag_type="text">of  state  transition  probabilities—p1,  p2,  and</text>
<text top="1908" left="1368" width="829" height="56" font="font6" id="p1_t87" reading_order_no="85" segment_no="13" tag_type="text">p3—governs  the  possible  transitions  between</text>
<text top="1956" left="1370" width="828" height="54" font="font6" id="p1_t88" reading_order_no="86" segment_no="13" tag_type="text">states.  They  specify  the  probability  of  going  from</text>
<text top="2006" left="1370" width="826" height="52" font="font0" id="p1_t89" reading_order_no="87" segment_no="13" tag_type="text">one  state  at  time  ¢  to  another  state  at  time  ¢  +  1.</text>
<text top="2051" left="1369" width="828" height="56" font="font6" id="p1_t90" reading_order_no="88" segment_no="13" tag_type="text">The  feature  vectors  emitted  while  making  a  par-</text>
<text top="2099" left="1369" width="828" height="56" font="font6" id="p1_t91" reading_order_no="89" segment_no="13" tag_type="text">ticular  transition  represent  the  spectral  charac-</text>
<text top="2146" left="1368" width="829" height="57" font="font10" id="p1_t92" reading_order_no="90" segment_no="13" tag_type="text">teristics  of  the  speech  at  that  point,  which  vary</text>
<text top="2194" left="1368" width="828" height="58" font="font10" id="p1_t93" reading_order_no="91" segment_no="13" tag_type="text">corresponding  to  different  pronunciations  of  the</text>
<text top="2242" left="1368" width="828" height="57" font="font10" id="p1_t94" reading_order_no="92" segment_no="13" tag_type="text">phoneme.  A  probability  distribution  or  proba-</text>
<text top="2291" left="1369" width="828" height="56" font="font6" id="p1_t95" reading_order_no="93" segment_no="13" tag_type="text">bility  density  function  models  this  variation.  The</text>
<text top="2341" left="1368" width="828" height="54" font="font0" id="p1_t96" reading_order_no="94" segment_no="13" tag_type="text">functions—p(yl1),  p(yl2),  and  p(yl3)—could  be</text>
<text top="2388" left="1369" width="827" height="55" font="font7" id="p1_t97" reading_order_no="95" segment_no="13" tag_type="text">different  for  different  transitions.  Typically,  these</text>
<text top="2435" left="1369" width="828" height="56" font="font6" id="p1_t98" reading_order_no="96" segment_no="13" tag_type="text">distributions  are  modeled  as  parametric  distri-</text>
<text top="2484" left="1370" width="826" height="55" font="font7" id="p1_t99" reading_order_no="97" segment_no="13" tag_type="text">butions—a  mixture  of  multidimensional  gaus-</text>
<text top="2532" left="1369" width="321" height="53" font="font7" id="p1_t100" reading_order_no="98" segment_no="13" tag_type="text">sians,  for  example.</text>
<text top="2580" left="1405" width="791" height="55" font="font7" id="p1_t101" reading_order_no="99" segment_no="17" tag_type="text">The  HMM  shown  in  Figure  2  consists  of  three</text>
<text top="2629" left="1368" width="828" height="53" font="font0" id="p1_t102" reading_order_no="100" segment_no="17" tag_type="text">states.  The  phoneme’s  pronunciation  corresponds</text>
<text top="2675" left="1368" width="828" height="54" font="font6" id="p1_t103" reading_order_no="101" segment_no="17" tag_type="text">to  starting  from  the  first  state  and  making  a</text>
<text top="2723" left="1369" width="828" height="56" font="font6" id="p1_t104" reading_order_no="102" segment_no="17" tag_type="text">sequence  of  transitions  to  eventually  arrive  at  the</text>
<text top="2771" left="1368" width="828" height="56" font="font6" id="p1_t105" reading_order_no="103" segment_no="17" tag_type="text">third  state.  The  duration  of  the  phoneme  equals  the</text>
<text top="2819" left="1369" width="827" height="56" font="font6" id="p1_t106" reading_order_no="104" segment_no="17" tag_type="text">number  of  time  frames  required  to  complete  the</text>
<text top="2867" left="1368" width="828" height="56" font="font6" id="p1_t107" reading_order_no="105" segment_no="17" tag_type="text">transition  sequence.  The  three  transition  probabil-</text>
<text top="2915" left="1368" width="828" height="56" font="font6" id="p1_t108" reading_order_no="106" segment_no="17" tag_type="text">ities  implicitly  specify  a  probability  distribution</text>
<text top="2963" left="1368" width="828" height="56" font="font6" id="p1_t109" reading_order_no="107" segment_no="17" tag_type="text">that  governs  this  duration.  If  any  of  these  transi-</text>
<text top="3011" left="1368" width="829" height="56" font="font6" id="p1_t110" reading_order_no="108" segment_no="17" tag_type="text">tions  exhibits  high  self-loop  probabilities,  the</text>
</page>
</pdf2xml>
