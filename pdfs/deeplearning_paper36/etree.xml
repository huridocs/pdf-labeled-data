<!DOCTYPE pdf2xml SYSTEM "pdf2xml.dtd">
<pdf2xml producer="poppler" version="23.04.0">
<page number="1" position="absolute" top="0" left="0" height="792" width="612">
	<fontspec id="font0" size="7" family="NimbusSanL-Regu" color="#000000"/>
	<fontspec id="font1" size="24" family="NimbusSanL-Regu" color="#000000"/>
	<fontspec id="font2" size="11" family="NimbusSanL-Regu" color="#000000"/>
	<fontspec id="font3" size="8" family="NimbusSanL,Bold" color="#000000"/>
	<fontspec id="font4" size="8" family="NimbusSanL-Regu" color="#000000"/>
	<fontspec id="font5" size="8" family="CMMI8" color="#000000"/>
	<fontspec id="font6" size="11" family="Dingbats" color="#000000"/>
	<fontspec id="font7" size="11" family="NimbusSanL,Bold" color="#000000"/>
	<fontspec id="font8" size="9" family="NimbusSanL,Bold" color="#000000"/>
	<fontspec id="font9" size="27" family="URWPalladioL-Roma" color="#000000"/>
	<fontspec id="font10" size="8" family="URWPalladioL-Roma" color="#000000"/>
	<fontspec id="font11" size="10" family="URWPalladioL-Roma" color="#000000"/>
	<fontspec id="font12" size="8" family="CMSY8" color="#000000"/>
	<fontspec id="font13" size="8" family="URWPalladioL-Ital" color="#000000"/>
	<fontspec id="font14" size="10" family="CMMI10" color="#000000"/>
	<fontspec id="font15" size="20" family="Times" color="#7f7f7f"/>
<text top="29" left="48" width="334" height="6" font="font0" id="p1_t1" reading_order_no="1" segment_no="0" tag_type="title">IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS, VOL. XX, NO. , AUGUST 2020</text>
<text top="29" left="560" width="4" height="6" font="font0" id="p1_t2" reading_order_no="2" segment_no="1" tag_type="text">1</text>
<text top="57" left="84" width="443" height="22" font="font1" id="p1_t3" reading_order_no="3" segment_no="2" tag_type="title">Deep3DPose: Realtime Reconstruction of</text>
<text top="85" left="72" width="467" height="22" font="font1" id="p1_t4" reading_order_no="4" segment_no="2" tag_type="title">Arbitrarily Posed Human Bodies from Single</text>
<text top="113" left="237" width="137" height="22" font="font1" id="p1_t5" reading_order_no="5" segment_no="2" tag_type="title">RGB Images</text>
<text top="151" left="71" width="471" height="10" font="font2" id="p1_t6" reading_order_no="6" segment_no="3" tag_type="text">Liguo Jiang, Miaopeng Li, Jianjie Zhang, Congyi Wang, Juntao Ye, Xinguo Liu, and Jinxiang Chai</text>
<text top="183" left="68" width="32" height="8" font="font3" id="p1_t7" reading_order_no="7" segment_no="4" tag_type="text"><b>Abstract</b></text>
<text top="183" left="101" width="439" height="7" font="font4" id="p1_t8" reading_order_no="8" segment_no="4" tag_type="text">—We introduce an approach that accurately reconstructs 3D human poses and detailed 3D full-body geometric models from</text>
<text top="193" left="68" width="457" height="7" font="font4" id="p1_t9" reading_order_no="9" segment_no="4" tag_type="text">single images in realtime. The key idea of our approach is a novel end-to-end multi-task deep learning framework that uses single</text>
<text top="203" left="68" width="464" height="7" font="font4" id="p1_t10" reading_order_no="10" segment_no="4" tag_type="text">images to predict five outputs simultaneously: foreground segmentation mask, 2D joints positions, semantic body partitions, 3D part</text>
<text top="214" left="68" width="57" height="7" font="font4" id="p1_t11" reading_order_no="11" segment_no="4" tag_type="text">orientations and</text>
<text top="214" left="127" width="9" height="7" font="font5" id="p1_t12" reading_order_no="12" segment_no="4" tag_type="text">uv</text>
<text top="214" left="139" width="46" height="7" font="font4" id="p1_t13" reading_order_no="13" segment_no="4" tag_type="text">coordinates (</text>
<text top="214" left="185" width="9" height="7" font="font5" id="p1_t14" reading_order_no="14" segment_no="4" tag_type="text">uv</text>
<text top="214" left="197" width="343" height="7" font="font4" id="p1_t15" reading_order_no="15" segment_no="4" tag_type="text">map). The multi-task network architecture not only generates more visual cues for reconstruction,</text>
<text top="224" left="68" width="475" height="7" font="font4" id="p1_t16" reading_order_no="16" segment_no="4" tag_type="text">but also makes each individual prediction more accurate. The CNN regressor is further combined with an optimization based algorithm</text>
<text top="234" left="68" width="469" height="7" font="font4" id="p1_t17" reading_order_no="17" segment_no="4" tag_type="text">for accurate kinematic pose reconstruction and full-body shape modeling. We show that the realtime reconstruction reaches accurate</text>
<text top="245" left="68" width="471" height="7" font="font4" id="p1_t18" reading_order_no="18" segment_no="4" tag_type="text">fitting that has not been seen before, especially for wild images. We demonstrate the results of our realtime 3D pose and human body</text>
<text top="255" left="68" width="461" height="7" font="font4" id="p1_t19" reading_order_no="19" segment_no="4" tag_type="text">reconstruction system on various challenging in-the-wild videos. We show the system advances the frontier of 3D human body and</text>
<text top="266" left="68" width="405" height="7" font="font4" id="p1_t20" reading_order_no="20" segment_no="4" tag_type="text">pose reconstruction from single images by quantitative evaluations and comparisons with state-of-the-art methods.</text>
<text top="287" left="68" width="47" height="8" font="font3" id="p1_t21" reading_order_no="21" segment_no="5" tag_type="text"><b>Index Terms</b></text>
<text top="287" left="115" width="372" height="7" font="font4" id="p1_t22" reading_order_no="22" segment_no="5" tag_type="text">—Realtime RGB-based motion capture, multi-task regression, 3D human body and shape reconstruction.</text>
<text top="302" left="302" width="9" height="12" font="font6" id="p1_t23" reading_order_no="23" segment_no="6" tag_type="text">F</text>
<text top="323" left="48" width="6" height="10" font="font7" id="p1_t24" reading_order_no="24" segment_no="7" tag_type="title"><b>1</b></text>
<text top="323" left="66" width="3" height="10" font="font7" id="p1_t25" reading_order_no="25" segment_no="7" tag_type="title"><b>I</b></text>
<text top="325" left="70" width="70" height="8" font="font8" id="p1_t26" reading_order_no="26" segment_no="7" tag_type="title"><b>NTRODUCTION</b></text>
<text top="345" left="48" width="19" height="27" font="font9" id="p1_t27" reading_order_no="27" segment_no="8" tag_type="text">C</text>
<text top="346" left="69" width="37" height="8" font="font10" id="p1_t28" reading_order_no="28" segment_no="8" tag_type="text">REATING</text>
<text top="345" left="110" width="190" height="9" font="font11" id="p1_t29" reading_order_no="29" segment_no="8" tag_type="text">natural-looking human characters with real-</text>
<text top="357" left="69" width="231" height="9" font="font11" id="p1_t30" reading_order_no="30" segment_no="8" tag_type="text">istic motions is essential for many applications, includ-</text>
<text top="368" left="48" width="252" height="9" font="font11" id="p1_t31" reading_order_no="31" segment_no="8" tag_type="text">ing movies, video games, robotics, sports training, medical</text>
<text top="380" left="48" width="252" height="9" font="font11" id="p1_t32" reading_order_no="32" segment_no="8" tag_type="text">analytics and social behavior recognition, and so on. Using</text>
<text top="391" left="48" width="252" height="9" font="font11" id="p1_t33" reading_order_no="33" segment_no="8" tag_type="text">expensive and special equipment, such as multi-cameras</text>
<text top="403" left="48" width="252" height="9" font="font11" id="p1_t34" reading_order_no="34" segment_no="8" tag_type="text">and reflective markers based motion capture systems, this</text>
<text top="414" left="48" width="252" height="9" font="font11" id="p1_t35" reading_order_no="35" segment_no="8" tag_type="text">task can be achieved without too much pain for scenes</text>
<text top="426" left="48" width="252" height="9" font="font11" id="p1_t36" reading_order_no="36" segment_no="8" tag_type="text">that do not impose many restrictions. Yet the inconvenient</text>
<text top="437" left="48" width="252" height="9" font="font11" id="p1_t37" reading_order_no="37" segment_no="8" tag_type="text">accessibility to such equipment has limited the flourishing</text>
<text top="449" left="48" width="177" height="9" font="font11" id="p1_t38" reading_order_no="38" segment_no="8" tag_type="text">of 3D human motion related applications.</text>
<text top="461" left="62" width="238" height="9" font="font11" id="p1_t39" reading_order_no="39" segment_no="11" tag_type="text">The ideal and most convenient way is to use off-the-</text>
<text top="473" left="48" width="252" height="9" font="font11" id="p1_t40" reading_order_no="40" segment_no="11" tag_type="text">shelf RGB cameras to capture live performance and create</text>
<text top="484" left="48" width="252" height="9" font="font11" id="p1_t41" reading_order_no="41" segment_no="11" tag_type="text">3D motion data. The minimal requirement of a single RGB</text>
<text top="496" left="48" width="252" height="9" font="font11" id="p1_t42" reading_order_no="42" segment_no="11" tag_type="text">camera is particularly appealing, as it offers the lowest cost,</text>
<text top="507" left="48" width="252" height="9" font="font11" id="p1_t43" reading_order_no="43" segment_no="11" tag_type="text">easy setup, and the potential of converting huge volume of</text>
<text top="519" left="48" width="252" height="9" font="font11" id="p1_t44" reading_order_no="44" segment_no="11" tag_type="text">Internet videos into a large-scale 3D human body corpus.</text>
<text top="530" left="48" width="252" height="9" font="font11" id="p1_t45" reading_order_no="45" segment_no="11" tag_type="text">Recent years have seen much research efforts being devoted</text>
<text top="542" left="48" width="252" height="9" font="font11" id="p1_t46" reading_order_no="46" segment_no="11" tag_type="text">to estimating not only the skeletal motion but also body</text>
<text top="553" left="48" width="252" height="9" font="font11" id="p1_t47" reading_order_no="47" segment_no="11" tag_type="text">pose and shape. Yet reconstructing 3D pose and shape from</text>
<text top="565" left="48" width="252" height="9" font="font11" id="p1_t48" reading_order_no="48" segment_no="11" tag_type="text">a single RGB camera is still a challenging and undercon-</text>
<text top="576" left="48" width="252" height="9" font="font11" id="p1_t49" reading_order_no="49" segment_no="11" tag_type="text">strained problem with inherent ambiguities, especially in</text>
<text top="588" left="48" width="252" height="9" font="font11" id="p1_t50" reading_order_no="50" segment_no="11" tag_type="text">wild uncontrolled environment and in realtime. Therefore</text>
<text top="599" left="48" width="252" height="9" font="font11" id="p1_t51" reading_order_no="51" segment_no="11" tag_type="text">the state-of-the-art results are often vulnerable to ambigu-</text>
<text top="611" left="48" width="252" height="9" font="font11" id="p1_t52" reading_order_no="52" segment_no="11" tag_type="text">ities in the video (e.g., occlusions, cloth deformation, and</text>
<text top="623" left="48" width="252" height="9" font="font11" id="p1_t53" reading_order_no="53" segment_no="11" tag_type="text">illumination changes), degeneracy in camera motion, and</text>
<text top="634" left="48" width="252" height="9" font="font11" id="p1_t54" reading_order_no="54" segment_no="11" tag_type="text">a lack of discernible features on a human body. Moreover,</text>
<text top="662" left="48" width="4" height="8" font="font12" id="p1_t55" reading_order_no="95" segment_no="14" tag_type="list">•</text>
<text top="662" left="61" width="239" height="8" font="font13" id="p1_t56" reading_order_no="96" segment_no="14" tag_type="list">L. Jiang, J. Ye are with NLPR, Institute of Automation, Chinese Academy</text>
<text top="671" left="61" width="239" height="8" font="font13" id="p1_t57" reading_order_no="97" segment_no="14" tag_type="list">of Sciences, Beijing, China and School of Artificial Intelligence, University</text>
<text top="680" left="61" width="156" height="8" font="font13" id="p1_t58" reading_order_no="98" segment_no="14" tag_type="list">of Chinese Academy of Sciences, Beijing, China.</text>
<text top="689" left="61" width="191" height="8" font="font13" id="p1_t59" reading_order_no="99" segment_no="14" tag_type="list">E-mail: jiangliguo2015@ia.ac.cn and yejuntao@gmail.com.</text>
<text top="698" left="48" width="4" height="8" font="font12" id="p1_t60" reading_order_no="100" segment_no="15" tag_type="list">•</text>
<text top="698" left="61" width="184" height="8" font="font13" id="p1_t61" reading_order_no="101" segment_no="15" tag_type="list">J. Zhang and C. Wang are with Xmov, Shanghai, China.</text>
<text top="707" left="48" width="4" height="8" font="font12" id="p1_t62" reading_order_no="102" segment_no="16" tag_type="list">•</text>
<text top="707" left="61" width="239" height="8" font="font13" id="p1_t63" reading_order_no="103" segment_no="16" tag_type="list">M. Li and X. Liu are with State Key Laboratory of CAD&amp;CG, Zhejiang</text>
<text top="716" left="61" width="99" height="8" font="font13" id="p1_t64" reading_order_no="104" segment_no="16" tag_type="list">University, Hangzhou, China.</text>
<text top="725" left="48" width="4" height="8" font="font12" id="p1_t65" reading_order_no="105" segment_no="17" tag_type="list">•</text>
<text top="725" left="61" width="127" height="8" font="font13" id="p1_t66" reading_order_no="106" segment_no="17" tag_type="list">J. Chai is with Texas A&amp;M University.</text>
<text top="345" left="312" width="252" height="9" font="font11" id="p1_t67" reading_order_no="55" segment_no="9" tag_type="text">methods that achieve realtime, robust as well as accurate</text>
<text top="357" left="312" width="215" height="9" font="font11" id="p1_t68" reading_order_no="56" segment_no="9" tag_type="text">performance have rarely been seen common so far.</text>
<text top="368" left="326" width="238" height="9" font="font11" id="p1_t69" reading_order_no="57" segment_no="10" tag_type="text">We introduce an approach that is capable of obtaining</text>
<text top="380" left="312" width="252" height="9" font="font11" id="p1_t70" reading_order_no="58" segment_no="10" tag_type="text">accurate 3D human poses and body shape from single wild</text>
<text top="391" left="312" width="252" height="9" font="font11" id="p1_t71" reading_order_no="59" segment_no="10" tag_type="text">images in realtime. When applied to video sequences, our</text>
<text top="403" left="312" width="252" height="9" font="font11" id="p1_t72" reading_order_no="60" segment_no="10" tag_type="text">system outputs temporally consistent bodies in motion at</text>
<text top="414" left="312" width="252" height="9" font="font11" id="p1_t73" reading_order_no="61" segment_no="10" tag_type="text">more than 20 Hz on a desktop computer. The power of</text>
<text top="426" left="312" width="252" height="9" font="font11" id="p1_t74" reading_order_no="62" segment_no="10" tag_type="text">our method comes from a convolutional neural network</text>
<text top="437" left="312" width="252" height="9" font="font11" id="p1_t75" reading_order_no="63" segment_no="10" tag_type="text">(CNN) which leverages a multi-task architecture that is able</text>
<text top="449" left="312" width="252" height="9" font="font11" id="p1_t76" reading_order_no="64" segment_no="10" tag_type="text">to outputs five results simultaneously: foreground mask, 2D</text>
<text top="460" left="312" width="252" height="9" font="font11" id="p1_t77" reading_order_no="65" segment_no="10" tag_type="text">joint positions, body partition, 3D part orientation fields</text>
<text top="472" left="312" width="49" height="9" font="font11" id="p1_t78" reading_order_no="66" segment_no="10" tag_type="text">(POFs) and</text>
<text top="472" left="366" width="11" height="9" font="font14" id="p1_t79" reading_order_no="67" segment_no="10" tag_type="text">uv</text>
<text top="472" left="381" width="167" height="9" font="font11" id="p1_t80" reading_order_no="68" segment_no="10" tag_type="text">coordinates. Body partition index and</text>
<text top="472" left="553" width="11" height="9" font="font14" id="p1_t81" reading_order_no="69" segment_no="10" tag_type="text">uv</text>
<text top="484" left="312" width="142" height="9" font="font11" id="p1_t82" reading_order_no="70" segment_no="10" tag_type="text">coordinates indicate part-specific</text>
<text top="483" left="458" width="11" height="9" font="font14" id="p1_t83" reading_order_no="71" segment_no="10" tag_type="text">uv</text>
<text top="484" left="472" width="92" height="9" font="font11" id="p1_t84" reading_order_no="72" segment_no="10" tag_type="text">coordinates, which is</text>
<text top="495" left="312" width="252" height="9" font="font11" id="p1_t85" reading_order_no="73" segment_no="10" tag_type="text">called IUV [1]. While none of existing networks support so</text>
<text top="507" left="312" width="252" height="9" font="font11" id="p1_t86" reading_order_no="74" segment_no="10" tag_type="text">many tasks at one time, this architecture makes it possible</text>
<text top="518" left="312" width="252" height="9" font="font11" id="p1_t87" reading_order_no="75" segment_no="10" tag_type="text">to refine multiple predictions recurrently. The regressed</text>
<text top="530" left="312" width="252" height="9" font="font11" id="p1_t88" reading_order_no="76" segment_no="10" tag_type="text">results are fed into a kinematic skeleton pose and body</text>
<text top="541" left="312" width="252" height="9" font="font11" id="p1_t89" reading_order_no="77" segment_no="10" tag_type="text">geometry fitting optimizer and outputs a camera-relative</text>
<text top="553" left="312" width="252" height="9" font="font11" id="p1_t90" reading_order_no="78" segment_no="10" tag_type="text">full 3D posed body mesh. The success of our approach</text>
<text top="564" left="312" width="252" height="9" font="font11" id="p1_t91" reading_order_no="79" segment_no="10" tag_type="text">also relies on the expansion of publicly available training</text>
<text top="576" left="312" width="252" height="9" font="font11" id="p1_t92" reading_order_no="80" segment_no="10" tag_type="text">datasets. While it is feasible to annotate a small number of</text>
<text top="587" left="312" width="252" height="9" font="font11" id="p1_t93" reading_order_no="81" segment_no="10" tag_type="text">labels in 2D images, upgrading to a large number of 3D rep-</text>
<text top="599" left="312" width="252" height="9" font="font11" id="p1_t94" reading_order_no="82" segment_no="10" tag_type="text">resentation becomes impractical. The new data is collected</text>
<text top="610" left="312" width="252" height="9" font="font11" id="p1_t95" reading_order_no="83" segment_no="10" tag_type="text">with our in-house cost-efficient, marker-less and scalable</text>
<text top="622" left="312" width="233" height="9" font="font11" id="p1_t96" reading_order_no="84" segment_no="10" tag_type="text">data acquisition system, and is preprocessed efficiently.</text>
<text top="634" left="326" width="238" height="9" font="font11" id="p1_t97" reading_order_no="85" segment_no="13" tag_type="text">The power of our system is demonstrated by recon-</text>
<text top="645" left="312" width="252" height="9" font="font11" id="p1_t98" reading_order_no="86" segment_no="13" tag_type="text">structing 3D human poses and shapes for a wide variety of</text>
<text top="657" left="312" width="252" height="9" font="font11" id="p1_t99" reading_order_no="87" segment_no="13" tag_type="text">subjects from monocular video sequences. We have tested</text>
<text top="668" left="312" width="252" height="9" font="font11" id="p1_t100" reading_order_no="88" segment_no="13" tag_type="text">our realtime system on both live video streams and the</text>
<text top="680" left="312" width="252" height="9" font="font11" id="p1_t101" reading_order_no="89" segment_no="13" tag_type="text">Internet videos, demonstrating its accuracy and robustness</text>
<text top="691" left="312" width="252" height="9" font="font11" id="p1_t102" reading_order_no="90" segment_no="13" tag_type="text">under a variety of uncontrolled illumination conditions and</text>
<text top="703" left="312" width="252" height="9" font="font11" id="p1_t103" reading_order_no="91" segment_no="13" tag_type="text">backgrounds, as well as significant variations on races,</text>
<text top="714" left="312" width="252" height="9" font="font11" id="p1_t104" reading_order_no="92" segment_no="13" tag_type="text">shapes, poses, clothes across individuals. We show that</text>
<text top="726" left="312" width="252" height="9" font="font11" id="p1_t105" reading_order_no="93" segment_no="13" tag_type="text">our system can reconstruct bodies with realistic poses for</text>
<text top="737" left="312" width="252" height="9" font="font11" id="p1_t106" reading_order_no="94" segment_no="13" tag_type="text">highly dynamic motions such as figure skating (Fig. 1), low</text>
<text top="546" left="32" width="0" height="18" font="font15" id="p1_t107" reading_order_no="0" segment_no="12" tag_type="title">arXiv:2106.11536v1  [cs.CV]  22 Jun 2021</text>
</page>
<page number="2" position="absolute" top="0" left="0" height="792" width="612">
	<fontspec id="font16" size="7" family="Verdana" color="#000000"/>
	<fontspec id="font17" size="7" family="CMSY7" color="#000000"/>
	<fontspec id="font18" size="10" family="URWPalladioL,Bold" color="#000000"/>
	<fontspec id="font19" size="10" family="CMR10" color="#000000"/>
	<fontspec id="font20" size="10" family="URWPalladioL-Ital" color="#000000"/>
<text top="29" left="48" width="334" height="6" font="font0" id="p2_t1" reading_order_no="0" segment_no="0" tag_type="title">IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS, VOL. XX, NO. , AUGUST 2020</text>
<text top="29" left="560" width="4" height="6" font="font0" id="p2_t2" reading_order_no="1" segment_no="1" tag_type="text">2</text>
<text top="127" left="171" width="11" height="9" font="font16" id="p2_t3" reading_order_no="2" segment_no="2" tag_type="figure">(a)</text>
<text top="218" left="171" width="11" height="9" font="font16" id="p2_t4" reading_order_no="5" segment_no="2" tag_type="figure">(d)</text>
<text top="127" left="309" width="11" height="9" font="font16" id="p2_t5" reading_order_no="3" segment_no="2" tag_type="figure">(b)</text>
<text top="127" left="450" width="11" height="9" font="font16" id="p2_t6" reading_order_no="4" segment_no="2" tag_type="figure">(c)</text>
<text top="218" left="310" width="11" height="9" font="font16" id="p2_t7" reading_order_no="6" segment_no="2" tag_type="figure">(e)</text>
<text top="219" left="451" width="10" height="9" font="font16" id="p2_t8" reading_order_no="7" segment_no="2" tag_type="figure">(f)</text>
<text top="219" left="542" width="11" height="9" font="font16" id="p2_t9" reading_order_no="8" segment_no="2" tag_type="figure">(g)</text>
<text top="240" left="48" width="516" height="9" font="font11" id="p2_t10" reading_order_no="9" segment_no="3" tag_type="text">Fig. 1: Given an image (a), our regression network produces five outputs simultaneously: foreground segmentation mask</text>
<text top="251" left="48" width="216" height="9" font="font11" id="p2_t11" reading_order_no="10" segment_no="3" tag_type="text">(b), 2D joints positions (c), body partition (d), and a</text>
<text top="251" left="266" width="11" height="9" font="font14" id="p2_t12" reading_order_no="11" segment_no="3" tag_type="text">uv</text>
<text top="251" left="279" width="285" height="9" font="font11" id="p2_t13" reading_order_no="12" segment_no="3" tag_type="text">map (e), 3D part orientations (applied to a mean skeleton) (f). These</text>
<text top="263" left="48" width="514" height="9" font="font11" id="p2_t14" reading_order_no="13" segment_no="3" tag_type="text">outputs further guide the generation of a full-body model (g). The whole process runs in realtime on a desktop computer.</text>
<text top="296" left="48" width="252" height="9" font="font11" id="p2_t15" reading_order_no="14" segment_no="4" tag_type="text">energy motions such as walking, and motions with human-</text>
<text top="307" left="48" width="252" height="9" font="font11" id="p2_t16" reading_order_no="15" segment_no="4" tag_type="text">environment interaction such as sitting and standing up. We</text>
<text top="319" left="48" width="252" height="9" font="font11" id="p2_t17" reading_order_no="16" segment_no="4" tag_type="text">evaluate the importance of each key component of our al-</text>
<text top="330" left="48" width="252" height="9" font="font11" id="p2_t18" reading_order_no="17" segment_no="4" tag_type="text">gorithm, by dropping off each component in the reconstruc-</text>
<text top="342" left="48" width="252" height="9" font="font11" id="p2_t19" reading_order_no="18" segment_no="4" tag_type="text">tion. We advance the state-of-the-art realtime reconstruction</text>
<text top="353" left="48" width="252" height="9" font="font11" id="p2_t20" reading_order_no="19" segment_no="4" tag_type="text">of 3D human poses and detailed geometric body meshes</text>
<text top="365" left="48" width="252" height="9" font="font11" id="p2_t21" reading_order_no="20" segment_no="4" tag_type="text">from single images, and offer comparisons with alternative</text>
<text top="376" left="48" width="70" height="9" font="font11" id="p2_t22" reading_order_no="21" segment_no="4" tag_type="text">solutions [2]–[5].</text>
<text top="388" left="62" width="215" height="9" font="font11" id="p2_t23" reading_order_no="22" segment_no="7" tag_type="text">The highlights of our 3D reconstruction system are</text>
<text top="407" left="62" width="4" height="7" font="font17" id="p2_t24" reading_order_no="23" segment_no="8" tag_type="list">•</text>
<text top="405" left="78" width="41" height="9" font="font18" id="p2_t25" reading_order_no="24" segment_no="8" tag_type="list"><b>Realtime.</b></text>
<text top="405" left="123" width="177" height="9" font="font11" id="p2_t26" reading_order_no="25" segment_no="8" tag_type="list">Thanks to our specially designed neural</text>
<text top="417" left="78" width="222" height="9" font="font11" id="p2_t27" reading_order_no="26" segment_no="8" tag_type="list">network, we are able to regress multiple human</text>
<text top="428" left="78" width="222" height="9" font="font11" id="p2_t28" reading_order_no="27" segment_no="8" tag_type="list">structural features from single images in realtime.</text>
<text top="440" left="78" width="222" height="9" font="font11" id="p2_t29" reading_order_no="28" segment_no="8" tag_type="list">We further feed network outputs to an efficient 3D</text>
<text top="451" left="78" width="222" height="9" font="font11" id="p2_t30" reading_order_no="29" segment_no="8" tag_type="list">human pose and body geometry fitting optimizer,</text>
<text top="463" left="78" width="209" height="9" font="font11" id="p2_t31" reading_order_no="30" segment_no="8" tag_type="list">and achieve realtime reconstruction performance.</text>
<text top="476" left="62" width="4" height="7" font="font17" id="p2_t32" reading_order_no="31" segment_no="9" tag_type="list">•</text>
<text top="475" left="78" width="131" height="9" font="font18" id="p2_t33" reading_order_no="32" segment_no="9" tag_type="list"><b>Fully automatic and robust.</b></text>
<text top="475" left="215" width="85" height="9" font="font11" id="p2_t34" reading_order_no="33" segment_no="9" tag_type="list">With the abundant</text>
<text top="486" left="78" width="222" height="9" font="font11" id="p2_t35" reading_order_no="34" segment_no="9" tag_type="list">regression outputs per-frame, reconstruction can be</text>
<text top="498" left="78" width="222" height="9" font="font11" id="p2_t36" reading_order_no="35" segment_no="9" tag_type="list">achieved from one single image, independent of any</text>
<text top="509" left="78" width="222" height="9" font="font11" id="p2_t37" reading_order_no="36" segment_no="9" tag_type="list">pre-initialized state. This makes reconstruction from</text>
<text top="521" left="78" width="222" height="9" font="font11" id="p2_t38" reading_order_no="37" segment_no="9" tag_type="list">videos no longer suffers from the headache of re-</text>
<text top="532" left="78" width="222" height="9" font="font11" id="p2_t39" reading_order_no="38" segment_no="9" tag_type="list">initialization. Our system is also robust to illumina-</text>
<text top="544" left="78" width="182" height="9" font="font11" id="p2_t40" reading_order_no="39" segment_no="9" tag_type="list">tion variation, as well as clothing diversity.</text>
<text top="557" left="62" width="4" height="7" font="font17" id="p2_t41" reading_order_no="40" segment_no="11" tag_type="list">•</text>
<text top="555" left="78" width="41" height="9" font="font18" id="p2_t42" reading_order_no="41" segment_no="11" tag_type="list"><b>Accuracy.</b></text>
<text top="555" left="122" width="178" height="9" font="font11" id="p2_t43" reading_order_no="42" segment_no="11" tag_type="list">Our realtime system achieves reconstruc-</text>
<text top="567" left="78" width="222" height="9" font="font11" id="p2_t44" reading_order_no="43" segment_no="11" tag_type="list">tion quality that is even more accurate than most</text>
<text top="578" left="78" width="222" height="9" font="font11" id="p2_t45" reading_order_no="44" segment_no="11" tag_type="list">offline or video-based methods in wild images. This</text>
<text top="590" left="78" width="222" height="9" font="font11" id="p2_t46" reading_order_no="45" segment_no="11" tag_type="list">achievement is mainly due to three points: (1) a novel</text>
<text top="601" left="78" width="222" height="9" font="font11" id="p2_t47" reading_order_no="46" segment_no="11" tag_type="list">multi-task deep learning network predicts abundant</text>
<text top="613" left="78" width="222" height="9" font="font11" id="p2_t48" reading_order_no="47" segment_no="11" tag_type="list">features, which boosts each other; (2) an efficient</text>
<text top="625" left="78" width="222" height="9" font="font11" id="p2_t49" reading_order_no="48" segment_no="11" tag_type="list">reconstruction process that seamlessly integrates all</text>
<text top="636" left="78" width="222" height="9" font="font11" id="p2_t50" reading_order_no="49" segment_no="11" tag_type="list">the visual features obtained from the deep learning</text>
<text top="648" left="78" width="222" height="9" font="font11" id="p2_t51" reading_order_no="50" segment_no="11" tag_type="list">network. (3) the augmentation to existing training</text>
<text top="659" left="78" width="161" height="9" font="font11" id="p2_t52" reading_order_no="51" segment_no="11" tag_type="list">dataset with our newly collected data.</text>
<text top="687" left="48" width="6" height="10" font="font7" id="p2_t53" reading_order_no="52" segment_no="12" tag_type="title"><b>2</b></text>
<text top="687" left="66" width="8" height="10" font="font7" id="p2_t54" reading_order_no="53" segment_no="12" tag_type="title"><b>R</b></text>
<text top="689" left="74" width="37" height="8" font="font8" id="p2_t55" reading_order_no="54" segment_no="12" tag_type="title"><b>ELATED</b></text>
<text top="687" left="115" width="10" height="10" font="font7" id="p2_t56" reading_order_no="55" segment_no="12" tag_type="title"><b>W</b></text>
<text top="689" left="126" width="21" height="8" font="font8" id="p2_t57" reading_order_no="56" segment_no="12" tag_type="title"><b>ORK</b></text>
<text top="703" left="48" width="252" height="9" font="font11" id="p2_t58" reading_order_no="57" segment_no="13" tag_type="text">The research on human body reconstruction from single</text>
<text top="714" left="48" width="252" height="9" font="font11" id="p2_t59" reading_order_no="58" segment_no="13" tag_type="text">RGB images is traced back to skeleton joints estimation,</text>
<text top="726" left="48" width="252" height="9" font="font11" id="p2_t60" reading_order_no="59" segment_no="13" tag_type="text">from 2D to 3D, and has achieved significant advances in</text>
<text top="737" left="48" width="252" height="9" font="font11" id="p2_t61" reading_order_no="60" segment_no="13" tag_type="text">recent years. This line of work has further boosted the</text>
<text top="296" left="312" width="252" height="9" font="font11" id="p2_t62" reading_order_no="61" segment_no="5" tag_type="text">interest for simultaneous pose and shape estimation. We will</text>
<text top="307" left="312" width="252" height="9" font="font11" id="p2_t63" reading_order_no="62" segment_no="5" tag_type="text">focus our review on 2D pose estimation, 3D pose and body</text>
<text top="319" left="312" width="146" height="9" font="font11" id="p2_t64" reading_order_no="63" segment_no="5" tag_type="text">reconstruction from single images.</text>
<text top="332" left="326" width="93" height="9" font="font18" id="p2_t65" reading_order_no="64" segment_no="6" tag_type="text"><b>2D Pose Estimation.</b></text>
<text top="332" left="425" width="139" height="9" font="font11" id="p2_t66" reading_order_no="65" segment_no="6" tag_type="text">Nowadays image based single-</text>
<text top="343" left="312" width="252" height="9" font="font11" id="p2_t67" reading_order_no="66" segment_no="6" tag_type="text">person estimation [6]–[8] has achieved great improvement</text>
<text top="355" left="312" width="252" height="9" font="font11" id="p2_t68" reading_order_no="67" segment_no="6" tag_type="text">due to the success of CNN. These methods usually regress</text>
<text top="366" left="312" width="252" height="9" font="font11" id="p2_t69" reading_order_no="68" segment_no="6" tag_type="text">a probability map for each joint, designating the probability</text>
<text top="378" left="312" width="252" height="9" font="font11" id="p2_t70" reading_order_no="69" segment_no="6" tag_type="text">of a joint being located on each image pixel. The image-</text>
<text top="390" left="312" width="252" height="9" font="font11" id="p2_t71" reading_order_no="70" segment_no="6" tag_type="text">to-surface correspondence (IUV), represented by human</text>
<text top="401" left="312" width="79" height="9" font="font11" id="p2_t72" reading_order_no="71" segment_no="6" tag_type="text">part partition and</text>
<text top="401" left="396" width="11" height="9" font="font14" id="p2_t73" reading_order_no="72" segment_no="6" tag_type="text">uv</text>
<text top="401" left="411" width="153" height="9" font="font11" id="p2_t74" reading_order_no="73" segment_no="6" tag_type="text">coordinates map, was proposed in</text>
<text top="413" left="312" width="252" height="9" font="font11" id="p2_t75" reading_order_no="74" segment_no="6" tag_type="text">Densepose [1], and it is more effective and expressive than</text>
<text top="424" left="312" width="225" height="9" font="font11" id="p2_t76" reading_order_no="75" segment_no="6" tag_type="text">positioning just sparse 2D joints. By predicting the</text>
<text top="424" left="541" width="4" height="9" font="font19" id="p2_t77" reading_order_no="76" segment_no="6" tag_type="text">(</text>
<text top="424" left="545" width="15" height="9" font="font14" id="p2_t78" reading_order_no="77" segment_no="6" tag_type="text">u, v</text>
<text top="424" left="560" width="4" height="9" font="font19" id="p2_t79" reading_order_no="78" segment_no="6" tag_type="text">)</text>
<text top="436" left="312" width="252" height="9" font="font11" id="p2_t80" reading_order_no="79" segment_no="6" tag_type="text">coordinates and body part index for each pixel, a dense</text>
<text top="447" left="312" width="252" height="9" font="font11" id="p2_t81" reading_order_no="80" segment_no="6" tag_type="text">correspondence between pixels and points on a 3D mesh</text>
<text top="459" left="312" width="252" height="9" font="font11" id="p2_t82" reading_order_no="81" segment_no="6" tag_type="text">is defined. Our goal is different from these 2D or dense</text>
<text top="470" left="312" width="252" height="9" font="font11" id="p2_t83" reading_order_no="82" segment_no="6" tag_type="text">pose estimation methods in that we focus on 3D pose and</text>
<text top="482" left="312" width="135" height="9" font="font11" id="p2_t84" reading_order_no="83" segment_no="6" tag_type="text">geometry model reconstruction.</text>
<text top="495" left="326" width="89" height="9" font="font18" id="p2_t85" reading_order_no="84" segment_no="10" tag_type="text"><b>3D Pose estimation.</b></text>
<text top="495" left="419" width="145" height="9" font="font11" id="p2_t86" reading_order_no="85" segment_no="10" tag_type="text">Other than regressing 2D pose or</text>
<text top="507" left="312" width="252" height="9" font="font11" id="p2_t87" reading_order_no="86" segment_no="10" tag_type="text">dense pose from single images, many people attempt to</text>
<text top="518" left="312" width="252" height="9" font="font11" id="p2_t88" reading_order_no="87" segment_no="10" tag_type="text">estimate 3D pose directly from images. Most recent works</text>
<text top="530" left="312" width="178" height="9" font="font11" id="p2_t89" reading_order_no="88" segment_no="10" tag_type="text">can be divided into two categories: the</text>
<text top="530" left="495" width="69" height="9" font="font20" id="p2_t90" reading_order_no="89" segment_no="10" tag_type="text">one-stage method</text>
<text top="541" left="312" width="32" height="9" font="font11" id="p2_t91" reading_order_no="90" segment_no="10" tag_type="text">and the</text>
<text top="541" left="347" width="68" height="9" font="font20" id="p2_t92" reading_order_no="91" segment_no="10" tag_type="text">two-stage method</text>
<text top="541" left="414" width="150" height="9" font="font11" id="p2_t93" reading_order_no="92" segment_no="10" tag_type="text">. In the two-stage methods [9]–[12],</text>
<text top="553" left="312" width="252" height="9" font="font11" id="p2_t94" reading_order_no="93" segment_no="10" tag_type="text">the task of 3D pose estimation is decoupled into 2D joint</text>
<text top="564" left="312" width="252" height="9" font="font11" id="p2_t95" reading_order_no="94" segment_no="10" tag_type="text">detection and 3D coordinate regression. However, due to</text>
<text top="576" left="312" width="252" height="9" font="font11" id="p2_t96" reading_order_no="95" segment_no="10" tag_type="text">ambiguity of 3D estimation from 2D joints, these methods</text>
<text top="587" left="312" width="252" height="9" font="font11" id="p2_t97" reading_order_no="96" segment_no="10" tag_type="text">not only overlook certain image features having 3D cues,</text>
<text top="599" left="312" width="252" height="9" font="font11" id="p2_t98" reading_order_no="97" segment_no="10" tag_type="text">but also are very sensitive to the results of 2D pose es-</text>
<text top="610" left="312" width="252" height="9" font="font11" id="p2_t99" reading_order_no="98" segment_no="10" tag_type="text">timation. To overcome the ambiguity in lifting 2D to 3D,</text>
<text top="622" left="312" width="252" height="9" font="font11" id="p2_t100" reading_order_no="99" segment_no="10" tag_type="text">priors are introduced in some works. Pavlakos et al. [13]</text>
<text top="634" left="312" width="252" height="9" font="font11" id="p2_t101" reading_order_no="100" segment_no="10" tag_type="text">further annotated the ordinal depth relation in the COCO</text>
<text top="645" left="312" width="252" height="9" font="font11" id="p2_t102" reading_order_no="101" segment_no="10" tag_type="text">dataset [14] and the MPII dataset [15], and proposed to</text>
<text top="657" left="312" width="252" height="9" font="font11" id="p2_t103" reading_order_no="102" segment_no="10" tag_type="text">estimate not only the 2D pose but also the ordinal depth</text>
<text top="668" left="312" width="252" height="9" font="font11" id="p2_t104" reading_order_no="103" segment_no="10" tag_type="text">relation as the extra input for lifting 2D to 3D. They achieved</text>
<text top="680" left="312" width="252" height="9" font="font11" id="p2_t105" reading_order_no="104" segment_no="10" tag_type="text">much better results. Different from [13], joint limits and</text>
<text top="691" left="312" width="252" height="9" font="font11" id="p2_t106" reading_order_no="105" segment_no="10" tag_type="text">bone lengths are introduced as constraints in [16]. The one-</text>
<text top="703" left="312" width="252" height="9" font="font11" id="p2_t107" reading_order_no="106" segment_no="10" tag_type="text">stage methods usually use a single cropped image as the</text>
<text top="714" left="312" width="252" height="9" font="font11" id="p2_t108" reading_order_no="107" segment_no="10" tag_type="text">input to a CNN, and directly obtain root-relative 3D joint</text>
<text top="726" left="312" width="252" height="9" font="font11" id="p2_t109" reading_order_no="108" segment_no="10" tag_type="text">positions [18]–[20], parent-relative joint positions [21], or</text>
<text top="737" left="312" width="252" height="9" font="font11" id="p2_t110" reading_order_no="109" segment_no="10" tag_type="text">voxel joint probability map [22], [23]. In the VNect method</text>
</page>
<page number="3" position="absolute" top="0" left="0" height="792" width="612">
	<fontspec id="font21" size="9" family="Calibri" color="#000000"/>
	<fontspec id="font22" size="8" family="Calibri" color="#000000"/>
<text top="29" left="48" width="334" height="6" font="font0" id="p3_t1" reading_order_no="0" segment_no="0" tag_type="title">IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS, VOL. XX, NO. , AUGUST 2020</text>
<text top="29" left="560" width="4" height="6" font="font0" id="p3_t2" reading_order_no="1" segment_no="1" tag_type="text">3</text>
<text top="54" left="411" width="79" height="13" font="font21" id="p3_t3" reading_order_no="10" segment_no="2" tag_type="figure">Full-body shape and </text>
<text top="65" left="414" width="72" height="13" font="font21" id="p3_t4" reading_order_no="11" segment_no="2" tag_type="figure">kinematic 3D pose </text>
<text top="77" left="421" width="56" height="13" font="font21" id="p3_t5" reading_order_no="12" segment_no="2" tag_type="figure">reconstruction</text>
<text top="60" left="275" width="19" height="13" font="font21" id="p3_t6" reading_order_no="4" segment_no="2" tag_type="figure">CNN </text>
<text top="71" left="263" width="41" height="13" font="font21" id="p3_t7" reading_order_no="5" segment_no="2" tag_type="figure">Regression</text>
<text top="60" left="155" width="30" height="13" font="font21" id="p3_t8" reading_order_no="2" segment_no="2" tag_type="figure">Human </text>
<text top="71" left="151" width="37" height="13" font="font21" id="p3_t9" reading_order_no="3" segment_no="2" tag_type="figure">Detection</text>
<text top="49" left="330" width="50" height="13" font="font21" id="p3_t10" reading_order_no="6" segment_no="2" tag_type="figure">a) 2D Joints</text>
<text top="60" left="330" width="36" height="13" font="font21" id="p3_t11" reading_order_no="7" segment_no="2" tag_type="figure">b) Mask</text>
<text top="71" left="330" width="30" height="13" font="font21" id="p3_t12" reading_order_no="8" segment_no="2" tag_type="figure">c) IUV</text>
<text top="83" left="330" width="31" height="13" font="font21" id="p3_t13" reading_order_no="9" segment_no="2" tag_type="figure">d) POF</text>
<text top="168" left="231" width="6" height="10" font="font22" id="p3_t14" reading_order_no="13" segment_no="2" tag_type="figure">a)</text>
<text top="168" left="272" width="6" height="10" font="font22" id="p3_t15" reading_order_no="14" segment_no="2" tag_type="figure">b)</text>
<text top="168" left="357" width="6" height="10" font="font22" id="p3_t16" reading_order_no="15" segment_no="2" tag_type="figure">c)</text>
<text top="168" left="439" width="6" height="10" font="font22" id="p3_t17" reading_order_no="16" segment_no="2" tag_type="figure">d)</text>
<text top="190" left="48" width="465" height="9" font="font11" id="p3_t18" reading_order_no="17" segment_no="3" tag_type="text">Fig. 2: System overview. The CNN outputs 2D joints, foreground mask, IUV (including body partition and</text>
<text top="190" left="517" width="6" height="9" font="font14" id="p3_t19" reading_order_no="18" segment_no="3" tag_type="text">u</text>
<text top="190" left="522" width="42" height="9" font="font11" id="p3_t20" reading_order_no="19" segment_no="3" tag_type="text">-map and</text>
<text top="201" left="48" width="5" height="9" font="font14" id="p3_t21" reading_order_no="20" segment_no="3" tag_type="text">v</text>
<text top="201" left="53" width="169" height="9" font="font11" id="p3_t22" reading_order_no="21" segment_no="3" tag_type="text">-map) and POF (Part Orientation Field).</text>
<text top="234" left="48" width="252" height="9" font="font11" id="p3_t23" reading_order_no="22" segment_no="4" tag_type="text">[3], a fully convolutional network structure is proposed</text>
<text top="246" left="48" width="252" height="9" font="font11" id="p3_t24" reading_order_no="23" segment_no="4" tag_type="text">to directly regress location maps, in order to decrease the</text>
<text top="257" left="48" width="252" height="9" font="font11" id="p3_t25" reading_order_no="24" segment_no="4" tag_type="text">dependency on tight bounding boxes for human. More</text>
<text top="269" left="48" width="252" height="9" font="font11" id="p3_t26" reading_order_no="25" segment_no="4" tag_type="text">importantly, VNect gets global coordinates rather than root-</text>
<text top="281" left="48" width="252" height="9" font="font11" id="p3_t27" reading_order_no="26" segment_no="4" tag_type="text">relative coordinates, and produces real-time performance.</text>
<text top="292" left="48" width="252" height="9" font="font11" id="p3_t28" reading_order_no="27" segment_no="4" tag_type="text">The OriNet [24] decouples bone lengths and bone ori-</text>
<text top="304" left="48" width="252" height="9" font="font11" id="p3_t29" reading_order_no="28" segment_no="4" tag_type="text">entations by representing 3D poses with 3D orientations</text>
<text top="315" left="48" width="252" height="9" font="font11" id="p3_t30" reading_order_no="29" segment_no="4" tag_type="text">of limbs, which are very suitable for motion control. We</text>
<text top="327" left="48" width="252" height="9" font="font11" id="p3_t31" reading_order_no="30" segment_no="4" tag_type="text">also adopt the representation of 3D orientations of limbs.</text>
<text top="338" left="48" width="252" height="9" font="font11" id="p3_t32" reading_order_no="31" segment_no="4" tag_type="text">Yet different from above 3D pose estimation network, we</text>
<text top="350" left="48" width="252" height="9" font="font11" id="p3_t33" reading_order_no="32" segment_no="4" tag_type="text">design an end-to-end network to regress a foreground mask,</text>
<text top="361" left="48" width="148" height="9" font="font11" id="p3_t34" reading_order_no="33" segment_no="4" tag_type="text">2D joint positions, body partition,</text>
<text top="361" left="200" width="11" height="9" font="font14" id="p3_t35" reading_order_no="34" segment_no="4" tag_type="text">uv</text>
<text top="361" left="215" width="85" height="9" font="font11" id="p3_t36" reading_order_no="35" segment_no="4" tag_type="text">coordinates and 3D</text>
<text top="373" left="48" width="252" height="9" font="font11" id="p3_t37" reading_order_no="36" segment_no="4" tag_type="text">part orientations simultaneously. Please note that existing</text>
<text top="384" left="48" width="252" height="9" font="font11" id="p3_t38" reading_order_no="37" segment_no="4" tag_type="text">works address only one or a subset of the tasks that we</text>
<text top="396" left="48" width="252" height="9" font="font11" id="p3_t39" reading_order_no="38" segment_no="4" tag_type="text">address. Multi-task learning usually boosts the quality of</text>
<text top="407" left="48" width="252" height="9" font="font11" id="p3_t40" reading_order_no="39" segment_no="4" tag_type="text">each individual output due to the correlation among tasks,</text>
<text top="419" left="48" width="252" height="9" font="font11" id="p3_t41" reading_order_no="40" segment_no="4" tag_type="text">and our experiments witness this fact. On the other hand,</text>
<text top="431" left="48" width="252" height="9" font="font11" id="p3_t42" reading_order_no="41" segment_no="4" tag_type="text">while their goal focuses on 3D pose estimation only, we</text>
<text top="442" left="48" width="252" height="9" font="font11" id="p3_t43" reading_order_no="42" segment_no="4" tag_type="text">further reconstruct human body geometry automatically.</text>
<text top="454" left="48" width="252" height="9" font="font11" id="p3_t44" reading_order_no="43" segment_no="4" tag_type="text">With these image features and the geometry model, we are</text>
<text top="465" left="48" width="252" height="9" font="font11" id="p3_t45" reading_order_no="44" segment_no="4" tag_type="text">able to obtain much more accurate pose reconstruction with</text>
<text top="477" left="48" width="98" height="9" font="font11" id="p3_t46" reading_order_no="45" segment_no="4" tag_type="text">strong temporal fitting.</text>
<text top="492" left="62" width="136" height="9" font="font18" id="p3_t47" reading_order_no="46" segment_no="7" tag_type="text"><b>Model-based Pose Estimation.</b></text>
<text top="492" left="202" width="98" height="9" font="font11" id="p3_t48" reading_order_no="47" segment_no="7" tag_type="text">Our method is related</text>
<text top="503" left="48" width="61" height="9" font="font11" id="p3_t49" reading_order_no="48" segment_no="7" tag_type="text">to one set of</text>
<text top="503" left="115" width="115" height="9" font="font20" id="p3_t50" reading_order_no="49" segment_no="7" tag_type="text">model-based pose estimation</text>
<text top="503" left="235" width="65" height="9" font="font11" id="p3_t51" reading_order_no="50" segment_no="7" tag_type="text">methods. Such</text>
<text top="515" left="48" width="252" height="9" font="font11" id="p3_t52" reading_order_no="51" segment_no="7" tag_type="text">approaches consider a parametric model of the human</text>
<text top="526" left="48" width="252" height="9" font="font11" id="p3_t53" reading_order_no="52" segment_no="7" tag_type="text">body, like SCAPE [25], SMPL [26] and SMPL-X [27], and</text>
<text top="538" left="48" width="252" height="9" font="font11" id="p3_t54" reading_order_no="53" segment_no="7" tag_type="text">the goal is to reconstruct a full 3D body pose and shape.</text>
<text top="549" left="48" width="201" height="9" font="font11" id="p3_t55" reading_order_no="54" segment_no="7" tag_type="text">These approaches can be further divided into</text>
<text top="549" left="253" width="47" height="9" font="font20" id="p3_t56" reading_order_no="55" segment_no="7" tag_type="text">model-based</text>
<text top="561" left="48" width="49" height="9" font="font20" id="p3_t57" reading_order_no="56" segment_no="7" tag_type="text">optimization</text>
<text top="561" left="99" width="16" height="9" font="font11" id="p3_t58" reading_order_no="57" segment_no="7" tag_type="text">and</text>
<text top="561" left="118" width="88" height="9" font="font20" id="p3_t59" reading_order_no="58" segment_no="7" tag_type="text">model-based regression</text>
<text top="561" left="206" width="2" height="9" font="font11" id="p3_t60" reading_order_no="59" segment_no="7" tag_type="text">.</text>
<text top="576" left="62" width="238" height="9" font="font11" id="p3_t61" reading_order_no="60" segment_no="8" tag_type="text">In the first category, [28] relies on annotated 2D ground</text>
<text top="587" left="48" width="252" height="9" font="font11" id="p3_t62" reading_order_no="61" segment_no="8" tag_type="text">truth, including joint landmarks and body silhouettes, to</text>
<text top="599" left="48" width="252" height="9" font="font11" id="p3_t63" reading_order_no="62" segment_no="8" tag_type="text">optimize the parameters of the SCAPE model through</text>
<text top="610" left="48" width="252" height="9" font="font11" id="p3_t64" reading_order_no="63" segment_no="8" tag_type="text">minimizing errors of the reprojected evidence. With the</text>
<text top="622" left="48" width="252" height="9" font="font11" id="p3_t65" reading_order_no="64" segment_no="8" tag_type="text">SMPLify approach [4], this procedure was made automatic</text>
<text top="634" left="48" width="252" height="9" font="font11" id="p3_t66" reading_order_no="65" segment_no="8" tag_type="text">by replacing annotated 2D joints with 2D pose estimator.</text>
<text top="645" left="48" width="252" height="9" font="font11" id="p3_t67" reading_order_no="66" segment_no="8" tag_type="text">The whole process is then independent of user interference.</text>
<text top="657" left="48" width="252" height="9" font="font11" id="p3_t68" reading_order_no="67" segment_no="8" tag_type="text">Moreover, inter-penetration constraints are introduced to</text>
<text top="668" left="48" width="252" height="9" font="font11" id="p3_t69" reading_order_no="68" segment_no="8" tag_type="text">decrease the depth ambiguity when lifting 2D joints to</text>
<text top="680" left="48" width="252" height="9" font="font11" id="p3_t70" reading_order_no="69" segment_no="8" tag_type="text">3D. The human shape estimation in SMPLify, however,</text>
<text top="691" left="48" width="252" height="9" font="font11" id="p3_t71" reading_order_no="70" segment_no="8" tag_type="text">relies on 2D joints only and does not constrain the body</text>
<text top="703" left="48" width="252" height="9" font="font11" id="p3_t72" reading_order_no="71" segment_no="8" tag_type="text">shape completely. To address this issue, UP3D [29] further</text>
<text top="714" left="48" width="252" height="9" font="font11" id="p3_t73" reading_order_no="72" segment_no="8" tag_type="text">extends the SMPLify method by adding human silhouette</text>
<text top="726" left="48" width="252" height="9" font="font11" id="p3_t74" reading_order_no="73" segment_no="8" tag_type="text">to estimate human shape parameters, with the pipeline</text>
<text top="737" left="48" width="252" height="9" font="font11" id="p3_t75" reading_order_no="74" segment_no="8" tag_type="text">being still automatic. Because of the binary representation</text>
<text top="234" left="312" width="252" height="9" font="font11" id="p3_t76" reading_order_no="75" segment_no="5" tag_type="text">of the human silhouette, as well as the introduction of</text>
<text top="246" left="312" width="252" height="9" font="font11" id="p3_t77" reading_order_no="76" segment_no="5" tag_type="text">cloth intervention in this method, the body shape is still</text>
<text top="257" left="312" width="252" height="9" font="font11" id="p3_t78" reading_order_no="77" segment_no="5" tag_type="text">not sufficiently constrained. To overcome these issues, two</text>
<text top="269" left="312" width="252" height="9" font="font11" id="p3_t79" reading_order_no="78" segment_no="5" tag_type="text">mechanisms have been introduced by our method. The first</text>
<text top="281" left="312" width="252" height="9" font="font11" id="p3_t80" reading_order_no="79" segment_no="5" tag_type="text">one is the IUV, which is albeit more expensive but provides</text>
<text top="292" left="312" width="252" height="9" font="font11" id="p3_t81" reading_order_no="80" segment_no="5" tag_type="text">a dense correspondence between an image and a 3D model.</text>
<text top="304" left="312" width="252" height="9" font="font11" id="p3_t82" reading_order_no="81" segment_no="5" tag_type="text">The second one is the 3D limb orientation, which makes the</text>
<text top="315" left="312" width="231" height="9" font="font11" id="p3_t83" reading_order_no="82" segment_no="5" tag_type="text">reconstruction of human shape and pose more precise.</text>
<text top="330" left="326" width="238" height="9" font="font11" id="p3_t84" reading_order_no="83" segment_no="6" tag_type="text">Among the model-based regression methods, HMR [30]</text>
<text top="342" left="312" width="252" height="9" font="font11" id="p3_t85" reading_order_no="84" segment_no="6" tag_type="text">uses a weakly supervised approach to regress the SMPL</text>
<text top="353" left="312" width="252" height="9" font="font11" id="p3_t86" reading_order_no="85" segment_no="6" tag_type="text">parameters directly from images, relying on 2D keypoints</text>
<text top="365" left="312" width="252" height="9" font="font11" id="p3_t87" reading_order_no="86" segment_no="6" tag_type="text">reprojection and a pose prior learnt in an adversarial man-</text>
<text top="376" left="312" width="252" height="9" font="font11" id="p3_t88" reading_order_no="87" segment_no="6" tag_type="text">ner. Instead of regressing SMPL parameters directly, CMR</text>
<text top="388" left="312" width="252" height="9" font="font11" id="p3_t89" reading_order_no="88" segment_no="6" tag_type="text">[31] builds a structure with Graph-CNN to model the con-</text>
<text top="399" left="312" width="252" height="9" font="font11" id="p3_t90" reading_order_no="89" segment_no="6" tag_type="text">nection of adjacent vertices of a human body mesh, and the</text>
<text top="411" left="312" width="252" height="9" font="font11" id="p3_t91" reading_order_no="90" segment_no="6" tag_type="text">3D coordinates of mesh vertices are directly regressed. EFT</text>
<text top="422" left="312" width="252" height="9" font="font11" id="p3_t92" reading_order_no="91" segment_no="6" tag_type="text">[32], on the other hand, attempts to enrich wild images with</text>
<text top="434" left="312" width="252" height="9" font="font11" id="p3_t93" reading_order_no="92" segment_no="6" tag_type="text">missing SMPL parameters. By fine-tuning the HMR for each</text>
<text top="445" left="312" width="252" height="9" font="font11" id="p3_t94" reading_order_no="93" segment_no="6" tag_type="text">wild image, a few iterations to minimize errors of the 2D</text>
<text top="457" left="312" width="252" height="9" font="font11" id="p3_t95" reading_order_no="94" segment_no="6" tag_type="text">projection, and the current SMPL parameters are obtained.</text>
<text top="469" left="312" width="252" height="9" font="font11" id="p3_t96" reading_order_no="95" segment_no="6" tag_type="text">Treating these parameters as the ground truth for wild</text>
<text top="480" left="312" width="252" height="9" font="font11" id="p3_t97" reading_order_no="96" segment_no="6" tag_type="text">images, the original HMR is fine-tuned for the whole wild</text>
<text top="492" left="312" width="252" height="9" font="font11" id="p3_t98" reading_order_no="97" segment_no="6" tag_type="text">datasets. SPIN [2] adopts a similar idea. Rather than fine-</text>
<text top="503" left="312" width="252" height="9" font="font11" id="p3_t99" reading_order_no="98" segment_no="6" tag_type="text">tuning the HMR to get the ground truth for wild images,</text>
<text top="515" left="312" width="252" height="9" font="font11" id="p3_t100" reading_order_no="99" segment_no="6" tag_type="text">SPIN use the optimization-based method, like SMPLify [4],</text>
<text top="526" left="312" width="252" height="9" font="font11" id="p3_t101" reading_order_no="100" segment_no="6" tag_type="text">to refine the result to be used by HMR as ground truth.</text>
<text top="538" left="312" width="252" height="9" font="font11" id="p3_t102" reading_order_no="101" segment_no="6" tag_type="text">Instead of directly regressing highly non-linear shape and</text>
<text top="549" left="312" width="252" height="9" font="font11" id="p3_t103" reading_order_no="102" segment_no="6" tag_type="text">pose parameters from an image, we regress multiple image</text>
<text top="561" left="312" width="252" height="9" font="font11" id="p3_t104" reading_order_no="103" segment_no="6" tag_type="text">features, and get body shape and pose by a well-designed</text>
<text top="572" left="312" width="252" height="9" font="font11" id="p3_t105" reading_order_no="104" segment_no="6" tag_type="text">optimization formulation. The experiments show that our</text>
<text top="584" left="312" width="252" height="9" font="font11" id="p3_t106" reading_order_no="105" segment_no="6" tag_type="text">reconstruction results are much more accurate, and also</text>
<text top="596" left="312" width="114" height="9" font="font11" id="p3_t107" reading_order_no="106" segment_no="6" tag_type="text">stable on image sequences.</text>
<text top="611" left="326" width="102" height="9" font="font18" id="p3_t108" reading_order_no="107" segment_no="9" tag_type="text"><b>Model-based tracking.</b></text>
<text top="610" left="434" width="130" height="9" font="font11" id="p3_t109" reading_order_no="108" segment_no="9" tag_type="text">Our work is also related to</text>
<text top="622" left="312" width="252" height="9" font="font11" id="p3_t110" reading_order_no="109" segment_no="9" tag_type="text">model-based tracking of 3D human poses using a single</text>
<text top="634" left="312" width="252" height="9" font="font11" id="p3_t111" reading_order_no="110" segment_no="9" tag_type="text">RGB camera. Usually this type of method pre-defines a</text>
<text top="645" left="312" width="252" height="9" font="font11" id="p3_t112" reading_order_no="111" segment_no="9" tag_type="text">human skeleton/body on initialization, and the 3D pose</text>
<text top="657" left="312" width="252" height="9" font="font11" id="p3_t113" reading_order_no="112" segment_no="9" tag_type="text">is updated by minimizing the inconsistency between the</text>
<text top="668" left="312" width="252" height="9" font="font11" id="p3_t114" reading_order_no="113" segment_no="9" tag_type="text">hypothesized poses and observed 2D measurements [33].</text>
<text top="680" left="312" width="252" height="9" font="font11" id="p3_t115" reading_order_no="114" segment_no="9" tag_type="text">This method, on one hand, needs a careful initialization;</text>
<text top="691" left="312" width="252" height="9" font="font11" id="p3_t116" reading_order_no="115" segment_no="9" tag_type="text">on the other hand the optimization is prone to get stuck</text>
<text top="703" left="312" width="252" height="9" font="font11" id="p3_t117" reading_order_no="116" segment_no="9" tag_type="text">in local minima, leading to track failures in the coming</text>
<text top="714" left="312" width="252" height="9" font="font11" id="p3_t118" reading_order_no="117" segment_no="9" tag_type="text">frames. What is different in our method is that the body</text>
<text top="726" left="312" width="252" height="9" font="font11" id="p3_t119" reading_order_no="118" segment_no="9" tag_type="text">model is reconstructed automatically, and is not sensitive to</text>
<text top="737" left="312" width="252" height="9" font="font11" id="p3_t120" reading_order_no="119" segment_no="9" tag_type="text">initialization under abundant constraints. Accurate results</text>
</page>
<page number="4" position="absolute" top="0" left="0" height="792" width="612">
	<fontspec id="font23" size="8" family="Calibri,Bold" color="#000000"/>
	<fontspec id="font24" size="5" family="Calibri,Bold" color="#000000"/>
	<fontspec id="font25" size="9" family="Calibri,Bold" color="#000000"/>
	<fontspec id="font26" size="11" family="Calibri,Bold" color="#000000"/>
	<fontspec id="font27" size="11" family="MicrosoftYaHei,Bold" color="#000000"/>
	<fontspec id="font28" size="4" family="TimesNewRomanPSMT" color="#000000"/>
	<fontspec id="font29" size="8" family="TimesNewRomanPS,Italic" color="#000000"/>
	<fontspec id="font30" size="4" family="TimesNewRomanPS,Italic" color="#000000"/>
	<fontspec id="font31" size="8" family="TimesNewRomanPSMT" color="#000000"/>
	<fontspec id="font32" size="8" family="SymbolMT" color="#000000"/>
	<fontspec id="font33" size="5" family="Calibri,Bold" color="#ffffff"/>
	<fontspec id="font34" size="6" family="Calibri" color="#000000"/>
	<fontspec id="font35" size="9" family="Calibri" color="#ffffff"/>
	<fontspec id="font36" size="10" family="CMSY10" color="#000000"/>
	<fontspec id="font37" size="7" family="CMR7" color="#000000"/>
	<fontspec id="font38" size="7" family="CMMI7" color="#000000"/>
<text top="29" left="48" width="334" height="6" font="font0" id="p4_t1" reading_order_no="0" segment_no="0" tag_type="title">IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS, VOL. XX, NO. , AUGUST 2020</text>
<text top="29" left="560" width="4" height="6" font="font0" id="p4_t2" reading_order_no="1" segment_no="1" tag_type="text">4</text>
<text top="126" left="157" width="3" height="11" font="font23" id="p4_t3" reading_order_no="8" segment_no="2" tag_type="figure"><b>F</b></text>
<text top="101" left="193" width="19" height="7" font="font24" id="p4_t4" reading_order_no="15" segment_no="2" tag_type="figure"><b>Branch 1</b></text>
<text top="140" left="193" width="19" height="7" font="font24" id="p4_t5" reading_order_no="31" segment_no="2" tag_type="figure"><b>Branch 2</b></text>
<text top="166" left="193" width="19" height="7" font="font24" id="p4_t6" reading_order_no="35" segment_no="2" tag_type="figure"><b>Branch 3</b></text>
<text top="166" left="238" width="9" height="7" font="font24" id="p4_t7" reading_order_no="36" segment_no="2" tag_type="figure"><b>UVs</b></text>
<text top="125" left="92" width="2" height="12" font="font25" id="p4_t8" reading_order_no="2" segment_no="2" tag_type="figure"><b>I</b></text>
<text top="101" left="325" width="19" height="7" font="font24" id="p4_t9" reading_order_no="27" segment_no="2" tag_type="figure"><b>Branch 1</b></text>
<text top="140" left="325" width="19" height="7" font="font24" id="p4_t10" reading_order_no="40" segment_no="2" tag_type="figure"><b>Branch 2</b></text>
<text top="166" left="325" width="19" height="7" font="font24" id="p4_t11" reading_order_no="44" segment_no="2" tag_type="figure"><b>Branch 3</b></text>
<text top="166" left="369" width="9" height="7" font="font24" id="p4_t12" reading_order_no="45" segment_no="2" tag_type="figure"><b>UVs</b></text>
<text top="123" left="415" width="5" height="15" font="font26" id="p4_t13" reading_order_no="48" segment_no="2" tag_type="figure"><b>+</b></text>
<text top="112" left="449" width="19" height="7" font="font24" id="p4_t14" reading_order_no="54" segment_no="2" tag_type="figure"><b>Branch 2</b></text>
<text top="163" left="449" width="19" height="7" font="font24" id="p4_t15" reading_order_no="62" segment_no="2" tag_type="figure"><b>Branch 4</b></text>
<text top="163" left="492" width="12" height="7" font="font24" id="p4_t16" reading_order_no="63" segment_no="2" tag_type="figure"><b>Mask</b></text>
<text top="83" left="449" width="19" height="7" font="font24" id="p4_t17" reading_order_no="50" segment_no="2" tag_type="figure"><b>Branch 1</b></text>
<text top="189" left="449" width="19" height="7" font="font24" id="p4_t18" reading_order_no="66" segment_no="2" tag_type="figure"><b>Branch 5</b></text>
<text top="189" left="492" width="11" height="7" font="font24" id="p4_t19" reading_order_no="67" segment_no="2" tag_type="figure"><b>POFs</b></text>
<text top="75" left="214" width="23" height="11" font="font23" id="p4_t20" reading_order_no="14" segment_no="2" tag_type="figure"><b>stage 1</b></text>
<text top="60" left="469" width="23" height="11" font="font23" id="p4_t21" reading_order_no="49" segment_no="2" tag_type="figure"><b>stage 6</b></text>
<text top="97" left="287" width="8" height="14" font="font27" id="p4_t22" reading_order_no="19" segment_no="2" tag_type="figure"><b>+</b></text>
<text top="149" left="288" width="5" height="15" font="font26" id="p4_t23" reading_order_no="39" segment_no="2" tag_type="figure"><b>+</b></text>
<text top="93" left="266" width="2" height="6" font="font28" id="p4_t24" reading_order_no="18" segment_no="2" tag_type="figure">1</text>
<text top="93" left="259" width="5" height="10" font="font29" id="p4_t25" reading_order_no="17" segment_no="2" tag_type="figure"><i>H</i></text>
<text top="134" left="264" width="2" height="6" font="font28" id="p4_t26" reading_order_no="34" segment_no="2" tag_type="figure">1</text>
<text top="134" left="260" width="4" height="10" font="font29" id="p4_t27" reading_order_no="33" segment_no="2" tag_type="figure"><i>S</i></text>
<text top="158" left="265" width="2" height="6" font="font28" id="p4_t28" reading_order_no="38" segment_no="2" tag_type="figure">1</text>
<text top="159" left="259" width="5" height="10" font="font29" id="p4_t29" reading_order_no="37" segment_no="2" tag_type="figure"><i>U</i></text>
<text top="160" left="395" width="1" height="6" font="font30" id="p4_t30" reading_order_no="47" segment_no="2" tag_type="figure"><i>t</i></text>
<text top="160" left="389" width="5" height="10" font="font29" id="p4_t31" reading_order_no="46" segment_no="2" tag_type="figure"><i>U</i></text>
<text top="134" left="394" width="1" height="6" font="font30" id="p4_t32" reading_order_no="43" segment_no="2" tag_type="figure"><i>t</i></text>
<text top="134" left="389" width="4" height="10" font="font29" id="p4_t33" reading_order_no="42" segment_no="2" tag_type="figure"><i>S</i></text>
<text top="93" left="395" width="1" height="6" font="font30" id="p4_t34" reading_order_no="30" segment_no="2" tag_type="figure"><i>t</i></text>
<text top="93" left="389" width="5" height="10" font="font29" id="p4_t35" reading_order_no="29" segment_no="2" tag_type="figure"><i>H</i></text>
<text top="77" left="331" width="19" height="11" font="font23" id="p4_t36" reading_order_no="20" segment_no="2" tag_type="figure"><b>stage </b></text>
<text top="78" left="379" width="4" height="10" font="font31" id="p4_t37" reading_order_no="26" segment_no="2" tag_type="figure">5</text>
<text top="78" left="358" width="4" height="10" font="font31" id="p4_t38" reading_order_no="22" segment_no="2" tag_type="figure">2</text>
<text top="78" left="373" width="4" height="9" font="font32" id="p4_t39" reading_order_no="25" segment_no="2" tag_type="figure"></text>
<text top="78" left="363" width="4" height="9" font="font32" id="p4_t40" reading_order_no="23" segment_no="2" tag_type="figure"></text>
<text top="78" left="369" width="2" height="10" font="font29" id="p4_t41" reading_order_no="24" segment_no="2" tag_type="figure"><i>t</i></text>
<text top="77" left="350" width="2" height="10" font="font29" id="p4_t42" reading_order_no="21" segment_no="2" tag_type="figure"><i>t</i></text>
<text top="83" left="520" width="2" height="6" font="font28" id="p4_t43" reading_order_no="53" segment_no="2" tag_type="figure">6</text>
<text top="83" left="513" width="5" height="10" font="font29" id="p4_t44" reading_order_no="52" segment_no="2" tag_type="figure"><i>H</i></text>
<text top="110" left="518" width="2" height="6" font="font28" id="p4_t45" reading_order_no="57" segment_no="2" tag_type="figure">6</text>
<text top="110" left="513" width="4" height="10" font="font29" id="p4_t46" reading_order_no="56" segment_no="2" tag_type="figure"><i>S</i></text>
<text top="138" left="449" width="19" height="7" font="font24" id="p4_t47" reading_order_no="58" segment_no="2" tag_type="figure"><b>Branch 3</b></text>
<text top="138" left="493" width="9" height="7" font="font24" id="p4_t48" reading_order_no="59" segment_no="2" tag_type="figure"><b>UVs</b></text>
<text top="136" left="520" width="2" height="6" font="font28" id="p4_t49" reading_order_no="61" segment_no="2" tag_type="figure">6</text>
<text top="137" left="513" width="5" height="10" font="font29" id="p4_t50" reading_order_no="60" segment_no="2" tag_type="figure"><i>U</i></text>
<text top="162" left="520" width="2" height="6" font="font28" id="p4_t51" reading_order_no="65" segment_no="2" tag_type="figure">6</text>
<text top="162" left="513" width="6" height="10" font="font29" id="p4_t52" reading_order_no="64" segment_no="2" tag_type="figure"><i>M</i></text>
<text top="124" left="116" width="16" height="7" font="font33" id="p4_t53" reading_order_no="6" segment_no="2" tag_type="figure"><b>Mobile</b></text>
<text top="130" left="116" width="16" height="7" font="font33" id="p4_t54" reading_order_no="7" segment_no="2" tag_type="figure"><b>Net-V2</b></text>
<text top="195" left="89" width="27" height="10" font="font22" id="p4_t55" reading_order_no="72" segment_no="2" tag_type="figure">Branch *</text>
<text top="215" left="187" width="4" height="10" font="font22" id="p4_t56" reading_order_no="83" segment_no="2" tag_type="figure">C</text>
<text top="215" left="102" width="4" height="10" font="font22" id="p4_t57" reading_order_no="74" segment_no="2" tag_type="figure">C</text>
<text top="223" left="101" width="8" height="8" font="font34" id="p4_t58" reading_order_no="75" segment_no="2" tag_type="figure">3x3</text>
<text top="215" left="131" width="4" height="10" font="font22" id="p4_t59" reading_order_no="77" segment_no="2" tag_type="figure">C</text>
<text top="223" left="128" width="8" height="8" font="font34" id="p4_t60" reading_order_no="78" segment_no="2" tag_type="figure">3x3</text>
<text top="215" left="158" width="4" height="10" font="font22" id="p4_t61" reading_order_no="80" segment_no="2" tag_type="figure">C</text>
<text top="223" left="156" width="8" height="8" font="font34" id="p4_t62" reading_order_no="81" segment_no="2" tag_type="figure">3x3</text>
<text top="215" left="215" width="4" height="10" font="font22" id="p4_t63" reading_order_no="86" segment_no="2" tag_type="figure">C</text>
<text top="224" left="184" width="8" height="8" font="font34" id="p4_t64" reading_order_no="84" segment_no="2" tag_type="figure">3x3</text>
<text top="224" left="213" width="8" height="8" font="font34" id="p4_t65" reading_order_no="87" segment_no="2" tag_type="figure">1x1</text>
<text top="205" left="92" width="4" height="10" font="font32" id="p4_t66" reading_order_no="73" segment_no="2" tag_type="figure"></text>
<text top="218" left="116" width="5" height="12" font="font35" id="p4_t67" reading_order_no="76" segment_no="2" tag_type="figure">B</text>
<text top="218" left="144" width="5" height="12" font="font35" id="p4_t68" reading_order_no="79" segment_no="2" tag_type="figure">B</text>
<text top="218" left="172" width="5" height="12" font="font35" id="p4_t69" reading_order_no="82" segment_no="2" tag_type="figure">B</text>
<text top="218" left="200" width="5" height="12" font="font35" id="p4_t70" reading_order_no="85" segment_no="2" tag_type="figure">B</text>
<text top="201" left="261" width="49" height="15" font="font22" id="p4_t71" reading_order_no="88" segment_no="2" tag_type="figure">C Convolution</text>
<text top="224" left="260" width="5" height="12" font="font35" id="p4_t72" reading_order_no="89" segment_no="2" tag_type="figure">B</text>
<text top="225" left="272" width="85" height="10" font="font22" id="p4_t73" reading_order_no="90" segment_no="2" tag_type="figure">Batch Normalization + ReLU</text>
<text top="203" left="322" width="5" height="15" font="font26" id="p4_t74" reading_order_no="91" segment_no="2" tag_type="figure"><b>+</b></text>
<text top="206" left="336" width="39" height="10" font="font22" id="p4_t75" reading_order_no="92" segment_no="2" tag_type="figure">Concatenate</text>
<text top="100" left="231" width="23" height="7" font="font24" id="p4_t76" reading_order_no="16" segment_no="2" tag_type="figure"><b>Heatmaps</b></text>
<text top="187" left="516" width="2" height="6" font="font28" id="p4_t77" reading_order_no="69" segment_no="2" tag_type="figure">6</text>
<text top="192" left="517" width="2" height="6" font="font28" id="p4_t78" reading_order_no="70" segment_no="2" tag_type="figure">3</text>
<text top="192" left="519" width="2" height="6" font="font30" id="p4_t79" reading_order_no="71" segment_no="2" tag_type="figure"><i>d</i></text>
<text top="187" left="513" width="4" height="10" font="font29" id="p4_t80" reading_order_no="68" segment_no="2" tag_type="figure"><i>L</i></text>
<text top="100" left="363" width="23" height="7" font="font24" id="p4_t81" reading_order_no="28" segment_no="2" tag_type="figure"><b>Heatmaps</b></text>
<text top="139" left="232" width="22" height="7" font="font24" id="p4_t82" reading_order_no="32" segment_no="2" tag_type="figure"><b>Partitions</b></text>
<text top="140" left="363" width="22" height="7" font="font24" id="p4_t83" reading_order_no="41" segment_no="2" tag_type="figure"><b>Partitions</b></text>
<text top="112" left="487" width="22" height="7" font="font24" id="p4_t84" reading_order_no="55" segment_no="2" tag_type="figure"><b>Partitions</b></text>
<text top="83" left="486" width="23" height="7" font="font24" id="p4_t85" reading_order_no="51" segment_no="2" tag_type="figure"><b>Heatmaps</b></text>
<text top="142" left="96" width="4" height="10" font="font29" id="p4_t86" reading_order_no="5" segment_no="2" tag_type="figure"><i>h</i></text>
<text top="142" left="85" width="5" height="10" font="font29" id="p4_t87" reading_order_no="3" segment_no="2" tag_type="figure"><i>w</i></text>
<text top="142" left="91" width="4" height="9" font="font32" id="p4_t88" reading_order_no="4" segment_no="2" tag_type="figure"></text>
<text top="142" left="164" width="6" height="10" font="font31" id="p4_t89" reading_order_no="13" segment_no="2" tag_type="figure">/8</text>
<text top="142" left="149" width="6" height="10" font="font31" id="p4_t90" reading_order_no="10" segment_no="2" tag_type="figure">/8</text>
<text top="143" left="160" width="4" height="10" font="font29" id="p4_t91" reading_order_no="12" segment_no="2" tag_type="figure"><i>h</i></text>
<text top="143" left="143" width="5" height="10" font="font29" id="p4_t92" reading_order_no="9" segment_no="2" tag_type="figure"><i>w</i></text>
<text top="143" left="155" width="4" height="9" font="font32" id="p4_t93" reading_order_no="11" segment_no="2" tag_type="figure"></text>
<text top="254" left="209" width="195" height="9" font="font11" id="p4_t94" reading_order_no="93" segment_no="3" tag_type="text">Fig. 3: Architecture of our multi-task network.</text>
<text top="287" left="48" width="252" height="9" font="font11" id="p4_t95" reading_order_no="94" segment_no="4" tag_type="text">are obtained from single images, therefore it is also robust</text>
<text top="298" left="48" width="87" height="9" font="font11" id="p4_t96" reading_order_no="95" segment_no="4" tag_type="text">on image sequences.</text>
<text top="310" left="62" width="238" height="9" font="font11" id="p4_t97" reading_order_no="96" segment_no="6" tag_type="text">Several other works combine the power of regression</text>
<text top="322" left="48" width="252" height="9" font="font11" id="p4_t98" reading_order_no="97" segment_no="6" tag_type="text">and fitting, as we do. The Total Capture method [34] re-</text>
<text top="333" left="48" width="252" height="9" font="font11" id="p4_t99" reading_order_no="98" segment_no="6" tag_type="text">gresses 2D joint positions and 3D limb orientations with a</text>
<text top="345" left="48" width="252" height="9" font="font11" id="p4_t100" reading_order_no="99" segment_no="6" tag_type="text">network, and then optimize human face, body, and hands</text>
<text top="356" left="48" width="252" height="9" font="font11" id="p4_t101" reading_order_no="100" segment_no="6" tag_type="text">with a unified model Adam [35]. Our method outputs</text>
<text top="368" left="48" width="252" height="9" font="font11" id="p4_t102" reading_order_no="101" segment_no="6" tag_type="text">more predictions in realtime (e.g. the IUV and foreground</text>
<text top="379" left="48" width="252" height="9" font="font11" id="p4_t103" reading_order_no="102" segment_no="6" tag_type="text">mask), thus gives more accurate reconstruction of body and</text>
<text top="391" left="48" width="252" height="9" font="font11" id="p4_t104" reading_order_no="103" segment_no="6" tag_type="text">pose. More importantly, the goal of our system design is</text>
<text top="402" left="48" width="252" height="9" font="font11" id="p4_t105" reading_order_no="104" segment_no="6" tag_type="text">realtime, therefore we want to discuss more about realtime</text>
<text top="414" left="48" width="252" height="9" font="font11" id="p4_t106" reading_order_no="105" segment_no="6" tag_type="text">systems here. VNect [3] is the first system that captures</text>
<text top="425" left="48" width="252" height="9" font="font11" id="p4_t107" reading_order_no="106" segment_no="6" tag_type="text">kinematic skeleton using a single RGB camera. It uses a</text>
<text top="437" left="48" width="252" height="9" font="font11" id="p4_t108" reading_order_no="107" segment_no="6" tag_type="text">fully convolutional network to regress 2D pose and 3D root-</text>
<text top="449" left="48" width="252" height="9" font="font11" id="p4_t109" reading_order_no="108" segment_no="6" tag_type="text">relative joint positions, and then fit for a kinematic skeleton.</text>
<text top="460" left="48" width="252" height="9" font="font11" id="p4_t110" reading_order_no="109" segment_no="6" tag_type="text">PhysCap [36] adds environment constraints for VNect to</text>
<text top="472" left="48" width="252" height="9" font="font11" id="p4_t111" reading_order_no="110" segment_no="6" tag_type="text">ensure the biophysical plausibility of human postures. In</text>
<text top="483" left="48" width="252" height="9" font="font11" id="p4_t112" reading_order_no="111" segment_no="6" tag_type="text">contrast, our multi-task network outputs more features thus</text>
<text top="495" left="48" width="252" height="9" font="font11" id="p4_t113" reading_order_no="112" segment_no="6" tag_type="text">more expressive geometry models can be reconstructed,</text>
<text top="506" left="48" width="252" height="9" font="font11" id="p4_t114" reading_order_no="113" segment_no="6" tag_type="text">which is manifested by the experimental results. Based on</text>
<text top="518" left="48" width="252" height="9" font="font11" id="p4_t115" reading_order_no="114" segment_no="6" tag_type="text">human skeleton pose capture, some methods further cap-</text>
<text top="529" left="48" width="252" height="9" font="font11" id="p4_t116" reading_order_no="115" segment_no="6" tag_type="text">ture non-rigid deformation of clothing using optimization</text>
<text top="541" left="48" width="252" height="9" font="font11" id="p4_t117" reading_order_no="116" segment_no="6" tag_type="text">such as MonoPerfCap [37] and LiveCap [38], or regression</text>
<text top="552" left="48" width="252" height="9" font="font11" id="p4_t118" reading_order_no="117" segment_no="6" tag_type="text">such as DeepCap [39]. However, the dependency on a pre-</text>
<text top="564" left="48" width="252" height="9" font="font11" id="p4_t119" reading_order_no="118" segment_no="6" tag_type="text">scanned, pre-reconstructed and pre-rigged subject-specific</text>
<text top="575" left="48" width="252" height="9" font="font11" id="p4_t120" reading_order_no="119" segment_no="6" tag_type="text">model limits the usability of these methods, while our</text>
<text top="587" left="48" width="108" height="9" font="font11" id="p4_t121" reading_order_no="120" segment_no="6" tag_type="text">system is fully automatic.</text>
<text top="617" left="48" width="6" height="10" font="font7" id="p4_t122" reading_order_no="121" segment_no="10" tag_type="title"><b>3</b></text>
<text top="617" left="66" width="9" height="10" font="font7" id="p4_t123" reading_order_no="122" segment_no="10" tag_type="title"><b>M</b></text>
<text top="618" left="76" width="33" height="8" font="font8" id="p4_t124" reading_order_no="123" segment_no="10" tag_type="title"><b>ETHOD</b></text>
<text top="617" left="112" width="9" height="10" font="font7" id="p4_t125" reading_order_no="124" segment_no="10" tag_type="title"><b>O</b></text>
<text top="618" left="121" width="43" height="8" font="font8" id="p4_t126" reading_order_no="125" segment_no="10" tag_type="title"><b>VERVIEW</b></text>
<text top="634" left="48" width="252" height="9" font="font11" id="p4_t127" reading_order_no="126" segment_no="11" tag_type="text">Our method takes as input a single RGB image with a</text>
<text top="645" left="48" width="252" height="9" font="font11" id="p4_t128" reading_order_no="127" segment_no="11" tag_type="text">single person, and outputs a 3D human body whose pose</text>
<text top="657" left="48" width="252" height="9" font="font11" id="p4_t129" reading_order_no="128" segment_no="11" tag_type="text">and shape are in accordance with the person in image.</text>
<text top="668" left="48" width="252" height="9" font="font11" id="p4_t130" reading_order_no="129" segment_no="11" tag_type="text">This method consists of two parts: a neural network that</text>
<text top="680" left="48" width="252" height="9" font="font11" id="p4_t131" reading_order_no="130" segment_no="11" tag_type="text">regress measurements of human anatomical structures, and</text>
<text top="691" left="48" width="252" height="9" font="font11" id="p4_t132" reading_order_no="131" segment_no="11" tag_type="text">an optimization model that utilizes the network outputs</text>
<text top="703" left="48" width="252" height="9" font="font11" id="p4_t133" reading_order_no="132" segment_no="11" tag_type="text">to build a 3D body mesh. For the regression part (§ 4),</text>
<text top="714" left="48" width="252" height="9" font="font11" id="p4_t134" reading_order_no="133" segment_no="11" tag_type="text">a human is first detected from image by YOLO [40], out-</text>
<text top="726" left="48" width="252" height="9" font="font11" id="p4_t135" reading_order_no="134" segment_no="11" tag_type="text">putting a bounding box. Then the cropped image is fed into</text>
<text top="737" left="48" width="252" height="9" font="font11" id="p4_t136" reading_order_no="135" segment_no="11" tag_type="text">a convolutional neural network (CNN) to get five outputs,</text>
<text top="287" left="312" width="252" height="9" font="font11" id="p4_t137" reading_order_no="136" segment_no="5" tag_type="text">namely foreground segmentation mask, 2D joints positions,</text>
<text top="298" left="312" width="65" height="9" font="font11" id="p4_t138" reading_order_no="137" segment_no="5" tag_type="text">body partition,</text>
<text top="298" left="382" width="11" height="9" font="font14" id="p4_t139" reading_order_no="138" segment_no="5" tag_type="text">uv</text>
<text top="298" left="398" width="166" height="9" font="font11" id="p4_t140" reading_order_no="139" segment_no="5" tag_type="text">coordinates, and 3D part orientations</text>
<text top="310" left="312" width="252" height="9" font="font11" id="p4_t141" reading_order_no="140" segment_no="5" tag_type="text">(which is also encoded as part orientation field [24], [34]).</text>
<text top="321" left="312" width="252" height="9" font="font11" id="p4_t142" reading_order_no="141" segment_no="5" tag_type="text">For the optimization part (§ 5), our method reconstructs</text>
<text top="333" left="312" width="252" height="9" font="font11" id="p4_t143" reading_order_no="142" segment_no="5" tag_type="text">body pose and shape by fitting a deformable human model.</text>
<text top="344" left="312" width="252" height="9" font="font11" id="p4_t144" reading_order_no="143" segment_no="5" tag_type="text">We show that with as many as five features being integrated</text>
<text top="356" left="312" width="252" height="9" font="font11" id="p4_t145" reading_order_no="144" segment_no="5" tag_type="text">into the optimization pipeline, the reconstruction reaches an</text>
<text top="368" left="312" width="252" height="9" font="font11" id="p4_t146" reading_order_no="145" segment_no="5" tag_type="text">accurate fitting that has not been seen before. The whole</text>
<text top="379" left="312" width="252" height="9" font="font11" id="p4_t147" reading_order_no="146" segment_no="5" tag_type="text">pipeline is illustrated in Fig. 2. The success of our approach</text>
<text top="391" left="312" width="252" height="9" font="font11" id="p4_t148" reading_order_no="147" segment_no="5" tag_type="text">also relies on the enlargement of publicly available training</text>
<text top="402" left="312" width="252" height="9" font="font11" id="p4_t149" reading_order_no="148" segment_no="5" tag_type="text">datasets. We describe how the new data is collected and</text>
<text top="414" left="312" width="243" height="9" font="font11" id="p4_t150" reading_order_no="149" segment_no="5" tag_type="text">preprocessed with our in-house acquisition system in § 6.</text>
<text top="443" left="312" width="6" height="10" font="font7" id="p4_t151" reading_order_no="150" segment_no="7" tag_type="title"><b>4</b></text>
<text top="443" left="330" width="7" height="10" font="font7" id="p4_t152" reading_order_no="151" segment_no="7" tag_type="title"><b>T</b></text>
<text top="445" left="337" width="13" height="8" font="font8" id="p4_t153" reading_order_no="152" segment_no="7" tag_type="title"><b>HE</b></text>
<text top="443" left="354" width="7" height="10" font="font7" id="p4_t154" reading_order_no="153" segment_no="7" tag_type="title"><b>T</b></text>
<text top="445" left="361" width="40" height="8" font="font8" id="p4_t155" reading_order_no="154" segment_no="7" tag_type="title"><b>RAINING</b></text>
<text top="443" left="405" width="8" height="10" font="font7" id="p4_t156" reading_order_no="155" segment_no="7" tag_type="title"><b>N</b></text>
<text top="445" left="413" width="42" height="8" font="font8" id="p4_t157" reading_order_no="156" segment_no="7" tag_type="title"><b>ETWORK</b></text>
<text top="460" left="312" width="252" height="9" font="font11" id="p4_t158" reading_order_no="157" segment_no="8" tag_type="text">As mentioned, the key of our method is a multi-task CNN</text>
<text top="472" left="312" width="252" height="9" font="font11" id="p4_t159" reading_order_no="158" segment_no="8" tag_type="text">regressor for predicting five human anatomical structures:</text>
<text top="483" left="312" width="252" height="9" font="font11" id="p4_t160" reading_order_no="159" segment_no="8" tag_type="text">foreground segmentation mask, 2D joints positions, body</text>
<text top="495" left="312" width="39" height="9" font="font11" id="p4_t161" reading_order_no="160" segment_no="8" tag_type="text">partition,</text>
<text top="495" left="357" width="11" height="9" font="font14" id="p4_t162" reading_order_no="161" segment_no="8" tag_type="text">uv</text>
<text top="495" left="373" width="191" height="9" font="font11" id="p4_t163" reading_order_no="162" segment_no="8" tag_type="text">coordinates and 3D part orientations. The</text>
<text top="506" left="312" width="252" height="9" font="font11" id="p4_t164" reading_order_no="163" segment_no="8" tag_type="text">motivation behind this multi-task architecture is that more</text>
<text top="518" left="312" width="252" height="9" font="font11" id="p4_t165" reading_order_no="164" segment_no="8" tag_type="text">outputs gives more visual cues to be used for reconstruc-</text>
<text top="529" left="312" width="252" height="9" font="font11" id="p4_t166" reading_order_no="165" segment_no="8" tag_type="text">tion. Actually this architecture refines multiple predictions</text>
<text top="541" left="312" width="252" height="9" font="font11" id="p4_t167" reading_order_no="166" segment_no="8" tag_type="text">recurrently, as a result each individual prediction turns to be</text>
<text top="552" left="312" width="252" height="9" font="font11" id="p4_t168" reading_order_no="167" segment_no="8" tag_type="text">more accurate. This is not a surprise, as the power of multi-</text>
<text top="564" left="312" width="252" height="9" font="font11" id="p4_t169" reading_order_no="168" segment_no="8" tag_type="text">task learning is that efficiency and prediction accuracy can</text>
<text top="576" left="312" width="252" height="9" font="font11" id="p4_t170" reading_order_no="169" segment_no="8" tag_type="text">be improved by learning multiple objectives from a shared</text>
<text top="587" left="312" width="81" height="9" font="font11" id="p4_t171" reading_order_no="170" segment_no="8" tag_type="text">representation [41].</text>
<text top="599" left="326" width="238" height="9" font="font11" id="p4_t172" reading_order_no="171" segment_no="9" tag_type="text">Our multi-task regressor is a fully convolutional net-</text>
<text top="610" left="312" width="185" height="9" font="font11" id="p4_t173" reading_order_no="172" segment_no="9" tag_type="text">work. More specificlly, given a RGB image</text>
<text top="610" left="501" width="4" height="9" font="font14" id="p4_t174" reading_order_no="173" segment_no="9" tag_type="text">I</text>
<text top="610" left="509" width="7" height="9" font="font36" id="p4_t175" reading_order_no="174" segment_no="9" tag_type="text">∈</text>
<text top="610" left="518" width="8" height="9" font="font14" id="p4_t176" reading_order_no="175" segment_no="9" tag_type="text">R</text>
<text top="609" left="526" width="4" height="6" font="font37" id="p4_t177" reading_order_no="176" segment_no="9" tag_type="text">3</text>
<text top="608" left="530" width="6" height="7" font="font17" id="p4_t178" reading_order_no="177" segment_no="9" tag_type="text">×</text>
<text top="609" left="536" width="6" height="6" font="font38" id="p4_t179" reading_order_no="178" segment_no="9" tag_type="text">w</text>
<text top="608" left="542" width="6" height="7" font="font17" id="p4_t180" reading_order_no="179" segment_no="9" tag_type="text">×</text>
<text top="609" left="548" width="5" height="6" font="font38" id="p4_t181" reading_order_no="180" segment_no="9" tag_type="text">h</text>
<text top="610" left="553" width="11" height="9" font="font11" id="p4_t182" reading_order_no="181" segment_no="9" tag_type="text">, a</text>
<text top="622" left="312" width="252" height="9" font="font11" id="p4_t183" reading_order_no="182" segment_no="9" tag_type="text">feed-forward network simultaneously predicts a set of 2D</text>
<text top="633" left="312" width="94" height="9" font="font11" id="p4_t184" reading_order_no="183" segment_no="9" tag_type="text">joint confidence maps</text>
<text top="633" left="410" width="8" height="9" font="font14" id="p4_t185" reading_order_no="184" segment_no="9" tag_type="text">H</text>
<text top="633" left="422" width="7" height="9" font="font36" id="p4_t186" reading_order_no="185" segment_no="9" tag_type="text">∈</text>
<text top="633" left="431" width="8" height="9" font="font14" id="p4_t187" reading_order_no="186" segment_no="9" tag_type="text">R</text>
<text top="632" left="439" width="4" height="6" font="font38" id="p4_t188" reading_order_no="187" segment_no="9" tag_type="text">J</text>
<text top="631" left="444" width="6" height="7" font="font17" id="p4_t189" reading_order_no="188" segment_no="9" tag_type="text">×</text>
<text top="632" left="450" width="6" height="6" font="font38" id="p4_t190" reading_order_no="189" segment_no="9" tag_type="text">w</text>
<text top="631" left="456" width="6" height="7" font="font17" id="p4_t191" reading_order_no="190" segment_no="9" tag_type="text">×</text>
<text top="632" left="462" width="5" height="6" font="font38" id="p4_t192" reading_order_no="191" segment_no="9" tag_type="text">h</text>
<text top="633" left="471" width="29" height="9" font="font11" id="p4_t193" reading_order_no="192" segment_no="9" tag_type="text">(where</text>
<text top="633" left="504" width="6" height="9" font="font14" id="p4_t194" reading_order_no="193" segment_no="9" tag_type="text">J</text>
<text top="633" left="515" width="22" height="9" font="font19" id="p4_t195" reading_order_no="194" segment_no="9" tag_type="text">= 18</text>
<text top="633" left="540" width="24" height="9" font="font11" id="p4_t196" reading_order_no="195" segment_no="9" tag_type="text">is the</text>
<text top="645" left="312" width="252" height="9" font="font11" id="p4_t197" reading_order_no="196" segment_no="9" tag_type="text">number of joints to predict), human mask probability map</text>
<text top="656" left="312" width="10" height="9" font="font14" id="p4_t198" reading_order_no="197" segment_no="9" tag_type="text">M</text>
<text top="656" left="326" width="7" height="9" font="font36" id="p4_t199" reading_order_no="198" segment_no="9" tag_type="text">∈</text>
<text top="656" left="335" width="8" height="9" font="font14" id="p4_t200" reading_order_no="199" segment_no="9" tag_type="text">R</text>
<text top="655" left="343" width="6" height="6" font="font38" id="p4_t201" reading_order_no="200" segment_no="9" tag_type="text">w</text>
<text top="654" left="349" width="6" height="7" font="font17" id="p4_t202" reading_order_no="201" segment_no="9" tag_type="text">×</text>
<text top="655" left="355" width="5" height="6" font="font38" id="p4_t203" reading_order_no="202" segment_no="9" tag_type="text">h</text>
<text top="656" left="360" width="147" height="9" font="font11" id="p4_t204" reading_order_no="203" segment_no="9" tag_type="text">, human part probability map plus</text>
<text top="656" left="510" width="11" height="9" font="font14" id="p4_t205" reading_order_no="204" segment_no="9" tag_type="text">uv</text>
<text top="656" left="524" width="40" height="9" font="font11" id="p4_t206" reading_order_no="205" segment_no="9" tag_type="text">map, and</text>
<text top="668" left="312" width="112" height="9" font="font11" id="p4_t207" reading_order_no="206" segment_no="9" tag_type="text">3D Part Orientation Fields</text>
<text top="668" left="427" width="7" height="9" font="font14" id="p4_t208" reading_order_no="207" segment_no="9" tag_type="text">L</text>
<text top="667" left="437" width="7" height="9" font="font36" id="p4_t209" reading_order_no="208" segment_no="9" tag_type="text">∈</text>
<text top="668" left="446" width="8" height="9" font="font14" id="p4_t210" reading_order_no="209" segment_no="9" tag_type="text">R</text>
<text top="666" left="454" width="4" height="6" font="font37" id="p4_t211" reading_order_no="210" segment_no="9" tag_type="text">3</text>
<text top="666" left="458" width="6" height="6" font="font38" id="p4_t212" reading_order_no="211" segment_no="9" tag_type="text">O</text>
<text top="666" left="464" width="6" height="7" font="font17" id="p4_t213" reading_order_no="212" segment_no="9" tag_type="text">×</text>
<text top="666" left="470" width="6" height="6" font="font38" id="p4_t214" reading_order_no="213" segment_no="9" tag_type="text">w</text>
<text top="666" left="476" width="6" height="7" font="font17" id="p4_t215" reading_order_no="214" segment_no="9" tag_type="text">×</text>
<text top="666" left="482" width="5" height="6" font="font38" id="p4_t216" reading_order_no="215" segment_no="9" tag_type="text">h</text>
<text top="668" left="488" width="32" height="9" font="font11" id="p4_t217" reading_order_no="216" segment_no="9" tag_type="text">, where</text>
<text top="668" left="522" width="8" height="9" font="font14" id="p4_t218" reading_order_no="217" segment_no="9" tag_type="text">O</text>
<text top="668" left="533" width="21" height="9" font="font19" id="p4_t219" reading_order_no="218" segment_no="9" tag_type="text">= 17</text>
<text top="668" left="557" width="7" height="9" font="font11" id="p4_t220" reading_order_no="219" segment_no="9" tag_type="text">is</text>
<text top="680" left="312" width="111" height="9" font="font11" id="p4_t221" reading_order_no="220" segment_no="9" tag_type="text">the number of body parts.</text>
<text top="691" left="326" width="72" height="9" font="font11" id="p4_t222" reading_order_no="221" segment_no="12" tag_type="text">We use the term</text>
<text top="691" left="402" width="38" height="9" font="font20" id="p4_t223" reading_order_no="222" segment_no="12" tag_type="text">IUV map</text>
<text top="691" left="444" width="120" height="9" font="font11" id="p4_t224" reading_order_no="223" segment_no="12" tag_type="text">to indicate human partition</text>
<text top="703" left="312" width="70" height="9" font="font11" id="p4_t225" reading_order_no="224" segment_no="12" tag_type="text">probability map</text>
<text top="703" left="386" width="6" height="9" font="font14" id="p4_t226" reading_order_no="225" segment_no="12" tag_type="text">S</text>
<text top="702" left="395" width="7" height="9" font="font36" id="p4_t227" reading_order_no="226" segment_no="12" tag_type="text">∈</text>
<text top="703" left="405" width="8" height="9" font="font14" id="p4_t228" reading_order_no="227" segment_no="12" tag_type="text">R</text>
<text top="701" left="413" width="3" height="6" font="font37" id="p4_t229" reading_order_no="228" segment_no="12" tag_type="text">(</text>
<text top="701" left="416" width="6" height="6" font="font38" id="p4_t230" reading_order_no="229" segment_no="12" tag_type="text">C</text>
<text top="701" left="422" width="13" height="6" font="font37" id="p4_t231" reading_order_no="230" segment_no="12" tag_type="text">+1)</text>
<text top="701" left="435" width="6" height="7" font="font17" id="p4_t232" reading_order_no="231" segment_no="12" tag_type="text">×</text>
<text top="701" left="441" width="6" height="6" font="font38" id="p4_t233" reading_order_no="232" segment_no="12" tag_type="text">w</text>
<text top="701" left="447" width="6" height="7" font="font17" id="p4_t234" reading_order_no="233" segment_no="12" tag_type="text">×</text>
<text top="701" left="453" width="5" height="6" font="font38" id="p4_t235" reading_order_no="234" segment_no="12" tag_type="text">h</text>
<text top="703" left="463" width="15" height="9" font="font11" id="p4_t236" reading_order_no="235" segment_no="12" tag_type="text">(for</text>
<text top="703" left="483" width="7" height="9" font="font14" id="p4_t237" reading_order_no="236" segment_no="12" tag_type="text">C</text>
<text top="703" left="496" width="23" height="9" font="font19" id="p4_t238" reading_order_no="237" segment_no="12" tag_type="text">= 24</text>
<text top="703" left="523" width="41" height="9" font="font11" id="p4_t239" reading_order_no="238" segment_no="12" tag_type="text">partitions</text>
<text top="714" left="312" width="109" height="9" font="font11" id="p4_t240" reading_order_no="239" segment_no="12" tag_type="text">and one background) and</text>
<text top="714" left="424" width="11" height="9" font="font14" id="p4_t241" reading_order_no="240" segment_no="12" tag_type="text">uv</text>
<text top="714" left="437" width="49" height="9" font="font11" id="p4_t242" reading_order_no="241" segment_no="12" tag_type="text">coordinates</text>
<text top="714" left="489" width="7" height="9" font="font14" id="p4_t243" reading_order_no="242" segment_no="12" tag_type="text">U</text>
<text top="714" left="499" width="7" height="9" font="font36" id="p4_t244" reading_order_no="243" segment_no="12" tag_type="text">∈</text>
<text top="714" left="509" width="8" height="9" font="font14" id="p4_t245" reading_order_no="244" segment_no="12" tag_type="text">R</text>
<text top="713" left="516" width="4" height="6" font="font37" id="p4_t246" reading_order_no="245" segment_no="12" tag_type="text">2</text>
<text top="713" left="520" width="6" height="6" font="font38" id="p4_t247" reading_order_no="246" segment_no="12" tag_type="text">C</text>
<text top="712" left="527" width="6" height="7" font="font17" id="p4_t248" reading_order_no="247" segment_no="12" tag_type="text">×</text>
<text top="713" left="533" width="6" height="6" font="font38" id="p4_t249" reading_order_no="248" segment_no="12" tag_type="text">w</text>
<text top="712" left="539" width="6" height="7" font="font17" id="p4_t250" reading_order_no="249" segment_no="12" tag_type="text">×</text>
<text top="713" left="545" width="5" height="6" font="font38" id="p4_t251" reading_order_no="250" segment_no="12" tag_type="text">h</text>
<text top="714" left="550" width="14" height="9" font="font11" id="p4_t252" reading_order_no="251" segment_no="12" tag_type="text">, as</text>
<text top="726" left="312" width="252" height="9" font="font11" id="p4_t253" reading_order_no="252" segment_no="12" tag_type="text">did in [1]. To our knowledge, no previous works have ever</text>
<text top="737" left="312" width="156" height="9" font="font11" id="p4_t254" reading_order_no="253" segment_no="12" tag_type="text">regressed so many outputs as we do.</text>
</page>
<page number="5" position="absolute" top="0" left="0" height="792" width="612">
	<fontspec id="font39" size="10" family="NimbusSanL,Bold" color="#000000"/>
<text top="29" left="48" width="334" height="6" font="font0" id="p5_t1" reading_order_no="0" segment_no="0" tag_type="title">IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS, VOL. XX, NO. , AUGUST 2020</text>
<text top="29" left="560" width="4" height="6" font="font0" id="p5_t2" reading_order_no="1" segment_no="1" tag_type="text">5</text>
<text top="45" left="48" width="13" height="9" font="font39" id="p5_t3" reading_order_no="2" segment_no="2" tag_type="title"><b>4.1</b></text>
<text top="45" left="71" width="122" height="9" font="font39" id="p5_t4" reading_order_no="3" segment_no="2" tag_type="title"><b>Multi-task CNN Regression</b></text>
<text top="60" left="48" width="252" height="9" font="font11" id="p5_t5" reading_order_no="4" segment_no="3" tag_type="text">Fig. 3 illustrates the structure of our multi-task network.</text>
<text top="71" left="48" width="252" height="9" font="font11" id="p5_t6" reading_order_no="5" segment_no="3" tag_type="text">It is inspired by architectures like [42]–[44], which refine</text>
<text top="83" left="48" width="252" height="9" font="font11" id="p5_t7" reading_order_no="6" segment_no="3" tag_type="text">the predictions recurrently. An image is first encoded by</text>
<text top="94" left="48" width="252" height="9" font="font11" id="p5_t8" reading_order_no="7" segment_no="3" tag_type="text">a convolutional network, generating a set of image features</text>
<text top="106" left="48" width="6" height="9" font="font14" id="p5_t9" reading_order_no="8" segment_no="3" tag_type="text">F</text>
<text top="106" left="56" width="244" height="9" font="font11" id="p5_t10" reading_order_no="9" segment_no="3" tag_type="text">, which are then passed over to the first estimation for</text>
<text top="117" left="48" width="252" height="9" font="font11" id="p5_t11" reading_order_no="10" segment_no="3" tag_type="text">each individual task at stage 2. We get coarse predictions</text>
<text top="129" left="48" width="112" height="9" font="font11" id="p5_t12" reading_order_no="11" segment_no="3" tag_type="text">for joint confidence maps</text>
<text top="129" left="165" width="8" height="9" font="font14" id="p5_t13" reading_order_no="12" segment_no="3" tag_type="text">H</text>
<text top="127" left="174" width="4" height="6" font="font37" id="p5_t14" reading_order_no="13" segment_no="3" tag_type="text">1</text>
<text top="129" left="178" width="122" height="9" font="font11" id="p5_t15" reading_order_no="14" segment_no="3" tag_type="text">, IUV maps (body partition</text>
<text top="140" left="48" width="6" height="9" font="font14" id="p5_t16" reading_order_no="15" segment_no="3" tag_type="text">S</text>
<text top="139" left="55" width="4" height="6" font="font37" id="p5_t17" reading_order_no="16" segment_no="3" tag_type="text">1</text>
<text top="140" left="64" width="16" height="9" font="font11" id="p5_t18" reading_order_no="17" segment_no="3" tag_type="text">and</text>
<text top="140" left="85" width="11" height="9" font="font14" id="p5_t19" reading_order_no="18" segment_no="3" tag_type="text">uv</text>
<text top="140" left="100" width="49" height="9" font="font11" id="p5_t20" reading_order_no="19" segment_no="3" tag_type="text">coordinates</text>
<text top="140" left="154" width="7" height="9" font="font14" id="p5_t21" reading_order_no="20" segment_no="3" tag_type="text">U</text>
<text top="139" left="162" width="4" height="6" font="font37" id="p5_t22" reading_order_no="21" segment_no="3" tag_type="text">1</text>
<text top="140" left="166" width="134" height="9" font="font11" id="p5_t23" reading_order_no="22" segment_no="3" tag_type="text">) in stage 1. In the successive</text>
<text top="152" left="48" width="223" height="9" font="font11" id="p5_t24" reading_order_no="23" segment_no="3" tag_type="text">stages, the network takes as input the image feature</text>
<text top="152" left="274" width="6" height="9" font="font14" id="p5_t25" reading_order_no="24" segment_no="3" tag_type="text">F</text>
<text top="152" left="281" width="19" height="9" font="font11" id="p5_t26" reading_order_no="25" segment_no="3" tag_type="text">, the</text>
<text top="163" left="48" width="252" height="9" font="font11" id="p5_t27" reading_order_no="26" segment_no="3" tag_type="text">results of previous stages of the same type. We formulates</text>
<text top="175" left="48" width="106" height="9" font="font11" id="p5_t28" reading_order_no="27" segment_no="3" tag_type="text">the procedure as follows:</text>
<text top="198" left="122" width="8" height="9" font="font14" id="p5_t29" reading_order_no="28" segment_no="4" tag_type="formula">H</text>
<text top="196" left="131" width="3" height="6" font="font38" id="p5_t30" reading_order_no="29" segment_no="4" tag_type="formula">t</text>
<text top="198" left="137" width="8" height="9" font="font19" id="p5_t31" reading_order_no="30" segment_no="4" tag_type="formula">=</text>
<text top="198" left="148" width="4" height="9" font="font14" id="p5_t32" reading_order_no="31" segment_no="4" tag_type="formula">δ</text>
<text top="196" left="153" width="3" height="6" font="font38" id="p5_t33" reading_order_no="32" segment_no="4" tag_type="formula">t</text>
<text top="203" left="152" width="7" height="6" font="font38" id="p5_t34" reading_order_no="33" segment_no="4" tag_type="formula">H</text>
<text top="198" left="160" width="4" height="9" font="font19" id="p5_t35" reading_order_no="34" segment_no="4" tag_type="formula">(</text>
<text top="198" left="164" width="17" height="9" font="font14" id="p5_t36" reading_order_no="35" segment_no="4" tag_type="formula">Cat</text>
<text top="198" left="180" width="4" height="9" font="font19" id="p5_t37" reading_order_no="36" segment_no="4" tag_type="formula">(</text>
<text top="198" left="184" width="19" height="9" font="font14" id="p5_t38" reading_order_no="37" segment_no="4" tag_type="formula">F, H</text>
<text top="196" left="205" width="3" height="6" font="font38" id="p5_t39" reading_order_no="38" segment_no="4" tag_type="formula">t</text>
<text top="196" left="208" width="6" height="7" font="font17" id="p5_t40" reading_order_no="39" segment_no="4" tag_type="formula">−</text>
<text top="196" left="214" width="4" height="6" font="font37" id="p5_t41" reading_order_no="40" segment_no="4" tag_type="formula">1</text>
<text top="198" left="218" width="8" height="9" font="font19" id="p5_t42" reading_order_no="41" segment_no="4" tag_type="formula">))</text>
<text top="198" left="289" width="11" height="9" font="font11" id="p5_t43" reading_order_no="42" segment_no="5" tag_type="text">(1)</text>
<text top="216" left="112" width="6" height="9" font="font14" id="p5_t44" reading_order_no="43" segment_no="6" tag_type="formula">S</text>
<text top="214" left="119" width="3" height="6" font="font38" id="p5_t45" reading_order_no="44" segment_no="6" tag_type="formula">t</text>
<text top="216" left="125" width="8" height="9" font="font19" id="p5_t46" reading_order_no="45" segment_no="6" tag_type="formula">=</text>
<text top="216" left="136" width="4" height="9" font="font14" id="p5_t47" reading_order_no="46" segment_no="6" tag_type="formula">δ</text>
<text top="214" left="141" width="3" height="6" font="font38" id="p5_t48" reading_order_no="47" segment_no="6" tag_type="formula">t</text>
<text top="221" left="140" width="5" height="6" font="font38" id="p5_t49" reading_order_no="48" segment_no="6" tag_type="formula">S</text>
<text top="216" left="146" width="4" height="9" font="font19" id="p5_t50" reading_order_no="49" segment_no="6" tag_type="formula">(</text>
<text top="216" left="150" width="17" height="9" font="font14" id="p5_t51" reading_order_no="50" segment_no="6" tag_type="formula">Cat</text>
<text top="216" left="167" width="4" height="9" font="font19" id="p5_t52" reading_order_no="51" segment_no="6" tag_type="formula">(</text>
<text top="216" left="170" width="17" height="9" font="font14" id="p5_t53" reading_order_no="52" segment_no="6" tag_type="formula">F, S</text>
<text top="214" left="188" width="3" height="6" font="font38" id="p5_t54" reading_order_no="53" segment_no="6" tag_type="formula">t</text>
<text top="214" left="191" width="6" height="7" font="font17" id="p5_t55" reading_order_no="54" segment_no="6" tag_type="formula">−</text>
<text top="214" left="197" width="4" height="6" font="font37" id="p5_t56" reading_order_no="55" segment_no="6" tag_type="formula">1</text>
<text top="216" left="202" width="11" height="9" font="font14" id="p5_t57" reading_order_no="56" segment_no="6" tag_type="formula">, U</text>
<text top="214" left="214" width="3" height="6" font="font38" id="p5_t58" reading_order_no="57" segment_no="6" tag_type="formula">t</text>
<text top="214" left="217" width="6" height="7" font="font17" id="p5_t59" reading_order_no="58" segment_no="6" tag_type="formula">−</text>
<text top="214" left="223" width="4" height="6" font="font37" id="p5_t60" reading_order_no="59" segment_no="6" tag_type="formula">1</text>
<text top="216" left="228" width="8" height="9" font="font19" id="p5_t61" reading_order_no="60" segment_no="6" tag_type="formula">))</text>
<text top="216" left="289" width="11" height="9" font="font11" id="p5_t62" reading_order_no="61" segment_no="7" tag_type="text">(2)</text>
<text top="234" left="111" width="7" height="9" font="font14" id="p5_t63" reading_order_no="62" segment_no="8" tag_type="formula">U</text>
<text top="232" left="119" width="3" height="6" font="font38" id="p5_t64" reading_order_no="63" segment_no="8" tag_type="formula">t</text>
<text top="234" left="125" width="8" height="9" font="font19" id="p5_t65" reading_order_no="64" segment_no="8" tag_type="formula">=</text>
<text top="234" left="136" width="4" height="9" font="font14" id="p5_t66" reading_order_no="65" segment_no="8" tag_type="formula">δ</text>
<text top="232" left="141" width="3" height="6" font="font38" id="p5_t67" reading_order_no="66" segment_no="8" tag_type="formula">t</text>
<text top="239" left="140" width="5" height="6" font="font38" id="p5_t68" reading_order_no="67" segment_no="8" tag_type="formula">U</text>
<text top="234" left="147" width="4" height="9" font="font19" id="p5_t69" reading_order_no="68" segment_no="8" tag_type="formula">(</text>
<text top="234" left="151" width="17" height="9" font="font14" id="p5_t70" reading_order_no="69" segment_no="8" tag_type="formula">Cat</text>
<text top="234" left="168" width="4" height="9" font="font19" id="p5_t71" reading_order_no="70" segment_no="8" tag_type="formula">(</text>
<text top="234" left="171" width="17" height="9" font="font14" id="p5_t72" reading_order_no="71" segment_no="8" tag_type="formula">F, S</text>
<text top="232" left="189" width="3" height="6" font="font38" id="p5_t73" reading_order_no="72" segment_no="8" tag_type="formula">t</text>
<text top="232" left="192" width="6" height="7" font="font17" id="p5_t74" reading_order_no="73" segment_no="8" tag_type="formula">−</text>
<text top="232" left="199" width="4" height="6" font="font37" id="p5_t75" reading_order_no="74" segment_no="8" tag_type="formula">1</text>
<text top="234" left="203" width="11" height="9" font="font14" id="p5_t76" reading_order_no="75" segment_no="8" tag_type="formula">, U</text>
<text top="232" left="215" width="3" height="6" font="font38" id="p5_t77" reading_order_no="76" segment_no="8" tag_type="formula">t</text>
<text top="232" left="218" width="6" height="7" font="font17" id="p5_t78" reading_order_no="77" segment_no="8" tag_type="formula">−</text>
<text top="232" left="225" width="4" height="6" font="font37" id="p5_t79" reading_order_no="78" segment_no="8" tag_type="formula">1</text>
<text top="234" left="229" width="8" height="9" font="font19" id="p5_t80" reading_order_no="79" segment_no="8" tag_type="formula">))</text>
<text top="235" left="289" width="11" height="9" font="font11" id="p5_t81" reading_order_no="80" segment_no="9" tag_type="text">(3)</text>
<text top="253" left="48" width="26" height="9" font="font11" id="p5_t82" reading_order_no="81" segment_no="11" tag_type="text">where</text>
<text top="253" left="77" width="5" height="9" font="font19" id="p5_t83" reading_order_no="82" segment_no="11" tag_type="text">2</text>
<text top="252" left="85" width="8" height="9" font="font36" id="p5_t84" reading_order_no="83" segment_no="11" tag_type="text">≤</text>
<text top="253" left="96" width="4" height="9" font="font14" id="p5_t85" reading_order_no="84" segment_no="11" tag_type="text">t</text>
<text top="252" left="102" width="8" height="9" font="font36" id="p5_t86" reading_order_no="85" segment_no="11" tag_type="text">≤</text>
<text top="253" left="113" width="5" height="9" font="font19" id="p5_t87" reading_order_no="86" segment_no="11" tag_type="text">5</text>
<text top="253" left="121" width="95" height="9" font="font11" id="p5_t88" reading_order_no="87" segment_no="11" tag_type="text">is the stage index, and</text>
<text top="253" left="218" width="4" height="9" font="font14" id="p5_t89" reading_order_no="88" segment_no="11" tag_type="text">δ</text>
<text top="253" left="223" width="4" height="9" font="font19" id="p5_t90" reading_order_no="89" segment_no="11" tag_type="text">(</text>
<text top="252" left="227" width="3" height="9" font="font36" id="p5_t91" reading_order_no="90" segment_no="11" tag_type="text">·</text>
<text top="253" left="230" width="4" height="9" font="font19" id="p5_t92" reading_order_no="91" segment_no="11" tag_type="text">)</text>
<text top="253" left="236" width="64" height="9" font="font11" id="p5_t93" reading_order_no="92" segment_no="11" tag_type="text">is the mapping</text>
<text top="264" left="48" width="165" height="9" font="font11" id="p5_t94" reading_order_no="93" segment_no="11" tag_type="text">for Branch *, as defined as four Conv3</text>
<text top="264" left="213" width="8" height="9" font="font36" id="p5_t95" reading_order_no="94" segment_no="11" tag_type="text">×</text>
<text top="264" left="221" width="79" height="9" font="font11" id="p5_t96" reading_order_no="95" segment_no="11" tag_type="text">3-BN-ReLU blocks</text>
<text top="276" left="48" width="69" height="9" font="font11" id="p5_t97" reading_order_no="96" segment_no="11" tag_type="text">and one Conv1</text>
<text top="275" left="117" width="8" height="9" font="font36" id="p5_t98" reading_order_no="97" segment_no="11" tag_type="text">×</text>
<text top="276" left="125" width="113" height="9" font="font11" id="p5_t99" reading_order_no="98" segment_no="11" tag_type="text">1 task-specified regressor.</text>
<text top="276" left="243" width="17" height="9" font="font14" id="p5_t100" reading_order_no="99" segment_no="11" tag_type="text">Cat</text>
<text top="276" left="259" width="4" height="9" font="font19" id="p5_t101" reading_order_no="100" segment_no="11" tag_type="text">(</text>
<text top="275" left="263" width="3" height="9" font="font36" id="p5_t102" reading_order_no="101" segment_no="11" tag_type="text">·</text>
<text top="276" left="266" width="4" height="9" font="font19" id="p5_t103" reading_order_no="102" segment_no="11" tag_type="text">)</text>
<text top="276" left="275" width="25" height="9" font="font11" id="p5_t104" reading_order_no="103" segment_no="11" tag_type="text">is the</text>
<text top="287" left="48" width="252" height="9" font="font11" id="p5_t105" reading_order_no="104" segment_no="11" tag_type="text">concatenation operation. In stage 6, the joint confidence</text>
<text top="299" left="48" width="252" height="9" font="font11" id="p5_t106" reading_order_no="105" segment_no="11" tag_type="text">map and IUV map from the previous stage is concatenated</text>
<text top="310" left="48" width="252" height="9" font="font11" id="p5_t107" reading_order_no="106" segment_no="11" tag_type="text">and treated as input to predict not only the joint and IUV,</text>
<text top="322" left="48" width="178" height="9" font="font11" id="p5_t108" reading_order_no="107" segment_no="11" tag_type="text">but also two additional terms: the mask</text>
<text top="322" left="230" width="10" height="9" font="font14" id="p5_t109" reading_order_no="108" segment_no="11" tag_type="text">M</text>
<text top="322" left="245" width="55" height="9" font="font11" id="p5_t110" reading_order_no="109" segment_no="11" tag_type="text">and the part</text>
<text top="333" left="48" width="72" height="9" font="font11" id="p5_t111" reading_order_no="110" segment_no="11" tag_type="text">orientation maps</text>
<text top="333" left="122" width="7" height="9" font="font14" id="p5_t112" reading_order_no="111" segment_no="11" tag_type="text">L</text>
<text top="337" left="129" width="4" height="6" font="font37" id="p5_t113" reading_order_no="112" segment_no="11" tag_type="text">3</text>
<text top="337" left="133" width="4" height="6" font="font38" id="p5_t114" reading_order_no="113" segment_no="11" tag_type="text">d</text>
<text top="333" left="138" width="2" height="9" font="font11" id="p5_t115" reading_order_no="114" segment_no="11" tag_type="text">.</text>
<text top="345" left="62" width="51" height="9" font="font18" id="p5_t116" reading_order_no="115" segment_no="13" tag_type="text"><b>Loss Term.</b></text>
<text top="345" left="119" width="181" height="9" font="font11" id="p5_t117" reading_order_no="116" segment_no="13" tag_type="text">To guide the training of the multi-task</text>
<text top="357" left="48" width="252" height="9" font="font11" id="p5_t118" reading_order_no="117" segment_no="13" tag_type="text">network, we apply losses for predictions at each stage,</text>
<text top="368" left="48" width="47" height="9" font="font11" id="p5_t119" reading_order_no="118" segment_no="13" tag_type="text">specifically</text>
<text top="368" left="98" width="7" height="9" font="font14" id="p5_t120" reading_order_no="119" segment_no="13" tag_type="text">L</text>
<text top="372" left="104" width="4" height="6" font="font37" id="p5_t121" reading_order_no="120" segment_no="13" tag_type="text">2</text>
<text top="368" left="112" width="130" height="9" font="font11" id="p5_t122" reading_order_no="121" segment_no="13" tag_type="text">losses for the confidence maps</text>
<text top="368" left="244" width="8" height="9" font="font14" id="p5_t123" reading_order_no="122" segment_no="13" tag_type="text">H</text>
<text top="368" left="253" width="47" height="9" font="font11" id="p5_t124" reading_order_no="123" segment_no="13" tag_type="text">, POFs and</text>
<text top="380" left="48" width="14" height="9" font="font14" id="p5_t125" reading_order_no="124" segment_no="13" tag_type="text">U V</text>
<text top="380" left="66" width="77" height="9" font="font11" id="p5_t126" reading_order_no="125" segment_no="13" tag_type="text">maps. Note for the</text>
<text top="380" left="145" width="14" height="9" font="font14" id="p5_t127" reading_order_no="126" segment_no="13" tag_type="text">U V</text>
<text top="380" left="163" width="137" height="9" font="font11" id="p5_t128" reading_order_no="127" segment_no="13" tag_type="text">map, we only take into account a</text>
<text top="391" left="48" width="252" height="9" font="font11" id="p5_t129" reading_order_no="128" segment_no="13" tag_type="text">body part if the pixel is located inside it. When training part</text>
<text top="403" left="48" width="252" height="9" font="font11" id="p5_t130" reading_order_no="129" segment_no="13" tag_type="text">partition, a standard multi-class cross-entropy loss is used.</text>
<text top="414" left="48" width="252" height="9" font="font11" id="p5_t131" reading_order_no="130" segment_no="13" tag_type="text">Note that due to the difference of human part areas, we</text>
<text top="426" left="48" width="252" height="9" font="font11" id="p5_t132" reading_order_no="131" segment_no="13" tag_type="text">balance the supervision for part segmentation classification</text>
<text top="437" left="48" width="58" height="9" font="font11" id="p5_t133" reading_order_no="132" segment_no="13" tag_type="text">by the weight</text>
<text top="437" left="108" width="7" height="9" font="font14" id="p5_t134" reading_order_no="133" segment_no="13" tag_type="text">w</text>
<text top="441" left="115" width="4" height="6" font="font38" id="p5_t135" reading_order_no="134" segment_no="13" tag_type="text">c</text>
<text top="437" left="122" width="86" height="9" font="font11" id="p5_t136" reading_order_no="135" segment_no="13" tag_type="text">for each human part</text>
<text top="437" left="210" width="4" height="9" font="font14" id="p5_t137" reading_order_no="136" segment_no="13" tag_type="text">c</text>
<text top="437" left="214" width="86" height="9" font="font11" id="p5_t138" reading_order_no="137" segment_no="13" tag_type="text">, so that the network</text>
<text top="449" left="48" width="252" height="9" font="font11" id="p5_t139" reading_order_no="138" segment_no="13" tag_type="text">would not over-fit body parts of large area. The balance</text>
<text top="460" left="48" width="29" height="9" font="font11" id="p5_t140" reading_order_no="139" segment_no="13" tag_type="text">weight</text>
<text top="460" left="81" width="7" height="9" font="font14" id="p5_t141" reading_order_no="140" segment_no="13" tag_type="text">w</text>
<text top="464" left="88" width="4" height="6" font="font38" id="p5_t142" reading_order_no="141" segment_no="13" tag_type="text">c</text>
<text top="460" left="96" width="204" height="9" font="font11" id="p5_t143" reading_order_no="142" segment_no="13" tag_type="text">is inversely proportional to the part area, as in</text>
<text top="472" left="48" width="145" height="9" font="font11" id="p5_t144" reading_order_no="143" segment_no="13" tag_type="text">[45]. Our IUV (body partition and</text>
<text top="472" left="197" width="14" height="9" font="font14" id="p5_t145" reading_order_no="144" segment_no="13" tag_type="text">U V</text>
<text top="472" left="216" width="84" height="9" font="font11" id="p5_t146" reading_order_no="145" segment_no="13" tag_type="text">maps) ground truth</text>
<text top="484" left="48" width="252" height="9" font="font11" id="p5_t147" reading_order_no="146" segment_no="13" tag_type="text">for hands is inaccurate, because we fit a statistic model into</text>
<text top="495" left="48" width="252" height="9" font="font11" id="p5_t148" reading_order_no="147" segment_no="13" tag_type="text">a skeleton without finger joints, so we just ignore the IUV</text>
<text top="507" left="48" width="252" height="9" font="font11" id="p5_t149" reading_order_no="148" segment_no="13" tag_type="text">loss for hands. The segmentation mask is trained by binary</text>
<text top="518" left="48" width="78" height="9" font="font11" id="p5_t150" reading_order_no="149" segment_no="13" tag_type="text">cross-entropy loss.</text>
<text top="530" left="62" width="73" height="9" font="font18" id="p5_t151" reading_order_no="150" segment_no="15" tag_type="text"><b>Implementation.</b></text>
<text top="530" left="137" width="163" height="9" font="font11" id="p5_t152" reading_order_no="151" segment_no="15" tag_type="text">The training of our multi-task network</text>
<text top="541" left="48" width="252" height="9" font="font11" id="p5_t153" reading_order_no="152" segment_no="15" tag_type="text">consists of three phases. (1) First, we pre-train our net-</text>
<text top="553" left="48" width="252" height="9" font="font11" id="p5_t154" reading_order_no="153" segment_no="15" tag_type="text">work for the 2D joint detection task with in-the-wild image</text>
<text top="564" left="48" width="71" height="9" font="font11" id="p5_t155" reading_order_no="154" segment_no="15" tag_type="text">dataset for stage</text>
<text top="564" left="123" width="5" height="9" font="font19" id="p5_t156" reading_order_no="155" segment_no="15" tag_type="text">1</text>
<text top="564" left="132" width="8" height="9" font="font36" id="p5_t157" reading_order_no="156" segment_no="15" tag_type="text">∼</text>
<text top="564" left="144" width="5" height="9" font="font19" id="p5_t158" reading_order_no="157" segment_no="15" tag_type="text">5</text>
<text top="564" left="149" width="151" height="9" font="font11" id="p5_t159" reading_order_no="158" segment_no="15" tag_type="text">, ignoring other tasks, which gives</text>
<text top="576" left="48" width="252" height="9" font="font11" id="p5_t160" reading_order_no="159" segment_no="15" tag_type="text">better generalization performance. Our 2D joint detection</text>
<text top="587" left="48" width="197" height="9" font="font11" id="p5_t161" reading_order_no="160" segment_no="15" tag_type="text">task is trained with an initial learning rate of</text>
<text top="587" left="249" width="10" height="9" font="font19" id="p5_t162" reading_order_no="161" segment_no="15" tag_type="text">10</text>
<text top="585" left="259" width="6" height="7" font="font17" id="p5_t163" reading_order_no="162" segment_no="15" tag_type="text">−</text>
<text top="586" left="265" width="4" height="6" font="font37" id="p5_t164" reading_order_no="163" segment_no="15" tag_type="text">3</text>
<text top="587" left="273" width="27" height="9" font="font11" id="p5_t165" reading_order_no="164" segment_no="15" tag_type="text">and is</text>
<text top="599" left="48" width="169" height="9" font="font11" id="p5_t166" reading_order_no="165" segment_no="15" tag_type="text">reduced every 200,000 iters by a factor</text>
<text top="599" left="220" width="5" height="9" font="font14" id="p5_t167" reading_order_no="166" segment_no="15" tag_type="text">γ</text>
<text top="599" left="231" width="17" height="9" font="font19" id="p5_t168" reading_order_no="167" segment_no="15" tag_type="text">= 0</text>
<text top="599" left="248" width="3" height="9" font="font14" id="p5_t169" reading_order_no="168" segment_no="15" tag_type="text">.</text>
<text top="599" left="251" width="15" height="9" font="font19" id="p5_t170" reading_order_no="169" segment_no="15" tag_type="text">333</text>
<text top="599" left="266" width="34" height="9" font="font11" id="p5_t171" reading_order_no="170" segment_no="15" tag_type="text">, as [46]</text>
<text top="610" left="48" width="252" height="9" font="font11" id="p5_t172" reading_order_no="171" segment_no="15" tag_type="text">does. (2) Second, we combine our newly collected dataset</text>
<text top="622" left="48" width="252" height="9" font="font11" id="p5_t173" reading_order_no="172" segment_no="15" tag_type="text">with 2D joint dataset, and apply a mix-training strategy for</text>
<text top="634" left="48" width="252" height="9" font="font11" id="p5_t174" reading_order_no="173" segment_no="15" tag_type="text">other tasks while freezing the weights of feature extractor</text>
<text top="645" left="48" width="252" height="9" font="font11" id="p5_t175" reading_order_no="174" segment_no="15" tag_type="text">and 2D joint detector for 100,000 iters by a learning rate of</text>
<text top="656" left="48" width="5" height="9" font="font19" id="p5_t176" reading_order_no="175" segment_no="15" tag_type="text">5</text>
<text top="656" left="55" width="8" height="9" font="font36" id="p5_t177" reading_order_no="176" segment_no="15" tag_type="text">×</text>
<text top="656" left="65" width="10" height="9" font="font19" id="p5_t178" reading_order_no="177" segment_no="15" tag_type="text">10</text>
<text top="655" left="75" width="6" height="7" font="font17" id="p5_t179" reading_order_no="178" segment_no="15" tag_type="text">−</text>
<text top="655" left="81" width="4" height="6" font="font37" id="p5_t180" reading_order_no="179" segment_no="15" tag_type="text">4</text>
<text top="657" left="85" width="215" height="9" font="font11" id="p5_t181" reading_order_no="180" segment_no="15" tag_type="text">. Note that our newly collected data has all desired</text>
<text top="668" left="48" width="252" height="9" font="font11" id="p5_t182" reading_order_no="181" segment_no="15" tag_type="text">ground truth for every task. Fig. 4 shows a few images</text>
<text top="680" left="48" width="252" height="9" font="font11" id="p5_t183" reading_order_no="182" segment_no="15" tag_type="text">in it, including the original captures and the augmented</text>
<text top="691" left="48" width="252" height="9" font="font11" id="p5_t184" reading_order_no="183" segment_no="15" tag_type="text">ones through background replacement. Data augmentation</text>
<text top="703" left="48" width="252" height="9" font="font11" id="p5_t185" reading_order_no="184" segment_no="15" tag_type="text">with background replacement greatly increases the gener-</text>
<text top="714" left="48" width="252" height="9" font="font11" id="p5_t186" reading_order_no="185" segment_no="15" tag_type="text">alization of in-the-wild images. (3) Finally, we unfreeze the</text>
<text top="726" left="48" width="252" height="9" font="font11" id="p5_t187" reading_order_no="186" segment_no="15" tag_type="text">weights of well-trained 2D task and feature extractors, but</text>
<text top="737" left="48" width="252" height="9" font="font11" id="p5_t188" reading_order_no="187" segment_no="15" tag_type="text">apply a smaller learning rate (multiplied by 0.1) for these</text>
<text top="243" left="312" width="252" height="9" font="font11" id="p5_t189" reading_order_no="188" segment_no="10" tag_type="text">Fig. 4: Our training dataset contains original captured im-</text>
<text top="254" left="312" width="252" height="9" font="font11" id="p5_t190" reading_order_no="189" segment_no="10" tag_type="text">ages, as well as augmented images with background re-</text>
<text top="266" left="312" width="46" height="9" font="font11" id="p5_t191" reading_order_no="190" segment_no="10" tag_type="text">placement.</text>
<text top="299" left="312" width="252" height="9" font="font11" id="p5_t192" reading_order_no="191" segment_no="12" tag_type="text">weights. Our full-task training takes 1,000,000 iterations</text>
<text top="311" left="312" width="94" height="9" font="font11" id="p5_t193" reading_order_no="192" segment_no="12" tag_type="text">with a learning rate of</text>
<text top="311" left="409" width="5" height="9" font="font19" id="p5_t194" reading_order_no="193" segment_no="12" tag_type="text">5</text>
<text top="310" left="416" width="8" height="9" font="font36" id="p5_t195" reading_order_no="194" segment_no="12" tag_type="text">×</text>
<text top="311" left="426" width="10" height="9" font="font19" id="p5_t196" reading_order_no="195" segment_no="12" tag_type="text">10</text>
<text top="309" left="436" width="6" height="7" font="font17" id="p5_t197" reading_order_no="196" segment_no="12" tag_type="text">−</text>
<text top="309" left="442" width="4" height="6" font="font37" id="p5_t198" reading_order_no="197" segment_no="12" tag_type="text">4</text>
<text top="311" left="449" width="115" height="9" font="font11" id="p5_t199" reading_order_no="198" segment_no="12" tag_type="text">reduced every 200,000 iters</text>
<text top="322" left="312" width="46" height="9" font="font11" id="p5_t200" reading_order_no="199" segment_no="12" tag_type="text">by a factor</text>
<text top="322" left="361" width="5" height="9" font="font14" id="p5_t201" reading_order_no="200" segment_no="12" tag_type="text">γ</text>
<text top="322" left="370" width="16" height="9" font="font19" id="p5_t202" reading_order_no="201" segment_no="12" tag_type="text">= 0</text>
<text top="322" left="386" width="3" height="9" font="font14" id="p5_t203" reading_order_no="202" segment_no="12" tag_type="text">.</text>
<text top="322" left="389" width="15" height="9" font="font19" id="p5_t204" reading_order_no="203" segment_no="12" tag_type="text">333</text>
<text top="322" left="404" width="160" height="9" font="font11" id="p5_t205" reading_order_no="204" segment_no="12" tag_type="text">. We employ a rotation augmentation</text>
<text top="334" left="312" width="3" height="9" font="font11" id="p5_t206" reading_order_no="205" segment_no="12" tag_type="text">(</text>
<text top="333" left="315" width="8" height="9" font="font36" id="p5_t207" reading_order_no="206" segment_no="12" tag_type="text">±</text>
<text top="334" left="323" width="10" height="9" font="font19" id="p5_t208" reading_order_no="207" segment_no="12" tag_type="text">30</text>
<text top="332" left="333" width="4" height="7" font="font17" id="p5_t209" reading_order_no="208" segment_no="12" tag_type="text">◦</text>
<text top="334" left="337" width="227" height="9" font="font11" id="p5_t210" reading_order_no="209" segment_no="12" tag_type="text">), a scaling augmentation (0.75-1.25) and left-right</text>
<text top="345" left="312" width="252" height="9" font="font11" id="p5_t211" reading_order_no="210" segment_no="12" tag_type="text">flipping (only for in-the-wild dataset) for training. We use</text>
<text top="357" left="312" width="252" height="9" font="font11" id="p5_t212" reading_order_no="211" segment_no="12" tag_type="text">the Caffe framework [47] for network training, and use</text>
<text top="368" left="312" width="252" height="9" font="font11" id="p5_t213" reading_order_no="212" segment_no="12" tag_type="text">the Adadelta solver [48]. The performance of each task is</text>
<text top="380" left="312" width="252" height="9" font="font11" id="p5_t214" reading_order_no="213" segment_no="12" tag_type="text">strongly dependent on the relative weighting between the</text>
<text top="392" left="312" width="252" height="9" font="font11" id="p5_t215" reading_order_no="214" segment_no="12" tag_type="text">loss of each task [49]. And in our experiment, we set loss</text>
<text top="403" left="312" width="83" height="9" font="font11" id="p5_t216" reading_order_no="215" segment_no="12" tag_type="text">weights as follows:</text>
<text top="403" left="399" width="7" height="9" font="font14" id="p5_t217" reading_order_no="216" segment_no="12" tag_type="text">w</text>
<text top="403" left="412" width="18" height="9" font="font19" id="p5_t218" reading_order_no="217" segment_no="12" tag_type="text">= 0</text>
<text top="403" left="429" width="3" height="9" font="font14" id="p5_t219" reading_order_no="218" segment_no="12" tag_type="text">.</text>
<text top="403" left="432" width="5" height="9" font="font19" id="p5_t220" reading_order_no="219" segment_no="12" tag_type="text">5</text>
<text top="403" left="441" width="12" height="9" font="font11" id="p5_t221" reading_order_no="220" segment_no="12" tag_type="text">for</text>
<text top="403" left="457" width="14" height="9" font="font14" id="p5_t222" reading_order_no="221" segment_no="12" tag_type="text">U V</text>
<text top="403" left="473" width="2" height="9" font="font11" id="p5_t223" reading_order_no="222" segment_no="12" tag_type="text">,</text>
<text top="403" left="480" width="7" height="9" font="font14" id="p5_t224" reading_order_no="223" segment_no="12" tag_type="text">w</text>
<text top="403" left="492" width="18" height="9" font="font19" id="p5_t225" reading_order_no="224" segment_no="12" tag_type="text">= 0</text>
<text top="403" left="510" width="3" height="9" font="font14" id="p5_t226" reading_order_no="225" segment_no="12" tag_type="text">.</text>
<text top="403" left="512" width="10" height="9" font="font19" id="p5_t227" reading_order_no="226" segment_no="12" tag_type="text">05</text>
<text top="403" left="526" width="38" height="9" font="font11" id="p5_t228" reading_order_no="227" segment_no="12" tag_type="text">for body</text>
<text top="415" left="312" width="39" height="9" font="font11" id="p5_t229" reading_order_no="228" segment_no="12" tag_type="text">partition,</text>
<text top="414" left="355" width="7" height="9" font="font14" id="p5_t230" reading_order_no="229" segment_no="12" tag_type="text">w</text>
<text top="414" left="368" width="18" height="9" font="font19" id="p5_t231" reading_order_no="230" segment_no="12" tag_type="text">= 0</text>
<text top="414" left="386" width="3" height="9" font="font14" id="p5_t232" reading_order_no="231" segment_no="12" tag_type="text">.</text>
<text top="414" left="389" width="5" height="9" font="font19" id="p5_t233" reading_order_no="232" segment_no="12" tag_type="text">5</text>
<text top="415" left="398" width="55" height="9" font="font11" id="p5_t234" reading_order_no="233" segment_no="12" tag_type="text">for heatmap,</text>
<text top="414" left="458" width="7" height="9" font="font14" id="p5_t235" reading_order_no="234" segment_no="12" tag_type="text">w</text>
<text top="414" left="470" width="18" height="9" font="font19" id="p5_t236" reading_order_no="235" segment_no="12" tag_type="text">= 1</text>
<text top="414" left="488" width="3" height="9" font="font14" id="p5_t237" reading_order_no="236" segment_no="12" tag_type="text">.</text>
<text top="414" left="491" width="5" height="9" font="font19" id="p5_t238" reading_order_no="237" segment_no="12" tag_type="text">0</text>
<text top="415" left="500" width="64" height="9" font="font11" id="p5_t239" reading_order_no="238" segment_no="12" tag_type="text">for foreground</text>
<text top="426" left="312" width="44" height="9" font="font11" id="p5_t240" reading_order_no="239" segment_no="12" tag_type="text">mask and</text>
<text top="426" left="361" width="7" height="9" font="font14" id="p5_t241" reading_order_no="240" segment_no="12" tag_type="text">w</text>
<text top="426" left="375" width="19" height="9" font="font19" id="p5_t242" reading_order_no="241" segment_no="12" tag_type="text">= 1</text>
<text top="426" left="394" width="3" height="9" font="font14" id="p5_t243" reading_order_no="242" segment_no="12" tag_type="text">.</text>
<text top="426" left="397" width="5" height="9" font="font19" id="p5_t244" reading_order_no="243" segment_no="12" tag_type="text">0</text>
<text top="426" left="407" width="157" height="9" font="font11" id="p5_t245" reading_order_no="244" segment_no="12" tag_type="text">for POFs. To balance accuracy and</text>
<text top="438" left="312" width="252" height="9" font="font11" id="p5_t246" reading_order_no="245" segment_no="12" tag_type="text">efficiency, we use MobileNet-V2 [50] as our feature extractor.</text>
<text top="449" left="312" width="252" height="9" font="font11" id="p5_t247" reading_order_no="246" segment_no="12" tag_type="text">Note that we removed the downsampling operations in</text>
<text top="461" left="312" width="252" height="9" font="font11" id="p5_t248" reading_order_no="247" segment_no="12" tag_type="text">last two blocks (by replacing stride=2 in downsampling</text>
<text top="472" left="312" width="252" height="9" font="font11" id="p5_t249" reading_order_no="248" segment_no="12" tag_type="text">convolution with stride=1), and maintained the size of the</text>
<text top="484" left="312" width="102" height="9" font="font11" id="p5_t250" reading_order_no="249" segment_no="12" tag_type="text">final feature map to be</text>
<text top="484" left="418" width="5" height="9" font="font19" id="p5_t251" reading_order_no="250" segment_no="12" tag_type="text">1</text>
<text top="484" left="423" width="5" height="9" font="font14" id="p5_t252" reading_order_no="251" segment_no="12" tag_type="text">/</text>
<text top="484" left="428" width="5" height="9" font="font19" id="p5_t253" reading_order_no="252" segment_no="12" tag_type="text">8</text>
<text top="484" left="438" width="126" height="9" font="font11" id="p5_t254" reading_order_no="253" segment_no="12" tag_type="text">of the input image, which is</text>
<text top="495" left="312" width="48" height="9" font="font11" id="p5_t255" reading_order_no="254" segment_no="12" tag_type="text">224-by-224.</text>
<text top="525" left="312" width="6" height="10" font="font7" id="p5_t256" reading_order_no="255" segment_no="14" tag_type="title"><b>5</b></text>
<text top="525" left="330" width="8" height="10" font="font7" id="p5_t257" reading_order_no="256" segment_no="14" tag_type="title"><b>A</b></text>
<text top="527" left="338" width="49" height="8" font="font8" id="p5_t258" reading_order_no="257" segment_no="14" tag_type="title"><b>UTOMATIC</b></text>
<text top="525" left="395" width="8" height="10" font="font7" id="p5_t259" reading_order_no="258" segment_no="14" tag_type="title"><b>K</b></text>
<text top="527" left="403" width="46" height="8" font="font8" id="p5_t260" reading_order_no="259" segment_no="14" tag_type="title"><b>INEMATIC</b></text>
<text top="525" left="456" width="7" height="10" font="font7" id="p5_t261" reading_order_no="260" segment_no="14" tag_type="title"><b>P</b></text>
<text top="527" left="464" width="20" height="8" font="font8" id="p5_t262" reading_order_no="261" segment_no="14" tag_type="title"><b>OSE</b></text>
<text top="525" left="491" width="8" height="10" font="font7" id="p5_t263" reading_order_no="262" segment_no="14" tag_type="title"><b>R</b></text>
<text top="527" left="500" width="60" height="8" font="font8" id="p5_t264" reading_order_no="263" segment_no="14" tag_type="title"><b>ECONSTRUC</b></text>
<text top="525" left="560" width="4" height="10" font="font7" id="p5_t265" reading_order_no="264" segment_no="14" tag_type="title"><b>-</b></text>
<text top="540" left="312" width="46" height="8" font="font8" id="p5_t266" reading_order_no="265" segment_no="14" tag_type="title"><b>TION AND</b></text>
<text top="539" left="362" width="7" height="10" font="font7" id="p5_t267" reading_order_no="266" segment_no="14" tag_type="title"><b>F</b></text>
<text top="540" left="370" width="18" height="8" font="font8" id="p5_t268" reading_order_no="267" segment_no="14" tag_type="title"><b>ULL</b></text>
<text top="539" left="388" width="4" height="10" font="font7" id="p5_t269" reading_order_no="268" segment_no="14" tag_type="title"><b>-</b></text>
<text top="540" left="392" width="26" height="8" font="font8" id="p5_t270" reading_order_no="269" segment_no="14" tag_type="title"><b>BODY</b></text>
<text top="539" left="423" width="7" height="10" font="font7" id="p5_t271" reading_order_no="270" segment_no="14" tag_type="title"><b>S</b></text>
<text top="540" left="430" width="26" height="8" font="font8" id="p5_t272" reading_order_no="271" segment_no="14" tag_type="title"><b>HAPE</b></text>
<text top="539" left="460" width="9" height="10" font="font7" id="p5_t273" reading_order_no="272" segment_no="14" tag_type="title"><b>M</b></text>
<text top="540" left="470" width="43" height="8" font="font8" id="p5_t274" reading_order_no="273" segment_no="14" tag_type="title"><b>ODELING</b></text>
<text top="555" left="312" width="252" height="9" font="font11" id="p5_t275" reading_order_no="274" segment_no="16" tag_type="text">Our work sets a new mark in terms of level-of-detail</text>
<text top="567" left="312" width="252" height="9" font="font11" id="p5_t276" reading_order_no="275" segment_no="16" tag_type="text">that previous work did not reach. This mainly attributes</text>
<text top="578" left="312" width="252" height="9" font="font11" id="p5_t277" reading_order_no="276" segment_no="16" tag_type="text">to our innovative kinematic pose reconstruction and full-</text>
<text top="590" left="312" width="252" height="9" font="font11" id="p5_t278" reading_order_no="277" segment_no="16" tag_type="text">body shape modeling. The network output (as in § 4) is</text>
<text top="601" left="312" width="252" height="9" font="font11" id="p5_t279" reading_order_no="278" segment_no="16" tag_type="text">of low-quality and noisy, and may not be compatible with</text>
<text top="613" left="312" width="252" height="9" font="font11" id="p5_t280" reading_order_no="279" segment_no="16" tag_type="text">input images or with human kinematic constraints. Directly</text>
<text top="625" left="312" width="252" height="9" font="font11" id="p5_t281" reading_order_no="280" segment_no="16" tag_type="text">using such information leads to inaccurate reconstruction of</text>
<text top="636" left="312" width="252" height="9" font="font11" id="p5_t282" reading_order_no="281" segment_no="16" tag_type="text">human motion. To refine the network output, we develop</text>
<text top="648" left="312" width="252" height="9" font="font11" id="p5_t283" reading_order_no="282" segment_no="16" tag_type="text">a novel algorithm that accurately reconstructs the human</text>
<text top="659" left="312" width="246" height="9" font="font11" id="p5_t284" reading_order_no="283" segment_no="16" tag_type="text">motion as well as a subject-specific full-body mesh model.</text>
<text top="688" left="312" width="13" height="9" font="font39" id="p5_t285" reading_order_no="284" segment_no="17" tag_type="title"><b>5.1</b></text>
<text top="688" left="335" width="149" height="9" font="font39" id="p5_t286" reading_order_no="285" segment_no="17" tag_type="title"><b>Human Full-body Representation</b></text>
<text top="703" left="312" width="252" height="9" font="font11" id="p5_t287" reading_order_no="286" segment_no="18" tag_type="text">Similar to SMPL, we approximate the human full-body</text>
<text top="714" left="312" width="252" height="9" font="font11" id="p5_t288" reading_order_no="287" segment_no="18" tag_type="text">geometry with a skinned mesh that is driven by an artic-</text>
<text top="726" left="312" width="252" height="9" font="font11" id="p5_t289" reading_order_no="288" segment_no="18" tag_type="text">ulated skeleton model using Linear Blend Skinning (LBS).</text>
<text top="737" left="312" width="252" height="9" font="font11" id="p5_t290" reading_order_no="289" segment_no="18" tag_type="text">Our skeleton has 45 degree of freedoms (DOFs), 6 of which</text>
</page>
<page number="6" position="absolute" top="0" left="0" height="792" width="612">
	<fontspec id="font40" size="7" family="URWPalladioL-Roma" color="#000000"/>
	<fontspec id="font41" size="10" family="CMMIB10" color="#000000"/>
	<fontspec id="font42" size="10" family="CMEX10" color="#000000"/>
	<fontspec id="font43" size="9" family="CMR9" color="#000000"/>
	<fontspec id="font44" size="6" family="CMMIB6" color="#000000"/>
	<fontspec id="font45" size="9" family="CMMI9" color="#000000"/>
	<fontspec id="font46" size="6" family="CMMI6" color="#000000"/>
	<fontspec id="font47" size="9" family="URWPalladioL-Roma" color="#000000"/>
	<fontspec id="font48" size="10" family="NimbusSanL-ReguItal" color="#000000"/>
	<fontspec id="font49" size="10" family="CMBX10" color="#000000"/>
<text top="29" left="48" width="334" height="6" font="font0" id="p6_t1" reading_order_no="0" segment_no="0" tag_type="title">IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS, VOL. XX, NO. , AUGUST 2020</text>
<text top="29" left="560" width="4" height="6" font="font0" id="p6_t2" reading_order_no="1" segment_no="1" tag_type="text">6</text>
<text top="197" left="48" width="252" height="9" font="font11" id="p6_t3" reading_order_no="2" segment_no="6" tag_type="text">Fig. 5: Human shape variations: (a) bone length variation;</text>
<text top="209" left="48" width="140" height="9" font="font11" id="p6_t4" reading_order_no="3" segment_no="6" tag_type="text">(b) body part thickness variation.</text>
<text top="242" left="48" width="252" height="9" font="font11" id="p6_t5" reading_order_no="4" segment_no="9" tag_type="text">are for global position and orientation, and 39 are for joint</text>
<text top="254" left="48" width="252" height="9" font="font11" id="p6_t6" reading_order_no="5" segment_no="9" tag_type="text">angles (note that a joint may be of 1, 2 or 3 DOFs). We built</text>
<text top="265" left="48" width="252" height="9" font="font11" id="p6_t7" reading_order_no="6" segment_no="9" tag_type="text">a female mesh model of 28,109 vertices (or 56,142 triangu-</text>
<text top="277" left="48" width="252" height="9" font="font11" id="p6_t8" reading_order_no="7" segment_no="9" tag_type="text">lar faces), carrying more geometric details than the SMPL</text>
<text top="288" left="48" width="39" height="9" font="font11" id="p6_t9" reading_order_no="8" segment_no="9" tag_type="text">model of</text>
<text top="288" left="91" width="5" height="9" font="font19" id="p6_t10" reading_order_no="9" segment_no="9" tag_type="text">6</text>
<text top="288" left="96" width="3" height="9" font="font14" id="p6_t11" reading_order_no="10" segment_no="9" tag_type="text">,</text>
<text top="288" left="101" width="15" height="9" font="font19" id="p6_t12" reading_order_no="11" segment_no="9" tag_type="text">890</text>
<text top="288" left="120" width="180" height="9" font="font11" id="p6_t13" reading_order_no="12" segment_no="9" tag_type="text">vertices. The female model is elaborately</text>
<text top="300" left="48" width="252" height="9" font="font11" id="p6_t14" reading_order_no="13" segment_no="9" tag_type="text">rigged and parameterized such that the shape can be easily</text>
<text top="311" left="48" width="45" height="9" font="font11" id="p6_t15" reading_order_no="14" segment_no="9" tag_type="text">controlled.</text>
<text top="310" left="96" width="3" height="7" font="font40" id="p6_t16" reading_order_no="15" segment_no="9" tag_type="text">1</text>
<text top="323" left="62" width="238" height="9" font="font11" id="p6_t17" reading_order_no="16" segment_no="10" tag_type="text">Following a relatively mature process we build a para-</text>
<text top="335" left="48" width="252" height="9" font="font11" id="p6_t18" reading_order_no="17" segment_no="10" tag_type="text">metric human full-body geometry model (Fig. 5). The model</text>
<text top="346" left="48" width="252" height="9" font="font11" id="p6_t19" reading_order_no="18" segment_no="10" tag_type="text">is controllable in two aspects: (1) skeleton scales, which</text>
<text top="358" left="48" width="252" height="9" font="font11" id="p6_t20" reading_order_no="19" segment_no="10" tag_type="text">encode coarse-level variation like the overall and the per-</text>
<text top="369" left="48" width="252" height="9" font="font11" id="p6_t21" reading_order_no="20" segment_no="10" tag_type="text">bone scales, (2) mesh vertex offsets, which encode fine-level</text>
<text top="381" left="48" width="252" height="9" font="font11" id="p6_t22" reading_order_no="21" segment_no="10" tag_type="text">shape variation, such as thickness of a limb. The parametric</text>
<text top="392" left="48" width="197" height="9" font="font11" id="p6_t23" reading_order_no="22" segment_no="10" tag_type="text">human full-body model can be represented as:</text>
<text top="421" left="108" width="8" height="9" font="font18" id="p6_t24" reading_order_no="23" segment_no="14" tag_type="formula"><b>H</b></text>
<text top="424" left="116" width="3" height="6" font="font38" id="p6_t25" reading_order_no="24" segment_no="14" tag_type="formula">i</text>
<text top="421" left="120" width="4" height="9" font="font19" id="p6_t26" reading_order_no="25" segment_no="14" tag_type="formula">(</text>
<text top="421" left="124" width="8" height="9" font="font41" id="p6_t27" reading_order_no="26" segment_no="14" tag_type="formula">α</text>
<text top="421" left="131" width="3" height="9" font="font14" id="p6_t28" reading_order_no="27" segment_no="14" tag_type="formula">,</text>
<text top="421" left="136" width="7" height="9" font="font41" id="p6_t29" reading_order_no="28" segment_no="14" tag_type="formula">β</text>
<text top="421" left="142" width="3" height="9" font="font14" id="p6_t30" reading_order_no="29" segment_no="14" tag_type="formula">,</text>
<text top="421" left="147" width="6" height="9" font="font41" id="p6_t31" reading_order_no="30" segment_no="14" tag_type="formula">θ</text>
<text top="421" left="153" width="14" height="9" font="font19" id="p6_t32" reading_order_no="31" segment_no="14" tag_type="formula">) =</text>
<text top="410" left="170" width="5" height="6" font="font38" id="p6_t33" reading_order_no="32" segment_no="14" tag_type="formula">n</text>
<text top="410" left="175" width="6" height="7" font="font17" id="p6_t34" reading_order_no="33" segment_no="14" tag_type="formula">−</text>
<text top="410" left="181" width="4" height="6" font="font37" id="p6_t35" reading_order_no="34" segment_no="14" tag_type="formula">1</text>
<text top="418" left="170" width="14" height="4" font="font42" id="p6_t36" reading_order_no="35" segment_no="14" tag_type="formula">X</text>
<text top="434" left="171" width="3" height="6" font="font38" id="p6_t37" reading_order_no="36" segment_no="14" tag_type="formula">j</text>
<text top="434" left="174" width="10" height="6" font="font37" id="p6_t38" reading_order_no="37" segment_no="14" tag_type="formula">=0</text>
<text top="421" left="187" width="7" height="9" font="font14" id="p6_t39" reading_order_no="38" segment_no="14" tag_type="formula">w</text>
<text top="424" left="194" width="6" height="6" font="font38" id="p6_t40" reading_order_no="39" segment_no="14" tag_type="formula">ij</text>
<text top="421" left="201" width="6" height="9" font="font14" id="p6_t41" reading_order_no="40" segment_no="14" tag_type="formula">T</text>
<text top="424" left="207" width="3" height="6" font="font38" id="p6_t42" reading_order_no="41" segment_no="14" tag_type="formula">j</text>
<text top="421" left="211" width="4" height="9" font="font19" id="p6_t43" reading_order_no="42" segment_no="14" tag_type="formula">(</text>
<text top="421" left="215" width="6" height="9" font="font41" id="p6_t44" reading_order_no="43" segment_no="14" tag_type="formula">θ</text>
<text top="421" left="221" width="9" height="9" font="font19" id="p6_t45" reading_order_no="44" segment_no="14" tag_type="formula">)ˆ</text>
<text top="421" left="225" width="5" height="9" font="font18" id="p6_t46" reading_order_no="45" segment_no="14" tag_type="formula"><b>v</b></text>
<text top="418" left="230" width="2" height="7" font="font17" id="p6_t47" reading_order_no="46" segment_no="14" tag_type="formula">0</text>
<text top="425" left="230" width="6" height="6" font="font38" id="p6_t48" reading_order_no="47" segment_no="14" tag_type="formula">ij</text>
<text top="421" left="237" width="3" height="9" font="font14" id="p6_t49" reading_order_no="48" segment_no="14" tag_type="formula">,</text>
<text top="446" left="123" width="5" height="9" font="font19" id="p6_t50" reading_order_no="49" segment_no="17" tag_type="formula">ˆ</text>
<text top="443" left="128" width="2" height="7" font="font17" id="p6_t51" reading_order_no="50" segment_no="17" tag_type="formula">0</text>
<text top="450" left="128" width="6" height="6" font="font38" id="p6_t52" reading_order_no="51" segment_no="17" tag_type="formula">ij</text>
<text top="446" left="138" width="8" height="9" font="font19" id="p6_t53" reading_order_no="52" segment_no="17" tag_type="formula">=</text>
<text top="446" left="149" width="6" height="9" font="font18" id="p6_t54" reading_order_no="53" segment_no="17" tag_type="formula"><b>S</b></text>
<text top="446" left="155" width="4" height="9" font="font19" id="p6_t55" reading_order_no="54" segment_no="17" tag_type="formula">(</text>
<text top="446" left="158" width="8" height="9" font="font41" id="p6_t56" reading_order_no="55" segment_no="17" tag_type="formula">α</text>
<text top="446" left="166" width="4" height="9" font="font19" id="p6_t57" reading_order_no="56" segment_no="17" tag_type="formula">)</text>
<text top="445" left="172" width="8" height="9" font="font36" id="p6_t58" reading_order_no="57" segment_no="17" tag_type="formula">⊗</text>
<text top="446" left="182" width="4" height="9" font="font19" id="p6_t59" reading_order_no="58" segment_no="17" tag_type="formula">(</text>
<text top="446" left="186" width="8" height="9" font="font18" id="p6_t60" reading_order_no="59" segment_no="17" tag_type="formula"><b>Q</b></text>
<text top="446" left="194" width="4" height="9" font="font19" id="p6_t61" reading_order_no="60" segment_no="17" tag_type="formula">(</text>
<text top="446" left="198" width="7" height="9" font="font41" id="p6_t62" reading_order_no="61" segment_no="17" tag_type="formula">β</text>
<text top="446" left="205" width="4" height="9" font="font19" id="p6_t63" reading_order_no="62" segment_no="17" tag_type="formula">)</text>
<text top="445" left="211" width="8" height="9" font="font36" id="p6_t64" reading_order_no="63" segment_no="17" tag_type="formula">⊕</text>
<text top="446" left="221" width="5" height="9" font="font19" id="p6_t65" reading_order_no="64" segment_no="17" tag_type="formula">ˆ</text>
<text top="449" left="226" width="6" height="6" font="font38" id="p6_t66" reading_order_no="65" segment_no="17" tag_type="formula">ij</text>
<text top="446" left="233" width="4" height="9" font="font19" id="p6_t67" reading_order_no="66" segment_no="17" tag_type="formula">)</text>
<text top="446" left="237" width="3" height="9" font="font14" id="p6_t68" reading_order_no="67" segment_no="17" tag_type="formula">,</text>
<text top="429" left="289" width="11" height="9" font="font11" id="p6_t69" reading_order_no="68" segment_no="16" tag_type="text">(4)</text>
<text top="465" left="48" width="26" height="9" font="font11" id="p6_t70" reading_order_no="69" segment_no="18" tag_type="text">where</text>
<text top="465" left="80" width="8" height="9" font="font18" id="p6_t71" reading_order_no="70" segment_no="18" tag_type="text"><b>H</b></text>
<text top="468" left="88" width="3" height="6" font="font38" id="p6_t72" reading_order_no="71" segment_no="18" tag_type="text">i</text>
<text top="465" left="91" width="4" height="9" font="font19" id="p6_t73" reading_order_no="72" segment_no="18" tag_type="text">(</text>
<text top="464" left="95" width="3" height="9" font="font36" id="p6_t74" reading_order_no="73" segment_no="18" tag_type="text">·</text>
<text top="465" left="98" width="4" height="9" font="font19" id="p6_t75" reading_order_no="74" segment_no="18" tag_type="text">)</text>
<text top="465" left="107" width="108" height="9" font="font11" id="p6_t76" reading_order_no="75" segment_no="18" tag_type="text">is the coordinate of the</text>
<text top="465" left="221" width="3" height="9" font="font14" id="p6_t77" reading_order_no="76" segment_no="18" tag_type="text">i</text>
<text top="465" left="224" width="76" height="9" font="font11" id="p6_t78" reading_order_no="77" segment_no="18" tag_type="text">-th vertex of the</text>
<text top="476" left="48" width="54" height="9" font="font11" id="p6_t79" reading_order_no="78" segment_no="18" tag_type="text">mesh model,</text>
<text top="476" left="105" width="5" height="9" font="font19" id="p6_t80" reading_order_no="79" segment_no="18" tag_type="text">ˆ</text>
<text top="477" left="105" width="5" height="9" font="font18" id="p6_t81" reading_order_no="80" segment_no="18" tag_type="text"><b>v</b></text>
<text top="474" left="111" width="2" height="7" font="font17" id="p6_t82" reading_order_no="81" segment_no="18" tag_type="text">0</text>
<text top="481" left="111" width="6" height="6" font="font38" id="p6_t83" reading_order_no="82" segment_no="18" tag_type="text">ij</text>
<text top="476" left="120" width="180" height="9" font="font11" id="p6_t84" reading_order_no="83" segment_no="18" tag_type="text">is the result after applying the scaling and</text>
<text top="488" left="48" width="51" height="9" font="font11" id="p6_t85" reading_order_no="84" segment_no="18" tag_type="text">offsetting to</text>
<text top="488" left="102" width="5" height="9" font="font19" id="p6_t86" reading_order_no="85" segment_no="18" tag_type="text">ˆ</text>
<text top="491" left="107" width="6" height="6" font="font38" id="p6_t87" reading_order_no="86" segment_no="18" tag_type="text">ij</text>
<text top="488" left="117" width="55" height="9" font="font11" id="p6_t88" reading_order_no="87" segment_no="18" tag_type="text">(which is the</text>
<text top="488" left="175" width="3" height="9" font="font14" id="p6_t89" reading_order_no="88" segment_no="18" tag_type="text">i</text>
<text top="488" left="179" width="121" height="9" font="font11" id="p6_t90" reading_order_no="89" segment_no="18" tag_type="text">-th vertex represented in the</text>
<text top="500" left="48" width="125" height="9" font="font11" id="p6_t91" reading_order_no="90" segment_no="18" tag_type="text">local coordinate frame of the</text>
<text top="499" left="177" width="4" height="9" font="font14" id="p6_t92" reading_order_no="91" segment_no="18" tag_type="text">j</text>
<text top="500" left="182" width="42" height="9" font="font11" id="p6_t93" reading_order_no="92" segment_no="18" tag_type="text">-th bone),</text>
<text top="500" left="227" width="8" height="9" font="font18" id="p6_t94" reading_order_no="93" segment_no="18" tag_type="text"><b>Q</b></text>
<text top="499" left="235" width="4" height="9" font="font19" id="p6_t95" reading_order_no="94" segment_no="18" tag_type="text">(</text>
<text top="499" left="239" width="7" height="9" font="font41" id="p6_t96" reading_order_no="95" segment_no="18" tag_type="text">β</text>
<text top="499" left="246" width="4" height="9" font="font19" id="p6_t97" reading_order_no="96" segment_no="18" tag_type="text">)</text>
<text top="499" left="250" width="8" height="9" font="font36" id="p6_t98" reading_order_no="97" segment_no="18" tag_type="text">⊕</text>
<text top="500" left="261" width="39" height="9" font="font11" id="p6_t99" reading_order_no="98" segment_no="18" tag_type="text">describes</text>
<text top="511" left="48" width="87" height="9" font="font11" id="p6_t100" reading_order_no="99" segment_no="18" tag_type="text">the vertex offsetting,</text>
<text top="511" left="139" width="6" height="9" font="font18" id="p6_t101" reading_order_no="100" segment_no="18" tag_type="text"><b>S</b></text>
<text top="511" left="144" width="4" height="9" font="font19" id="p6_t102" reading_order_no="101" segment_no="18" tag_type="text">(</text>
<text top="511" left="148" width="8" height="9" font="font41" id="p6_t103" reading_order_no="102" segment_no="18" tag_type="text">α</text>
<text top="511" left="156" width="4" height="9" font="font19" id="p6_t104" reading_order_no="103" segment_no="18" tag_type="text">)</text>
<text top="510" left="160" width="8" height="9" font="font36" id="p6_t105" reading_order_no="104" segment_no="18" tag_type="text">⊗</text>
<text top="511" left="170" width="130" height="9" font="font11" id="p6_t106" reading_order_no="105" segment_no="18" tag_type="text">describes the bone scaling, the</text>
<text top="523" left="48" width="76" height="9" font="font11" id="p6_t107" reading_order_no="106" segment_no="18" tag_type="text">shape parameters</text>
<text top="523" left="129" width="8" height="9" font="font41" id="p6_t108" reading_order_no="107" segment_no="18" tag_type="text">α</text>
<text top="522" left="141" width="7" height="9" font="font36" id="p6_t109" reading_order_no="108" segment_no="18" tag_type="text">∈</text>
<text top="523" left="153" width="8" height="9" font="font14" id="p6_t110" reading_order_no="109" segment_no="18" tag_type="text">R</text>
<text top="521" left="161" width="4" height="6" font="font37" id="p6_t111" reading_order_no="110" segment_no="18" tag_type="text">8</text>
<text top="523" left="170" width="16" height="9" font="font11" id="p6_t112" reading_order_no="111" segment_no="18" tag_type="text">and</text>
<text top="523" left="190" width="7" height="9" font="font41" id="p6_t113" reading_order_no="112" segment_no="18" tag_type="text">β</text>
<text top="522" left="202" width="7" height="9" font="font36" id="p6_t114" reading_order_no="113" segment_no="18" tag_type="text">∈</text>
<text top="523" left="214" width="8" height="9" font="font14" id="p6_t115" reading_order_no="114" segment_no="18" tag_type="text">R</text>
<text top="521" left="222" width="8" height="6" font="font37" id="p6_t116" reading_order_no="115" segment_no="18" tag_type="text">26</text>
<text top="523" left="235" width="65" height="9" font="font11" id="p6_t117" reading_order_no="116" segment_no="18" tag_type="text">provide a low-</text>
<text top="534" left="48" width="252" height="9" font="font11" id="p6_t118" reading_order_no="117" segment_no="18" tag_type="text">dimensional representation of human bone scale variances</text>
<text top="546" left="48" width="252" height="9" font="font11" id="p6_t119" reading_order_no="118" segment_no="18" tag_type="text">and vertex offset variances across individuals respectively,</text>
<text top="557" left="48" width="6" height="9" font="font41" id="p6_t120" reading_order_no="119" segment_no="18" tag_type="text">θ</text>
<text top="557" left="58" width="121" height="9" font="font11" id="p6_t121" reading_order_no="120" segment_no="18" tag_type="text">is the pose for deformation,</text>
<text top="557" left="182" width="6" height="9" font="font14" id="p6_t122" reading_order_no="121" segment_no="18" tag_type="text">T</text>
<text top="561" left="188" width="3" height="6" font="font38" id="p6_t123" reading_order_no="122" segment_no="18" tag_type="text">j</text>
<text top="557" left="192" width="4" height="9" font="font19" id="p6_t124" reading_order_no="123" segment_no="18" tag_type="text">(</text>
<text top="557" left="196" width="6" height="9" font="font41" id="p6_t125" reading_order_no="124" segment_no="18" tag_type="text">θ</text>
<text top="557" left="202" width="4" height="9" font="font19" id="p6_t126" reading_order_no="125" segment_no="18" tag_type="text">)</text>
<text top="557" left="210" width="90" height="9" font="font11" id="p6_t127" reading_order_no="126" segment_no="18" tag_type="text">is the transformation</text>
<text top="569" left="48" width="25" height="9" font="font11" id="p6_t128" reading_order_no="127" segment_no="18" tag_type="text">of the</text>
<text top="569" left="76" width="4" height="9" font="font14" id="p6_t129" reading_order_no="128" segment_no="18" tag_type="text">j</text>
<text top="569" left="81" width="73" height="9" font="font11" id="p6_t130" reading_order_no="129" segment_no="18" tag_type="text">-th bone for pose</text>
<text top="569" left="157" width="6" height="9" font="font41" id="p6_t131" reading_order_no="130" segment_no="18" tag_type="text">θ</text>
<text top="569" left="163" width="2" height="9" font="font11" id="p6_t132" reading_order_no="131" segment_no="18" tag_type="text">,</text>
<text top="569" left="168" width="7" height="9" font="font14" id="p6_t133" reading_order_no="132" segment_no="18" tag_type="text">w</text>
<text top="572" left="176" width="6" height="6" font="font38" id="p6_t134" reading_order_no="133" segment_no="18" tag_type="text">ij</text>
<text top="569" left="186" width="114" height="9" font="font11" id="p6_t135" reading_order_no="134" segment_no="18" tag_type="text">is a sparse weight map for</text>
<text top="580" left="48" width="55" height="9" font="font11" id="p6_t136" reading_order_no="135" segment_no="18" tag_type="text">deformation,</text>
<text top="580" left="105" width="6" height="9" font="font14" id="p6_t137" reading_order_no="136" segment_no="18" tag_type="text">n</text>
<text top="580" left="114" width="99" height="9" font="font11" id="p6_t138" reading_order_no="137" segment_no="18" tag_type="text">is the number of bones.</text>
<text top="609" left="48" width="13" height="9" font="font39" id="p6_t139" reading_order_no="138" segment_no="25" tag_type="title"><b>5.2</b></text>
<text top="609" left="71" width="143" height="9" font="font39" id="p6_t140" reading_order_no="139" segment_no="25" tag_type="title"><b>Kinematic Pose Reconstruction</b></text>
<text top="625" left="48" width="252" height="9" font="font11" id="p6_t141" reading_order_no="140" segment_no="27" tag_type="text">Given the subject-specific full-body mesh model (obtained</text>
<text top="636" left="48" width="252" height="9" font="font11" id="p6_t142" reading_order_no="141" segment_no="27" tag_type="text">in § 5.3) and the network observations (2D pose from 2D</text>
<text top="648" left="48" width="252" height="9" font="font11" id="p6_t143" reading_order_no="142" segment_no="27" tag_type="text">joints probability maps, 3D part orientations from the 3D</text>
<text top="659" left="48" width="252" height="9" font="font11" id="p6_t144" reading_order_no="143" segment_no="27" tag_type="text">limb orientation fields, the human mask, the IUV map for</text>
<text top="671" left="48" width="54" height="9" font="font11" id="p6_t145" reading_order_no="144" segment_no="27" tag_type="text">frame image</text>
<text top="671" left="107" width="4" height="9" font="font14" id="p6_t146" reading_order_no="145" segment_no="27" tag_type="text">I</text>
<text top="674" left="111" width="3" height="6" font="font38" id="p6_t147" reading_order_no="146" segment_no="27" tag_type="text">i</text>
<text top="671" left="114" width="176" height="9" font="font11" id="p6_t148" reading_order_no="147" segment_no="27" tag_type="text">), our goal is to estimate a human pose</text>
<text top="671" left="294" width="6" height="9" font="font41" id="p6_t149" reading_order_no="148" segment_no="27" tag_type="text">θ</text>
<text top="683" left="48" width="252" height="9" font="font11" id="p6_t150" reading_order_no="149" segment_no="27" tag_type="text">which best matches the network observations. We estimate</text>
<text top="702" left="56" width="244" height="8" font="font10" id="p6_t151" reading_order_no="150" segment_no="29" tag_type="footnote">1. Yet currently we do not have a decently parameterized male model</text>
<text top="711" left="48" width="252" height="8" font="font10" id="p6_t152" reading_order_no="151" segment_no="29" tag_type="footnote">on par with the female model. For scenes with a male subject, we either</text>
<text top="720" left="48" width="252" height="8" font="font10" id="p6_t153" reading_order_no="152" segment_no="29" tag_type="footnote">use motion-retargeting to drive a male model mesh but without body</text>
<text top="729" left="48" width="252" height="8" font="font10" id="p6_t154" reading_order_no="402" segment_no="29" tag_type="footnote">dimension adjustment (e.g. Fig. 17(b), or just blindly use the female</text>
<text top="738" left="48" width="175" height="8" font="font10" id="p6_t155" reading_order_no="403" segment_no="29" tag_type="footnote">model (e.g. one case in the accompanying video).</text>
<text top="45" left="312" width="71" height="9" font="font11" id="p6_t156" reading_order_no="404" segment_no="2" tag_type="text">the human pose</text>
<text top="45" left="387" width="6" height="9" font="font41" id="p6_t157" reading_order_no="405" segment_no="2" tag_type="text">θ</text>
<text top="45" left="397" width="167" height="9" font="font11" id="p6_t158" reading_order_no="406" segment_no="2" tag_type="text">by minimizing the following objective</text>
<text top="57" left="312" width="38" height="9" font="font11" id="p6_t159" reading_order_no="153" segment_no="2" tag_type="text">function:</text>
<text top="75" left="318" width="30" height="8" font="font43" id="p6_t160" reading_order_no="154" segment_no="4" tag_type="formula">arg min</text>
<text top="84" left="331" width="4" height="5" font="font44" id="p6_t161" reading_order_no="155" segment_no="4" tag_type="formula">θ</text>
<text top="75" left="353" width="4" height="8" font="font43" id="p6_t162" reading_order_no="156" segment_no="4" tag_type="formula">(</text>
<text top="75" left="356" width="7" height="8" font="font45" id="p6_t163" reading_order_no="157" segment_no="4" tag_type="formula">w</text>
<text top="78" left="363" width="15" height="5" font="font46" id="p6_t164" reading_order_no="158" segment_no="4" tag_type="formula">data</text>
<text top="75" left="378" width="7" height="8" font="font45" id="p6_t165" reading_order_no="159" segment_no="4" tag_type="formula">E</text>
<text top="78" left="385" width="15" height="5" font="font46" id="p6_t166" reading_order_no="160" segment_no="4" tag_type="formula">data</text>
<text top="75" left="401" width="7" height="8" font="font43" id="p6_t167" reading_order_no="161" segment_no="4" tag_type="formula">+</text>
<text top="75" left="408" width="7" height="8" font="font45" id="p6_t168" reading_order_no="162" segment_no="4" tag_type="formula">w</text>
<text top="78" left="415" width="17" height="5" font="font46" id="p6_t169" reading_order_no="163" segment_no="4" tag_type="formula">prior</text>
<text top="75" left="433" width="7" height="8" font="font45" id="p6_t170" reading_order_no="164" segment_no="4" tag_type="formula">E</text>
<text top="78" left="440" width="17" height="5" font="font46" id="p6_t171" reading_order_no="165" segment_no="4" tag_type="formula">prior</text>
<text top="75" left="458" width="7" height="8" font="font43" id="p6_t172" reading_order_no="166" segment_no="4" tag_type="formula">+</text>
<text top="75" left="466" width="7" height="8" font="font45" id="p6_t173" reading_order_no="167" segment_no="4" tag_type="formula">w</text>
<text top="78" left="473" width="31" height="5" font="font46" id="p6_t174" reading_order_no="168" segment_no="4" tag_type="formula">temporal</text>
<text top="75" left="504" width="7" height="8" font="font45" id="p6_t175" reading_order_no="169" segment_no="4" tag_type="formula">E</text>
<text top="78" left="510" width="31" height="5" font="font46" id="p6_t176" reading_order_no="170" segment_no="4" tag_type="formula">temporal</text>
<text top="75" left="541" width="4" height="8" font="font43" id="p6_t177" reading_order_no="171" segment_no="4" tag_type="formula">)</text>
<text top="75" left="545" width="3" height="8" font="font45" id="p6_t178" reading_order_no="172" segment_no="4" tag_type="formula">.</text>
<text top="74" left="554" width="10" height="9" font="font47" id="p6_t179" reading_order_no="173" segment_no="3" tag_type="text">(5)</text>
<text top="97" left="312" width="26" height="9" font="font11" id="p6_t180" reading_order_no="174" segment_no="5" tag_type="text">where</text>
<text top="97" left="343" width="7" height="9" font="font14" id="p6_t181" reading_order_no="175" segment_no="5" tag_type="text">E</text>
<text top="100" left="350" width="16" height="6" font="font38" id="p6_t182" reading_order_no="176" segment_no="5" tag_type="text">data</text>
<text top="97" left="371" width="193" height="9" font="font11" id="p6_t183" reading_order_no="177" segment_no="5" tag_type="text">is the data term penalizing the registration</text>
<text top="109" left="312" width="252" height="9" font="font11" id="p6_t184" reading_order_no="178" segment_no="5" tag_type="text">error between the synthesized human model and the obser-</text>
<text top="120" left="312" width="29" height="9" font="font11" id="p6_t185" reading_order_no="179" segment_no="5" tag_type="text">vation.</text>
<text top="120" left="343" width="7" height="9" font="font14" id="p6_t186" reading_order_no="180" segment_no="5" tag_type="text">E</text>
<text top="123" left="351" width="18" height="6" font="font38" id="p6_t187" reading_order_no="181" segment_no="5" tag_type="text">prior</text>
<text top="120" left="372" width="192" height="9" font="font11" id="p6_t188" reading_order_no="182" segment_no="5" tag_type="text">is the prior term that penalizes invalid human</text>
<text top="132" left="312" width="103" height="9" font="font11" id="p6_t189" reading_order_no="183" segment_no="5" tag_type="text">pose configuration, and</text>
<text top="131" left="419" width="7" height="9" font="font14" id="p6_t190" reading_order_no="184" segment_no="5" tag_type="text">E</text>
<text top="135" left="426" width="33" height="6" font="font38" id="p6_t191" reading_order_no="185" segment_no="5" tag_type="text">temporal</text>
<text top="132" left="463" width="101" height="9" font="font11" id="p6_t192" reading_order_no="186" segment_no="5" tag_type="text">is the pose smoothness</text>
<text top="143" left="312" width="252" height="9" font="font11" id="p6_t193" reading_order_no="187" segment_no="5" tag_type="text">term that penalizes the jerkiness in the motion, which is only</text>
<text top="155" left="312" width="252" height="9" font="font11" id="p6_t194" reading_order_no="188" segment_no="5" tag_type="text">used for video application. While searching for the solution</text>
<text top="166" left="312" width="252" height="9" font="font11" id="p6_t195" reading_order_no="189" segment_no="5" tag_type="text">in an iterative manner, it is possible (and recommended) to</text>
<text top="178" left="312" width="55" height="9" font="font11" id="p6_t196" reading_order_no="190" segment_no="5" tag_type="text">use the pose</text>
<text top="178" left="371" width="6" height="9" font="font41" id="p6_t197" reading_order_no="191" segment_no="5" tag_type="text">θ</text>
<text top="181" left="377" width="16" height="6" font="font38" id="p6_t198" reading_order_no="192" segment_no="5" tag_type="text">prev</text>
<text top="178" left="398" width="166" height="9" font="font11" id="p6_t199" reading_order_no="193" segment_no="5" tag_type="text">from the previous frame as the initial</text>
<text top="189" left="312" width="252" height="9" font="font11" id="p6_t200" reading_order_no="194" segment_no="5" tag_type="text">guess. We will describe each term in detail in the following</text>
<text top="201" left="312" width="51" height="9" font="font11" id="p6_t201" reading_order_no="195" segment_no="5" tag_type="text">subsections.</text>
<text top="225" left="312" width="21" height="9" font="font48" id="p6_t202" reading_order_no="196" segment_no="7" tag_type="title">5.2.1</text>
<text top="225" left="343" width="63" height="9" font="font48" id="p6_t203" reading_order_no="197" segment_no="7" tag_type="title">The Data Term</text>
<text top="239" left="312" width="60" height="9" font="font11" id="p6_t204" reading_order_no="198" segment_no="8" tag_type="text">The data term</text>
<text top="239" left="374" width="7" height="9" font="font14" id="p6_t205" reading_order_no="199" segment_no="8" tag_type="text">E</text>
<text top="243" left="382" width="16" height="6" font="font38" id="p6_t206" reading_order_no="200" segment_no="8" tag_type="text">data</text>
<text top="239" left="401" width="163" height="9" font="font11" id="p6_t207" reading_order_no="201" segment_no="8" tag_type="text">evaluates how well the current human</text>
<text top="251" left="312" width="19" height="9" font="font11" id="p6_t208" reading_order_no="202" segment_no="8" tag_type="text">pose</text>
<text top="251" left="335" width="6" height="9" font="font41" id="p6_t209" reading_order_no="203" segment_no="8" tag_type="text">θ</text>
<text top="251" left="345" width="219" height="9" font="font11" id="p6_t210" reading_order_no="204" segment_no="8" tag_type="text">matches the network observations by the analysis-</text>
<text top="262" left="312" width="200" height="9" font="font11" id="p6_t211" reading_order_no="205" segment_no="8" tag_type="text">by-synthesis strategy. Given the human pose</text>
<text top="262" left="517" width="6" height="9" font="font41" id="p6_t212" reading_order_no="206" segment_no="8" tag_type="text">θ</text>
<text top="262" left="523" width="41" height="9" font="font11" id="p6_t213" reading_order_no="207" segment_no="8" tag_type="text">, we first</text>
<text top="274" left="312" width="24" height="9" font="font11" id="p6_t214" reading_order_no="208" segment_no="8" tag_type="text">apply</text>
<text top="274" left="339" width="116" height="9" font="font20" id="p6_t215" reading_order_no="209" segment_no="8" tag_type="text">skeleton subspace deformation</text>
<text top="274" left="459" width="105" height="9" font="font11" id="p6_t216" reading_order_no="210" segment_no="8" tag_type="text">to synthesize a full-body</text>
<text top="285" left="312" width="252" height="9" font="font11" id="p6_t217" reading_order_no="211" segment_no="8" tag_type="text">mesh model. And then we compute the registration error</text>
<text top="297" left="312" width="252" height="9" font="font11" id="p6_t218" reading_order_no="212" segment_no="8" tag_type="text">between the network observations and the synthesized hu-</text>
<text top="308" left="312" width="168" height="9" font="font11" id="p6_t219" reading_order_no="213" segment_no="8" tag_type="text">man model. The data term is defined as</text>
<text top="327" left="317" width="7" height="9" font="font14" id="p6_t220" reading_order_no="214" segment_no="11" tag_type="formula">E</text>
<text top="331" left="324" width="16" height="6" font="font38" id="p6_t221" reading_order_no="215" segment_no="11" tag_type="formula">data</text>
<text top="327" left="341" width="4" height="9" font="font19" id="p6_t222" reading_order_no="216" segment_no="11" tag_type="formula">(</text>
<text top="327" left="345" width="6" height="9" font="font41" id="p6_t223" reading_order_no="217" segment_no="11" tag_type="formula">θ</text>
<text top="327" left="350" width="14" height="9" font="font19" id="p6_t224" reading_order_no="218" segment_no="11" tag_type="formula">) =</text>
<text top="327" left="368" width="7" height="9" font="font14" id="p6_t225" reading_order_no="219" segment_no="11" tag_type="formula">w</text>
<text top="331" left="375" width="4" height="6" font="font37" id="p6_t226" reading_order_no="220" segment_no="11" tag_type="formula">2</text>
<text top="331" left="379" width="4" height="6" font="font38" id="p6_t227" reading_order_no="221" segment_no="11" tag_type="formula">d</text>
<text top="327" left="383" width="7" height="9" font="font14" id="p6_t228" reading_order_no="222" segment_no="11" tag_type="formula">E</text>
<text top="331" left="391" width="4" height="6" font="font37" id="p6_t229" reading_order_no="223" segment_no="11" tag_type="formula">2</text>
<text top="331" left="395" width="4" height="6" font="font38" id="p6_t230" reading_order_no="224" segment_no="11" tag_type="formula">d</text>
<text top="327" left="399" width="8" height="9" font="font19" id="p6_t231" reading_order_no="225" segment_no="11" tag_type="formula">+</text>
<text top="327" left="406" width="7" height="9" font="font14" id="p6_t232" reading_order_no="226" segment_no="11" tag_type="formula">w</text>
<text top="331" left="413" width="4" height="6" font="font37" id="p6_t233" reading_order_no="227" segment_no="11" tag_type="formula">3</text>
<text top="331" left="417" width="4" height="6" font="font38" id="p6_t234" reading_order_no="228" segment_no="11" tag_type="formula">d</text>
<text top="327" left="422" width="7" height="9" font="font14" id="p6_t235" reading_order_no="229" segment_no="11" tag_type="formula">E</text>
<text top="331" left="429" width="4" height="6" font="font37" id="p6_t236" reading_order_no="230" segment_no="11" tag_type="formula">3</text>
<text top="331" left="433" width="4" height="6" font="font38" id="p6_t237" reading_order_no="231" segment_no="11" tag_type="formula">d</text>
<text top="327" left="437" width="8" height="9" font="font19" id="p6_t238" reading_order_no="232" segment_no="11" tag_type="formula">+</text>
<text top="327" left="445" width="7" height="9" font="font14" id="p6_t239" reading_order_no="233" segment_no="11" tag_type="formula">w</text>
<text top="331" left="452" width="12" height="6" font="font38" id="p6_t240" reading_order_no="234" segment_no="11" tag_type="formula">iuv</text>
<text top="327" left="464" width="7" height="9" font="font14" id="p6_t241" reading_order_no="235" segment_no="11" tag_type="formula">E</text>
<text top="331" left="471" width="12" height="6" font="font38" id="p6_t242" reading_order_no="236" segment_no="11" tag_type="formula">iuv</text>
<text top="327" left="483" width="8" height="9" font="font19" id="p6_t243" reading_order_no="237" segment_no="11" tag_type="formula">+</text>
<text top="327" left="491" width="7" height="9" font="font14" id="p6_t244" reading_order_no="238" segment_no="11" tag_type="formula">w</text>
<text top="331" left="498" width="19" height="6" font="font38" id="p6_t245" reading_order_no="239" segment_no="11" tag_type="formula">mask</text>
<text top="327" left="518" width="7" height="9" font="font14" id="p6_t246" reading_order_no="240" segment_no="11" tag_type="formula">E</text>
<text top="331" left="525" width="19" height="6" font="font38" id="p6_t247" reading_order_no="241" segment_no="11" tag_type="formula">mask</text>
<text top="327" left="545" width="3" height="9" font="font14" id="p6_t248" reading_order_no="242" segment_no="11" tag_type="formula">.</text>
<text top="328" left="553" width="11" height="9" font="font11" id="p6_t249" reading_order_no="243" segment_no="12" tag_type="text">(6)</text>
<text top="347" left="312" width="21" height="9" font="font11" id="p6_t250" reading_order_no="244" segment_no="13" tag_type="text">Here</text>
<text top="346" left="338" width="7" height="9" font="font14" id="p6_t251" reading_order_no="245" segment_no="13" tag_type="text">E</text>
<text top="350" left="346" width="4" height="6" font="font37" id="p6_t252" reading_order_no="246" segment_no="13" tag_type="text">2</text>
<text top="350" left="350" width="4" height="6" font="font38" id="p6_t253" reading_order_no="247" segment_no="13" tag_type="text">d</text>
<text top="347" left="360" width="16" height="9" font="font11" id="p6_t254" reading_order_no="248" segment_no="13" tag_type="text">and</text>
<text top="346" left="382" width="7" height="9" font="font14" id="p6_t255" reading_order_no="249" segment_no="13" tag_type="text">E</text>
<text top="350" left="390" width="4" height="6" font="font37" id="p6_t256" reading_order_no="250" segment_no="13" tag_type="text">3</text>
<text top="350" left="394" width="4" height="6" font="font38" id="p6_t257" reading_order_no="251" segment_no="13" tag_type="text">d</text>
<text top="347" left="404" width="160" height="9" font="font11" id="p6_t258" reading_order_no="252" segment_no="13" tag_type="text">are alignment constraints based on</text>
<text top="358" left="312" width="252" height="9" font="font11" id="p6_t259" reading_order_no="253" segment_no="13" tag_type="text">predicted 2D joints positions and 3D limb orientations, re-</text>
<text top="370" left="312" width="44" height="9" font="font11" id="p6_t260" reading_order_no="254" segment_no="13" tag_type="text">spectively.</text>
<text top="370" left="358" width="7" height="9" font="font14" id="p6_t261" reading_order_no="255" segment_no="13" tag_type="text">E</text>
<text top="373" left="366" width="12" height="6" font="font38" id="p6_t262" reading_order_no="256" segment_no="13" tag_type="text">iuv</text>
<text top="370" left="381" width="183" height="9" font="font11" id="p6_t263" reading_order_no="257" segment_no="13" tag_type="text">penalizes the registration error between the</text>
<text top="381" left="312" width="50" height="9" font="font11" id="p6_t264" reading_order_no="258" segment_no="13" tag_type="text">synthesized</text>
<text top="381" left="365" width="11" height="9" font="font14" id="p6_t265" reading_order_no="259" segment_no="13" tag_type="text">uv</text>
<text top="381" left="379" width="96" height="9" font="font11" id="p6_t266" reading_order_no="260" segment_no="13" tag_type="text">map and the observed</text>
<text top="381" left="479" width="11" height="9" font="font14" id="p6_t267" reading_order_no="261" segment_no="13" tag_type="text">uv</text>
<text top="381" left="493" width="41" height="9" font="font11" id="p6_t268" reading_order_no="262" segment_no="13" tag_type="text">map, and</text>
<text top="381" left="537" width="7" height="9" font="font14" id="p6_t269" reading_order_no="263" segment_no="13" tag_type="text">E</text>
<text top="385" left="544" width="19" height="6" font="font38" id="p6_t270" reading_order_no="264" segment_no="13" tag_type="text">mask</text>
<text top="393" left="312" width="252" height="9" font="font11" id="p6_t271" reading_order_no="265" segment_no="13" tag_type="text">penalizes error between the synthesized and the observed</text>
<text top="404" left="312" width="25" height="9" font="font11" id="p6_t272" reading_order_no="266" segment_no="13" tag_type="text">mask.</text>
<text top="416" left="326" width="95" height="9" font="font18" id="p6_t273" reading_order_no="267" segment_no="15" tag_type="text"><b>Sparse 2D alignment.</b></text>
<text top="416" left="425" width="139" height="9" font="font11" id="p6_t274" reading_order_no="268" segment_no="15" tag_type="text">To minimize the discrepancy be-</text>
<text top="428" left="312" width="110" height="9" font="font11" id="p6_t275" reading_order_no="269" segment_no="15" tag_type="text">tween estimated 2D joints</text>
<text top="426" left="426" width="5" height="9" font="font19" id="p6_t276" reading_order_no="270" segment_no="15" tag_type="text">ˆ</text>
<text top="428" left="424" width="6" height="9" font="font14" id="p6_t277" reading_order_no="271" segment_no="15" tag_type="text">P</text>
<text top="432" left="431" width="4" height="6" font="font37" id="p6_t278" reading_order_no="272" segment_no="15" tag_type="text">2</text>
<text top="432" left="435" width="4" height="6" font="font38" id="p6_t279" reading_order_no="273" segment_no="15" tag_type="text">d</text>
<text top="428" left="442" width="122" height="9" font="font11" id="p6_t280" reading_order_no="274" segment_no="15" tag_type="text">and the projections of the 3D</text>
<text top="440" left="312" width="215" height="9" font="font11" id="p6_t281" reading_order_no="275" segment_no="15" tag_type="text">joints from the human body model, we incorporate</text>
<text top="438" left="532" width="5" height="9" font="font19" id="p6_t282" reading_order_no="276" segment_no="15" tag_type="text">ˆ</text>
<text top="440" left="530" width="6" height="9" font="font14" id="p6_t283" reading_order_no="277" segment_no="15" tag_type="text">P</text>
<text top="444" left="536" width="4" height="6" font="font37" id="p6_t284" reading_order_no="278" segment_no="15" tag_type="text">2</text>
<text top="444" left="540" width="4" height="6" font="font38" id="p6_t285" reading_order_no="279" segment_no="15" tag_type="text">d</text>
<text top="440" left="547" width="17" height="9" font="font11" id="p6_t286" reading_order_no="280" segment_no="15" tag_type="text">into</text>
<text top="452" left="312" width="156" height="9" font="font11" id="p6_t287" reading_order_no="281" segment_no="15" tag_type="text">the following reprojection constraint:</text>
<text top="472" left="364" width="7" height="9" font="font14" id="p6_t288" reading_order_no="282" segment_no="19" tag_type="formula">E</text>
<text top="476" left="372" width="4" height="6" font="font37" id="p6_t289" reading_order_no="283" segment_no="19" tag_type="formula">2</text>
<text top="476" left="376" width="4" height="6" font="font38" id="p6_t290" reading_order_no="284" segment_no="19" tag_type="formula">d</text>
<text top="472" left="380" width="4" height="9" font="font19" id="p6_t291" reading_order_no="285" segment_no="19" tag_type="formula">(</text>
<text top="472" left="384" width="6" height="9" font="font41" id="p6_t292" reading_order_no="286" segment_no="19" tag_type="formula">θ</text>
<text top="472" left="390" width="14" height="9" font="font19" id="p6_t293" reading_order_no="287" segment_no="19" tag_type="formula">) =</text>
<text top="469" left="407" width="14" height="4" font="font42" id="p6_t294" reading_order_no="288" segment_no="19" tag_type="formula">X</text>
<text top="486" left="413" width="3" height="6" font="font38" id="p6_t295" reading_order_no="289" segment_no="19" tag_type="formula">i</text>
<text top="472" left="423" width="6" height="9" font="font36" id="p6_t296" reading_order_no="290" segment_no="19" tag_type="formula">||</text>
<text top="472" left="429" width="11" height="9" font="font19" id="p6_t297" reading_order_no="291" segment_no="19" tag_type="formula">Π(</text>
<text top="472" left="440" width="6" height="9" font="font14" id="p6_t298" reading_order_no="292" segment_no="19" tag_type="formula">J</text>
<text top="470" left="447" width="3" height="6" font="font38" id="p6_t299" reading_order_no="293" segment_no="19" tag_type="formula">i</text>
<text top="477" left="446" width="4" height="6" font="font37" id="p6_t300" reading_order_no="294" segment_no="19" tag_type="formula">3</text>
<text top="477" left="450" width="4" height="6" font="font38" id="p6_t301" reading_order_no="295" segment_no="19" tag_type="formula">d</text>
<text top="472" left="454" width="4" height="9" font="font19" id="p6_t302" reading_order_no="296" segment_no="19" tag_type="formula">(</text>
<text top="472" left="458" width="6" height="9" font="font41" id="p6_t303" reading_order_no="297" segment_no="19" tag_type="formula">θ</text>
<text top="472" left="464" width="8" height="9" font="font19" id="p6_t304" reading_order_no="298" segment_no="19" tag_type="formula">))</text>
<text top="472" left="474" width="8" height="9" font="font36" id="p6_t305" reading_order_no="299" segment_no="19" tag_type="formula">−</text>
<text top="470" left="486" width="5" height="9" font="font19" id="p6_t306" reading_order_no="300" segment_no="19" tag_type="formula">ˆ</text>
<text top="472" left="484" width="6" height="9" font="font14" id="p6_t307" reading_order_no="301" segment_no="19" tag_type="formula">P</text>
<text top="470" left="492" width="3" height="6" font="font38" id="p6_t308" reading_order_no="302" segment_no="19" tag_type="formula">i</text>
<text top="477" left="490" width="4" height="6" font="font37" id="p6_t309" reading_order_no="303" segment_no="19" tag_type="formula">2</text>
<text top="477" left="494" width="4" height="6" font="font38" id="p6_t310" reading_order_no="304" segment_no="19" tag_type="formula">d</text>
<text top="472" left="499" width="6" height="9" font="font36" id="p6_t311" reading_order_no="305" segment_no="19" tag_type="formula">||</text>
<text top="470" left="505" width="4" height="6" font="font37" id="p6_t312" reading_order_no="306" segment_no="19" tag_type="formula">2</text>
<text top="477" left="505" width="4" height="6" font="font37" id="p6_t313" reading_order_no="307" segment_no="19" tag_type="formula">2</text>
<text top="472" left="509" width="3" height="9" font="font14" id="p6_t314" reading_order_no="308" segment_no="19" tag_type="formula">.</text>
<text top="473" left="553" width="11" height="9" font="font11" id="p6_t315" reading_order_no="309" segment_no="20" tag_type="text">(7)</text>
<text top="501" left="312" width="21" height="9" font="font11" id="p6_t316" reading_order_no="310" segment_no="21" tag_type="text">Here</text>
<text top="501" left="335" width="6" height="9" font="font14" id="p6_t317" reading_order_no="311" segment_no="21" tag_type="text">J</text>
<text top="499" left="342" width="3" height="6" font="font38" id="p6_t318" reading_order_no="312" segment_no="21" tag_type="text">i</text>
<text top="506" left="341" width="4" height="6" font="font37" id="p6_t319" reading_order_no="313" segment_no="21" tag_type="text">3</text>
<text top="506" left="345" width="4" height="6" font="font38" id="p6_t320" reading_order_no="314" segment_no="21" tag_type="text">d</text>
<text top="501" left="349" width="4" height="9" font="font19" id="p6_t321" reading_order_no="315" segment_no="21" tag_type="text">(</text>
<text top="501" left="353" width="6" height="9" font="font41" id="p6_t322" reading_order_no="316" segment_no="21" tag_type="text">θ</text>
<text top="501" left="359" width="4" height="9" font="font19" id="p6_t323" reading_order_no="317" segment_no="21" tag_type="text">)</text>
<text top="501" left="365" width="22" height="9" font="font11" id="p6_t324" reading_order_no="318" segment_no="21" tag_type="text">is the</text>
<text top="501" left="390" width="3" height="9" font="font14" id="p6_t325" reading_order_no="319" segment_no="21" tag_type="text">i</text>
<text top="501" left="394" width="118" height="9" font="font11" id="p6_t326" reading_order_no="320" segment_no="21" tag_type="text">-th joint in the skeleton, and</text>
<text top="501" left="514" width="7" height="9" font="font19" id="p6_t327" reading_order_no="321" segment_no="21" tag_type="text">Π</text>
<text top="501" left="524" width="40" height="9" font="font11" id="p6_t328" reading_order_no="322" segment_no="21" tag_type="text">is the 3D-</text>
<text top="513" left="312" width="252" height="9" font="font11" id="p6_t329" reading_order_no="323" segment_no="21" tag_type="text">to-2D projection matrix according to known intrinsic camera</text>
<text top="524" left="312" width="50" height="9" font="font11" id="p6_t330" reading_order_no="324" segment_no="21" tag_type="text">parameters.</text>
<text top="536" left="326" width="97" height="9" font="font18" id="p6_t331" reading_order_no="325" segment_no="22" tag_type="text"><b>Sparse 3D alignment.</b></text>
<text top="536" left="427" width="137" height="9" font="font11" id="p6_t332" reading_order_no="326" segment_no="22" tag_type="text">Since many 3D poses share the</text>
<text top="547" left="312" width="252" height="9" font="font11" id="p6_t333" reading_order_no="327" segment_no="22" tag_type="text">same reprojection of 2D pose in single image, and it is hard</text>
<text top="559" left="312" width="252" height="9" font="font11" id="p6_t334" reading_order_no="328" segment_no="22" tag_type="text">to infer a 3D pose only with above mentioned reprojection</text>
<text top="571" left="312" width="216" height="9" font="font11" id="p6_t335" reading_order_no="329" segment_no="22" tag_type="text">constraint. Therefore we add another 3D constraint</text>
<text top="590" left="317" width="7" height="9" font="font14" id="p6_t336" reading_order_no="330" segment_no="23" tag_type="formula">E</text>
<text top="593" left="324" width="4" height="6" font="font37" id="p6_t337" reading_order_no="331" segment_no="23" tag_type="formula">3</text>
<text top="593" left="328" width="4" height="6" font="font38" id="p6_t338" reading_order_no="332" segment_no="23" tag_type="formula">d</text>
<text top="590" left="333" width="4" height="9" font="font19" id="p6_t339" reading_order_no="333" segment_no="23" tag_type="formula">(</text>
<text top="590" left="337" width="6" height="9" font="font41" id="p6_t340" reading_order_no="334" segment_no="23" tag_type="formula">θ</text>
<text top="590" left="343" width="13" height="9" font="font19" id="p6_t341" reading_order_no="335" segment_no="23" tag_type="formula">) =</text>
<text top="587" left="366" width="14" height="4" font="font42" id="p6_t342" reading_order_no="336" segment_no="23" tag_type="formula">X</text>
<text top="604" left="357" width="3" height="6" font="font37" id="p6_t343" reading_order_no="337" segment_no="23" tag_type="formula">(</text>
<text top="604" left="360" width="14" height="6" font="font38" id="p6_t344" reading_order_no="338" segment_no="23" tag_type="formula">m,n</text>
<text top="604" left="374" width="3" height="6" font="font37" id="p6_t345" reading_order_no="339" segment_no="23" tag_type="formula">)</text>
<text top="604" left="377" width="5" height="7" font="font17" id="p6_t346" reading_order_no="340" segment_no="23" tag_type="formula">∈</text>
<text top="604" left="383" width="6" height="6" font="font38" id="p6_t347" reading_order_no="341" segment_no="23" tag_type="formula">B</text>
<text top="589" left="391" width="6" height="9" font="font36" id="p6_t348" reading_order_no="342" segment_no="23" tag_type="formula">||</text>
<text top="590" left="396" width="4" height="9" font="font19" id="p6_t349" reading_order_no="343" segment_no="23" tag_type="formula">(</text>
<text top="589" left="400" width="6" height="9" font="font36" id="p6_t350" reading_order_no="344" segment_no="23" tag_type="formula">||</text>
<text top="590" left="405" width="6" height="9" font="font14" id="p6_t351" reading_order_no="345" segment_no="23" tag_type="formula">J</text>
<text top="587" left="412" width="7" height="6" font="font38" id="p6_t352" reading_order_no="346" segment_no="23" tag_type="formula">m</text>
<text top="594" left="411" width="4" height="6" font="font37" id="p6_t353" reading_order_no="347" segment_no="23" tag_type="formula">3</text>
<text top="594" left="415" width="4" height="6" font="font38" id="p6_t354" reading_order_no="348" segment_no="23" tag_type="formula">d</text>
<text top="589" left="420" width="8" height="9" font="font36" id="p6_t355" reading_order_no="349" segment_no="23" tag_type="formula">−</text>
<text top="590" left="428" width="6" height="9" font="font14" id="p6_t356" reading_order_no="350" segment_no="23" tag_type="formula">J</text>
<text top="587" left="434" width="5" height="6" font="font38" id="p6_t357" reading_order_no="351" segment_no="23" tag_type="formula">n</text>
<text top="594" left="433" width="4" height="6" font="font37" id="p6_t358" reading_order_no="352" segment_no="23" tag_type="formula">3</text>
<text top="594" left="437" width="4" height="6" font="font38" id="p6_t359" reading_order_no="353" segment_no="23" tag_type="formula">d</text>
<text top="589" left="442" width="6" height="9" font="font36" id="p6_t360" reading_order_no="354" segment_no="23" tag_type="formula">||</text>
<text top="593" left="448" width="4" height="6" font="font37" id="p6_t361" reading_order_no="355" segment_no="23" tag_type="formula">2</text>
<text top="589" left="452" width="3" height="9" font="font36" id="p6_t362" reading_order_no="356" segment_no="23" tag_type="formula">·</text>
<text top="587" left="457" width="5" height="9" font="font19" id="p6_t363" reading_order_no="357" segment_no="23" tag_type="formula">ˆ</text>
<text top="590" left="455" width="9" height="9" font="font49" id="p6_t364" reading_order_no="358" segment_no="23" tag_type="formula">O</text>
<text top="593" left="464" width="14" height="6" font="font38" id="p6_t365" reading_order_no="359" segment_no="23" tag_type="formula">m,n</text>
<text top="589" left="479" width="8" height="9" font="font36" id="p6_t366" reading_order_no="360" segment_no="23" tag_type="formula">−</text>
<text top="590" left="487" width="4" height="9" font="font19" id="p6_t367" reading_order_no="361" segment_no="23" tag_type="formula">(</text>
<text top="590" left="491" width="6" height="9" font="font14" id="p6_t368" reading_order_no="362" segment_no="23" tag_type="formula">J</text>
<text top="587" left="497" width="7" height="6" font="font38" id="p6_t369" reading_order_no="363" segment_no="23" tag_type="formula">m</text>
<text top="594" left="496" width="4" height="6" font="font37" id="p6_t370" reading_order_no="364" segment_no="23" tag_type="formula">3</text>
<text top="594" left="500" width="4" height="6" font="font38" id="p6_t371" reading_order_no="365" segment_no="23" tag_type="formula">d</text>
<text top="589" left="505" width="8" height="9" font="font36" id="p6_t372" reading_order_no="366" segment_no="23" tag_type="formula">−</text>
<text top="590" left="513" width="6" height="9" font="font14" id="p6_t373" reading_order_no="367" segment_no="23" tag_type="formula">J</text>
<text top="587" left="520" width="5" height="6" font="font38" id="p6_t374" reading_order_no="368" segment_no="23" tag_type="formula">n</text>
<text top="594" left="519" width="4" height="6" font="font37" id="p6_t375" reading_order_no="369" segment_no="23" tag_type="formula">3</text>
<text top="594" left="523" width="4" height="6" font="font38" id="p6_t376" reading_order_no="370" segment_no="23" tag_type="formula">d</text>
<text top="590" left="527" width="8" height="9" font="font19" id="p6_t377" reading_order_no="371" segment_no="23" tag_type="formula">))</text>
<text top="589" left="535" width="6" height="9" font="font36" id="p6_t378" reading_order_no="372" segment_no="23" tag_type="formula">||</text>
<text top="587" left="541" width="4" height="6" font="font37" id="p6_t379" reading_order_no="373" segment_no="23" tag_type="formula">2</text>
<text top="594" left="541" width="4" height="6" font="font37" id="p6_t380" reading_order_no="374" segment_no="23" tag_type="formula">2</text>
<text top="590" left="545" width="3" height="9" font="font14" id="p6_t381" reading_order_no="375" segment_no="23" tag_type="formula">.</text>
<text top="590" left="553" width="11" height="9" font="font11" id="p6_t382" reading_order_no="376" segment_no="24" tag_type="text">(8)</text>
<text top="622" left="312" width="21" height="9" font="font11" id="p6_t383" reading_order_no="377" segment_no="26" tag_type="text">Here</text>
<text top="619" left="339" width="5" height="9" font="font19" id="p6_t384" reading_order_no="378" segment_no="26" tag_type="text">ˆ</text>
<text top="622" left="337" width="9" height="9" font="font49" id="p6_t385" reading_order_no="379" segment_no="26" tag_type="text">O</text>
<text top="625" left="346" width="14" height="6" font="font38" id="p6_t386" reading_order_no="380" segment_no="26" tag_type="text">m,n</text>
<text top="622" left="365" width="165" height="9" font="font11" id="p6_t387" reading_order_no="381" segment_no="26" tag_type="text">is the estimated 3D direction of limb</text>
<text top="622" left="535" width="4" height="9" font="font19" id="p6_t388" reading_order_no="382" segment_no="26" tag_type="text">(</text>
<text top="622" left="539" width="19" height="9" font="font14" id="p6_t389" reading_order_no="383" segment_no="26" tag_type="text">m, n</text>
<text top="622" left="558" width="4" height="9" font="font19" id="p6_t390" reading_order_no="384" segment_no="26" tag_type="text">)</text>
<text top="622" left="562" width="2" height="9" font="font11" id="p6_t391" reading_order_no="385" segment_no="26" tag_type="text">,</text>
<text top="633" left="312" width="225" height="9" font="font11" id="p6_t392" reading_order_no="386" segment_no="26" tag_type="text">which is the mean value along the segment from joint</text>
<text top="633" left="539" width="6" height="9" font="font14" id="p6_t393" reading_order_no="387" segment_no="26" tag_type="text">J</text>
<text top="632" left="546" width="7" height="6" font="font38" id="p6_t394" reading_order_no="388" segment_no="26" tag_type="text">m</text>
<text top="633" left="556" width="8" height="9" font="font11" id="p6_t395" reading_order_no="389" segment_no="26" tag_type="text">to</text>
<text top="645" left="312" width="6" height="9" font="font14" id="p6_t396" reading_order_no="390" segment_no="26" tag_type="text">J</text>
<text top="643" left="318" width="5" height="6" font="font38" id="p6_t397" reading_order_no="391" segment_no="26" tag_type="text">n</text>
<text top="645" left="324" width="2" height="9" font="font11" id="p6_t398" reading_order_no="392" segment_no="26" tag_type="text">.</text>
<text top="657" left="326" width="134" height="9" font="font18" id="p6_t399" reading_order_no="393" segment_no="28" tag_type="text"><b>Why do we use 3D direction?</b></text>
<text top="657" left="464" width="100" height="9" font="font11" id="p6_t400" reading_order_no="394" segment_no="28" tag_type="text">Various representations</text>
<text top="668" left="312" width="252" height="9" font="font11" id="p6_t401" reading_order_no="395" segment_no="28" tag_type="text">have been put forward to denote a 3D pose, including 3D</text>
<text top="680" left="312" width="252" height="9" font="font11" id="p6_t402" reading_order_no="396" segment_no="28" tag_type="text">joint positions, 2D joints position plus root-relative depth,</text>
<text top="691" left="312" width="252" height="9" font="font11" id="p6_t403" reading_order_no="397" segment_no="28" tag_type="text">and 3D limb directions and so on. We adopt 3D limb</text>
<text top="703" left="312" width="252" height="9" font="font11" id="p6_t404" reading_order_no="398" segment_no="28" tag_type="text">direction due to its two advantages. First, limb orientation</text>
<text top="714" left="312" width="252" height="9" font="font11" id="p6_t405" reading_order_no="399" segment_no="28" tag_type="text">is scale-invariant and dataset independent, which helps</text>
<text top="726" left="312" width="252" height="9" font="font11" id="p6_t406" reading_order_no="400" segment_no="28" tag_type="text">resolve scale ambiguity and generalizes easily to diversity</text>
<text top="737" left="312" width="252" height="9" font="font11" id="p6_t407" reading_order_no="401" segment_no="28" tag_type="text">data. Second, because an auto-reconstruction of human</text>
</page>
<page number="7" position="absolute" top="0" left="0" height="792" width="612">
	<fontspec id="font50" size="10" family="CMTT10" color="#000000"/>
	<fontspec id="font51" size="7" family="CMMIB7" color="#000000"/>
<text top="29" left="48" width="334" height="6" font="font0" id="p7_t1" reading_order_no="0" segment_no="0" tag_type="title">IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS, VOL. XX, NO. , AUGUST 2020</text>
<text top="29" left="560" width="4" height="6" font="font0" id="p7_t2" reading_order_no="1" segment_no="1" tag_type="text">7</text>
<text top="45" left="48" width="252" height="9" font="font11" id="p7_t3" reading_order_no="2" segment_no="3" tag_type="text">shape is done before tracking, there is no need to worry</text>
<text top="57" left="48" width="248" height="9" font="font11" id="p7_t4" reading_order_no="3" segment_no="3" tag_type="text">too much about limb length ratios in the following frames.</text>
<text top="68" left="62" width="101" height="9" font="font18" id="p7_t5" reading_order_no="4" segment_no="4" tag_type="text"><b>Dense IUV alignment.</b></text>
<text top="68" left="168" width="132" height="9" font="font11" id="p7_t6" reading_order_no="5" segment_no="4" tag_type="text">In addition to the coarse level</text>
<text top="80" left="48" width="252" height="9" font="font11" id="p7_t7" reading_order_no="6" segment_no="4" tag_type="text">shape variations caused by bone length and pose change,</text>
<text top="91" left="48" width="79" height="9" font="font11" id="p7_t8" reading_order_no="7" segment_no="4" tag_type="text">another data term</text>
<text top="91" left="132" width="7" height="9" font="font14" id="p7_t9" reading_order_no="8" segment_no="4" tag_type="text">E</text>
<text top="95" left="139" width="12" height="6" font="font38" id="p7_t10" reading_order_no="9" segment_no="4" tag_type="text">iuv</text>
<text top="91" left="156" width="144" height="9" font="font11" id="p7_t11" reading_order_no="10" segment_no="4" tag_type="text">constrains fine-level shape varia-</text>
<text top="103" left="48" width="252" height="9" font="font11" id="p7_t12" reading_order_no="11" segment_no="4" tag_type="text">tions, such as the thickness of limbs. To this end, we con-</text>
<text top="114" left="48" width="252" height="9" font="font11" id="p7_t13" reading_order_no="12" segment_no="4" tag_type="text">struct a dense pixel-to-surface correspondence represented</text>
<text top="126" left="48" width="252" height="9" font="font11" id="p7_t14" reading_order_no="13" segment_no="4" tag_type="text">as an IUV map. Each pixel of an IUV image has a body part</text>
<text top="137" left="48" width="24" height="9" font="font11" id="p7_t15" reading_order_no="14" segment_no="4" tag_type="text">index</text>
<text top="137" left="74" width="3" height="9" font="font14" id="p7_t16" reading_order_no="15" segment_no="4" tag_type="text">i</text>
<text top="137" left="78" width="28" height="9" font="font11" id="p7_t17" reading_order_no="16" segment_no="4" tag_type="text">, and a</text>
<text top="137" left="109" width="4" height="9" font="font19" id="p7_t18" reading_order_no="17" segment_no="4" tag_type="text">(</text>
<text top="137" left="112" width="11" height="9" font="font14" id="p7_t19" reading_order_no="18" segment_no="4" tag_type="text">uv</text>
<text top="137" left="123" width="4" height="9" font="font19" id="p7_t20" reading_order_no="19" segment_no="4" tag_type="text">)</text>
<text top="137" left="130" width="170" height="9" font="font11" id="p7_t21" reading_order_no="20" segment_no="4" tag_type="text">coordinate that maps a pixel to a unique</text>
<text top="149" left="48" width="252" height="9" font="font11" id="p7_t22" reading_order_no="21" segment_no="4" tag_type="text">point on the surface of a body model. Given an IUV map</text>
<text top="161" left="48" width="252" height="9" font="font11" id="p7_t23" reading_order_no="22" segment_no="4" tag_type="text">predicted by the neural network, we select some reliable</text>
<text top="172" left="48" width="25" height="9" font="font11" id="p7_t24" reading_order_no="23" segment_no="4" tag_type="text">pixels</text>
<text top="172" left="76" width="5" height="9" font="font14" id="p7_t25" reading_order_no="24" segment_no="4" tag_type="text">p</text>
<text top="172" left="84" width="62" height="9" font="font11" id="p7_t26" reading_order_no="25" segment_no="4" tag_type="text">which satisfies</text>
<text top="172" left="148" width="4" height="9" font="font14" id="p7_t27" reading_order_no="26" segment_no="4" tag_type="text">δ</text>
<text top="170" left="153" width="10" height="6" font="font37" id="p7_t28" reading_order_no="27" segment_no="4" tag_type="text">(1)</text>
<text top="172" left="164" width="4" height="9" font="font19" id="p7_t29" reading_order_no="28" segment_no="4" tag_type="text">(</text>
<text top="172" left="168" width="5" height="9" font="font14" id="p7_t30" reading_order_no="29" segment_no="4" tag_type="text">p</text>
<text top="172" left="173" width="23" height="9" font="font19" id="p7_t31" reading_order_no="30" segment_no="4" tag_type="text">) = 1</text>
<text top="172" left="199" width="101" height="9" font="font11" id="p7_t32" reading_order_no="31" segment_no="4" tag_type="text">for the function defined</text>
<text top="184" left="48" width="9" height="9" font="font11" id="p7_t33" reading_order_no="32" segment_no="4" tag_type="text">as</text>
<text top="206" left="51" width="4" height="9" font="font14" id="p7_t34" reading_order_no="33" segment_no="11" tag_type="formula">δ</text>
<text top="203" left="56" width="10" height="6" font="font37" id="p7_t35" reading_order_no="34" segment_no="11" tag_type="formula">(1)</text>
<text top="206" left="66" width="4" height="9" font="font19" id="p7_t36" reading_order_no="35" segment_no="11" tag_type="formula">(</text>
<text top="206" left="70" width="5" height="9" font="font14" id="p7_t37" reading_order_no="36" segment_no="11" tag_type="formula">p</text>
<text top="206" left="75" width="13" height="9" font="font19" id="p7_t38" reading_order_no="37" segment_no="11" tag_type="formula">) =</text>
<text top="200" left="102" width="5" height="9" font="font19" id="p7_t39" reading_order_no="38" segment_no="11" tag_type="formula">1</text>
<text top="200" left="107" width="3" height="9" font="font14" id="p7_t40" reading_order_no="39" segment_no="11" tag_type="formula">,</text>
<text top="200" left="119" width="6" height="9" font="font11" id="p7_t41" reading_order_no="40" segment_no="11" tag_type="formula">if</text>
<text top="200" left="135" width="16" height="8" font="font50" id="p7_t42" reading_order_no="41" segment_no="11" tag_type="formula">Max</text>
<text top="199" left="150" width="5" height="9" font="font36" id="p7_t43" reading_order_no="42" segment_no="11" tag_type="formula">{</text>
<text top="200" left="155" width="6" height="9" font="font49" id="p7_t44" reading_order_no="43" segment_no="11" tag_type="formula">v</text>
<text top="200" left="162" width="4" height="9" font="font19" id="p7_t45" reading_order_no="44" segment_no="11" tag_type="formula">(</text>
<text top="200" left="165" width="5" height="9" font="font14" id="p7_t46" reading_order_no="45" segment_no="11" tag_type="formula">p</text>
<text top="200" left="170" width="4" height="9" font="font19" id="p7_t47" reading_order_no="46" segment_no="11" tag_type="formula">)</text>
<text top="199" left="174" width="15" height="9" font="font36" id="p7_t48" reading_order_no="47" segment_no="11" tag_type="formula">} −</text>
<text top="200" left="191" width="31" height="8" font="font50" id="p7_t49" reading_order_no="48" segment_no="11" tag_type="formula">Max2nd</text>
<text top="199" left="223" width="5" height="9" font="font36" id="p7_t50" reading_order_no="49" segment_no="11" tag_type="formula">{</text>
<text top="200" left="228" width="6" height="9" font="font49" id="p7_t51" reading_order_no="50" segment_no="11" tag_type="formula">v</text>
<text top="200" left="234" width="4" height="9" font="font19" id="p7_t52" reading_order_no="51" segment_no="11" tag_type="formula">(</text>
<text top="200" left="238" width="5" height="9" font="font14" id="p7_t53" reading_order_no="52" segment_no="11" tag_type="formula">p</text>
<text top="200" left="243" width="4" height="9" font="font19" id="p7_t54" reading_order_no="53" segment_no="11" tag_type="formula">)</text>
<text top="199" left="247" width="5" height="9" font="font36" id="p7_t55" reading_order_no="54" segment_no="11" tag_type="formula">}</text>
<text top="200" left="255" width="16" height="9" font="font14" id="p7_t56" reading_order_no="55" segment_no="11" tag_type="formula">&gt; φ</text>
<text top="211" left="102" width="5" height="9" font="font19" id="p7_t57" reading_order_no="56" segment_no="11" tag_type="formula">0</text>
<text top="211" left="107" width="3" height="9" font="font14" id="p7_t58" reading_order_no="57" segment_no="11" tag_type="formula">,</text>
<text top="211" left="119" width="41" height="9" font="font11" id="p7_t59" reading_order_no="58" segment_no="11" tag_type="formula">otherwise</text>
<text top="206" left="289" width="11" height="9" font="font11" id="p7_t60" reading_order_no="59" segment_no="12" tag_type="text">(9)</text>
<text top="230" left="48" width="26" height="9" font="font11" id="p7_t61" reading_order_no="60" segment_no="15" tag_type="text">where</text>
<text top="230" left="78" width="6" height="9" font="font49" id="p7_t62" reading_order_no="61" segment_no="15" tag_type="text">v</text>
<text top="230" left="84" width="4" height="9" font="font19" id="p7_t63" reading_order_no="62" segment_no="15" tag_type="text">(</text>
<text top="230" left="88" width="5" height="9" font="font14" id="p7_t64" reading_order_no="63" segment_no="15" tag_type="text">p</text>
<text top="230" left="93" width="4" height="9" font="font19" id="p7_t65" reading_order_no="64" segment_no="15" tag_type="text">)</text>
<text top="230" left="100" width="200" height="9" font="font11" id="p7_t66" reading_order_no="65" segment_no="15" tag_type="text">is the segmentation probability vector of pixel</text>
<text top="241" left="48" width="5" height="9" font="font14" id="p7_t67" reading_order_no="66" segment_no="15" tag_type="text">p</text>
<text top="242" left="53" width="160" height="9" font="font11" id="p7_t68" reading_order_no="67" segment_no="15" tag_type="text">. In our experiment, we set threshold</text>
<text top="241" left="216" width="6" height="9" font="font14" id="p7_t69" reading_order_no="68" segment_no="15" tag_type="text">φ</text>
<text top="241" left="225" width="16" height="9" font="font19" id="p7_t70" reading_order_no="69" segment_no="15" tag_type="text">= 0</text>
<text top="241" left="242" width="3" height="9" font="font14" id="p7_t71" reading_order_no="70" segment_no="15" tag_type="text">.</text>
<text top="241" left="245" width="5" height="9" font="font19" id="p7_t72" reading_order_no="71" segment_no="15" tag_type="text">5</text>
<text top="242" left="250" width="50" height="9" font="font11" id="p7_t73" reading_order_no="72" segment_no="15" tag_type="text">. Interpolat-</text>
<text top="253" left="48" width="252" height="9" font="font11" id="p7_t74" reading_order_no="73" segment_no="15" tag_type="text">ing these image-to-surface points, a more accurate human</text>
<text top="265" left="48" width="141" height="9" font="font11" id="p7_t75" reading_order_no="74" segment_no="15" tag_type="text">model is obtained by minimizing</text>
<text top="285" left="80" width="7" height="9" font="font14" id="p7_t76" reading_order_no="75" segment_no="18" tag_type="formula">E</text>
<text top="289" left="87" width="12" height="6" font="font38" id="p7_t77" reading_order_no="76" segment_no="18" tag_type="formula">iuv</text>
<text top="285" left="99" width="4" height="9" font="font19" id="p7_t78" reading_order_no="77" segment_no="18" tag_type="formula">(</text>
<text top="285" left="103" width="6" height="9" font="font41" id="p7_t79" reading_order_no="78" segment_no="18" tag_type="formula">θ</text>
<text top="285" left="109" width="14" height="9" font="font19" id="p7_t80" reading_order_no="79" segment_no="18" tag_type="formula">) =</text>
<text top="282" left="126" width="14" height="4" font="font42" id="p7_t81" reading_order_no="80" segment_no="18" tag_type="formula">X</text>
<text top="299" left="132" width="4" height="6" font="font38" id="p7_t82" reading_order_no="81" segment_no="18" tag_type="formula">p</text>
<text top="285" left="142" width="4" height="9" font="font14" id="p7_t83" reading_order_no="82" segment_no="18" tag_type="formula">δ</text>
<text top="283" left="147" width="10" height="6" font="font37" id="p7_t84" reading_order_no="83" segment_no="18" tag_type="formula">(1)</text>
<text top="285" left="158" width="4" height="9" font="font19" id="p7_t85" reading_order_no="84" segment_no="18" tag_type="formula">(</text>
<text top="285" left="162" width="5" height="9" font="font14" id="p7_t86" reading_order_no="85" segment_no="18" tag_type="formula">p</text>
<text top="285" left="167" width="4" height="9" font="font19" id="p7_t87" reading_order_no="86" segment_no="18" tag_type="formula">)</text>
<text top="284" left="171" width="6" height="9" font="font36" id="p7_t88" reading_order_no="87" segment_no="18" tag_type="formula">||</text>
<text top="285" left="176" width="11" height="9" font="font19" id="p7_t89" reading_order_no="88" segment_no="18" tag_type="formula">Π(</text>
<text top="285" left="188" width="10" height="9" font="font14" id="p7_t90" reading_order_no="89" segment_no="18" tag_type="formula">M</text>
<text top="285" left="198" width="4" height="9" font="font19" id="p7_t91" reading_order_no="90" segment_no="18" tag_type="formula">(</text>
<text top="285" left="202" width="6" height="9" font="font41" id="p7_t92" reading_order_no="91" segment_no="18" tag_type="formula">θ</text>
<text top="285" left="208" width="9" height="9" font="font14" id="p7_t93" reading_order_no="92" segment_no="18" tag_type="formula">, p</text>
<text top="285" left="218" width="8" height="9" font="font19" id="p7_t94" reading_order_no="93" segment_no="18" tag_type="formula">))</text>
<text top="284" left="228" width="8" height="9" font="font36" id="p7_t95" reading_order_no="94" segment_no="18" tag_type="formula">−</text>
<text top="283" left="239" width="5" height="9" font="font19" id="p7_t96" reading_order_no="95" segment_no="18" tag_type="formula">ˆ</text>
<text top="285" left="237" width="4" height="9" font="font14" id="p7_t97" reading_order_no="96" segment_no="18" tag_type="formula">I</text>
<text top="285" left="243" width="4" height="9" font="font19" id="p7_t98" reading_order_no="97" segment_no="18" tag_type="formula">(</text>
<text top="285" left="247" width="5" height="9" font="font14" id="p7_t99" reading_order_no="98" segment_no="18" tag_type="formula">p</text>
<text top="285" left="252" width="4" height="9" font="font19" id="p7_t100" reading_order_no="99" segment_no="18" tag_type="formula">)</text>
<text top="284" left="255" width="6" height="9" font="font36" id="p7_t101" reading_order_no="100" segment_no="18" tag_type="formula">||</text>
<text top="283" left="261" width="4" height="6" font="font37" id="p7_t102" reading_order_no="101" segment_no="18" tag_type="formula">2</text>
<text top="290" left="261" width="4" height="6" font="font37" id="p7_t103" reading_order_no="102" segment_no="18" tag_type="formula">2</text>
<text top="285" left="265" width="3" height="9" font="font14" id="p7_t104" reading_order_no="103" segment_no="18" tag_type="formula">,</text>
<text top="285" left="284" width="16" height="9" font="font11" id="p7_t105" reading_order_no="104" segment_no="19" tag_type="text">(10)</text>
<text top="314" left="48" width="26" height="9" font="font11" id="p7_t106" reading_order_no="105" segment_no="20" tag_type="text">where</text>
<text top="314" left="77" width="10" height="9" font="font14" id="p7_t107" reading_order_no="106" segment_no="20" tag_type="text">M</text>
<text top="314" left="88" width="4" height="9" font="font19" id="p7_t108" reading_order_no="107" segment_no="20" tag_type="text">(</text>
<text top="314" left="92" width="6" height="9" font="font41" id="p7_t109" reading_order_no="108" segment_no="20" tag_type="text">θ</text>
<text top="314" left="98" width="9" height="9" font="font14" id="p7_t110" reading_order_no="109" segment_no="20" tag_type="text">, p</text>
<text top="314" left="107" width="4" height="9" font="font19" id="p7_t111" reading_order_no="110" segment_no="20" tag_type="text">)</text>
<text top="314" left="114" width="186" height="9" font="font11" id="p7_t112" reading_order_no="111" segment_no="20" tag_type="text">is the synthesized mesh vertex correspond-</text>
<text top="325" left="48" width="53" height="9" font="font11" id="p7_t113" reading_order_no="112" segment_no="20" tag_type="text">ing to pixel</text>
<text top="325" left="106" width="5" height="9" font="font14" id="p7_t114" reading_order_no="113" segment_no="20" tag_type="text">p</text>
<text top="325" left="111" width="23" height="9" font="font11" id="p7_t115" reading_order_no="114" segment_no="20" tag_type="text">, and</text>
<text top="325" left="139" width="7" height="9" font="font19" id="p7_t116" reading_order_no="115" segment_no="20" tag_type="text">Π</text>
<text top="325" left="152" width="148" height="9" font="font11" id="p7_t117" reading_order_no="116" segment_no="20" tag_type="text">is the 3D-to-2D projection matrix</text>
<text top="337" left="48" width="207" height="9" font="font11" id="p7_t118" reading_order_no="117" segment_no="20" tag_type="text">according to known intrinsic camera parameters.</text>
<text top="349" left="62" width="54" height="9" font="font18" id="p7_t119" reading_order_no="118" segment_no="24" tag_type="text"><b>Mask Term.</b></text>
<text top="349" left="120" width="180" height="9" font="font11" id="p7_t120" reading_order_no="119" segment_no="24" tag_type="text">The foreground segmentation mask term</text>
<text top="360" left="48" width="252" height="9" font="font11" id="p7_t121" reading_order_no="120" segment_no="24" tag_type="text">is to penalize the inconsistency between the mask of syn-</text>
<text top="372" left="48" width="252" height="9" font="font11" id="p7_t122" reading_order_no="121" segment_no="24" tag_type="text">thesized human mesh model and the mask from network</text>
<text top="383" left="48" width="56" height="9" font="font11" id="p7_t123" reading_order_no="122" segment_no="24" tag_type="text">observations.</text>
<text top="402" left="96" width="7" height="9" font="font14" id="p7_t124" reading_order_no="123" segment_no="27" tag_type="formula">E</text>
<text top="406" left="103" width="19" height="6" font="font38" id="p7_t125" reading_order_no="124" segment_no="27" tag_type="formula">mask</text>
<text top="402" left="123" width="4" height="9" font="font19" id="p7_t126" reading_order_no="125" segment_no="27" tag_type="formula">(</text>
<text top="402" left="127" width="6" height="9" font="font41" id="p7_t127" reading_order_no="126" segment_no="27" tag_type="formula">θ</text>
<text top="402" left="133" width="14" height="9" font="font19" id="p7_t128" reading_order_no="127" segment_no="27" tag_type="formula">) =</text>
<text top="399" left="150" width="14" height="4" font="font42" id="p7_t129" reading_order_no="128" segment_no="27" tag_type="formula">X</text>
<text top="416" left="155" width="4" height="6" font="font38" id="p7_t130" reading_order_no="129" segment_no="27" tag_type="formula">v</text>
<text top="402" left="166" width="4" height="9" font="font14" id="p7_t131" reading_order_no="130" segment_no="27" tag_type="formula">δ</text>
<text top="400" left="171" width="10" height="6" font="font37" id="p7_t132" reading_order_no="131" segment_no="27" tag_type="formula">(2)</text>
<text top="402" left="182" width="4" height="9" font="font19" id="p7_t133" reading_order_no="132" segment_no="27" tag_type="formula">(</text>
<text top="402" left="186" width="5" height="9" font="font14" id="p7_t134" reading_order_no="133" segment_no="27" tag_type="formula">v</text>
<text top="402" left="191" width="4" height="9" font="font19" id="p7_t135" reading_order_no="134" segment_no="27" tag_type="formula">)</text>
<text top="402" left="195" width="6" height="9" font="font36" id="p7_t136" reading_order_no="135" segment_no="27" tag_type="formula">||</text>
<text top="402" left="200" width="11" height="9" font="font19" id="p7_t137" reading_order_no="136" segment_no="27" tag_type="formula">Π(</text>
<text top="402" left="212" width="5" height="9" font="font14" id="p7_t138" reading_order_no="137" segment_no="27" tag_type="formula">v</text>
<text top="402" left="217" width="4" height="9" font="font19" id="p7_t139" reading_order_no="138" segment_no="27" tag_type="formula">)</text>
<text top="402" left="223" width="8" height="9" font="font36" id="p7_t140" reading_order_no="139" segment_no="27" tag_type="formula">−</text>
<text top="402" left="233" width="4" height="9" font="font14" id="p7_t141" reading_order_no="140" segment_no="27" tag_type="formula">q</text>
<text top="406" left="237" width="4" height="6" font="font38" id="p7_t142" reading_order_no="141" segment_no="27" tag_type="formula">v</text>
<text top="402" left="242" width="6" height="9" font="font36" id="p7_t143" reading_order_no="142" segment_no="27" tag_type="formula">||</text>
<text top="400" left="248" width="4" height="6" font="font37" id="p7_t144" reading_order_no="143" segment_no="27" tag_type="formula">2</text>
<text top="407" left="248" width="4" height="6" font="font37" id="p7_t145" reading_order_no="144" segment_no="27" tag_type="formula">2</text>
<text top="402" left="284" width="16" height="9" font="font11" id="p7_t146" reading_order_no="145" segment_no="28" tag_type="text">(11)</text>
<text top="429" left="48" width="26" height="9" font="font11" id="p7_t147" reading_order_no="146" segment_no="29" tag_type="text">where</text>
<text top="429" left="78" width="5" height="9" font="font14" id="p7_t148" reading_order_no="147" segment_no="29" tag_type="text">v</text>
<text top="429" left="88" width="83" height="9" font="font11" id="p7_t149" reading_order_no="148" segment_no="29" tag_type="text">is the mesh vertex,</text>
<text top="429" left="175" width="7" height="9" font="font19" id="p7_t150" reading_order_no="149" segment_no="29" tag_type="text">Π</text>
<text top="429" left="187" width="113" height="9" font="font11" id="p7_t151" reading_order_no="150" segment_no="29" tag_type="text">is the 3D-to-2D projection</text>
<text top="441" left="48" width="252" height="9" font="font11" id="p7_t152" reading_order_no="151" segment_no="29" tag_type="text">matrix according to known intrinsic camera parameters,</text>
<text top="452" left="48" width="4" height="9" font="font14" id="p7_t153" reading_order_no="152" segment_no="29" tag_type="text">δ</text>
<text top="450" left="53" width="10" height="6" font="font37" id="p7_t154" reading_order_no="153" segment_no="29" tag_type="text">(2)</text>
<text top="452" left="64" width="4" height="9" font="font19" id="p7_t155" reading_order_no="154" segment_no="29" tag_type="text">(</text>
<text top="452" left="67" width="5" height="9" font="font14" id="p7_t156" reading_order_no="155" segment_no="29" tag_type="text">v</text>
<text top="452" left="73" width="4" height="9" font="font19" id="p7_t157" reading_order_no="156" segment_no="29" tag_type="text">)</text>
<text top="452" left="80" width="81" height="9" font="font11" id="p7_t158" reading_order_no="157" segment_no="29" tag_type="text">indicating whether</text>
<text top="452" left="165" width="5" height="9" font="font14" id="p7_t159" reading_order_no="158" segment_no="29" tag_type="text">v</text>
<text top="452" left="173" width="127" height="9" font="font11" id="p7_t160" reading_order_no="159" segment_no="29" tag_type="text">is outside the observed mask</text>
<text top="464" left="48" width="30" height="9" font="font11" id="p7_t161" reading_order_no="160" segment_no="29" tag_type="text">or not,</text>
<text top="464" left="83" width="4" height="9" font="font14" id="p7_t162" reading_order_no="161" segment_no="29" tag_type="text">q</text>
<text top="467" left="87" width="4" height="6" font="font38" id="p7_t163" reading_order_no="162" segment_no="29" tag_type="text">v</text>
<text top="464" left="96" width="194" height="9" font="font11" id="p7_t164" reading_order_no="163" segment_no="29" tag_type="text">is the corresponding 2D image position for</text>
<text top="464" left="295" width="5" height="9" font="font14" id="p7_t165" reading_order_no="164" segment_no="29" tag_type="text">v</text>
<text top="475" left="48" width="230" height="9" font="font11" id="p7_t166" reading_order_no="165" segment_no="29" tag_type="text">obtained from the distance map of the observed mask.</text>
<text top="499" left="48" width="21" height="9" font="font48" id="p7_t167" reading_order_no="166" segment_no="32" tag_type="title">5.2.2</text>
<text top="499" left="79" width="63" height="9" font="font48" id="p7_t168" reading_order_no="167" segment_no="32" tag_type="title">The Prior Term</text>
<text top="513" left="48" width="252" height="9" font="font11" id="p7_t169" reading_order_no="168" segment_no="33" tag_type="text">To make joints of a human skeleton to be physically mean-</text>
<text top="525" left="48" width="252" height="9" font="font11" id="p7_t170" reading_order_no="169" segment_no="33" tag_type="text">ingful, two different priors, the pose space prior and the</text>
<text top="536" left="48" width="232" height="9" font="font11" id="p7_t171" reading_order_no="170" segment_no="33" tag_type="text">joint limit, are defined and used to form the prior term</text>
<text top="555" left="65" width="7" height="9" font="font14" id="p7_t172" reading_order_no="171" segment_no="36" tag_type="formula">E</text>
<text top="559" left="73" width="18" height="6" font="font38" id="p7_t173" reading_order_no="172" segment_no="36" tag_type="formula">prior</text>
<text top="555" left="95" width="8" height="9" font="font19" id="p7_t174" reading_order_no="173" segment_no="36" tag_type="formula">=</text>
<text top="555" left="105" width="7" height="9" font="font14" id="p7_t175" reading_order_no="174" segment_no="36" tag_type="formula">w</text>
<text top="559" left="112" width="37" height="6" font="font38" id="p7_t176" reading_order_no="175" segment_no="36" tag_type="formula">pose prior</text>
<text top="555" left="150" width="7" height="9" font="font14" id="p7_t177" reading_order_no="176" segment_no="36" tag_type="formula">E</text>
<text top="559" left="158" width="37" height="6" font="font38" id="p7_t178" reading_order_no="177" segment_no="36" tag_type="formula">pose prior</text>
<text top="555" left="198" width="8" height="9" font="font19" id="p7_t179" reading_order_no="178" segment_no="36" tag_type="formula">+</text>
<text top="555" left="208" width="7" height="9" font="font14" id="p7_t180" reading_order_no="179" segment_no="36" tag_type="formula">w</text>
<text top="559" left="215" width="28" height="6" font="font38" id="p7_t181" reading_order_no="180" segment_no="36" tag_type="formula">jt limit</text>
<text top="555" left="244" width="7" height="9" font="font14" id="p7_t182" reading_order_no="181" segment_no="36" tag_type="formula">E</text>
<text top="559" left="251" width="28" height="6" font="font38" id="p7_t183" reading_order_no="182" segment_no="36" tag_type="formula">jt limit</text>
<text top="555" left="280" width="3" height="9" font="font14" id="p7_t184" reading_order_no="183" segment_no="36" tag_type="formula">.</text>
<text top="574" left="62" width="76" height="9" font="font18" id="p7_t185" reading_order_no="184" segment_no="37" tag_type="text"><b>Pose Space Prior.</b></text>
<text top="574" left="141" width="159" height="9" font="font11" id="p7_t186" reading_order_no="185" segment_no="37" tag_type="text">We construct individual PCA models</text>
<text top="586" left="48" width="252" height="9" font="font11" id="p7_t187" reading_order_no="186" segment_no="37" tag_type="text">for each body part (e.g., shoulders, arms, spines, legs and</text>
<text top="597" left="48" width="132" height="9" font="font11" id="p7_t188" reading_order_no="187" segment_no="37" tag_type="text">feet) via CMU mocap database</text>
<text top="596" left="180" width="3" height="7" font="font40" id="p7_t189" reading_order_no="188" segment_no="37" tag_type="text">2</text>
<text top="597" left="183" width="117" height="9" font="font11" id="p7_t190" reading_order_no="189" segment_no="37" tag_type="text">. With those part-wise PCA</text>
<text top="609" left="48" width="252" height="9" font="font11" id="p7_t191" reading_order_no="190" segment_no="37" tag_type="text">models, we are able to constraint the solution space into</text>
<text top="620" left="48" width="252" height="9" font="font11" id="p7_t192" reading_order_no="191" segment_no="37" tag_type="text">the physically meaningful area by minimizing the following</text>
<text top="632" left="48" width="77" height="9" font="font11" id="p7_t193" reading_order_no="192" segment_no="37" tag_type="text">objective function:</text>
<text top="651" left="69" width="7" height="9" font="font14" id="p7_t194" reading_order_no="193" segment_no="41" tag_type="formula">E</text>
<text top="654" left="76" width="37" height="6" font="font38" id="p7_t195" reading_order_no="194" segment_no="41" tag_type="formula">pose prior</text>
<text top="651" left="115" width="4" height="9" font="font19" id="p7_t196" reading_order_no="195" segment_no="41" tag_type="formula">(</text>
<text top="651" left="118" width="6" height="9" font="font41" id="p7_t197" reading_order_no="196" segment_no="41" tag_type="formula">θ</text>
<text top="651" left="124" width="14" height="9" font="font19" id="p7_t198" reading_order_no="197" segment_no="41" tag_type="formula">) =</text>
<text top="650" left="141" width="6" height="9" font="font36" id="p7_t199" reading_order_no="198" segment_no="41" tag_type="formula">||</text>
<text top="651" left="147" width="6" height="9" font="font14" id="p7_t200" reading_order_no="199" segment_no="41" tag_type="formula">P</text>
<text top="649" left="155" width="5" height="6" font="font38" id="p7_t201" reading_order_no="200" segment_no="41" tag_type="formula">T</text>
<text top="655" left="153" width="4" height="6" font="font38" id="p7_t202" reading_order_no="201" segment_no="41" tag_type="formula">k</text>
<text top="651" left="161" width="4" height="9" font="font19" id="p7_t203" reading_order_no="202" segment_no="41" tag_type="formula">(</text>
<text top="651" left="165" width="6" height="9" font="font14" id="p7_t204" reading_order_no="203" segment_no="41" tag_type="formula">P</text>
<text top="654" left="171" width="4" height="6" font="font38" id="p7_t205" reading_order_no="204" segment_no="41" tag_type="formula">k</text>
<text top="651" left="176" width="4" height="9" font="font19" id="p7_t206" reading_order_no="205" segment_no="41" tag_type="formula">(</text>
<text top="651" left="180" width="6" height="9" font="font41" id="p7_t207" reading_order_no="206" segment_no="41" tag_type="formula">θ</text>
<text top="650" left="188" width="8" height="9" font="font36" id="p7_t208" reading_order_no="207" segment_no="41" tag_type="formula">−</text>
<text top="651" left="198" width="7" height="9" font="font41" id="p7_t209" reading_order_no="208" segment_no="41" tag_type="formula">µ</text>
<text top="651" left="205" width="18" height="9" font="font19" id="p7_t210" reading_order_no="209" segment_no="41" tag_type="formula">)) +</text>
<text top="651" left="225" width="7" height="9" font="font41" id="p7_t211" reading_order_no="210" segment_no="41" tag_type="formula">µ</text>
<text top="650" left="234" width="8" height="9" font="font36" id="p7_t212" reading_order_no="211" segment_no="41" tag_type="formula">−</text>
<text top="651" left="244" width="6" height="9" font="font41" id="p7_t213" reading_order_no="212" segment_no="41" tag_type="formula">θ</text>
<text top="650" left="250" width="6" height="9" font="font36" id="p7_t214" reading_order_no="213" segment_no="41" tag_type="formula">||</text>
<text top="649" left="256" width="4" height="6" font="font37" id="p7_t215" reading_order_no="214" segment_no="41" tag_type="formula">2</text>
<text top="655" left="256" width="4" height="6" font="font37" id="p7_t216" reading_order_no="215" segment_no="41" tag_type="formula">2</text>
<text top="651" left="260" width="3" height="9" font="font14" id="p7_t217" reading_order_no="216" segment_no="41" tag_type="formula">,</text>
<text top="651" left="284" width="16" height="9" font="font11" id="p7_t218" reading_order_no="217" segment_no="42" tag_type="text">(12)</text>
<text top="670" left="48" width="26" height="9" font="font11" id="p7_t219" reading_order_no="218" segment_no="44" tag_type="text">where</text>
<text top="670" left="78" width="7" height="9" font="font41" id="p7_t220" reading_order_no="219" segment_no="44" tag_type="text">µ</text>
<text top="670" left="89" width="186" height="9" font="font11" id="p7_t221" reading_order_no="220" segment_no="44" tag_type="text">is the mean vector of the PCA model, and</text>
<text top="670" left="278" width="6" height="9" font="font14" id="p7_t222" reading_order_no="221" segment_no="44" tag_type="text">P</text>
<text top="673" left="285" width="4" height="6" font="font38" id="p7_t223" reading_order_no="222" segment_no="44" tag_type="text">k</text>
<text top="670" left="293" width="7" height="9" font="font11" id="p7_t224" reading_order_no="223" segment_no="44" tag_type="text">is</text>
<text top="681" left="48" width="33" height="9" font="font11" id="p7_t225" reading_order_no="224" segment_no="44" tag_type="text">the first</text>
<text top="681" left="84" width="5" height="9" font="font14" id="p7_t226" reading_order_no="225" segment_no="44" tag_type="text">k</text>
<text top="681" left="93" width="199" height="9" font="font11" id="p7_t227" reading_order_no="226" segment_no="44" tag_type="text">principle components of the PCA model. Here</text>
<text top="681" left="294" width="5" height="9" font="font14" id="p7_t228" reading_order_no="227" segment_no="44" tag_type="text">k</text>
<text top="693" left="48" width="190" height="9" font="font11" id="p7_t229" reading_order_no="228" segment_no="44" tag_type="text">is chosen to retain 95% of original variations.</text>
<text top="705" left="62" width="52" height="9" font="font18" id="p7_t230" reading_order_no="229" segment_no="45" tag_type="text"><b>Joint Limit.</b></text>
<text top="705" left="119" width="181" height="9" font="font11" id="p7_t231" reading_order_no="230" segment_no="45" tag_type="text">The joint limit term is added to penalize</text>
<text top="716" left="48" width="252" height="9" font="font11" id="p7_t232" reading_order_no="231" segment_no="45" tag_type="text">invalid joint poses that exceed the range of joint movement.</text>
<text top="738" left="56" width="155" height="8" font="font10" id="p7_t233" reading_order_no="520" segment_no="47" tag_type="footnote">2. http://mocap.cs.cmu.edu/resources.php</text>
<text top="45" left="312" width="72" height="9" font="font11" id="p7_t234" reading_order_no="232" segment_no="2" tag_type="text">Every joint angle</text>
<text top="45" left="386" width="5" height="9" font="font14" id="p7_t235" reading_order_no="233" segment_no="2" tag_type="text">θ</text>
<text top="48" left="391" width="3" height="6" font="font38" id="p7_t236" reading_order_no="234" segment_no="2" tag_type="text">i</text>
<text top="45" left="394" width="2" height="9" font="font11" id="p7_t237" reading_order_no="235" segment_no="2" tag_type="text">,</text>
<text top="45" left="400" width="3" height="9" font="font14" id="p7_t238" reading_order_no="236" segment_no="2" tag_type="text">i</text>
<text top="45" left="406" width="16" height="9" font="font19" id="p7_t239" reading_order_no="237" segment_no="2" tag_type="text">= 7</text>
<text top="45" left="421" width="3" height="9" font="font14" id="p7_t240" reading_order_no="238" segment_no="2" tag_type="text">,</text>
<text top="45" left="426" width="5" height="9" font="font19" id="p7_t241" reading_order_no="239" segment_no="2" tag_type="text">8</text>
<text top="45" left="431" width="8" height="9" font="font14" id="p7_t242" reading_order_no="240" segment_no="2" tag_type="text">...</text>
<text top="45" left="439" width="10" height="9" font="font19" id="p7_t243" reading_order_no="241" segment_no="2" tag_type="text">45</text>
<text top="45" left="452" width="79" height="9" font="font11" id="p7_t244" reading_order_no="242" segment_no="2" tag_type="text">should stay within</text>
<text top="45" left="533" width="3" height="9" font="font19" id="p7_t245" reading_order_no="243" segment_no="2" tag_type="text">[</text>
<text top="45" left="536" width="5" height="9" font="font14" id="p7_t246" reading_order_no="244" segment_no="2" tag_type="text">θ</text>
<text top="43" left="541" width="3" height="6" font="font38" id="p7_t247" reading_order_no="245" segment_no="2" tag_type="text">l</text>
<text top="50" left="541" width="3" height="6" font="font38" id="p7_t248" reading_order_no="246" segment_no="2" tag_type="text">i</text>
<text top="45" left="544" width="9" height="9" font="font14" id="p7_t249" reading_order_no="247" segment_no="2" tag_type="text">, θ</text>
<text top="43" left="554" width="5" height="6" font="font38" id="p7_t250" reading_order_no="248" segment_no="2" tag_type="text">u</text>
<text top="50" left="553" width="3" height="6" font="font38" id="p7_t251" reading_order_no="249" segment_no="2" tag_type="text">i</text>
<text top="45" left="559" width="3" height="9" font="font19" id="p7_t252" reading_order_no="250" segment_no="2" tag_type="text">]</text>
<text top="45" left="562" width="2" height="9" font="font11" id="p7_t253" reading_order_no="251" segment_no="2" tag_type="text">.</text>
<text top="57" left="312" width="82" height="9" font="font11" id="p7_t254" reading_order_no="252" segment_no="2" tag_type="text">The joint limit term</text>
<text top="56" left="397" width="7" height="9" font="font14" id="p7_t255" reading_order_no="253" segment_no="2" tag_type="text">E</text>
<text top="60" left="404" width="28" height="6" font="font38" id="p7_t256" reading_order_no="254" segment_no="2" tag_type="text">jt limit</text>
<text top="57" left="436" width="91" height="9" font="font11" id="p7_t257" reading_order_no="255" segment_no="2" tag_type="text">can be represented as</text>
<text top="84" left="349" width="7" height="9" font="font14" id="p7_t258" reading_order_no="256" segment_no="5" tag_type="formula">E</text>
<text top="87" left="357" width="28" height="6" font="font38" id="p7_t259" reading_order_no="257" segment_no="5" tag_type="formula">jt limit</text>
<text top="84" left="385" width="4" height="9" font="font19" id="p7_t260" reading_order_no="258" segment_no="5" tag_type="formula">(</text>
<text top="84" left="389" width="6" height="9" font="font41" id="p7_t261" reading_order_no="259" segment_no="5" tag_type="formula">θ</text>
<text top="84" left="395" width="14" height="9" font="font19" id="p7_t262" reading_order_no="260" segment_no="5" tag_type="formula">) =</text>
<text top="73" left="416" width="8" height="6" font="font37" id="p7_t263" reading_order_no="261" segment_no="5" tag_type="formula">45</text>
<text top="81" left="412" width="14" height="4" font="font42" id="p7_t264" reading_order_no="262" segment_no="5" tag_type="formula">X</text>
<text top="98" left="413" width="3" height="6" font="font38" id="p7_t265" reading_order_no="263" segment_no="5" tag_type="formula">i</text>
<text top="98" left="416" width="10" height="6" font="font37" id="p7_t266" reading_order_no="264" segment_no="5" tag_type="formula">=7</text>
<text top="84" left="427" width="4" height="9" font="font19" id="p7_t267" reading_order_no="265" segment_no="5" tag_type="formula">(</text>
<text top="84" left="431" width="4" height="9" font="font14" id="p7_t268" reading_order_no="266" segment_no="5" tag_type="formula">δ</text>
<text top="82" left="435" width="10" height="6" font="font37" id="p7_t269" reading_order_no="267" segment_no="5" tag_type="formula">(3)</text>
<text top="84" left="446" width="4" height="9" font="font19" id="p7_t270" reading_order_no="268" segment_no="5" tag_type="formula">(</text>
<text top="84" left="450" width="5" height="9" font="font14" id="p7_t271" reading_order_no="269" segment_no="5" tag_type="formula">θ</text>
<text top="87" left="455" width="3" height="6" font="font38" id="p7_t272" reading_order_no="270" segment_no="5" tag_type="formula">i</text>
<text top="84" left="461" width="15" height="9" font="font14" id="p7_t273" reading_order_no="271" segment_no="5" tag_type="formula">&lt; θ</text>
<text top="82" left="476" width="3" height="6" font="font38" id="p7_t274" reading_order_no="272" segment_no="5" tag_type="formula">l</text>
<text top="88" left="476" width="3" height="6" font="font38" id="p7_t275" reading_order_no="273" segment_no="5" tag_type="formula">i</text>
<text top="84" left="479" width="4" height="9" font="font19" id="p7_t276" reading_order_no="274" segment_no="5" tag_type="formula">)</text>
<text top="83" left="483" width="6" height="9" font="font36" id="p7_t277" reading_order_no="275" segment_no="5" tag_type="formula">||</text>
<text top="84" left="489" width="5" height="9" font="font14" id="p7_t278" reading_order_no="276" segment_no="5" tag_type="formula">θ</text>
<text top="87" left="493" width="3" height="6" font="font38" id="p7_t279" reading_order_no="277" segment_no="5" tag_type="formula">i</text>
<text top="83" left="499" width="8" height="9" font="font36" id="p7_t280" reading_order_no="278" segment_no="5" tag_type="formula">−</text>
<text top="84" left="509" width="5" height="9" font="font14" id="p7_t281" reading_order_no="279" segment_no="5" tag_type="formula">θ</text>
<text top="82" left="514" width="3" height="6" font="font38" id="p7_t282" reading_order_no="280" segment_no="5" tag_type="formula">l</text>
<text top="88" left="513" width="3" height="6" font="font38" id="p7_t283" reading_order_no="281" segment_no="5" tag_type="formula">i</text>
<text top="83" left="517" width="6" height="9" font="font36" id="p7_t284" reading_order_no="282" segment_no="5" tag_type="formula">||</text>
<text top="82" left="522" width="4" height="6" font="font37" id="p7_t285" reading_order_no="283" segment_no="5" tag_type="formula">2</text>
<text top="109" left="412" width="8" height="9" font="font19" id="p7_t286" reading_order_no="284" segment_no="7" tag_type="formula">+</text>
<text top="109" left="420" width="4" height="9" font="font14" id="p7_t287" reading_order_no="285" segment_no="7" tag_type="formula">δ</text>
<text top="107" left="424" width="10" height="6" font="font37" id="p7_t288" reading_order_no="286" segment_no="7" tag_type="formula">(3)</text>
<text top="109" left="435" width="4" height="9" font="font19" id="p7_t289" reading_order_no="287" segment_no="7" tag_type="formula">(</text>
<text top="109" left="439" width="5" height="9" font="font14" id="p7_t290" reading_order_no="288" segment_no="7" tag_type="formula">θ</text>
<text top="112" left="444" width="3" height="6" font="font38" id="p7_t291" reading_order_no="289" segment_no="7" tag_type="formula">i</text>
<text top="109" left="450" width="15" height="9" font="font14" id="p7_t292" reading_order_no="290" segment_no="7" tag_type="formula">&gt; θ</text>
<text top="107" left="465" width="5" height="6" font="font38" id="p7_t293" reading_order_no="291" segment_no="7" tag_type="formula">u</text>
<text top="113" left="465" width="3" height="6" font="font38" id="p7_t294" reading_order_no="292" segment_no="7" tag_type="formula">i</text>
<text top="109" left="470" width="4" height="9" font="font19" id="p7_t295" reading_order_no="293" segment_no="7" tag_type="formula">)</text>
<text top="108" left="474" width="6" height="9" font="font36" id="p7_t296" reading_order_no="294" segment_no="7" tag_type="formula">||</text>
<text top="109" left="480" width="5" height="9" font="font14" id="p7_t297" reading_order_no="295" segment_no="7" tag_type="formula">θ</text>
<text top="112" left="485" width="3" height="6" font="font38" id="p7_t298" reading_order_no="296" segment_no="7" tag_type="formula">i</text>
<text top="108" left="490" width="8" height="9" font="font36" id="p7_t299" reading_order_no="297" segment_no="7" tag_type="formula">−</text>
<text top="109" left="500" width="5" height="9" font="font14" id="p7_t300" reading_order_no="298" segment_no="7" tag_type="formula">θ</text>
<text top="107" left="505" width="5" height="6" font="font38" id="p7_t301" reading_order_no="299" segment_no="7" tag_type="formula">u</text>
<text top="113" left="505" width="3" height="6" font="font38" id="p7_t302" reading_order_no="300" segment_no="7" tag_type="formula">i</text>
<text top="108" left="510" width="6" height="9" font="font36" id="p7_t303" reading_order_no="301" segment_no="7" tag_type="formula">||</text>
<text top="107" left="516" width="4" height="6" font="font37" id="p7_t304" reading_order_no="302" segment_no="7" tag_type="formula">2</text>
<text top="109" left="520" width="4" height="9" font="font19" id="p7_t305" reading_order_no="303" segment_no="7" tag_type="formula">)</text>
<text top="109" left="524" width="3" height="9" font="font14" id="p7_t306" reading_order_no="304" segment_no="7" tag_type="formula">,</text>
<text top="92" left="548" width="16" height="9" font="font11" id="p7_t307" reading_order_no="305" segment_no="6" tag_type="text">(13)</text>
<text top="128" left="326" width="111" height="9" font="font11" id="p7_t308" reading_order_no="306" segment_no="8" tag_type="text">where the binary function</text>
<text top="128" left="440" width="4" height="9" font="font14" id="p7_t309" reading_order_no="307" segment_no="8" tag_type="text">δ</text>
<text top="126" left="444" width="10" height="6" font="font37" id="p7_t310" reading_order_no="308" segment_no="8" tag_type="text">(3)</text>
<text top="128" left="455" width="4" height="9" font="font19" id="p7_t311" reading_order_no="309" segment_no="8" tag_type="text">(</text>
<text top="128" left="459" width="6" height="9" font="font14" id="p7_t312" reading_order_no="310" segment_no="8" tag_type="text">x</text>
<text top="128" left="465" width="4" height="9" font="font19" id="p7_t313" reading_order_no="311" segment_no="8" tag_type="text">)</text>
<text top="128" left="472" width="23" height="9" font="font11" id="p7_t314" reading_order_no="312" segment_no="8" tag_type="text">is 1 if</text>
<text top="128" left="498" width="6" height="9" font="font14" id="p7_t315" reading_order_no="313" segment_no="8" tag_type="text">x</text>
<text top="128" left="506" width="58" height="9" font="font11" id="p7_t316" reading_order_no="314" segment_no="8" tag_type="text">is true, and is</text>
<text top="139" left="312" width="13" height="9" font="font11" id="p7_t317" reading_order_no="315" segment_no="8" tag_type="text">0 if</text>
<text top="139" left="328" width="6" height="9" font="font14" id="p7_t318" reading_order_no="316" segment_no="8" tag_type="text">x</text>
<text top="139" left="336" width="31" height="9" font="font11" id="p7_t319" reading_order_no="317" segment_no="8" tag_type="text">is false.</text>
<text top="162" left="312" width="21" height="9" font="font48" id="p7_t320" reading_order_no="318" segment_no="9" tag_type="title">5.2.3</text>
<text top="162" left="343" width="118" height="9" font="font48" id="p7_t321" reading_order_no="319" segment_no="9" tag_type="title">Temporal Smoothness Term</text>
<text top="176" left="312" width="252" height="9" font="font11" id="p7_t322" reading_order_no="320" segment_no="10" tag_type="text">We add a smoothness term to penalize the pose jerkiness</text>
<text top="187" left="312" width="252" height="9" font="font11" id="p7_t323" reading_order_no="321" segment_no="10" tag_type="text">between two consecutive frames. This smoothness term is</text>
<text top="199" left="312" width="46" height="9" font="font11" id="p7_t324" reading_order_no="322" segment_no="10" tag_type="text">defined as:</text>
<text top="217" left="376" width="7" height="9" font="font14" id="p7_t325" reading_order_no="323" segment_no="13" tag_type="formula">E</text>
<text top="220" left="384" width="33" height="6" font="font38" id="p7_t326" reading_order_no="324" segment_no="13" tag_type="formula">temporal</text>
<text top="217" left="417" width="4" height="9" font="font19" id="p7_t327" reading_order_no="325" segment_no="13" tag_type="formula">(</text>
<text top="217" left="421" width="6" height="9" font="font41" id="p7_t328" reading_order_no="326" segment_no="13" tag_type="formula">θ</text>
<text top="217" left="427" width="14" height="9" font="font19" id="p7_t329" reading_order_no="327" segment_no="13" tag_type="formula">) =</text>
<text top="216" left="444" width="6" height="9" font="font36" id="p7_t330" reading_order_no="328" segment_no="13" tag_type="formula">||</text>
<text top="217" left="449" width="6" height="9" font="font41" id="p7_t331" reading_order_no="329" segment_no="13" tag_type="formula">θ</text>
<text top="216" left="458" width="8" height="9" font="font36" id="p7_t332" reading_order_no="330" segment_no="13" tag_type="formula">−</text>
<text top="217" left="467" width="6" height="9" font="font41" id="p7_t333" reading_order_no="331" segment_no="13" tag_type="formula">θ</text>
<text top="220" left="473" width="16" height="6" font="font38" id="p7_t334" reading_order_no="332" segment_no="13" tag_type="formula">prev</text>
<text top="216" left="490" width="6" height="9" font="font36" id="p7_t335" reading_order_no="333" segment_no="13" tag_type="formula">||</text>
<text top="215" left="495" width="4" height="6" font="font37" id="p7_t336" reading_order_no="334" segment_no="13" tag_type="formula">2</text>
<text top="221" left="495" width="4" height="6" font="font37" id="p7_t337" reading_order_no="335" segment_no="13" tag_type="formula">2</text>
<text top="217" left="548" width="16" height="9" font="font11" id="p7_t338" reading_order_no="336" segment_no="14" tag_type="text">(14)</text>
<text top="239" left="312" width="21" height="9" font="font48" id="p7_t339" reading_order_no="337" segment_no="16" tag_type="title">5.2.4</text>
<text top="239" left="343" width="53" height="9" font="font48" id="p7_t340" reading_order_no="338" segment_no="16" tag_type="title">Optimization</text>
<text top="253" left="312" width="252" height="9" font="font11" id="p7_t341" reading_order_no="339" segment_no="17" tag_type="text">As Eq. 5 is represented as a sum of squares, we can</text>
<text top="265" left="312" width="252" height="9" font="font11" id="p7_t342" reading_order_no="340" segment_no="17" tag_type="text">efficiently solve it by Gauss-Newton method. Since every</text>
<text top="276" left="312" width="252" height="9" font="font11" id="p7_t343" reading_order_no="341" segment_no="17" tag_type="text">term is differentiable, we can directly compute the Jacobian</text>
<text top="288" left="312" width="28" height="9" font="font11" id="p7_t344" reading_order_no="342" segment_no="17" tag_type="text">matrix</text>
<text top="288" left="344" width="6" height="9" font="font14" id="p7_t345" reading_order_no="343" segment_no="17" tag_type="text">J</text>
<text top="288" left="350" width="4" height="9" font="font19" id="p7_t346" reading_order_no="344" segment_no="17" tag_type="text">(</text>
<text top="288" left="354" width="6" height="9" font="font41" id="p7_t347" reading_order_no="345" segment_no="17" tag_type="text">θ</text>
<text top="288" left="360" width="4" height="9" font="font19" id="p7_t348" reading_order_no="346" segment_no="17" tag_type="text">)</text>
<text top="288" left="368" width="196" height="9" font="font11" id="p7_t349" reading_order_no="347" segment_no="17" tag_type="text">and then follow the standard Gauss-Newton</text>
<text top="299" left="312" width="53" height="9" font="font11" id="p7_t350" reading_order_no="348" segment_no="17" tag_type="text">step to solve</text>
<text top="299" left="368" width="4" height="9" font="font14" id="p7_t351" reading_order_no="349" segment_no="17" tag_type="text">δ</text>
<text top="299" left="372" width="6" height="9" font="font41" id="p7_t352" reading_order_no="350" segment_no="17" tag_type="text">θ</text>
<text top="299" left="381" width="82" height="9" font="font11" id="p7_t353" reading_order_no="351" segment_no="17" tag_type="text">and update current</text>
<text top="299" left="465" width="6" height="9" font="font41" id="p7_t354" reading_order_no="352" segment_no="17" tag_type="text">θ</text>
<text top="317" left="379" width="6" height="9" font="font14" id="p7_t355" reading_order_no="353" segment_no="21" tag_type="formula">J</text>
<text top="317" left="385" width="4" height="9" font="font19" id="p7_t356" reading_order_no="354" segment_no="21" tag_type="formula">(</text>
<text top="317" left="389" width="6" height="9" font="font41" id="p7_t357" reading_order_no="355" segment_no="21" tag_type="formula">θ</text>
<text top="317" left="395" width="4" height="9" font="font19" id="p7_t358" reading_order_no="356" segment_no="21" tag_type="formula">)</text>
<text top="315" left="399" width="5" height="6" font="font38" id="p7_t359" reading_order_no="357" segment_no="21" tag_type="formula">T</text>
<text top="317" left="405" width="6" height="9" font="font14" id="p7_t360" reading_order_no="358" segment_no="21" tag_type="formula">J</text>
<text top="317" left="412" width="4" height="9" font="font19" id="p7_t361" reading_order_no="359" segment_no="21" tag_type="formula">(</text>
<text top="317" left="416" width="6" height="9" font="font41" id="p7_t362" reading_order_no="360" segment_no="21" tag_type="formula">θ</text>
<text top="317" left="422" width="4" height="9" font="font19" id="p7_t363" reading_order_no="361" segment_no="21" tag_type="formula">)</text>
<text top="317" left="425" width="4" height="9" font="font14" id="p7_t364" reading_order_no="362" segment_no="21" tag_type="formula">δ</text>
<text top="317" left="430" width="6" height="9" font="font41" id="p7_t365" reading_order_no="363" segment_no="21" tag_type="formula">θ</text>
<text top="317" left="439" width="8" height="9" font="font19" id="p7_t366" reading_order_no="364" segment_no="21" tag_type="formula">=</text>
<text top="317" left="449" width="6" height="9" font="font14" id="p7_t367" reading_order_no="365" segment_no="21" tag_type="formula">J</text>
<text top="317" left="456" width="4" height="9" font="font19" id="p7_t368" reading_order_no="366" segment_no="21" tag_type="formula">(</text>
<text top="317" left="460" width="6" height="9" font="font41" id="p7_t369" reading_order_no="367" segment_no="21" tag_type="formula">θ</text>
<text top="317" left="466" width="4" height="9" font="font19" id="p7_t370" reading_order_no="368" segment_no="21" tag_type="formula">)</text>
<text top="315" left="470" width="5" height="6" font="font38" id="p7_t371" reading_order_no="369" segment_no="21" tag_type="formula">T</text>
<text top="317" left="476" width="4" height="9" font="font14" id="p7_t372" reading_order_no="370" segment_no="21" tag_type="formula">r</text>
<text top="317" left="481" width="4" height="9" font="font19" id="p7_t373" reading_order_no="371" segment_no="21" tag_type="formula">(</text>
<text top="317" left="485" width="6" height="9" font="font41" id="p7_t374" reading_order_no="372" segment_no="21" tag_type="formula">θ</text>
<text top="317" left="490" width="4" height="9" font="font19" id="p7_t375" reading_order_no="373" segment_no="21" tag_type="formula">)</text>
<text top="317" left="494" width="3" height="9" font="font14" id="p7_t376" reading_order_no="374" segment_no="21" tag_type="formula">,</text>
<text top="332" left="379" width="6" height="9" font="font41" id="p7_t377" reading_order_no="375" segment_no="23" tag_type="formula">θ</text>
<text top="332" left="388" width="8" height="9" font="font19" id="p7_t378" reading_order_no="376" segment_no="23" tag_type="formula">=</text>
<text top="332" left="398" width="6" height="9" font="font41" id="p7_t379" reading_order_no="377" segment_no="23" tag_type="formula">θ</text>
<text top="332" left="406" width="8" height="9" font="font19" id="p7_t380" reading_order_no="378" segment_no="23" tag_type="formula">+</text>
<text top="332" left="416" width="4" height="9" font="font14" id="p7_t381" reading_order_no="379" segment_no="23" tag_type="formula">δ</text>
<text top="332" left="421" width="6" height="9" font="font41" id="p7_t382" reading_order_no="380" segment_no="23" tag_type="formula">θ</text>
<text top="332" left="427" width="3" height="9" font="font14" id="p7_t383" reading_order_no="381" segment_no="23" tag_type="formula">,</text>
<text top="325" left="548" width="16" height="9" font="font11" id="p7_t384" reading_order_no="382" segment_no="22" tag_type="text">(15)</text>
<text top="350" left="312" width="26" height="9" font="font11" id="p7_t385" reading_order_no="383" segment_no="25" tag_type="text">where</text>
<text top="349" left="342" width="4" height="9" font="font14" id="p7_t386" reading_order_no="384" segment_no="25" tag_type="text">r</text>
<text top="349" left="346" width="4" height="9" font="font19" id="p7_t387" reading_order_no="385" segment_no="25" tag_type="text">(</text>
<text top="349" left="350" width="6" height="9" font="font41" id="p7_t388" reading_order_no="386" segment_no="25" tag_type="text">θ</text>
<text top="349" left="356" width="4" height="9" font="font19" id="p7_t389" reading_order_no="387" segment_no="25" tag_type="text">)</text>
<text top="350" left="363" width="201" height="9" font="font11" id="p7_t390" reading_order_no="388" segment_no="25" tag_type="text">is the residual vector formed by concatenating</text>
<text top="361" left="312" width="44" height="9" font="font11" id="p7_t391" reading_order_no="389" segment_no="25" tag_type="text">each term.</text>
<text top="373" left="326" width="79" height="9" font="font18" id="p7_t392" reading_order_no="390" segment_no="26" tag_type="text"><b>Parameter values.</b></text>
<text top="373" left="409" width="155" height="9" font="font11" id="p7_t393" reading_order_no="391" segment_no="26" tag_type="text">In our implementation, the weights</text>
<text top="384" left="312" width="7" height="9" font="font14" id="p7_t394" reading_order_no="392" segment_no="26" tag_type="text">w</text>
<text top="388" left="319" width="16" height="6" font="font38" id="p7_t395" reading_order_no="393" segment_no="26" tag_type="text">data</text>
<text top="384" left="335" width="2" height="9" font="font11" id="p7_t396" reading_order_no="394" segment_no="26" tag_type="text">,</text>
<text top="384" left="340" width="7" height="9" font="font14" id="p7_t397" reading_order_no="395" segment_no="26" tag_type="text">w</text>
<text top="388" left="347" width="18" height="6" font="font38" id="p7_t398" reading_order_no="396" segment_no="26" tag_type="text">prior</text>
<text top="384" left="369" width="16" height="9" font="font11" id="p7_t399" reading_order_no="397" segment_no="26" tag_type="text">and</text>
<text top="384" left="387" width="7" height="9" font="font14" id="p7_t400" reading_order_no="398" segment_no="26" tag_type="text">w</text>
<text top="388" left="394" width="33" height="6" font="font38" id="p7_t401" reading_order_no="399" segment_no="26" tag_type="text">temporal</text>
<text top="384" left="430" width="134" height="9" font="font11" id="p7_t402" reading_order_no="400" segment_no="26" tag_type="text">in Eq. 5 are set to 1.0, 0.5 and 5.0</text>
<text top="396" left="312" width="200" height="9" font="font11" id="p7_t403" reading_order_no="401" segment_no="26" tag_type="text">in our experiments. Weight settings in Eq. 6 are</text>
<text top="396" left="515" width="7" height="9" font="font14" id="p7_t404" reading_order_no="402" segment_no="26" tag_type="text">w</text>
<text top="399" left="522" width="4" height="6" font="font37" id="p7_t405" reading_order_no="403" segment_no="26" tag_type="text">2</text>
<text top="399" left="526" width="4" height="6" font="font38" id="p7_t406" reading_order_no="404" segment_no="26" tag_type="text">d</text>
<text top="396" left="533" width="20" height="9" font="font19" id="p7_t407" reading_order_no="405" segment_no="26" tag_type="text">= 20</text>
<text top="396" left="554" width="3" height="9" font="font14" id="p7_t408" reading_order_no="406" segment_no="26" tag_type="text">.</text>
<text top="396" left="557" width="5" height="9" font="font19" id="p7_t409" reading_order_no="407" segment_no="26" tag_type="text">0</text>
<text top="396" left="562" width="2" height="9" font="font11" id="p7_t410" reading_order_no="408" segment_no="26" tag_type="text">,</text>
<text top="407" left="312" width="7" height="9" font="font14" id="p7_t411" reading_order_no="409" segment_no="26" tag_type="text">w</text>
<text top="411" left="319" width="4" height="6" font="font37" id="p7_t412" reading_order_no="410" segment_no="26" tag_type="text">3</text>
<text top="411" left="323" width="4" height="6" font="font38" id="p7_t413" reading_order_no="411" segment_no="26" tag_type="text">d</text>
<text top="407" left="333" width="27" height="9" font="font19" id="p7_t414" reading_order_no="412" segment_no="26" tag_type="text">= 300</text>
<text top="407" left="360" width="3" height="9" font="font14" id="p7_t415" reading_order_no="413" segment_no="26" tag_type="text">.</text>
<text top="407" left="363" width="5" height="9" font="font19" id="p7_t416" reading_order_no="414" segment_no="26" tag_type="text">0</text>
<text top="407" left="368" width="2" height="9" font="font11" id="p7_t417" reading_order_no="415" segment_no="26" tag_type="text">,</text>
<text top="407" left="374" width="7" height="9" font="font14" id="p7_t418" reading_order_no="416" segment_no="26" tag_type="text">w</text>
<text top="411" left="381" width="12" height="6" font="font38" id="p7_t419" reading_order_no="417" segment_no="26" tag_type="text">iuv</text>
<text top="407" left="398" width="17" height="9" font="font19" id="p7_t420" reading_order_no="418" segment_no="26" tag_type="text">= 2</text>
<text top="407" left="416" width="3" height="9" font="font14" id="p7_t421" reading_order_no="419" segment_no="26" tag_type="text">.</text>
<text top="407" left="418" width="5" height="9" font="font19" id="p7_t422" reading_order_no="420" segment_no="26" tag_type="text">0</text>
<text top="407" left="427" width="16" height="9" font="font11" id="p7_t423" reading_order_no="421" segment_no="26" tag_type="text">and</text>
<text top="407" left="447" width="7" height="9" font="font14" id="p7_t424" reading_order_no="422" segment_no="26" tag_type="text">w</text>
<text top="411" left="455" width="19" height="6" font="font38" id="p7_t425" reading_order_no="423" segment_no="26" tag_type="text">mask</text>
<text top="407" left="479" width="17" height="9" font="font19" id="p7_t426" reading_order_no="424" segment_no="26" tag_type="text">= 1</text>
<text top="407" left="497" width="3" height="9" font="font14" id="p7_t427" reading_order_no="425" segment_no="26" tag_type="text">.</text>
<text top="407" left="500" width="5" height="9" font="font19" id="p7_t428" reading_order_no="426" segment_no="26" tag_type="text">0</text>
<text top="407" left="505" width="59" height="9" font="font11" id="p7_t429" reading_order_no="427" segment_no="26" tag_type="text">. The weights</text>
<text top="419" left="312" width="8" height="9" font="font11" id="p7_t430" reading_order_no="428" segment_no="26" tag_type="text">in</text>
<text top="419" left="324" width="7" height="9" font="font14" id="p7_t431" reading_order_no="429" segment_no="26" tag_type="text">E</text>
<text top="422" left="331" width="18" height="6" font="font38" id="p7_t432" reading_order_no="430" segment_no="26" tag_type="text">prior</text>
<text top="419" left="354" width="13" height="9" font="font11" id="p7_t433" reading_order_no="431" segment_no="26" tag_type="text">are</text>
<text top="419" left="370" width="7" height="9" font="font14" id="p7_t434" reading_order_no="432" segment_no="26" tag_type="text">w</text>
<text top="422" left="377" width="37" height="6" font="font38" id="p7_t435" reading_order_no="433" segment_no="26" tag_type="text">pose prior</text>
<text top="419" left="420" width="17" height="9" font="font19" id="p7_t436" reading_order_no="434" segment_no="26" tag_type="text">= 0</text>
<text top="419" left="437" width="3" height="9" font="font14" id="p7_t437" reading_order_no="435" segment_no="26" tag_type="text">.</text>
<text top="419" left="439" width="15" height="9" font="font19" id="p7_t438" reading_order_no="436" segment_no="26" tag_type="text">002</text>
<text top="419" left="458" width="16" height="9" font="font11" id="p7_t439" reading_order_no="437" segment_no="26" tag_type="text">and</text>
<text top="419" left="477" width="7" height="9" font="font14" id="p7_t440" reading_order_no="438" segment_no="26" tag_type="text">w</text>
<text top="422" left="485" width="28" height="6" font="font38" id="p7_t441" reading_order_no="439" segment_no="26" tag_type="text">jt limit</text>
<text top="419" left="518" width="17" height="9" font="font19" id="p7_t442" reading_order_no="440" segment_no="26" tag_type="text">= 5</text>
<text top="419" left="534" width="3" height="9" font="font14" id="p7_t443" reading_order_no="441" segment_no="26" tag_type="text">.</text>
<text top="419" left="537" width="5" height="9" font="font19" id="p7_t444" reading_order_no="442" segment_no="26" tag_type="text">0</text>
<text top="419" left="542" width="22" height="9" font="font11" id="p7_t445" reading_order_no="443" segment_no="26" tag_type="text">. The</text>
<text top="430" left="312" width="169" height="9" font="font11" id="p7_t446" reading_order_no="444" segment_no="26" tag_type="text">weight for temporal smoothness term is</text>
<text top="430" left="484" width="7" height="9" font="font14" id="p7_t447" reading_order_no="445" segment_no="26" tag_type="text">w</text>
<text top="434" left="491" width="33" height="6" font="font38" id="p7_t448" reading_order_no="446" segment_no="26" tag_type="text">temporal</text>
<text top="430" left="527" width="15" height="9" font="font19" id="p7_t449" reading_order_no="447" segment_no="26" tag_type="text">= 0</text>
<text top="430" left="542" width="3" height="9" font="font14" id="p7_t450" reading_order_no="448" segment_no="26" tag_type="text">.</text>
<text top="430" left="545" width="15" height="9" font="font19" id="p7_t451" reading_order_no="449" segment_no="26" tag_type="text">003</text>
<text top="430" left="560" width="2" height="9" font="font11" id="p7_t452" reading_order_no="450" segment_no="26" tag_type="text">.</text>
<text top="457" left="312" width="13" height="9" font="font39" id="p7_t453" reading_order_no="451" segment_no="30" tag_type="title"><b>5.3</b></text>
<text top="457" left="335" width="118" height="9" font="font39" id="p7_t454" reading_order_no="452" segment_no="30" tag_type="title"><b>Full-body Shape Modeling</b></text>
<text top="472" left="312" width="252" height="9" font="font11" id="p7_t455" reading_order_no="453" segment_no="31" tag_type="text">Now we describe how to reconstruct a full-body mesh</text>
<text top="483" left="312" width="252" height="9" font="font11" id="p7_t456" reading_order_no="454" segment_no="31" tag_type="text">model for a subject using the network observations. Note</text>
<text top="495" left="312" width="252" height="9" font="font11" id="p7_t457" reading_order_no="455" segment_no="31" tag_type="text">in the case that the input is a video stream, the shape</text>
<text top="506" left="312" width="219" height="9" font="font11" id="p7_t458" reading_order_no="456" segment_no="31" tag_type="text">reconstruction is done only once, for the first frame.</text>
<text top="529" left="312" width="21" height="9" font="font48" id="p7_t459" reading_order_no="457" segment_no="34" tag_type="title">5.3.1</text>
<text top="529" left="343" width="94" height="9" font="font48" id="p7_t460" reading_order_no="458" segment_no="34" tag_type="title">Shape Reconstruction</text>
<text top="543" left="312" width="72" height="9" font="font11" id="p7_t461" reading_order_no="459" segment_no="35" tag_type="text">Given an image</text>
<text top="543" left="389" width="4" height="9" font="font14" id="p7_t462" reading_order_no="460" segment_no="35" tag_type="text">I</text>
<text top="543" left="394" width="170" height="9" font="font11" id="p7_t463" reading_order_no="461" segment_no="35" tag_type="text">, our goal is to reconstruct a subject-</text>
<text top="554" left="312" width="122" height="9" font="font11" id="p7_t464" reading_order_no="462" segment_no="35" tag_type="text">specific human body model</text>
<text top="554" left="439" width="8" height="9" font="font18" id="p7_t465" reading_order_no="463" segment_no="35" tag_type="text"><b>H</b></text>
<text top="554" left="447" width="4" height="9" font="font19" id="p7_t466" reading_order_no="464" segment_no="35" tag_type="text">(</text>
<text top="554" left="450" width="8" height="9" font="font41" id="p7_t467" reading_order_no="465" segment_no="35" tag_type="text">α</text>
<text top="554" left="458" width="3" height="9" font="font14" id="p7_t468" reading_order_no="466" segment_no="35" tag_type="text">,</text>
<text top="554" left="462" width="7" height="9" font="font41" id="p7_t469" reading_order_no="467" segment_no="35" tag_type="text">β</text>
<text top="554" left="469" width="3" height="9" font="font14" id="p7_t470" reading_order_no="468" segment_no="35" tag_type="text">,</text>
<text top="554" left="474" width="6" height="9" font="font41" id="p7_t471" reading_order_no="469" segment_no="35" tag_type="text">θ</text>
<text top="554" left="480" width="4" height="9" font="font19" id="p7_t472" reading_order_no="470" segment_no="35" tag_type="text">)</text>
<text top="554" left="484" width="80" height="9" font="font11" id="p7_t473" reading_order_no="471" segment_no="35" tag_type="text">, with the derived</text>
<text top="566" left="312" width="252" height="9" font="font11" id="p7_t474" reading_order_no="472" segment_no="35" tag_type="text">image positions for 2D joints, the segmentation mask, body</text>
<text top="577" left="312" width="252" height="9" font="font11" id="p7_t475" reading_order_no="473" segment_no="35" tag_type="text">partition, 3D part orientation, and the dense correspondence</text>
<text top="589" left="312" width="3" height="9" font="font11" id="p7_t476" reading_order_no="474" segment_no="35" tag_type="text">(</text>
<text top="589" left="315" width="11" height="9" font="font14" id="p7_t477" reading_order_no="475" segment_no="35" tag_type="text">uv</text>
<text top="589" left="329" width="235" height="9" font="font11" id="p7_t478" reading_order_no="476" segment_no="35" tag_type="text">map) for human parts. We formulate the reconstruction</text>
<text top="600" left="312" width="157" height="9" font="font11" id="p7_t479" reading_order_no="477" segment_no="35" tag_type="text">as a non-linear optimization problem</text>
<text top="618" left="331" width="32" height="9" font="font19" id="p7_t480" reading_order_no="478" segment_no="38" tag_type="formula">arg min</text>
<text top="628" left="336" width="6" height="6" font="font51" id="p7_t481" reading_order_no="479" segment_no="38" tag_type="formula">α</text>
<text top="628" left="342" width="2" height="6" font="font38" id="p7_t482" reading_order_no="480" segment_no="38" tag_type="formula">,</text>
<text top="628" left="345" width="5" height="6" font="font51" id="p7_t483" reading_order_no="481" segment_no="38" tag_type="formula">β</text>
<text top="628" left="350" width="2" height="6" font="font38" id="p7_t484" reading_order_no="482" segment_no="38" tag_type="formula">,</text>
<text top="628" left="352" width="4" height="6" font="font51" id="p7_t485" reading_order_no="483" segment_no="38" tag_type="formula">θ</text>
<text top="618" left="368" width="4" height="9" font="font19" id="p7_t486" reading_order_no="484" segment_no="38" tag_type="formula">(</text>
<text top="618" left="372" width="7" height="9" font="font14" id="p7_t487" reading_order_no="485" segment_no="38" tag_type="formula">w</text>
<text top="621" left="379" width="16" height="6" font="font38" id="p7_t488" reading_order_no="486" segment_no="38" tag_type="formula">data</text>
<text top="618" left="395" width="7" height="9" font="font14" id="p7_t489" reading_order_no="487" segment_no="38" tag_type="formula">E</text>
<text top="621" left="403" width="16" height="6" font="font38" id="p7_t490" reading_order_no="488" segment_no="38" tag_type="formula">data</text>
<text top="618" left="421" width="8" height="9" font="font19" id="p7_t491" reading_order_no="489" segment_no="38" tag_type="formula">+</text>
<text top="618" left="431" width="7" height="9" font="font14" id="p7_t492" reading_order_no="490" segment_no="38" tag_type="formula">w</text>
<text top="621" left="438" width="37" height="6" font="font38" id="p7_t493" reading_order_no="491" segment_no="38" tag_type="formula">pose prior</text>
<text top="618" left="476" width="7" height="9" font="font14" id="p7_t494" reading_order_no="492" segment_no="38" tag_type="formula">E</text>
<text top="621" left="484" width="37" height="6" font="font38" id="p7_t495" reading_order_no="493" segment_no="38" tag_type="formula">pose prior</text>
<text top="618" left="522" width="8" height="9" font="font19" id="p7_t496" reading_order_no="494" segment_no="38" tag_type="formula">+</text>
<text top="639" left="422" width="7" height="9" font="font14" id="p7_t497" reading_order_no="495" segment_no="40" tag_type="formula">w</text>
<text top="643" left="429" width="42" height="6" font="font38" id="p7_t498" reading_order_no="496" segment_no="40" tag_type="formula">shape prior</text>
<text top="639" left="473" width="7" height="9" font="font14" id="p7_t499" reading_order_no="497" segment_no="40" tag_type="formula">E</text>
<text top="643" left="480" width="42" height="6" font="font38" id="p7_t500" reading_order_no="498" segment_no="40" tag_type="formula">shape prior</text>
<text top="639" left="523" width="4" height="9" font="font19" id="p7_t501" reading_order_no="499" segment_no="40" tag_type="formula">)</text>
<text top="639" left="527" width="3" height="9" font="font14" id="p7_t502" reading_order_no="500" segment_no="40" tag_type="formula">,</text>
<text top="629" left="548" width="16" height="9" font="font11" id="p7_t503" reading_order_no="501" segment_no="39" tag_type="text">(16)</text>
<text top="657" left="312" width="26" height="9" font="font11" id="p7_t504" reading_order_no="502" segment_no="43" tag_type="text">where</text>
<text top="656" left="341" width="7" height="9" font="font14" id="p7_t505" reading_order_no="503" segment_no="43" tag_type="text">E</text>
<text top="660" left="348" width="16" height="6" font="font38" id="p7_t506" reading_order_no="504" segment_no="43" tag_type="text">data</text>
<text top="657" left="368" width="196" height="9" font="font11" id="p7_t507" reading_order_no="505" segment_no="43" tag_type="text">is the data term that describes the registration</text>
<text top="668" left="312" width="252" height="9" font="font11" id="p7_t508" reading_order_no="506" segment_no="43" tag_type="text">error between the synthesized model and the network ob-</text>
<text top="680" left="312" width="151" height="9" font="font11" id="p7_t509" reading_order_no="507" segment_no="43" tag_type="text">servations that inherits from § 5.2,</text>
<text top="680" left="467" width="7" height="9" font="font14" id="p7_t510" reading_order_no="508" segment_no="43" tag_type="text">E</text>
<text top="683" left="474" width="37" height="6" font="font38" id="p7_t511" reading_order_no="509" segment_no="43" tag_type="text">pose prior</text>
<text top="680" left="517" width="48" height="9" font="font11" id="p7_t512" reading_order_no="510" segment_no="43" tag_type="text">is the pose</text>
<text top="691" left="312" width="146" height="9" font="font11" id="p7_t513" reading_order_no="511" segment_no="43" tag_type="text">prior term that inherits from § 5.2,</text>
<text top="691" left="461" width="7" height="9" font="font14" id="p7_t514" reading_order_no="512" segment_no="43" tag_type="text">E</text>
<text top="695" left="468" width="42" height="6" font="font38" id="p7_t515" reading_order_no="513" segment_no="43" tag_type="text">shape prior</text>
<text top="691" left="514" width="50" height="9" font="font11" id="p7_t516" reading_order_no="514" segment_no="43" tag_type="text">is the shape</text>
<text top="703" left="312" width="252" height="9" font="font11" id="p7_t517" reading_order_no="515" segment_no="43" tag_type="text">prior term that penalizes the deviation of shape parameters</text>
<text top="714" left="312" width="165" height="9" font="font11" id="p7_t518" reading_order_no="516" segment_no="43" tag_type="text">from the human shape in the database.</text>
<text top="726" left="326" width="99" height="9" font="font18" id="p7_t519" reading_order_no="517" segment_no="46" tag_type="text"><b>The shape prior term.</b></text>
<text top="726" left="430" width="134" height="9" font="font11" id="p7_t520" reading_order_no="518" segment_no="46" tag_type="text">We model the shape prior dis-</text>
<text top="737" left="312" width="252" height="9" font="font11" id="p7_t521" reading_order_no="519" segment_no="46" tag_type="text">tribution with multiple single-variable Gaussian models</text>
</page>
<page number="8" position="absolute" top="0" left="0" height="792" width="612">
<text top="29" left="48" width="334" height="6" font="font0" id="p8_t1" reading_order_no="0" segment_no="0" tag_type="title">IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS, VOL. XX, NO. , AUGUST 2020</text>
<text top="29" left="560" width="4" height="6" font="font0" id="p8_t2" reading_order_no="1" segment_no="1" tag_type="text">8</text>
<text top="206" left="121" width="107" height="9" font="font11" id="p8_t3" reading_order_no="2" segment_no="4" tag_type="text">Fig. 6: The capture space.</text>
<text top="241" left="48" width="252" height="9" font="font11" id="p8_t4" reading_order_no="3" segment_no="5" tag_type="text">that is learnt from the human shape database. We define</text>
<text top="252" left="48" width="7" height="9" font="font14" id="p8_t5" reading_order_no="4" segment_no="5" tag_type="text">E</text>
<text top="256" left="55" width="42" height="6" font="font38" id="p8_t6" reading_order_no="5" segment_no="5" tag_type="text">shape prior</text>
<text top="252" left="101" width="176" height="9" font="font11" id="p8_t7" reading_order_no="6" segment_no="5" tag_type="text">as the deviation distance with parameters</text>
<text top="276" left="59" width="7" height="9" font="font14" id="p8_t8" reading_order_no="7" segment_no="6" tag_type="formula">E</text>
<text top="279" left="67" width="42" height="6" font="font38" id="p8_t9" reading_order_no="8" segment_no="6" tag_type="formula">shape prior</text>
<text top="276" left="112" width="14" height="9" font="font19" id="p8_t10" reading_order_no="9" segment_no="6" tag_type="formula">= (</text>
<text top="273" left="127" width="14" height="4" font="font42" id="p8_t11" reading_order_no="10" segment_no="6" tag_type="formula">X</text>
<text top="289" left="133" width="3" height="6" font="font38" id="p8_t12" reading_order_no="11" segment_no="6" tag_type="formula">i</text>
<text top="275" left="143" width="3" height="9" font="font36" id="p8_t13" reading_order_no="12" segment_no="6" tag_type="formula">|</text>
<text top="276" left="146" width="6" height="9" font="font14" id="p8_t14" reading_order_no="13" segment_no="6" tag_type="formula">α</text>
<text top="274" left="152" width="3" height="6" font="font38" id="p8_t15" reading_order_no="14" segment_no="6" tag_type="formula">i</text>
<text top="275" left="158" width="8" height="9" font="font36" id="p8_t16" reading_order_no="15" segment_no="6" tag_type="formula">−</text>
<text top="276" left="168" width="6" height="9" font="font14" id="p8_t17" reading_order_no="16" segment_no="6" tag_type="formula">µ</text>
<text top="274" left="174" width="3" height="6" font="font38" id="p8_t18" reading_order_no="17" segment_no="6" tag_type="formula">i</text>
<text top="280" left="174" width="5" height="6" font="font38" id="p8_t19" reading_order_no="18" segment_no="6" tag_type="formula">α</text>
<text top="275" left="179" width="3" height="9" font="font36" id="p8_t20" reading_order_no="19" segment_no="6" tag_type="formula">|</text>
<text top="276" left="182" width="11" height="9" font="font14" id="p8_t21" reading_order_no="20" segment_no="6" tag_type="formula">/σ</text>
<text top="274" left="193" width="3" height="6" font="font38" id="p8_t22" reading_order_no="21" segment_no="6" tag_type="formula">i</text>
<text top="280" left="193" width="5" height="6" font="font38" id="p8_t23" reading_order_no="22" segment_no="6" tag_type="formula">α</text>
<text top="276" left="201" width="8" height="9" font="font19" id="p8_t24" reading_order_no="23" segment_no="6" tag_type="formula">+</text>
<text top="273" left="211" width="14" height="4" font="font42" id="p8_t25" reading_order_no="24" segment_no="6" tag_type="formula">X</text>
<text top="289" left="216" width="3" height="6" font="font38" id="p8_t26" reading_order_no="25" segment_no="6" tag_type="formula">j</text>
<text top="275" left="227" width="3" height="9" font="font36" id="p8_t27" reading_order_no="26" segment_no="6" tag_type="formula">|</text>
<text top="276" left="229" width="6" height="9" font="font14" id="p8_t28" reading_order_no="27" segment_no="6" tag_type="formula">β</text>
<text top="274" left="236" width="3" height="6" font="font38" id="p8_t29" reading_order_no="28" segment_no="6" tag_type="formula">j</text>
<text top="275" left="242" width="8" height="9" font="font36" id="p8_t30" reading_order_no="29" segment_no="6" tag_type="formula">−</text>
<text top="276" left="252" width="6" height="9" font="font14" id="p8_t31" reading_order_no="30" segment_no="6" tag_type="formula">µ</text>
<text top="273" left="258" width="3" height="6" font="font38" id="p8_t32" reading_order_no="31" segment_no="6" tag_type="formula">j</text>
<text top="281" left="258" width="5" height="6" font="font38" id="p8_t33" reading_order_no="32" segment_no="6" tag_type="formula">β</text>
<text top="275" left="263" width="3" height="9" font="font36" id="p8_t34" reading_order_no="33" segment_no="6" tag_type="formula">|</text>
<text top="276" left="266" width="11" height="9" font="font14" id="p8_t35" reading_order_no="34" segment_no="6" tag_type="formula">/σ</text>
<text top="273" left="277" width="3" height="6" font="font38" id="p8_t36" reading_order_no="35" segment_no="6" tag_type="formula">j</text>
<text top="281" left="277" width="5" height="6" font="font38" id="p8_t37" reading_order_no="36" segment_no="6" tag_type="formula">β</text>
<text top="276" left="282" width="4" height="9" font="font19" id="p8_t38" reading_order_no="37" segment_no="6" tag_type="formula">)</text>
<text top="276" left="286" width="3" height="9" font="font14" id="p8_t39" reading_order_no="38" segment_no="6" tag_type="formula">,</text>
<text top="307" left="48" width="26" height="9" font="font11" id="p8_t40" reading_order_no="39" segment_no="11" tag_type="text">where</text>
<text top="307" left="77" width="6" height="9" font="font14" id="p8_t41" reading_order_no="40" segment_no="11" tag_type="text">µ</text>
<text top="307" left="85" width="93" height="9" font="font11" id="p8_t42" reading_order_no="41" segment_no="11" tag_type="text">is the mean value and</text>
<text top="307" left="181" width="6" height="9" font="font14" id="p8_t43" reading_order_no="42" segment_no="11" tag_type="text">σ</text>
<text top="307" left="190" width="107" height="9" font="font11" id="p8_t44" reading_order_no="43" segment_no="11" tag_type="text">is the standard deviation.</text>
<text top="334" left="48" width="21" height="9" font="font48" id="p8_t45" reading_order_no="44" segment_no="12" tag_type="title">5.3.2</text>
<text top="334" left="79" width="53" height="9" font="font48" id="p8_t46" reading_order_no="45" segment_no="12" tag_type="title">Optimization</text>
<text top="351" left="48" width="252" height="9" font="font11" id="p8_t47" reading_order_no="46" segment_no="7" tag_type="text">Directly optimizing Eq. 16 is not efficient and often falls into</text>
<text top="363" left="48" width="252" height="9" font="font11" id="p8_t48" reading_order_no="47" segment_no="7" tag_type="text">local minima, because the pose and the shape are coupled.</text>
<text top="374" left="48" width="252" height="9" font="font11" id="p8_t49" reading_order_no="48" segment_no="7" tag_type="text">To address this issue, we decouple the optimization into two</text>
<text top="386" left="48" width="252" height="9" font="font11" id="p8_t50" reading_order_no="49" segment_no="7" tag_type="text">sub-optimization problems: pose optimization and shape</text>
<text top="397" left="48" width="252" height="9" font="font11" id="p8_t51" reading_order_no="50" segment_no="7" tag_type="text">optimization. In each iteration, we first fix shape parameters</text>
<text top="409" left="48" width="218" height="9" font="font11" id="p8_t52" reading_order_no="51" segment_no="7" tag_type="text">and optimize pose parameters, and then vice versa.</text>
<text top="421" left="62" width="74" height="9" font="font18" id="p8_t53" reading_order_no="52" segment_no="15" tag_type="text"><b>Pose estimation.</b></text>
<text top="421" left="142" width="158" height="9" font="font11" id="p8_t54" reading_order_no="53" segment_no="15" tag_type="text">In this step, we optimize the pose</text>
<text top="433" left="48" width="43" height="9" font="font11" id="p8_t55" reading_order_no="54" segment_no="15" tag_type="text">parameter</text>
<text top="432" left="96" width="6" height="9" font="font41" id="p8_t56" reading_order_no="55" segment_no="15" tag_type="text">θ</text>
<text top="433" left="106" width="146" height="9" font="font11" id="p8_t57" reading_order_no="56" segment_no="15" tag_type="text">while fixing the shape parameter</text>
<text top="432" left="256" width="8" height="9" font="font41" id="p8_t58" reading_order_no="57" segment_no="15" tag_type="text">α</text>
<text top="432" left="264" width="3" height="9" font="font14" id="p8_t59" reading_order_no="58" segment_no="15" tag_type="text">,</text>
<text top="432" left="268" width="7" height="9" font="font41" id="p8_t60" reading_order_no="59" segment_no="15" tag_type="text">β</text>
<text top="433" left="275" width="25" height="9" font="font11" id="p8_t61" reading_order_no="60" segment_no="15" tag_type="text">. This</text>
<text top="444" left="48" width="145" height="9" font="font11" id="p8_t62" reading_order_no="61" segment_no="15" tag_type="text">process is identical to that in § 5.2.</text>
<text top="457" left="62" width="79" height="9" font="font18" id="p8_t63" reading_order_no="62" segment_no="17" tag_type="text"><b>Shape estimation.</b></text>
<text top="456" left="146" width="154" height="9" font="font11" id="p8_t64" reading_order_no="63" segment_no="17" tag_type="text">In this step, we optimize the shape</text>
<text top="468" left="48" width="43" height="9" font="font11" id="p8_t65" reading_order_no="64" segment_no="17" tag_type="text">parameter</text>
<text top="468" left="95" width="8" height="9" font="font41" id="p8_t66" reading_order_no="65" segment_no="17" tag_type="text">α</text>
<text top="468" left="102" width="3" height="9" font="font14" id="p8_t67" reading_order_no="66" segment_no="17" tag_type="text">,</text>
<text top="468" left="107" width="7" height="9" font="font41" id="p8_t68" reading_order_no="67" segment_no="17" tag_type="text">β</text>
<text top="468" left="117" width="147" height="9" font="font11" id="p8_t69" reading_order_no="68" segment_no="17" tag_type="text">while keeping the pose parameter</text>
<text top="468" left="267" width="6" height="9" font="font41" id="p8_t70" reading_order_no="69" segment_no="17" tag_type="text">θ</text>
<text top="468" left="277" width="23" height="9" font="font11" id="p8_t71" reading_order_no="70" segment_no="17" tag_type="text">fixed.</text>
<text top="480" left="48" width="252" height="9" font="font11" id="p8_t72" reading_order_no="71" segment_no="17" tag_type="text">And therefore the optimization problem can be represented</text>
<text top="491" left="48" width="11" height="9" font="font11" id="p8_t73" reading_order_no="72" segment_no="17" tag_type="text">by</text>
<text top="513" left="65" width="32" height="9" font="font19" id="p8_t74" reading_order_no="73" segment_no="19" tag_type="formula">arg min</text>
<text top="523" left="74" width="6" height="6" font="font51" id="p8_t75" reading_order_no="74" segment_no="19" tag_type="formula">α</text>
<text top="523" left="80" width="2" height="6" font="font38" id="p8_t76" reading_order_no="75" segment_no="19" tag_type="formula">,</text>
<text top="523" left="82" width="5" height="6" font="font51" id="p8_t77" reading_order_no="76" segment_no="19" tag_type="formula">β</text>
<text top="513" left="97" width="4" height="9" font="font19" id="p8_t78" reading_order_no="77" segment_no="19" tag_type="formula">(</text>
<text top="513" left="101" width="7" height="9" font="font14" id="p8_t79" reading_order_no="78" segment_no="19" tag_type="formula">w</text>
<text top="516" left="108" width="16" height="6" font="font38" id="p8_t80" reading_order_no="79" segment_no="19" tag_type="formula">data</text>
<text top="513" left="124" width="7" height="9" font="font14" id="p8_t81" reading_order_no="80" segment_no="19" tag_type="formula">E</text>
<text top="516" left="132" width="16" height="6" font="font38" id="p8_t82" reading_order_no="81" segment_no="19" tag_type="formula">data</text>
<text top="513" left="150" width="8" height="9" font="font19" id="p8_t83" reading_order_no="82" segment_no="19" tag_type="formula">+</text>
<text top="513" left="160" width="7" height="9" font="font14" id="p8_t84" reading_order_no="83" segment_no="19" tag_type="formula">w</text>
<text top="516" left="167" width="42" height="6" font="font38" id="p8_t85" reading_order_no="84" segment_no="19" tag_type="formula">shape prior</text>
<text top="513" left="210" width="7" height="9" font="font14" id="p8_t86" reading_order_no="85" segment_no="19" tag_type="formula">E</text>
<text top="516" left="218" width="42" height="6" font="font38" id="p8_t87" reading_order_no="86" segment_no="19" tag_type="formula">shape prior</text>
<text top="513" left="261" width="4" height="9" font="font19" id="p8_t88" reading_order_no="87" segment_no="19" tag_type="formula">)</text>
<text top="513" left="265" width="3" height="9" font="font14" id="p8_t89" reading_order_no="88" segment_no="19" tag_type="formula">.</text>
<text top="513" left="284" width="16" height="9" font="font11" id="p8_t90" reading_order_no="89" segment_no="20" tag_type="text">(17)</text>
<text top="541" left="48" width="252" height="9" font="font11" id="p8_t91" reading_order_no="90" segment_no="21" tag_type="text">Following the optimization method in § 5.2.4, we can solve</text>
<text top="552" left="48" width="90" height="9" font="font11" id="p8_t92" reading_order_no="91" segment_no="21" tag_type="text">the shape parameters</text>
<text top="552" left="141" width="8" height="9" font="font41" id="p8_t93" reading_order_no="92" segment_no="21" tag_type="text">α</text>
<text top="552" left="151" width="16" height="9" font="font11" id="p8_t94" reading_order_no="93" segment_no="21" tag_type="text">and</text>
<text top="552" left="170" width="7" height="9" font="font41" id="p8_t95" reading_order_no="94" segment_no="21" tag_type="text">β</text>
<text top="552" left="177" width="2" height="9" font="font11" id="p8_t96" reading_order_no="95" segment_no="21" tag_type="text">.</text>
<text top="565" left="62" width="78" height="9" font="font18" id="p8_t97" reading_order_no="96" segment_no="24" tag_type="text"><b>Parameter values.</b></text>
<text top="565" left="143" width="157" height="9" font="font11" id="p8_t98" reading_order_no="97" segment_no="24" tag_type="text">For shape reconstruction, the energy</text>
<text top="576" left="48" width="24" height="9" font="font11" id="p8_t99" reading_order_no="98" segment_no="24" tag_type="text">terms</text>
<text top="576" left="76" width="7" height="9" font="font14" id="p8_t100" reading_order_no="99" segment_no="24" tag_type="text">E</text>
<text top="580" left="83" width="16" height="6" font="font38" id="p8_t101" reading_order_no="100" segment_no="24" tag_type="text">data</text>
<text top="576" left="103" width="16" height="9" font="font11" id="p8_t102" reading_order_no="101" segment_no="24" tag_type="text">and</text>
<text top="576" left="123" width="7" height="9" font="font14" id="p8_t103" reading_order_no="102" segment_no="24" tag_type="text">E</text>
<text top="580" left="131" width="37" height="6" font="font38" id="p8_t104" reading_order_no="103" segment_no="24" tag_type="text">pose prior</text>
<text top="576" left="173" width="127" height="9" font="font11" id="p8_t105" reading_order_no="104" segment_no="24" tag_type="text">are the same as in § 5.2. The</text>
<text top="588" left="48" width="122" height="9" font="font11" id="p8_t106" reading_order_no="105" segment_no="24" tag_type="text">shape prior weight we use is</text>
<text top="588" left="172" width="7" height="9" font="font14" id="p8_t107" reading_order_no="106" segment_no="24" tag_type="text">w</text>
<text top="591" left="180" width="42" height="6" font="font38" id="p8_t108" reading_order_no="107" segment_no="24" tag_type="text">shape prior</text>
<text top="588" left="225" width="15" height="9" font="font19" id="p8_t109" reading_order_no="108" segment_no="24" tag_type="text">= 0</text>
<text top="588" left="241" width="3" height="9" font="font14" id="p8_t110" reading_order_no="109" segment_no="24" tag_type="text">.</text>
<text top="588" left="244" width="5" height="9" font="font19" id="p8_t111" reading_order_no="110" segment_no="24" tag_type="text">1</text>
<text top="588" left="249" width="2" height="9" font="font11" id="p8_t112" reading_order_no="111" segment_no="24" tag_type="text">.</text>
<text top="624" left="48" width="6" height="10" font="font7" id="p8_t113" reading_order_no="112" segment_no="26" tag_type="title"><b>6</b></text>
<text top="624" left="66" width="7" height="10" font="font7" id="p8_t114" reading_order_no="113" segment_no="26" tag_type="title"><b>T</b></text>
<text top="626" left="73" width="40" height="8" font="font8" id="p8_t115" reading_order_no="114" segment_no="26" tag_type="title"><b>RAINING</b></text>
<text top="624" left="117" width="8" height="10" font="font7" id="p8_t116" reading_order_no="115" segment_no="26" tag_type="title"><b>D</b></text>
<text top="626" left="125" width="18" height="8" font="font8" id="p8_t117" reading_order_no="116" segment_no="26" tag_type="title"><b>ATA</b></text>
<text top="645" left="48" width="252" height="9" font="font11" id="p8_t118" reading_order_no="117" segment_no="28" tag_type="text">As one major highlight of our work, we complement ex-</text>
<text top="657" left="48" width="252" height="9" font="font11" id="p8_t119" reading_order_no="118" segment_no="28" tag_type="text">isting datasets by building a dataset with a large number</text>
<text top="668" left="48" width="252" height="9" font="font11" id="p8_t120" reading_order_no="119" segment_no="28" tag_type="text">of actors, everyday clothing appearances, a broad range</text>
<text top="680" left="48" width="252" height="9" font="font11" id="p8_t121" reading_order_no="120" segment_no="28" tag_type="text">of motions. The data capture setup eases the appearance</text>
<text top="691" left="48" width="252" height="9" font="font11" id="p8_t122" reading_order_no="121" segment_no="28" tag_type="text">augmentation and extends the captured variability. This</text>
<text top="703" left="48" width="252" height="9" font="font11" id="p8_t123" reading_order_no="122" segment_no="28" tag_type="text">gives a potential to bring significant boost to accuracy and</text>
<text top="714" left="48" width="252" height="9" font="font11" id="p8_t124" reading_order_no="123" segment_no="28" tag_type="text">generalizability of the learnt models. In this section we</text>
<text top="726" left="48" width="252" height="9" font="font11" id="p8_t125" reading_order_no="124" segment_no="28" tag_type="text">describe the capture environment and the recording process,</text>
<text top="737" left="48" width="195" height="9" font="font11" id="p8_t126" reading_order_no="125" segment_no="28" tag_type="text">as well as the processing of the captured data.</text>
<text top="45" left="312" width="13" height="9" font="font39" id="p8_t127" reading_order_no="126" segment_no="2" tag_type="title"><b>6.1</b></text>
<text top="45" left="335" width="89" height="9" font="font39" id="p8_t128" reading_order_no="127" segment_no="2" tag_type="title"><b>Experimental Setup</b></text>
<text top="60" left="312" width="252" height="9" font="font11" id="p8_t129" reading_order_no="128" segment_no="3" tag_type="text">Our laboratory setup is shown in Fig. 6, where data is</text>
<text top="72" left="312" width="252" height="9" font="font11" id="p8_t130" reading_order_no="129" segment_no="3" tag_type="text">captured by four digital video cameras. The designated</text>
<text top="83" left="312" width="102" height="9" font="font11" id="p8_t131" reading_order_no="130" segment_no="3" tag_type="text">laboratory area is about</text>
<text top="83" left="417" width="5" height="9" font="font19" id="p8_t132" reading_order_no="131" segment_no="3" tag_type="text">4</text>
<text top="83" left="422" width="9" height="9" font="font14" id="p8_t133" reading_order_no="132" segment_no="3" tag_type="text">m</text>
<text top="83" left="433" width="8" height="9" font="font36" id="p8_t134" reading_order_no="133" segment_no="3" tag_type="text">×</text>
<text top="83" left="443" width="5" height="9" font="font19" id="p8_t135" reading_order_no="134" segment_no="3" tag_type="text">4</text>
<text top="83" left="448" width="9" height="9" font="font14" id="p8_t136" reading_order_no="135" segment_no="3" tag_type="text">m</text>
<text top="83" left="457" width="107" height="9" font="font11" id="p8_t137" reading_order_no="136" segment_no="3" tag_type="text">, and within it we obtain</text>
<text top="95" left="312" width="167" height="9" font="font11" id="p8_t138" reading_order_no="137" segment_no="3" tag_type="text">effective capture court of approximately</text>
<text top="95" left="481" width="5" height="9" font="font19" id="p8_t139" reading_order_no="138" segment_no="3" tag_type="text">2</text>
<text top="95" left="486" width="3" height="9" font="font14" id="p8_t140" reading_order_no="139" segment_no="3" tag_type="text">.</text>
<text top="95" left="489" width="5" height="9" font="font19" id="p8_t141" reading_order_no="140" segment_no="3" tag_type="text">5</text>
<text top="95" left="494" width="9" height="9" font="font14" id="p8_t142" reading_order_no="141" segment_no="3" tag_type="text">m</text>
<text top="94" left="504" width="8" height="9" font="font36" id="p8_t143" reading_order_no="142" segment_no="3" tag_type="text">×</text>
<text top="95" left="512" width="5" height="9" font="font19" id="p8_t144" reading_order_no="143" segment_no="3" tag_type="text">2</text>
<text top="95" left="517" width="3" height="9" font="font14" id="p8_t145" reading_order_no="144" segment_no="3" tag_type="text">.</text>
<text top="95" left="520" width="5" height="9" font="font19" id="p8_t146" reading_order_no="145" segment_no="3" tag_type="text">5</text>
<text top="95" left="525" width="9" height="9" font="font14" id="p8_t147" reading_order_no="146" segment_no="3" tag_type="text">m</text>
<text top="95" left="533" width="31" height="9" font="font11" id="p8_t148" reading_order_no="147" segment_no="3" tag_type="text">, where</text>
<text top="107" left="312" width="252" height="9" font="font11" id="p8_t149" reading_order_no="148" segment_no="3" tag_type="text">each subject is fully visible to all cameras. Four cameras are</text>
<text top="118" left="312" width="252" height="9" font="font11" id="p8_t150" reading_order_no="149" segment_no="3" tag_type="text">placed at four corners of the court. The floor and the wall are</text>
<text top="130" left="312" width="252" height="9" font="font11" id="p8_t151" reading_order_no="150" segment_no="3" tag_type="text">mantled with green curtains, making it easy for automatic</text>
<text top="141" left="312" width="252" height="9" font="font11" id="p8_t152" reading_order_no="151" segment_no="3" tag_type="text">segmentation of the foreground body. The total number of</text>
<text top="153" left="312" width="100" height="9" font="font11" id="p8_t153" reading_order_no="152" segment_no="3" tag_type="text">actors screened are over</text>
<text top="153" left="414" width="15" height="9" font="font19" id="p8_t154" reading_order_no="153" segment_no="3" tag_type="text">300</text>
<text top="153" left="429" width="135" height="9" font="font11" id="p8_t155" reading_order_no="154" segment_no="3" tag_type="text">, covering a broad range of ages,</text>
<text top="164" left="312" width="252" height="9" font="font11" id="p8_t156" reading_order_no="155" segment_no="3" tag_type="text">body shapes and pose extensions. Our dataset has much</text>
<text top="176" left="312" width="252" height="9" font="font11" id="p8_t157" reading_order_no="156" segment_no="3" tag_type="text">more subjects than in any of existing 3D datasets. Each per-</text>
<text top="187" left="312" width="252" height="9" font="font11" id="p8_t158" reading_order_no="157" segment_no="3" tag_type="text">son is asked to do certain daily life motions as well as sport</text>
<text top="199" left="312" width="252" height="9" font="font11" id="p8_t159" reading_order_no="158" segment_no="3" tag_type="text">motions, for about three minutes. To eliminate redundancy</text>
<text top="210" left="312" width="252" height="9" font="font11" id="p8_t160" reading_order_no="159" segment_no="3" tag_type="text">between consecutive video frames, frame images are further</text>
<text top="222" left="312" width="252" height="9" font="font11" id="p8_t161" reading_order_no="160" segment_no="3" tag_type="text">filtered, and only 500 to 1,000 images are sampled for each</text>
<text top="233" left="312" width="252" height="9" font="font11" id="p8_t162" reading_order_no="161" segment_no="3" tag_type="text">actor. The sampling is achieved by clustering frame images</text>
<text top="245" left="312" width="183" height="9" font="font11" id="p8_t163" reading_order_no="162" segment_no="3" tag_type="text">according to the similarity of human poses.</text>
<text top="274" left="312" width="13" height="9" font="font39" id="p8_t164" reading_order_no="163" segment_no="9" tag_type="title"><b>6.2</b></text>
<text top="274" left="335" width="194" height="9" font="font39" id="p8_t165" reading_order_no="164" segment_no="9" tag_type="title"><b>Shape Reconstruction from Measurements</b></text>
<text top="289" left="312" width="252" height="9" font="font11" id="p8_t166" reading_order_no="165" segment_no="10" tag_type="text">To build a highly accurate parametric body model for each</text>
<text top="301" left="312" width="252" height="9" font="font11" id="p8_t167" reading_order_no="166" segment_no="10" tag_type="text">actor, we take some body measurements while an actor is</text>
<text top="312" left="312" width="206" height="9" font="font11" id="p8_t168" reading_order_no="167" segment_no="10" tag_type="text">standing still in A-pose. A set of measurements</text>
<text top="312" left="522" width="11" height="9" font="font49" id="p8_t169" reading_order_no="168" segment_no="10" tag_type="text">M</text>
<text top="312" left="537" width="7" height="9" font="font36" id="p8_t170" reading_order_no="169" segment_no="10" tag_type="text">∈</text>
<text top="312" left="548" width="8" height="9" font="font14" id="p8_t171" reading_order_no="170" segment_no="10" tag_type="text">R</text>
<text top="311" left="556" width="8" height="6" font="font37" id="p8_t172" reading_order_no="171" segment_no="10" tag_type="text">44</text>
<text top="324" left="312" width="252" height="9" font="font11" id="p8_t173" reading_order_no="172" segment_no="10" tag_type="text">(including but not limited to lengths of limbs, shoulder</text>
<text top="335" left="312" width="252" height="9" font="font11" id="p8_t174" reading_order_no="173" segment_no="10" tag_type="text">and back, girths of chest, wrist, hip and stomach, etc.), are</text>
<text top="347" left="312" width="252" height="9" font="font11" id="p8_t175" reading_order_no="174" segment_no="10" tag_type="text">tailoring measured with a ruler. Our parametric model has</text>
<text top="358" left="312" width="51" height="9" font="font19" id="p8_t176" reading_order_no="175" segment_no="10" tag_type="text">8 + 26 = 34</text>
<text top="358" left="366" width="198" height="9" font="font11" id="p8_t177" reading_order_no="176" segment_no="10" tag_type="text">shape parameters, more sophisticated than the</text>
<text top="370" left="312" width="252" height="9" font="font11" id="p8_t178" reading_order_no="177" segment_no="10" tag_type="text">SMPL model, which has only 10 shape parameters. With</text>
<text top="382" left="312" width="132" height="9" font="font11" id="p8_t179" reading_order_no="178" segment_no="10" tag_type="text">the measurements, parameters</text>
<text top="381" left="448" width="8" height="9" font="font41" id="p8_t180" reading_order_no="179" segment_no="10" tag_type="text">α</text>
<text top="382" left="459" width="16" height="9" font="font11" id="p8_t181" reading_order_no="180" segment_no="10" tag_type="text">and</text>
<text top="381" left="479" width="7" height="9" font="font41" id="p8_t182" reading_order_no="181" segment_no="10" tag_type="text">β</text>
<text top="382" left="490" width="74" height="9" font="font11" id="p8_t183" reading_order_no="182" segment_no="10" tag_type="text">are computed by</text>
<text top="393" left="312" width="139" height="9" font="font11" id="p8_t184" reading_order_no="183" segment_no="10" tag_type="text">minimization an energy function</text>
<text top="412" left="352" width="7" height="9" font="font14" id="p8_t185" reading_order_no="184" segment_no="13" tag_type="formula">E</text>
<text top="412" left="360" width="4" height="9" font="font19" id="p8_t186" reading_order_no="185" segment_no="13" tag_type="formula">(</text>
<text top="412" left="364" width="8" height="9" font="font41" id="p8_t187" reading_order_no="186" segment_no="13" tag_type="formula">α</text>
<text top="412" left="371" width="3" height="9" font="font14" id="p8_t188" reading_order_no="187" segment_no="13" tag_type="formula">,</text>
<text top="412" left="376" width="7" height="9" font="font41" id="p8_t189" reading_order_no="188" segment_no="13" tag_type="formula">β</text>
<text top="412" left="382" width="14" height="9" font="font19" id="p8_t190" reading_order_no="189" segment_no="13" tag_type="formula">) =</text>
<text top="412" left="400" width="7" height="9" font="font14" id="p8_t191" reading_order_no="190" segment_no="13" tag_type="formula">w</text>
<text top="416" left="407" width="4" height="6" font="font37" id="p8_t192" reading_order_no="191" segment_no="13" tag_type="formula">1</text>
<text top="412" left="411" width="7" height="9" font="font14" id="p8_t193" reading_order_no="192" segment_no="13" tag_type="formula">E</text>
<text top="416" left="419" width="28" height="6" font="font38" id="p8_t194" reading_order_no="193" segment_no="13" tag_type="formula">geoDist</text>
<text top="412" left="449" width="8" height="9" font="font19" id="p8_t195" reading_order_no="194" segment_no="13" tag_type="formula">+</text>
<text top="412" left="459" width="7" height="9" font="font14" id="p8_t196" reading_order_no="195" segment_no="13" tag_type="formula">w</text>
<text top="416" left="467" width="4" height="6" font="font37" id="p8_t197" reading_order_no="196" segment_no="13" tag_type="formula">2</text>
<text top="412" left="471" width="7" height="9" font="font14" id="p8_t198" reading_order_no="197" segment_no="13" tag_type="formula">E</text>
<text top="416" left="478" width="42" height="6" font="font38" id="p8_t199" reading_order_no="198" segment_no="13" tag_type="formula">shape prior</text>
<text top="412" left="522" width="3" height="9" font="font14" id="p8_t200" reading_order_no="199" segment_no="13" tag_type="formula">,</text>
<text top="412" left="548" width="16" height="9" font="font11" id="p8_t201" reading_order_no="200" segment_no="14" tag_type="text">(18)</text>
<text top="432" left="312" width="26" height="9" font="font11" id="p8_t202" reading_order_no="201" segment_no="16" tag_type="text">where</text>
<text top="432" left="344" width="7" height="9" font="font14" id="p8_t203" reading_order_no="202" segment_no="16" tag_type="text">E</text>
<text top="436" left="351" width="28" height="6" font="font38" id="p8_t204" reading_order_no="203" segment_no="16" tag_type="text">geoDist</text>
<text top="432" left="387" width="8" height="9" font="font19" id="p8_t205" reading_order_no="204" segment_no="16" tag_type="text">=</text>
<text top="431" left="401" width="11" height="4" font="font42" id="p8_t206" reading_order_no="205" segment_no="16" tag_type="text">P</text>
<text top="429" left="412" width="8" height="6" font="font37" id="p8_t207" reading_order_no="206" segment_no="16" tag_type="text">44</text>
<text top="437" left="412" width="3" height="6" font="font38" id="p8_t208" reading_order_no="207" segment_no="16" tag_type="text">i</text>
<text top="437" left="415" width="10" height="6" font="font37" id="p8_t209" reading_order_no="208" segment_no="16" tag_type="text">=1</text>
<text top="432" left="427" width="6" height="9" font="font36" id="p8_t210" reading_order_no="209" segment_no="16" tag_type="text">||</text>
<text top="432" left="433" width="5" height="9" font="font14" id="p8_t211" reading_order_no="210" segment_no="16" tag_type="text">f</text>
<text top="436" left="437" width="3" height="6" font="font38" id="p8_t212" reading_order_no="211" segment_no="16" tag_type="text">i</text>
<text top="432" left="441" width="4" height="9" font="font19" id="p8_t213" reading_order_no="212" segment_no="16" tag_type="text">(</text>
<text top="432" left="445" width="8" height="9" font="font41" id="p8_t214" reading_order_no="213" segment_no="16" tag_type="text">α</text>
<text top="432" left="452" width="3" height="9" font="font14" id="p8_t215" reading_order_no="214" segment_no="16" tag_type="text">,</text>
<text top="432" left="457" width="7" height="9" font="font41" id="p8_t216" reading_order_no="215" segment_no="16" tag_type="text">β</text>
<text top="432" left="464" width="4" height="9" font="font19" id="p8_t217" reading_order_no="216" segment_no="16" tag_type="text">)</text>
<text top="432" left="471" width="8" height="9" font="font36" id="p8_t218" reading_order_no="217" segment_no="16" tag_type="text">−</text>
<text top="432" left="483" width="10" height="9" font="font14" id="p8_t219" reading_order_no="218" segment_no="16" tag_type="text">M</text>
<text top="436" left="493" width="3" height="6" font="font38" id="p8_t220" reading_order_no="219" segment_no="16" tag_type="text">i</text>
<text top="432" left="496" width="6" height="9" font="font36" id="p8_t221" reading_order_no="220" segment_no="16" tag_type="text">||</text>
<text top="436" left="501" width="4" height="6" font="font37" id="p8_t222" reading_order_no="221" segment_no="16" tag_type="text">2</text>
<text top="432" left="511" width="53" height="9" font="font11" id="p8_t223" reading_order_no="222" segment_no="16" tag_type="text">assesses the</text>
<text top="444" left="312" width="252" height="9" font="font11" id="p8_t224" reading_order_no="223" segment_no="16" tag_type="text">error of geodesic distance on the parameterized human</text>
<text top="455" left="312" width="23" height="9" font="font11" id="p8_t225" reading_order_no="224" segment_no="16" tag_type="text">body,</text>
<text top="455" left="339" width="7" height="9" font="font14" id="p8_t226" reading_order_no="225" segment_no="16" tag_type="text">E</text>
<text top="459" left="347" width="42" height="6" font="font38" id="p8_t227" reading_order_no="226" segment_no="16" tag_type="text">shape prior</text>
<text top="455" left="394" width="170" height="9" font="font11" id="p8_t228" reading_order_no="227" segment_no="16" tag_type="text">determines the shape prior error, with</text>
<text top="467" left="312" width="252" height="9" font="font11" id="p8_t229" reading_order_no="228" segment_no="16" tag_type="text">respect to mixed Gaussian distribution. The above energy</text>
<text top="478" left="312" width="252" height="9" font="font11" id="p8_t230" reading_order_no="229" segment_no="16" tag_type="text">is minimized with the Particle Swarm Optimization method</text>
<text top="490" left="312" width="39" height="9" font="font11" id="p8_t231" reading_order_no="230" segment_no="16" tag_type="text">[51], [52].</text>
<text top="502" left="326" width="79" height="9" font="font18" id="p8_t232" reading_order_no="231" segment_no="18" tag_type="text"><b>Parameter values.</b></text>
<text top="502" left="410" width="29" height="9" font="font11" id="p8_t233" reading_order_no="232" segment_no="18" tag_type="text">We set</text>
<text top="502" left="443" width="7" height="9" font="font14" id="p8_t234" reading_order_no="233" segment_no="18" tag_type="text">w</text>
<text top="505" left="451" width="4" height="6" font="font37" id="p8_t235" reading_order_no="234" segment_no="18" tag_type="text">1</text>
<text top="502" left="461" width="18" height="9" font="font19" id="p8_t236" reading_order_no="235" segment_no="18" tag_type="text">= 8</text>
<text top="502" left="479" width="3" height="9" font="font14" id="p8_t237" reading_order_no="236" segment_no="18" tag_type="text">.</text>
<text top="502" left="482" width="5" height="9" font="font19" id="p8_t238" reading_order_no="237" segment_no="18" tag_type="text">0</text>
<text top="502" left="491" width="12" height="9" font="font11" id="p8_t239" reading_order_no="238" segment_no="18" tag_type="text">for</text>
<text top="502" left="507" width="7" height="9" font="font14" id="p8_t240" reading_order_no="239" segment_no="18" tag_type="text">E</text>
<text top="505" left="515" width="28" height="6" font="font38" id="p8_t241" reading_order_no="240" segment_no="18" tag_type="text">geoDist</text>
<text top="502" left="548" width="16" height="9" font="font11" id="p8_t242" reading_order_no="241" segment_no="18" tag_type="text">and</text>
<text top="513" left="312" width="7" height="9" font="font14" id="p8_t243" reading_order_no="242" segment_no="18" tag_type="text">w</text>
<text top="517" left="319" width="4" height="6" font="font37" id="p8_t244" reading_order_no="243" segment_no="18" tag_type="text">2</text>
<text top="513" left="326" width="15" height="9" font="font19" id="p8_t245" reading_order_no="244" segment_no="18" tag_type="text">= 0</text>
<text top="513" left="342" width="3" height="9" font="font14" id="p8_t246" reading_order_no="245" segment_no="18" tag_type="text">.</text>
<text top="513" left="345" width="5" height="9" font="font19" id="p8_t247" reading_order_no="246" segment_no="18" tag_type="text">8</text>
<text top="513" left="352" width="12" height="9" font="font11" id="p8_t248" reading_order_no="247" segment_no="18" tag_type="text">for</text>
<text top="513" left="367" width="7" height="9" font="font14" id="p8_t249" reading_order_no="248" segment_no="18" tag_type="text">E</text>
<text top="517" left="374" width="42" height="6" font="font38" id="p8_t250" reading_order_no="249" segment_no="18" tag_type="text">shape prior</text>
<text top="513" left="420" width="39" height="9" font="font11" id="p8_t251" reading_order_no="250" segment_no="18" tag_type="text">in Eq. 18.</text>
<text top="542" left="312" width="13" height="9" font="font39" id="p8_t252" reading_order_no="251" segment_no="22" tag_type="title"><b>6.3</b></text>
<text top="542" left="335" width="95" height="9" font="font39" id="p8_t253" reading_order_no="252" segment_no="22" tag_type="title"><b>Pose Reconstruction</b></text>
<text top="557" left="312" width="252" height="9" font="font11" id="p8_t254" reading_order_no="253" segment_no="23" tag_type="text">With four multi-view images for each frame, a 3D pose is</text>
<text top="569" left="312" width="200" height="9" font="font11" id="p8_t255" reading_order_no="254" segment_no="23" tag_type="text">reconstructed, according to the following steps.</text>
<text top="587" left="326" width="8" height="9" font="font11" id="p8_t256" reading_order_no="255" segment_no="25" tag_type="list">1)</text>
<text top="587" left="346" width="218" height="9" font="font11" id="p8_t257" reading_order_no="256" segment_no="25" tag_type="list">Estimate 18 joints on each image from each camera,</text>
<text top="599" left="346" width="166" height="9" font="font11" id="p8_t258" reading_order_no="257" segment_no="25" tag_type="list">with a 2D joint estimation method [43].</text>
<text top="610" left="326" width="8" height="9" font="font11" id="p8_t259" reading_order_no="258" segment_no="8" tag_type="list">2)</text>
<text top="610" left="346" width="218" height="9" font="font11" id="p8_t260" reading_order_no="259" segment_no="8" tag_type="list">Validate the consistency of the estimated 2D joints</text>
<text top="622" left="346" width="209" height="9" font="font11" id="p8_t261" reading_order_no="260" segment_no="8" tag_type="list">from multi-views (see the following explanation).</text>
<text top="634" left="326" width="8" height="9" font="font11" id="p8_t262" reading_order_no="261" segment_no="27" tag_type="list">3)</text>
<text top="634" left="346" width="218" height="9" font="font11" id="p8_t263" reading_order_no="262" segment_no="27" tag_type="list">Segment foreground body from background auto-</text>
<text top="645" left="346" width="141" height="9" font="font11" id="p8_t264" reading_order_no="263" segment_no="27" tag_type="list">matically (green curtains setting).</text>
<text top="657" left="326" width="8" height="9" font="font11" id="p8_t265" reading_order_no="264" segment_no="29" tag_type="list">4)</text>
<text top="657" left="346" width="218" height="9" font="font11" id="p8_t266" reading_order_no="265" segment_no="29" tag_type="list">Solve the human motion by extending Eq. 5 into</text>
<text top="668" left="346" width="218" height="9" font="font11" id="p8_t267" reading_order_no="266" segment_no="29" tag_type="list">multi-views, while dropping off the IUV constraints</text>
<text top="680" left="346" width="218" height="9" font="font11" id="p8_t268" reading_order_no="267" segment_no="29" tag_type="list">and the 3D constraints from Eq. 6 (As both con-</text>
<text top="691" left="346" width="218" height="9" font="font11" id="p8_t269" reading_order_no="268" segment_no="29" tag_type="list">straints are not available when constructing our</text>
<text top="703" left="346" width="40" height="9" font="font11" id="p8_t270" reading_order_no="269" segment_no="29" tag_type="list">datasets).</text>
<text top="714" left="326" width="8" height="9" font="font11" id="p8_t271" reading_order_no="270" segment_no="30" tag_type="list">5)</text>
<text top="714" left="346" width="218" height="9" font="font11" id="p8_t272" reading_order_no="271" segment_no="30" tag_type="list">Recover the 3D body mesh with the shape from</text>
<text top="726" left="346" width="218" height="9" font="font11" id="p8_t273" reading_order_no="272" segment_no="30" tag_type="list">measurements and the pose from multi-view im-</text>
<text top="737" left="346" width="91" height="9" font="font11" id="p8_t274" reading_order_no="273" segment_no="30" tag_type="list">ages, shown in Fig. 7.</text>
</page>
<page number="9" position="absolute" top="0" left="0" height="792" width="612">
	<fontspec id="font52" size="8" family="CMR8" color="#000000"/>
<text top="29" left="48" width="334" height="6" font="font0" id="p9_t1" reading_order_no="0" segment_no="0" tag_type="title">IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS, VOL. XX, NO. , AUGUST 2020</text>
<text top="29" left="560" width="4" height="6" font="font0" id="p9_t2" reading_order_no="1" segment_no="1" tag_type="text">9</text>
<text top="179" left="48" width="252" height="9" font="font11" id="p9_t3" reading_order_no="2" segment_no="3" tag_type="text">Fig. 7: We reconstruct body mesh from multi-views as</text>
<text top="191" left="48" width="57" height="9" font="font11" id="p9_t4" reading_order_no="3" segment_no="3" tag_type="text">ground truth.</text>
<text top="225" left="48" width="252" height="9" font="font11" id="p9_t5" reading_order_no="4" segment_no="5" tag_type="text">In Step 2, it is very common that in a single-view image</text>
<text top="237" left="48" width="252" height="9" font="font11" id="p9_t6" reading_order_no="5" segment_no="5" tag_type="text">some joints could be invisible due to occlusion. Therefore we</text>
<text top="248" left="48" width="252" height="9" font="font11" id="p9_t7" reading_order_no="6" segment_no="5" tag_type="text">propose a cross validation scheme based on multiple views.</text>
<text top="260" left="48" width="252" height="9" font="font11" id="p9_t8" reading_order_no="7" segment_no="5" tag_type="text">For a certain joint, we choose any pair of cameras and use</text>
<text top="271" left="48" width="252" height="9" font="font11" id="p9_t9" reading_order_no="8" segment_no="5" tag_type="text">the two 2D estimations to build the 3D joint position. The</text>
<text top="283" left="48" width="252" height="9" font="font11" id="p9_t10" reading_order_no="9" segment_no="5" tag_type="text">3D joint is then re-projected with respect to the view-ports</text>
<text top="294" left="48" width="252" height="9" font="font11" id="p9_t11" reading_order_no="10" segment_no="5" tag_type="text">of the other two cameras, creating two projected joints. Each</text>
<text top="306" left="48" width="252" height="9" font="font11" id="p9_t12" reading_order_no="11" segment_no="5" tag_type="text">projected joint is compared against the estimated 2D joint</text>
<text top="318" left="48" width="252" height="9" font="font11" id="p9_t13" reading_order_no="12" segment_no="5" tag_type="text">under the same view-port, and their Eucleadian distance</text>
<text top="329" left="48" width="252" height="9" font="font11" id="p9_t14" reading_order_no="13" segment_no="5" tag_type="text">is calculated. Only if the distances in two view-ports are</text>
<text top="341" left="48" width="252" height="9" font="font11" id="p9_t15" reading_order_no="14" segment_no="5" tag_type="text">both below a certain threshold (18 pixels in our experiment),</text>
<text top="352" left="48" width="252" height="9" font="font11" id="p9_t16" reading_order_no="15" segment_no="5" tag_type="text">this set of four 2D estimations for this joint is considered to</text>
<text top="364" left="48" width="252" height="9" font="font11" id="p9_t17" reading_order_no="16" segment_no="5" tag_type="text">be consistent and reliable. If four view-ports fail to reach</text>
<text top="375" left="48" width="252" height="9" font="font11" id="p9_t18" reading_order_no="17" segment_no="5" tag_type="text">consistency, we check if any three of them do. If that</text>
<text top="387" left="48" width="252" height="9" font="font11" id="p9_t19" reading_order_no="18" segment_no="5" tag_type="text">happens, the 2D joint estimation in the three view-ports</text>
<text top="398" left="48" width="252" height="9" font="font11" id="p9_t20" reading_order_no="19" segment_no="5" tag_type="text">are treated as reliable. If such three view-ports can not be</text>
<text top="410" left="48" width="252" height="9" font="font11" id="p9_t21" reading_order_no="20" segment_no="5" tag_type="text">found, we have to ask for help from the previous frame.</text>
<text top="421" left="48" width="252" height="9" font="font11" id="p9_t22" reading_order_no="21" segment_no="5" tag_type="text">The 3D joint from the previous frame is compared with the</text>
<text top="433" left="48" width="252" height="9" font="font11" id="p9_t23" reading_order_no="22" segment_no="5" tag_type="text">reconstructed 3D joint from any pair of cameras, and the</text>
<text top="444" left="48" width="252" height="9" font="font11" id="p9_t24" reading_order_no="23" segment_no="5" tag_type="text">distances are calculated. The minimal distance designates</text>
<text top="456" left="48" width="252" height="9" font="font11" id="p9_t25" reading_order_no="24" segment_no="5" tag_type="text">the pair of cameras and their estimations are treated as</text>
<text top="468" left="48" width="33" height="9" font="font11" id="p9_t26" reading_order_no="25" segment_no="5" tag_type="text">reliable.</text>
<text top="500" left="48" width="13" height="9" font="font39" id="p9_t27" reading_order_no="26" segment_no="10" tag_type="title"><b>6.4</b></text>
<text top="500" left="71" width="43" height="9" font="font39" id="p9_t28" reading_order_no="27" segment_no="10" tag_type="title"><b>IUV Maps</b></text>
<text top="517" left="48" width="252" height="9" font="font11" id="p9_t29" reading_order_no="28" segment_no="12" tag_type="text">The image-to-surface correspondence (IUV map) proposed</text>
<text top="529" left="48" width="252" height="9" font="font11" id="p9_t30" reading_order_no="29" segment_no="12" tag_type="text">in Densepose [1] for human body is an essential mechanism</text>
<text top="541" left="48" width="252" height="9" font="font11" id="p9_t31" reading_order_no="30" segment_no="12" tag_type="text">for mapping a 2D image into a 3D geometry. We improved</text>
<text top="552" left="48" width="252" height="9" font="font11" id="p9_t32" reading_order_no="31" segment_no="12" tag_type="text">this idea with a more solid implementation, and it works</text>
<text top="564" left="48" width="252" height="9" font="font11" id="p9_t33" reading_order_no="32" segment_no="12" tag_type="text">well for persons with loose clothes. In Densepose certain</text>
<text top="575" left="48" width="252" height="9" font="font11" id="p9_t34" reading_order_no="33" segment_no="12" tag_type="text">pixels are manually sampled on each human part, and their</text>
<text top="587" left="48" width="252" height="9" font="font11" id="p9_t35" reading_order_no="34" segment_no="12" tag_type="text">corresponding points on the meshed surface are manually</text>
<text top="598" left="48" width="252" height="9" font="font11" id="p9_t36" reading_order_no="35" segment_no="12" tag_type="text">marked as well. Annotators are asked to determine the</text>
<text top="610" left="48" width="252" height="9" font="font11" id="p9_t37" reading_order_no="36" segment_no="12" tag_type="text">body silhouette if it is covered by clothes, and mark around</text>
<text top="621" left="48" width="252" height="9" font="font11" id="p9_t38" reading_order_no="37" segment_no="12" tag_type="text">100 points for each human. In this situation the burden is</text>
<text top="633" left="48" width="252" height="9" font="font11" id="p9_t39" reading_order_no="38" segment_no="12" tag_type="text">heavy and errors prone to happen, especially when a human</text>
<text top="644" left="48" width="145" height="9" font="font11" id="p9_t40" reading_order_no="39" segment_no="12" tag_type="text">instance wears a large/loose skirt.</text>
<text top="657" left="62" width="238" height="9" font="font11" id="p9_t41" reading_order_no="40" segment_no="15" tag_type="text">We adopt a quite different scheme for computing the</text>
<text top="668" left="48" width="75" height="9" font="font11" id="p9_t42" reading_order_no="41" segment_no="15" tag_type="text">part label and the</text>
<text top="668" left="125" width="4" height="9" font="font19" id="p9_t43" reading_order_no="42" segment_no="15" tag_type="text">(</text>
<text top="668" left="129" width="15" height="9" font="font14" id="p9_t44" reading_order_no="43" segment_no="15" tag_type="text">u, v</text>
<text top="668" left="145" width="4" height="9" font="font19" id="p9_t45" reading_order_no="44" segment_no="15" tag_type="text">)</text>
<text top="668" left="151" width="149" height="9" font="font11" id="p9_t46" reading_order_no="45" segment_no="15" tag_type="text">coordinate for each pixel, requiring</text>
<text top="680" left="48" width="252" height="9" font="font11" id="p9_t47" reading_order_no="46" segment_no="15" tag_type="text">much less human intervention. The reconstructed 3D mesh</text>
<text top="691" left="48" width="252" height="9" font="font11" id="p9_t48" reading_order_no="47" segment_no="15" tag_type="text">by measurements is re-projected according to the view-</text>
<text top="703" left="48" width="252" height="9" font="font11" id="p9_t49" reading_order_no="48" segment_no="15" tag_type="text">ports of the cameras, creating four images. As each mesh</text>
<text top="714" left="48" width="51" height="9" font="font11" id="p9_t50" reading_order_no="49" segment_no="15" tag_type="text">vertex has a</text>
<text top="714" left="101" width="4" height="9" font="font19" id="p9_t51" reading_order_no="50" segment_no="15" tag_type="text">(</text>
<text top="714" left="105" width="15" height="9" font="font14" id="p9_t52" reading_order_no="51" segment_no="15" tag_type="text">u, v</text>
<text top="714" left="121" width="4" height="9" font="font19" id="p9_t53" reading_order_no="52" segment_no="15" tag_type="text">)</text>
<text top="714" left="127" width="173" height="9" font="font11" id="p9_t54" reading_order_no="53" segment_no="15" tag_type="text">coordinate and a part label, it is trivial to</text>
<text top="726" left="48" width="37" height="9" font="font11" id="p9_t55" reading_order_no="54" segment_no="15" tag_type="text">compute</text>
<text top="726" left="87" width="4" height="9" font="font19" id="p9_t56" reading_order_no="55" segment_no="15" tag_type="text">(</text>
<text top="726" left="91" width="15" height="9" font="font14" id="p9_t57" reading_order_no="56" segment_no="15" tag_type="text">u, v</text>
<text top="726" left="106" width="4" height="9" font="font19" id="p9_t58" reading_order_no="57" segment_no="15" tag_type="text">)</text>
<text top="726" left="113" width="187" height="9" font="font11" id="p9_t59" reading_order_no="58" segment_no="15" tag_type="text">and label for each pixel of these images. Due</text>
<text top="737" left="48" width="252" height="9" font="font11" id="p9_t60" reading_order_no="59" segment_no="15" tag_type="text">to the topological complexity of human meshes, we follow</text>
<text top="168" left="348" width="179" height="9" font="font11" id="p9_t61" reading_order_no="60" segment_no="2" tag_type="text">Fig. 8: The IUV maps of the 24 body parts.</text>
<text top="190" left="393" width="42" height="8" font="font10" id="p9_t62" reading_order_no="61" segment_no="4" tag_type="table">Component</text>
<text top="190" left="484" width="36" height="8" font="font10" id="p9_t63" reading_order_no="62" segment_no="4" tag_type="table">Time (ms)</text>
<text top="199" left="368" width="92" height="8" font="font10" id="p9_t64" reading_order_no="63" segment_no="4" tag_type="table">Human detection (YOLO)</text>
<text top="199" left="493" width="18" height="8" font="font10" id="p9_t65" reading_order_no="64" segment_no="4" tag_type="table">8.554</text>
<text top="208" left="383" width="62" height="8" font="font10" id="p9_t66" reading_order_no="65" segment_no="4" tag_type="table">Image Preprocess</text>
<text top="208" left="493" width="18" height="8" font="font10" id="p9_t67" reading_order_no="66" segment_no="4" tag_type="table">0.312</text>
<text top="217" left="376" width="75" height="8" font="font10" id="p9_t68" reading_order_no="67" segment_no="4" tag_type="table">Multi-task Prediction</text>
<text top="217" left="491" width="22" height="8" font="font10" id="p9_t69" reading_order_no="68" segment_no="4" tag_type="table">18.269</text>
<text top="226" left="378" width="72" height="8" font="font10" id="p9_t70" reading_order_no="69" segment_no="4" tag_type="table">Pose Reconstruction</text>
<text top="226" left="491" width="22" height="8" font="font10" id="p9_t71" reading_order_no="70" segment_no="4" tag_type="table">10.232</text>
<text top="235" left="402" width="24" height="8" font="font10" id="p9_t72" reading_order_no="71" segment_no="4" tag_type="table">Others</text>
<text top="235" left="491" width="22" height="8" font="font10" id="p9_t73" reading_order_no="72" segment_no="4" tag_type="table">11.678</text>
<text top="245" left="356" width="79" height="8" font="font10" id="p9_t74" reading_order_no="73" segment_no="4" tag_type="table">Shape Recon (only for</text>
<text top="245" left="437" width="4" height="7" font="font52" id="p9_t75" reading_order_no="74" segment_no="4" tag_type="table">1</text>
<text top="245" left="441" width="32" height="8" font="font10" id="p9_t76" reading_order_no="75" segment_no="4" tag_type="table">st frame)</text>
<text top="245" left="489" width="26" height="8" font="font10" id="p9_t77" reading_order_no="76" segment_no="4" tag_type="table">328.227</text>
<text top="264" left="315" width="246" height="9" font="font11" id="p9_t78" reading_order_no="77" segment_no="6" tag_type="title">TABLE 1: Running time of each component in our system.</text>
<text top="297" left="312" width="252" height="9" font="font11" id="p9_t79" reading_order_no="78" segment_no="7" tag_type="text">Densepose and segment a human mesh into 24 parts, and</text>
<text top="309" left="312" width="34" height="9" font="font11" id="p9_t80" reading_order_no="79" segment_no="7" tag_type="text">define a</text>
<text top="309" left="348" width="11" height="9" font="font14" id="p9_t81" reading_order_no="80" segment_no="7" tag_type="text">uv</text>
<text top="309" left="359" width="161" height="9" font="font11" id="p9_t82" reading_order_no="81" segment_no="7" tag_type="text">-field on each part, as shown in Fig. 8.</text>
<text top="339" left="312" width="6" height="10" font="font7" id="p9_t83" reading_order_no="82" segment_no="8" tag_type="title"><b>7</b></text>
<text top="339" left="330" width="8" height="10" font="font7" id="p9_t84" reading_order_no="83" segment_no="8" tag_type="title"><b>R</b></text>
<text top="341" left="338" width="60" height="8" font="font8" id="p9_t85" reading_order_no="84" segment_no="8" tag_type="title"><b>ESULTS AND</b></text>
<text top="339" left="402" width="7" height="10" font="font7" id="p9_t86" reading_order_no="85" segment_no="8" tag_type="title"><b>E</b></text>
<text top="341" left="410" width="60" height="8" font="font8" id="p9_t87" reading_order_no="86" segment_no="8" tag_type="title"><b>VALUATIONS</b></text>
<text top="357" left="312" width="252" height="9" font="font11" id="p9_t88" reading_order_no="87" segment_no="9" tag_type="text">We demonstrate the power and effectiveness of our system,</text>
<text top="368" left="312" width="252" height="9" font="font11" id="p9_t89" reading_order_no="88" segment_no="9" tag_type="text">by reconstructing 3D human bodies from both live streams</text>
<text top="380" left="312" width="252" height="9" font="font11" id="p9_t90" reading_order_no="89" segment_no="9" tag_type="text">and in-the-wild videos of various scenes (§ 7.1). We quan-</text>
<text top="391" left="312" width="252" height="9" font="font11" id="p9_t91" reading_order_no="90" segment_no="9" tag_type="text">titatively compare the accuracy of our results with state-of-</text>
<text top="403" left="312" width="252" height="9" font="font11" id="p9_t92" reading_order_no="91" segment_no="9" tag_type="text">the-art 3D pose and/or mesh reconstruction methods (§ 7.2).</text>
<text top="415" left="312" width="252" height="9" font="font11" id="p9_t93" reading_order_no="92" segment_no="9" tag_type="text">Our method is also qualitatively compared against four</text>
<text top="426" left="312" width="252" height="9" font="font11" id="p9_t94" reading_order_no="93" segment_no="9" tag_type="text">most related state-of-the-art methods (§ 7.3). In § 7.4, we</text>
<text top="438" left="312" width="252" height="9" font="font11" id="p9_t95" reading_order_no="94" segment_no="9" tag_type="text">evaluate different part the key components of our system</text>
<text top="449" left="312" width="252" height="9" font="font11" id="p9_t96" reading_order_no="95" segment_no="9" tag_type="text">by dropping off each term at one time for both multi-task</text>
<text top="461" left="312" width="252" height="9" font="font11" id="p9_t97" reading_order_no="96" segment_no="9" tag_type="text">network and optimization procedure. Our results are best</text>
<text top="472" left="312" width="138" height="9" font="font11" id="p9_t98" reading_order_no="97" segment_no="9" tag_type="text">seen in the accompanying video.</text>
<text top="508" left="326" width="92" height="9" font="font18" id="p9_t99" reading_order_no="98" segment_no="11" tag_type="text"><b>Computational time.</b></text>
<text top="508" left="423" width="141" height="9" font="font11" id="p9_t100" reading_order_no="99" segment_no="11" tag_type="text">Our system runs at 20 fps on a</text>
<text top="519" left="312" width="252" height="9" font="font11" id="p9_t101" reading_order_no="100" segment_no="11" tag_type="text">desktop computer for the current implementation. Table 1</text>
<text top="531" left="312" width="252" height="9" font="font11" id="p9_t102" reading_order_no="101" segment_no="11" tag_type="text">reports the detailed timing for each component in our</text>
<text top="542" left="312" width="252" height="9" font="font11" id="p9_t103" reading_order_no="102" segment_no="11" tag_type="text">processing pipeline. All execution time is collected on a</text>
<text top="554" left="312" width="252" height="9" font="font11" id="p9_t104" reading_order_no="103" segment_no="11" tag_type="text">computer with an Intel i7 CPU and a nvidia Geforce GTX</text>
<text top="565" left="312" width="252" height="9" font="font11" id="p9_t105" reading_order_no="104" segment_no="11" tag_type="text">2080Ti GPU. Apart from the shape reconstruction, which is</text>
<text top="577" left="312" width="252" height="9" font="font11" id="p9_t106" reading_order_no="105" segment_no="11" tag_type="text">done only once in the first frame, the total processing time</text>
<text top="588" left="312" width="121" height="9" font="font11" id="p9_t107" reading_order_no="106" segment_no="11" tag_type="text">for one cycle is under 50 ms.</text>
<text top="618" left="312" width="13" height="9" font="font39" id="p9_t108" reading_order_no="107" segment_no="13" tag_type="title"><b>7.1</b></text>
<text top="618" left="335" width="193" height="9" font="font39" id="p9_t109" reading_order_no="108" segment_no="13" tag_type="title"><b>Test on live streams and in-the-wild videos</b></text>
<text top="633" left="312" width="252" height="9" font="font11" id="p9_t110" reading_order_no="109" segment_no="14" tag_type="text">Our system reconstructs 3D human poses and full-body</text>
<text top="645" left="312" width="252" height="9" font="font11" id="p9_t111" reading_order_no="110" segment_no="14" tag_type="text">geometry models from single images in realtime, and the</text>
<text top="656" left="312" width="252" height="9" font="font11" id="p9_t112" reading_order_no="111" segment_no="14" tag_type="text">reconstructed 3D poses is retargeted to animate a character</text>
<text top="668" left="312" width="252" height="9" font="font11" id="p9_t113" reading_order_no="112" segment_no="14" tag_type="text">in realtime (See Fig. 10). Our technology has potentials</text>
<text top="679" left="312" width="252" height="9" font="font11" id="p9_t114" reading_order_no="113" segment_no="14" tag_type="text">in applications such as game character control, embodied</text>
<text top="691" left="312" width="252" height="9" font="font11" id="p9_t115" reading_order_no="114" segment_no="14" tag_type="text">VR, sport motion analysis and reconstruction of community</text>
<text top="703" left="312" width="26" height="9" font="font11" id="p9_t116" reading_order_no="115" segment_no="14" tag_type="text">video.</text>
<text top="714" left="326" width="238" height="9" font="font11" id="p9_t117" reading_order_no="116" segment_no="16" tag_type="text">We also test our method on various in-the-wild videos,</text>
<text top="726" left="312" width="252" height="9" font="font11" id="p9_t118" reading_order_no="117" segment_no="16" tag_type="text">showing its robustness to different actors with different</text>
<text top="737" left="312" width="252" height="9" font="font11" id="p9_t119" reading_order_no="118" segment_no="16" tag_type="text">body shapes and clothes, even under significant occlusion,</text>
</page>
<page number="10" position="absolute" top="0" left="0" height="792" width="612">
	<fontspec id="font53" size="8" family="URWPalladioL,Bold" color="#000000"/>
<text top="29" left="48" width="334" height="6" font="font0" id="p10_t1" reading_order_no="0" segment_no="0" tag_type="title">IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS, VOL. XX, NO. , AUGUST 2020</text>
<text top="29" left="556" width="8" height="6" font="font0" id="p10_t2" reading_order_no="1" segment_no="1" tag_type="text">10</text>
<text top="127" left="82" width="9" height="8" font="font10" id="p10_t3" reading_order_no="2" segment_no="3" tag_type="figure">(a)</text>
<text top="127" left="166" width="10" height="8" font="font10" id="p10_t4" reading_order_no="3" segment_no="3" tag_type="figure">(b)</text>
<text top="127" left="250" width="9" height="8" font="font10" id="p10_t5" reading_order_no="4" segment_no="3" tag_type="figure">(c)</text>
<text top="149" left="48" width="252" height="9" font="font11" id="p10_t6" reading_order_no="5" segment_no="4" tag_type="text">Fig. 9: On the left of each subfigure is the input view from</text>
<text top="161" left="48" width="252" height="9" font="font11" id="p10_t7" reading_order_no="6" segment_no="4" tag_type="text">which the 3D model is reconstructed. On the right, the</text>
<text top="172" left="48" width="215" height="9" font="font11" id="p10_t8" reading_order_no="7" segment_no="4" tag_type="text">model is rendered and overlaid in a different view.</text>
<text top="333" left="48" width="252" height="9" font="font11" id="p10_t9" reading_order_no="8" segment_no="8" tag_type="text">Fig. 10: The reconstructed 3D poses from our system can be</text>
<text top="344" left="48" width="189" height="9" font="font11" id="p10_t10" reading_order_no="9" segment_no="8" tag_type="text">retargeted to animate a character in realtime.</text>
<text top="380" left="48" width="252" height="9" font="font11" id="p10_t11" reading_order_no="10" segment_no="9" tag_type="text">lighting and background changes. Fig. 11 shows some ex-</text>
<text top="392" left="48" width="252" height="9" font="font11" id="p10_t12" reading_order_no="11" segment_no="9" tag_type="text">cerpted frames. Besides, we also present other-view overlay</text>
<text top="403" left="48" width="252" height="9" font="font11" id="p10_t13" reading_order_no="12" segment_no="9" tag_type="text">results in Fig. 9 by using our multi-view test dataset, which</text>
<text top="415" left="48" width="252" height="9" font="font11" id="p10_t14" reading_order_no="13" segment_no="9" tag_type="text">reflects the accuracy of human reconstruction achieved by</text>
<text top="426" left="48" width="252" height="9" font="font11" id="p10_t15" reading_order_no="14" segment_no="9" tag_type="text">our method. Please refer to the accompanying video for</text>
<text top="438" left="48" width="79" height="9" font="font11" id="p10_t16" reading_order_no="15" segment_no="9" tag_type="text">more vivid results.</text>
<text top="475" left="48" width="13" height="9" font="font39" id="p10_t17" reading_order_no="16" segment_no="12" tag_type="title"><b>7.2</b></text>
<text top="475" left="71" width="105" height="9" font="font39" id="p10_t18" reading_order_no="17" segment_no="12" tag_type="title"><b>Quantitative Evaluation</b></text>
<text top="494" left="48" width="252" height="9" font="font11" id="p10_t19" reading_order_no="18" segment_no="13" tag_type="text">We evaluate the performance of our method on two pop-</text>
<text top="505" left="48" width="252" height="9" font="font11" id="p10_t20" reading_order_no="19" segment_no="13" tag_type="text">ular test benchmarks: 3DPW [53] (outdoor scenes) and</text>
<text top="517" left="48" width="252" height="9" font="font11" id="p10_t21" reading_order_no="20" segment_no="13" tag_type="text">Human3.6M [54] (indoor scenes). Following the standard</text>
<text top="528" left="48" width="252" height="9" font="font11" id="p10_t22" reading_order_no="21" segment_no="13" tag_type="text">protocol for 3D pose estimation [22] in Human3.6M, we</text>
<text top="540" left="48" width="252" height="9" font="font11" id="p10_t23" reading_order_no="22" segment_no="13" tag_type="text">use 5 subjects (S1, S5, S6, S7 and S8) for training, and the</text>
<text top="552" left="48" width="252" height="9" font="font11" id="p10_t24" reading_order_no="23" segment_no="13" tag_type="text">rest 2 subjects (S9 and S11) for testing. As for Human3.6M,</text>
<text top="563" left="48" width="252" height="9" font="font11" id="p10_t25" reading_order_no="24" segment_no="13" tag_type="text">we get ground truth parameters for training images using</text>
<text top="575" left="48" width="252" height="9" font="font11" id="p10_t26" reading_order_no="25" segment_no="13" tag_type="text">MoSh [56] from the raw 3D Mocap markers like [30]. As</text>
<text top="586" left="48" width="252" height="9" font="font11" id="p10_t27" reading_order_no="26" segment_no="13" tag_type="text">for 3DPW, we only use its testing dataset for evaluation as</text>
<text top="598" left="48" width="252" height="9" font="font11" id="p10_t28" reading_order_no="27" segment_no="13" tag_type="text">previous works [2]. Note that Human3.6M and 3DPW have</text>
<text top="609" left="48" width="252" height="9" font="font11" id="p10_t29" reading_order_no="28" segment_no="13" tag_type="text">different skeleton configurations from ours, we therefore</text>
<text top="621" left="48" width="252" height="9" font="font11" id="p10_t30" reading_order_no="29" segment_no="13" tag_type="text">learn a linear regressor for a mapping which maps our mesh</text>
<text top="632" left="48" width="252" height="9" font="font11" id="p10_t31" reading_order_no="30" segment_no="13" tag_type="text">vertices to 17 joints defined in Human3.6M, as did in [30].</text>
<text top="644" left="48" width="252" height="9" font="font11" id="p10_t32" reading_order_no="31" segment_no="13" tag_type="text">For evaluation, we adopt averaged skeleton dimensions</text>
<text top="655" left="48" width="252" height="9" font="font11" id="p10_t33" reading_order_no="32" segment_no="13" tag_type="text">computed from the training set to rescale our reconstruction</text>
<text top="667" left="48" width="93" height="9" font="font11" id="p10_t34" reading_order_no="33" segment_no="13" tag_type="text">human, as did in [22].</text>
<text top="680" left="62" width="238" height="9" font="font11" id="p10_t35" reading_order_no="34" segment_no="16" tag_type="text">The results are shown in Table 2. Our single image</text>
<text top="691" left="48" width="252" height="9" font="font11" id="p10_t36" reading_order_no="35" segment_no="16" tag_type="text">based method is even competitive to the video-based VIBE</text>
<text top="703" left="48" width="252" height="9" font="font11" id="p10_t37" reading_order_no="36" segment_no="16" tag_type="text">[5] on Human3.6M and 3DPW. The results also show that</text>
<text top="714" left="48" width="252" height="9" font="font11" id="p10_t38" reading_order_no="37" segment_no="16" tag_type="text">our newly collected data improves the performance further,</text>
<text top="726" left="48" width="252" height="9" font="font11" id="p10_t39" reading_order_no="38" segment_no="16" tag_type="text">especially on 3DPW (wild), with improved wild generaliza-</text>
<text top="737" left="48" width="19" height="9" font="font11" id="p10_t40" reading_order_no="39" segment_no="16" tag_type="text">tion.</text>
<text top="41" left="361" width="28" height="8" font="font10" id="p10_t41" reading_order_no="40" segment_no="2" tag_type="table">Method</text>
<text top="41" left="438" width="34" height="8" font="font10" id="p10_t42" reading_order_no="41" segment_no="2" tag_type="table">H36M-P1</text>
<text top="41" left="474" width="4" height="8" font="font12" id="p10_t43" reading_order_no="42" segment_no="2" tag_type="table">↓</text>
<text top="41" left="481" width="35" height="8" font="font10" id="p10_t44" reading_order_no="43" segment_no="2" tag_type="table">H36M-PA</text>
<text top="41" left="516" width="4" height="8" font="font12" id="p10_t45" reading_order_no="44" segment_no="2" tag_type="table">↓</text>
<text top="41" left="522" width="36" height="8" font="font10" id="p10_t46" reading_order_no="45" segment_no="2" tag_type="table">3DPW-PA</text>
<text top="41" left="558" width="4" height="8" font="font12" id="p10_t47" reading_order_no="46" segment_no="2" tag_type="table">↓</text>
<text top="51" left="349" width="23" height="8" font="font10" id="p10_t48" reading_order_no="47" segment_no="2" tag_type="table">Mehta</text>
<text top="51" left="374" width="16" height="8" font="font13" id="p10_t49" reading_order_no="48" segment_no="2" tag_type="table">et al.</text>
<text top="51" left="392" width="9" height="8" font="font10" id="p10_t50" reading_order_no="49" segment_no="2" tag_type="table">[3]</text>
<text top="51" left="451" width="14" height="8" font="font10" id="p10_t51" reading_order_no="50" segment_no="2" tag_type="table">80.5</text>
<text top="51" left="499" width="3" height="8" font="font10" id="p10_t52" reading_order_no="51" segment_no="2" tag_type="table">-</text>
<text top="51" left="541" width="3" height="8" font="font10" id="p10_t53" reading_order_no="52" segment_no="2" tag_type="table">-</text>
<text top="60" left="342" width="32" height="8" font="font10" id="p10_t54" reading_order_no="53" segment_no="2" tag_type="table">Pavlakos</text>
<text top="60" left="376" width="16" height="8" font="font13" id="p10_t55" reading_order_no="54" segment_no="2" tag_type="table">et al.</text>
<text top="60" left="394" width="13" height="8" font="font10" id="p10_t56" reading_order_no="55" segment_no="2" tag_type="table">[13]</text>
<text top="60" left="451" width="14" height="8" font="font10" id="p10_t57" reading_order_no="56" segment_no="2" tag_type="table">56.2</text>
<text top="60" left="491" width="18" height="8" font="font10" id="p10_t58" reading_order_no="57" segment_no="2" tag_type="table">41.80</text>
<text top="60" left="541" width="3" height="8" font="font10" id="p10_t59" reading_order_no="58" segment_no="2" tag_type="table">-</text>
<text top="69" left="351" width="14" height="8" font="font10" id="p10_t60" reading_order_no="59" segment_no="2" tag_type="table">Sun</text>
<text top="69" left="367" width="16" height="8" font="font13" id="p10_t61" reading_order_no="60" segment_no="2" tag_type="table">et al.</text>
<text top="69" left="385" width="13" height="8" font="font10" id="p10_t62" reading_order_no="61" segment_no="2" tag_type="table">[23]</text>
<text top="69" left="451" width="14" height="8" font="font10" id="p10_t63" reading_order_no="62" segment_no="2" tag_type="table">49.6</text>
<text top="69" left="491" width="18" height="8" font="font10" id="p10_t64" reading_order_no="63" segment_no="2" tag_type="table">40.60</text>
<text top="69" left="541" width="3" height="8" font="font10" id="p10_t65" reading_order_no="64" segment_no="2" tag_type="table">-</text>
<text top="78" left="348" width="19" height="8" font="font10" id="p10_t66" reading_order_no="65" segment_no="2" tag_type="table">Zhou</text>
<text top="78" left="370" width="16" height="8" font="font13" id="p10_t67" reading_order_no="66" segment_no="2" tag_type="table">et al.</text>
<text top="78" left="388" width="13" height="8" font="font10" id="p10_t68" reading_order_no="67" segment_no="2" tag_type="table">[57]</text>
<text top="78" left="451" width="14" height="8" font="font53" id="p10_t69" reading_order_no="68" segment_no="2" tag_type="table"><b>39.9</b></text>
<text top="78" left="493" width="14" height="8" font="font53" id="p10_t70" reading_order_no="69" segment_no="2" tag_type="table"><b>32.1</b></text>
<text top="78" left="541" width="3" height="8" font="font10" id="p10_t71" reading_order_no="70" segment_no="2" tag_type="table">-</text>
<text top="87" left="351" width="18" height="8" font="font10" id="p10_t72" reading_order_no="71" segment_no="2" tag_type="table">Bogo</text>
<text top="87" left="371" width="16" height="8" font="font13" id="p10_t73" reading_order_no="72" segment_no="2" tag_type="table">et al.</text>
<text top="87" left="389" width="9" height="8" font="font10" id="p10_t74" reading_order_no="73" segment_no="2" tag_type="table">[4]</text>
<text top="87" left="451" width="14" height="8" font="font10" id="p10_t75" reading_order_no="74" segment_no="2" tag_type="table">82.3</text>
<text top="87" left="499" width="3" height="8" font="font10" id="p10_t76" reading_order_no="75" segment_no="2" tag_type="table">-</text>
<text top="87" left="541" width="3" height="8" font="font10" id="p10_t77" reading_order_no="76" segment_no="2" tag_type="table">-</text>
<text top="96" left="340" width="37" height="8" font="font10" id="p10_t78" reading_order_no="77" segment_no="2" tag_type="table">Kanazawa</text>
<text top="96" left="379" width="16" height="8" font="font13" id="p10_t79" reading_order_no="78" segment_no="2" tag_type="table">et al.</text>
<text top="96" left="397" width="13" height="8" font="font10" id="p10_t80" reading_order_no="79" segment_no="2" tag_type="table">[30]</text>
<text top="96" left="449" width="18" height="8" font="font10" id="p10_t81" reading_order_no="80" segment_no="2" tag_type="table">87.97</text>
<text top="96" left="493" width="14" height="8" font="font10" id="p10_t82" reading_order_no="81" segment_no="2" tag_type="table">56.8</text>
<text top="96" left="535" width="14" height="8" font="font10" id="p10_t83" reading_order_no="82" segment_no="2" tag_type="table">76.7</text>
<text top="105" left="348" width="21" height="8" font="font10" id="p10_t84" reading_order_no="83" segment_no="2" tag_type="table">Xiang</text>
<text top="105" left="371" width="16" height="8" font="font13" id="p10_t85" reading_order_no="84" segment_no="2" tag_type="table">et al.</text>
<text top="105" left="389" width="13" height="8" font="font10" id="p10_t86" reading_order_no="85" segment_no="2" tag_type="table">[34]</text>
<text top="105" left="451" width="14" height="8" font="font10" id="p10_t87" reading_order_no="86" segment_no="2" tag_type="table">58.3</text>
<text top="105" left="499" width="3" height="8" font="font10" id="p10_t88" reading_order_no="87" segment_no="2" tag_type="table">-</text>
<text top="105" left="541" width="3" height="8" font="font10" id="p10_t89" reading_order_no="88" segment_no="2" tag_type="table">-</text>
<text top="114" left="339" width="38" height="8" font="font10" id="p10_t90" reading_order_no="89" segment_no="2" tag_type="table">kolotouros</text>
<text top="114" left="379" width="16" height="8" font="font13" id="p10_t91" reading_order_no="90" segment_no="2" tag_type="table">et al.</text>
<text top="114" left="397" width="13" height="8" font="font10" id="p10_t92" reading_order_no="91" segment_no="2" tag_type="table">[31]</text>
<text top="114" left="451" width="14" height="8" font="font10" id="p10_t93" reading_order_no="92" segment_no="2" tag_type="table">74.7</text>
<text top="114" left="493" width="14" height="8" font="font10" id="p10_t94" reading_order_no="93" segment_no="2" tag_type="table">50.1</text>
<text top="114" left="535" width="14" height="8" font="font10" id="p10_t95" reading_order_no="94" segment_no="2" tag_type="table">70.2</text>
<text top="123" left="341" width="38" height="8" font="font10" id="p10_t96" reading_order_no="95" segment_no="2" tag_type="table">kolotouros</text>
<text top="123" left="381" width="16" height="8" font="font13" id="p10_t97" reading_order_no="96" segment_no="2" tag_type="table">et al.</text>
<text top="123" left="399" width="9" height="8" font="font10" id="p10_t98" reading_order_no="97" segment_no="2" tag_type="table">[2]</text>
<text top="123" left="457" width="3" height="8" font="font10" id="p10_t99" reading_order_no="98" segment_no="2" tag_type="table">-</text>
<text top="123" left="493" width="14" height="8" font="font10" id="p10_t100" reading_order_no="99" segment_no="2" tag_type="table">44.3</text>
<text top="123" left="535" width="14" height="8" font="font10" id="p10_t101" reading_order_no="100" segment_no="2" tag_type="table">59.2</text>
<text top="132" left="352" width="11" height="8" font="font10" id="p10_t102" reading_order_no="101" segment_no="2" tag_type="table">Joo</text>
<text top="132" left="366" width="16" height="8" font="font13" id="p10_t103" reading_order_no="102" segment_no="2" tag_type="table">et al.</text>
<text top="132" left="384" width="13" height="8" font="font10" id="p10_t104" reading_order_no="103" segment_no="2" tag_type="table">[58]</text>
<text top="132" left="457" width="3" height="8" font="font10" id="p10_t105" reading_order_no="104" segment_no="2" tag_type="table">-</text>
<text top="132" left="493" width="14" height="8" font="font10" id="p10_t106" reading_order_no="105" segment_no="2" tag_type="table">45.2</text>
<text top="132" left="535" width="14" height="8" font="font10" id="p10_t107" reading_order_no="106" segment_no="2" tag_type="table">55.7</text>
<text top="141" left="345" width="30" height="8" font="font10" id="p10_t108" reading_order_no="107" segment_no="2" tag_type="table">Kocabas</text>
<text top="141" left="377" width="16" height="8" font="font13" id="p10_t109" reading_order_no="108" segment_no="2" tag_type="table">et al.</text>
<text top="141" left="395" width="9" height="8" font="font10" id="p10_t110" reading_order_no="109" segment_no="2" tag_type="table">[5]</text>
<text top="141" left="451" width="14" height="8" font="font10" id="p10_t111" reading_order_no="110" segment_no="2" tag_type="table">65.6</text>
<text top="141" left="493" width="14" height="8" font="font10" id="p10_t112" reading_order_no="111" segment_no="2" tag_type="table">41.4</text>
<text top="141" left="535" width="14" height="8" font="font53" id="p10_t113" reading_order_no="112" segment_no="2" tag_type="table"><b>51.9</b></text>
<text top="150" left="326" width="97" height="8" font="font10" id="p10_t114" reading_order_no="113" segment_no="2" tag_type="table">Ours (wild image + H36M)</text>
<text top="150" left="451" width="14" height="8" font="font10" id="p10_t115" reading_order_no="114" segment_no="2" tag_type="table">66.3</text>
<text top="150" left="493" width="14" height="8" font="font10" id="p10_t116" reading_order_no="115" segment_no="2" tag_type="table">47.2</text>
<text top="150" left="535" width="14" height="8" font="font10" id="p10_t117" reading_order_no="116" segment_no="2" tag_type="table">64.1</text>
<text top="159" left="314" width="122" height="8" font="font10" id="p10_t118" reading_order_no="117" segment_no="2" tag_type="table">Ours (wild image + H36M + ours)</text>
<text top="159" left="451" width="14" height="8" font="font10" id="p10_t119" reading_order_no="118" segment_no="2" tag_type="table">63.7</text>
<text top="159" left="493" width="14" height="8" font="font10" id="p10_t120" reading_order_no="119" segment_no="2" tag_type="table">41.8</text>
<text top="159" left="535" width="14" height="8" font="font10" id="p10_t121" reading_order_no="120" segment_no="2" tag_type="table">53.2</text>
<text top="178" left="312" width="252" height="9" font="font11" id="p10_t122" reading_order_no="121" segment_no="5" tag_type="text">TABLE 2: Quantitative Evaluation on Human3.6M (indoor)</text>
<text top="190" left="312" width="252" height="9" font="font11" id="p10_t123" reading_order_no="122" segment_no="5" tag_type="text">and 3DPW (outdoor). The number of H36M-P1 is the Mean</text>
<text top="201" left="312" width="252" height="9" font="font11" id="p10_t124" reading_order_no="123" segment_no="5" tag_type="text">Per Joint Position Error (MPJPE) in millimeter on Hu-</text>
<text top="213" left="312" width="252" height="9" font="font11" id="p10_t125" reading_order_no="124" segment_no="5" tag_type="text">man3.6M, while the number of H36m-PA is the MPJPE on</text>
<text top="224" left="312" width="252" height="9" font="font11" id="p10_t126" reading_order_no="125" segment_no="5" tag_type="text">Human3.6M after procrustes alignment (PA). And 3DPW-</text>
<text top="236" left="312" width="252" height="9" font="font11" id="p10_t127" reading_order_no="126" segment_no="5" tag_type="text">PA is the MPJPE on 3DPW after PA. Our method achieves</text>
<text top="247" left="312" width="210" height="9" font="font11" id="p10_t128" reading_order_no="127" segment_no="5" tag_type="text">competitive performance against previous works.</text>
<text top="271" left="367" width="31" height="8" font="font10" id="p10_t129" reading_order_no="128" segment_no="6" tag_type="table">Methods</text>
<text top="271" left="428" width="37" height="8" font="font10" id="p10_t130" reading_order_no="129" segment_no="6" tag_type="table">PCKh@0.5</text>
<text top="270" left="467" width="4" height="8" font="font12" id="p10_t131" reading_order_no="130" segment_no="6" tag_type="table">↑</text>
<text top="271" left="483" width="36" height="8" font="font10" id="p10_t132" reading_order_no="131" segment_no="6" tag_type="table">MPJPE-P1</text>
<text top="270" left="522" width="4" height="8" font="font12" id="p10_t133" reading_order_no="132" segment_no="6" tag_type="table">↓</text>
<text top="280" left="378" width="10" height="8" font="font10" id="p10_t134" reading_order_no="133" segment_no="6" tag_type="table">2D</text>
<text top="280" left="443" width="14" height="8" font="font10" id="p10_t135" reading_order_no="134" segment_no="6" tag_type="table">96.3</text>
<text top="280" left="503" width="3" height="8" font="font10" id="p10_t136" reading_order_no="135" segment_no="6" tag_type="table">-</text>
<text top="289" left="364" width="38" height="8" font="font10" id="p10_t137" reading_order_no="136" segment_no="6" tag_type="table">2D + IUVs</text>
<text top="289" left="443" width="14" height="8" font="font10" id="p10_t138" reading_order_no="137" segment_no="6" tag_type="table">97.5</text>
<text top="289" left="503" width="3" height="8" font="font10" id="p10_t139" reading_order_no="138" segment_no="6" tag_type="table">-</text>
<text top="298" left="364" width="38" height="8" font="font10" id="p10_t140" reading_order_no="139" segment_no="6" tag_type="table">2D + POFs</text>
<text top="298" left="443" width="14" height="8" font="font10" id="p10_t141" reading_order_no="140" segment_no="6" tag_type="table">96.2</text>
<text top="298" left="498" width="14" height="8" font="font10" id="p10_t142" reading_order_no="141" segment_no="6" tag_type="table">51.8</text>
<text top="307" left="350" width="66" height="8" font="font10" id="p10_t143" reading_order_no="142" segment_no="6" tag_type="table">2D + IUVs + POFs</text>
<text top="307" left="443" width="14" height="8" font="font53" id="p10_t144" reading_order_no="143" segment_no="6" tag_type="table"><b>97.8</b></text>
<text top="307" left="498" width="14" height="8" font="font53" id="p10_t145" reading_order_no="144" segment_no="6" tag_type="table"><b>49.8</b></text>
<text top="326" left="312" width="252" height="9" font="font11" id="p10_t146" reading_order_no="145" segment_no="7" tag_type="text">TABLE 3: Ablation experiments on the effect of multi-task</text>
<text top="337" left="312" width="252" height="9" font="font11" id="p10_t147" reading_order_no="146" segment_no="7" tag_type="text">learning. In the experiment, we modify Fig. 3 to set different</text>
<text top="349" left="312" width="252" height="9" font="font11" id="p10_t148" reading_order_no="147" segment_no="7" tag_type="text">task combinations. Our results shows that IUVs is beneficial</text>
<text top="360" left="312" width="226" height="9" font="font11" id="p10_t149" reading_order_no="148" segment_no="7" tag_type="text">to 2D joint detection and part orientation predictions.</text>
<text top="395" left="312" width="13" height="9" font="font39" id="p10_t150" reading_order_no="149" segment_no="10" tag_type="title"><b>7.3</b></text>
<text top="395" left="335" width="194" height="9" font="font39" id="p10_t151" reading_order_no="150" segment_no="10" tag_type="title"><b>Comparisons with state-of-the-art methods</b></text>
<text top="413" left="312" width="252" height="9" font="font11" id="p10_t152" reading_order_no="151" segment_no="11" tag_type="text">To show the efficiency of our method, we compare against</text>
<text top="424" left="312" width="252" height="9" font="font11" id="p10_t153" reading_order_no="152" segment_no="11" tag_type="text">two state-of-the-art regression-based methods, one is single</text>
<text top="436" left="312" width="252" height="9" font="font11" id="p10_t154" reading_order_no="153" segment_no="11" tag_type="text">frame method, SPIN [2], the other is video-based method,</text>
<text top="447" left="312" width="252" height="9" font="font11" id="p10_t155" reading_order_no="154" segment_no="11" tag_type="text">VIBE [5]. Fig. 12 shows the result of a side-by-side compar-</text>
<text top="459" left="312" width="252" height="9" font="font11" id="p10_t156" reading_order_no="155" segment_no="11" tag_type="text">ison. It is obvious that our method achieves better image-</text>
<text top="470" left="312" width="252" height="9" font="font11" id="p10_t157" reading_order_no="156" segment_no="11" tag_type="text">model alignments than SPIN and VIBE. Regression-based</text>
<text top="482" left="312" width="252" height="9" font="font11" id="p10_t158" reading_order_no="157" segment_no="11" tag_type="text">methods usually achieves global image-model alignments</text>
<text top="493" left="312" width="252" height="9" font="font11" id="p10_t159" reading_order_no="158" segment_no="11" tag_type="text">quickly, but at the cost of low quality. This type of nonlinear</text>
<text top="505" left="312" width="252" height="9" font="font11" id="p10_t160" reading_order_no="159" segment_no="11" tag_type="text">prediction is also uneasy to control, due to the mutual effect</text>
<text top="517" left="312" width="252" height="9" font="font11" id="p10_t161" reading_order_no="160" segment_no="11" tag_type="text">between human pose and shape. We decouple them, and</text>
<text top="528" left="312" width="252" height="9" font="font11" id="p10_t162" reading_order_no="161" segment_no="11" tag_type="text">since 2D joint positions and dense image-to-surface corre-</text>
<text top="540" left="312" width="252" height="9" font="font11" id="p10_t163" reading_order_no="162" segment_no="11" tag_type="text">spondence (IUV map) offer better image-model alignments,</text>
<text top="551" left="312" width="252" height="9" font="font11" id="p10_t164" reading_order_no="163" segment_no="11" tag_type="text">and 3D part orientation helps to avoid depth ambiguity, our</text>
<text top="563" left="312" width="252" height="9" font="font11" id="p10_t165" reading_order_no="164" segment_no="11" tag_type="text">method produces more accurate body reconstruction than</text>
<text top="574" left="312" width="67" height="9" font="font11" id="p10_t166" reading_order_no="165" segment_no="11" tag_type="text">SPIN and VIBE.</text>
<text top="587" left="326" width="238" height="9" font="font11" id="p10_t167" reading_order_no="166" segment_no="14" tag_type="text">Furthermore, SPIN does not guarantee temporal stability</text>
<text top="598" left="312" width="252" height="9" font="font11" id="p10_t168" reading_order_no="167" segment_no="14" tag_type="text">because it regresses different body shapes from different</text>
<text top="610" left="312" width="252" height="9" font="font11" id="p10_t169" reading_order_no="168" segment_no="14" tag_type="text">images in a sequence, while VIBE fixes it, but it is not in</text>
<text top="621" left="312" width="252" height="9" font="font11" id="p10_t170" reading_order_no="169" segment_no="14" tag_type="text">realtime. Please refer to Fig. 12 and the accompanying video</text>
<text top="633" left="312" width="113" height="9" font="font11" id="p10_t171" reading_order_no="170" segment_no="14" tag_type="text">for the comparison results.</text>
<text top="645" left="326" width="238" height="9" font="font11" id="p10_t172" reading_order_no="171" segment_no="15" tag_type="text">Our method is also compared against a recent realtime</text>
<text top="657" left="312" width="252" height="9" font="font11" id="p10_t173" reading_order_no="172" segment_no="15" tag_type="text">system, VNect [3], though it captures poses only. We com-</text>
<text top="668" left="312" width="252" height="9" font="font11" id="p10_t174" reading_order_no="173" segment_no="15" tag_type="text">pare not only the raw network outputs, but also the final</text>
<text top="680" left="312" width="252" height="9" font="font11" id="p10_t175" reading_order_no="174" segment_no="15" tag_type="text">fitting results (see Fig. 13). It is obvious that our method</text>
<text top="691" left="312" width="252" height="9" font="font11" id="p10_t176" reading_order_no="175" segment_no="15" tag_type="text">achieves better pose reconstruction than VNect. Two reasons</text>
<text top="703" left="312" width="252" height="9" font="font11" id="p10_t177" reading_order_no="176" segment_no="15" tag_type="text">account for this. Firstly, our multi-task network produces</text>
<text top="714" left="312" width="252" height="9" font="font11" id="p10_t178" reading_order_no="177" segment_no="15" tag_type="text">more accurate 3D joint positions, as shown in Fig. 13(c).</text>
<text top="726" left="312" width="252" height="9" font="font11" id="p10_t179" reading_order_no="178" segment_no="15" tag_type="text">Secondly, VNect initializes bone lengths for forearm and</text>
<text top="737" left="312" width="252" height="9" font="font11" id="p10_t180" reading_order_no="179" segment_no="15" tag_type="text">upper arm to an improper ratio, as seen in Fig. 13(b), while</text>
</page>
<page number="11" position="absolute" top="0" left="0" height="792" width="612">
<text top="29" left="48" width="334" height="6" font="font0" id="p11_t1" reading_order_no="0" segment_no="0" tag_type="title">IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS, VOL. XX, NO. , AUGUST 2020</text>
<text top="29" left="556" width="8" height="6" font="font0" id="p11_t2" reading_order_no="1" segment_no="1" tag_type="text">11</text>
<text top="283" left="48" width="516" height="9" font="font11" id="p11_t3" reading_order_no="2" segment_no="2" tag_type="text">Fig. 11: Our reconstructed 3D bodies with different shapes and clothes, under occlusion, lighting and background</text>
<text top="295" left="48" width="44" height="9" font="font11" id="p11_t4" reading_order_no="3" segment_no="2" tag_type="text">variations.</text>
<text top="324" left="96" width="31" height="8" font="font10" id="p11_t5" reading_order_no="4" segment_no="3" tag_type="table">Methods</text>
<text top="324" left="176" width="34" height="8" font="font10" id="p11_t6" reading_order_no="5" segment_no="3" tag_type="table">H36M-P1</text>
<text top="323" left="210" width="4" height="8" font="font12" id="p11_t7" reading_order_no="6" segment_no="3" tag_type="table">↓</text>
<text top="324" left="216" width="35" height="8" font="font10" id="p11_t8" reading_order_no="7" segment_no="3" tag_type="table">H36M-PA</text>
<text top="323" left="251" width="4" height="8" font="font12" id="p11_t9" reading_order_no="8" segment_no="3" tag_type="table">↓</text>
<text top="324" left="258" width="36" height="8" font="font10" id="p11_t10" reading_order_no="9" segment_no="3" tag_type="table">3DPW-PA</text>
<text top="323" left="293" width="4" height="8" font="font12" id="p11_t11" reading_order_no="10" segment_no="3" tag_type="table">↓</text>
<text top="333" left="107" width="10" height="8" font="font10" id="p11_t12" reading_order_no="11" segment_no="3" tag_type="table">2D</text>
<text top="333" left="186" width="18" height="8" font="font10" id="p11_t13" reading_order_no="12" segment_no="3" tag_type="table">121.3</text>
<text top="333" left="227" width="18" height="8" font="font10" id="p11_t14" reading_order_no="13" segment_no="3" tag_type="table">103.4</text>
<text top="333" left="269" width="18" height="8" font="font10" id="p11_t15" reading_order_no="14" segment_no="3" tag_type="table">116.8</text>
<text top="342" left="93" width="38" height="8" font="font10" id="p11_t16" reading_order_no="15" segment_no="3" tag_type="table">2D + mask</text>
<text top="342" left="186" width="18" height="8" font="font10" id="p11_t17" reading_order_no="16" segment_no="3" tag_type="table">118.3</text>
<text top="342" left="227" width="18" height="8" font="font10" id="p11_t18" reading_order_no="17" segment_no="3" tag_type="table">105.1</text>
<text top="342" left="269" width="18" height="8" font="font10" id="p11_t19" reading_order_no="18" segment_no="3" tag_type="table">110.9</text>
<text top="351" left="83" width="58" height="8" font="font10" id="p11_t20" reading_order_no="19" segment_no="3" tag_type="table">2D + mask + 3D</text>
<text top="351" left="188" width="14" height="8" font="font10" id="p11_t21" reading_order_no="20" segment_no="3" tag_type="table">64.7</text>
<text top="351" left="229" width="14" height="8" font="font10" id="p11_t22" reading_order_no="21" segment_no="3" tag_type="table">43.4</text>
<text top="351" left="271" width="14" height="8" font="font10" id="p11_t23" reading_order_no="22" segment_no="3" tag_type="table">51.8</text>
<text top="360" left="71" width="82" height="8" font="font10" id="p11_t24" reading_order_no="23" segment_no="3" tag_type="table">2D + mask + 3D + IUV</text>
<text top="360" left="188" width="14" height="8" font="font53" id="p11_t25" reading_order_no="24" segment_no="3" tag_type="table"><b>63.7</b></text>
<text top="360" left="229" width="14" height="8" font="font53" id="p11_t26" reading_order_no="25" segment_no="3" tag_type="table"><b>41.8</b></text>
<text top="360" left="271" width="14" height="8" font="font53" id="p11_t27" reading_order_no="26" segment_no="3" tag_type="table"><b>51.1</b></text>
<text top="369" left="50" width="123" height="8" font="font10" id="p11_t28" reading_order_no="27" segment_no="3" tag_type="table">2D + mask + 3D + IUV + temporal</text>
<text top="369" left="188" width="14" height="8" font="font10" id="p11_t29" reading_order_no="28" segment_no="3" tag_type="table">65.9</text>
<text top="369" left="229" width="14" height="8" font="font10" id="p11_t30" reading_order_no="29" segment_no="3" tag_type="table">42.4</text>
<text top="369" left="271" width="14" height="8" font="font10" id="p11_t31" reading_order_no="30" segment_no="3" tag_type="table">53.5</text>
<text top="388" left="48" width="252" height="9" font="font11" id="p11_t32" reading_order_no="31" segment_no="4" tag_type="text">TABLE 4: Ablation study on the importance of each energy</text>
<text top="399" left="48" width="252" height="9" font="font11" id="p11_t33" reading_order_no="32" segment_no="4" tag_type="text">term in optimization. We report the MPJPE/MPJPE-PA on</text>
<text top="411" left="48" width="252" height="9" font="font11" id="p11_t34" reading_order_no="33" segment_no="4" tag_type="text">Human3.6M (indoor) and 3DPW (outdoor) on 5 experi-</text>
<text top="422" left="48" width="252" height="9" font="font11" id="p11_t35" reading_order_no="34" segment_no="4" tag_type="text">ments. All five experiments share the same network outputs</text>
<text top="434" left="48" width="194" height="9" font="font11" id="p11_t36" reading_order_no="35" segment_no="4" tag_type="text">but differ in the energy terms in optimization.</text>
<text top="471" left="48" width="252" height="9" font="font11" id="p11_t37" reading_order_no="36" segment_no="6" tag_type="text">our initialization matches with person in image very well.</text>
<text top="482" left="48" width="252" height="9" font="font11" id="p11_t38" reading_order_no="37" segment_no="6" tag_type="text">VNect initializes skeleton by averaging 3D joint positions</text>
<text top="494" left="48" width="252" height="9" font="font11" id="p11_t39" reading_order_no="38" segment_no="6" tag_type="text">from the CNN output at the beginning, which is thus very</text>
<text top="505" left="48" width="252" height="9" font="font11" id="p11_t40" reading_order_no="39" segment_no="6" tag_type="text">sensitive to single CNN outputs (3D joint positions). We</text>
<text top="517" left="48" width="252" height="9" font="font11" id="p11_t41" reading_order_no="40" segment_no="6" tag_type="text">instead utilize more image features, including 2D joints,</text>
<text top="528" left="48" width="252" height="9" font="font11" id="p11_t42" reading_order_no="41" segment_no="6" tag_type="text">3D part orientation and IUV maps, to reconstruct human</text>
<text top="540" left="48" width="252" height="9" font="font11" id="p11_t43" reading_order_no="42" segment_no="6" tag_type="text">bodies more accurately and robustly. Please refer to the</text>
<text top="551" left="48" width="212" height="9" font="font11" id="p11_t44" reading_order_no="43" segment_no="6" tag_type="text">accompanying video for more comparison results.</text>
<text top="564" left="62" width="238" height="9" font="font11" id="p11_t45" reading_order_no="44" segment_no="7" tag_type="text">SMPLify [4] is a somewhat hybrid method: it fits the</text>
<text top="576" left="48" width="252" height="9" font="font11" id="p11_t46" reading_order_no="45" segment_no="7" tag_type="text">SMPL model by optimizing regressed 2D joints without user</text>
<text top="587" left="48" width="252" height="9" font="font11" id="p11_t47" reading_order_no="46" segment_no="7" tag_type="text">intervention. Fig. 14 shows the results given by SMPLify</text>
<text top="599" left="48" width="252" height="9" font="font11" id="p11_t48" reading_order_no="47" segment_no="7" tag_type="text">and our method. At least three issues about SMPLify can be</text>
<text top="610" left="48" width="252" height="9" font="font11" id="p11_t49" reading_order_no="48" segment_no="7" tag_type="text">interpreted from the figure. First, SMPLify is more vulner-</text>
<text top="622" left="48" width="252" height="9" font="font11" id="p11_t50" reading_order_no="49" segment_no="7" tag_type="text">able to depth ambiguity than our method, as can be seen</text>
<text top="634" left="48" width="252" height="9" font="font11" id="p11_t51" reading_order_no="50" segment_no="7" tag_type="text">from images in the first row. This is because SMPLify relies</text>
<text top="645" left="48" width="252" height="9" font="font11" id="p11_t52" reading_order_no="51" segment_no="7" tag_type="text">on 2D joint reprojection alone for model fitting, and this is</text>
<text top="657" left="48" width="252" height="9" font="font11" id="p11_t53" reading_order_no="52" segment_no="7" tag_type="text">insufficient to robustly establish a 3D pose. Second, there</text>
<text top="668" left="48" width="252" height="9" font="font11" id="p11_t54" reading_order_no="53" segment_no="7" tag_type="text">is no constraints for foot orientation in SMPLify. Last, it is</text>
<text top="680" left="48" width="252" height="9" font="font11" id="p11_t55" reading_order_no="54" segment_no="7" tag_type="text">easy for SMPLify to fall into a local minima, as shown in</text>
<text top="691" left="48" width="252" height="9" font="font11" id="p11_t56" reading_order_no="55" segment_no="7" tag_type="text">second row. Our method has hardly convergence problem.</text>
<text top="703" left="48" width="252" height="9" font="font11" id="p11_t57" reading_order_no="56" segment_no="7" tag_type="text">For a single image, the initial shape from the average of our</text>
<text top="714" left="48" width="252" height="9" font="font11" id="p11_t58" reading_order_no="57" segment_no="7" tag_type="text">human model. We use it and predicted 2D joint positions</text>
<text top="726" left="48" width="252" height="9" font="font11" id="p11_t59" reading_order_no="58" segment_no="7" tag_type="text">and 3D bone directions to roughly estimate the root position</text>
<text top="737" left="48" width="252" height="9" font="font11" id="p11_t60" reading_order_no="59" segment_no="7" tag_type="text">and joint angles as initial pose. The optimization problem is</text>
<text top="433" left="362" width="151" height="8" font="font10" id="p11_t61" reading_order_no="60" segment_no="5" tag_type="figure">(a) Comparison our method with SPIN [2]</text>
<text top="552" left="362" width="152" height="8" font="font10" id="p11_t62" reading_order_no="61" segment_no="5" tag_type="figure">(b) Comparison our method with VIBE [5]</text>
<text top="575" left="312" width="252" height="9" font="font11" id="p11_t63" reading_order_no="62" segment_no="8" tag_type="text">Fig. 12: From left to right: the input, SPIN/VIBE and our re-</text>
<text top="587" left="312" width="252" height="9" font="font11" id="p11_t64" reading_order_no="63" segment_no="8" tag_type="text">sults. Our method produces better image-model alignments</text>
<text top="598" left="312" width="89" height="9" font="font11" id="p11_t65" reading_order_no="64" segment_no="8" tag_type="text">than SPIN and VIBE.</text>
<text top="629" left="312" width="73" height="9" font="font11" id="p11_t66" reading_order_no="65" segment_no="9" tag_type="text">over-constrained.</text>
<text top="654" left="312" width="13" height="9" font="font39" id="p11_t67" reading_order_no="66" segment_no="10" tag_type="title"><b>7.4</b></text>
<text top="654" left="335" width="67" height="9" font="font39" id="p11_t68" reading_order_no="67" segment_no="10" tag_type="title"><b>Ablation Study</b></text>
<text top="668" left="312" width="252" height="9" font="font11" id="p11_t69" reading_order_no="68" segment_no="11" tag_type="text">We have designed a realtime multi-task network that re-</text>
<text top="680" left="312" width="252" height="9" font="font11" id="p11_t70" reading_order_no="69" segment_no="11" tag_type="text">gresses more features than any other deep learning based</text>
<text top="691" left="312" width="252" height="9" font="font11" id="p11_t71" reading_order_no="70" segment_no="11" tag_type="text">methods. We believe that more features offer more visual</text>
<text top="703" left="312" width="252" height="9" font="font11" id="p11_t72" reading_order_no="71" segment_no="11" tag_type="text">cues that facilitate pose and shape reconstruction. In this</text>
<text top="714" left="312" width="252" height="9" font="font11" id="p11_t73" reading_order_no="72" segment_no="11" tag_type="text">section we justify this belief with experiments, evaluating</text>
<text top="726" left="312" width="252" height="9" font="font11" id="p11_t74" reading_order_no="73" segment_no="11" tag_type="text">the role of each regressed features in both the CNN regres-</text>
<text top="737" left="312" width="176" height="9" font="font11" id="p11_t75" reading_order_no="74" segment_no="11" tag_type="text">sion and the body reconstruction process.</text>
</page>
<page number="12" position="absolute" top="0" left="0" height="792" width="612">
	<fontspec id="font54" size="7" family="Calibri" color="#000000"/>
<text top="29" left="48" width="334" height="6" font="font0" id="p12_t1" reading_order_no="0" segment_no="0" tag_type="title">IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS, VOL. XX, NO. , AUGUST 2020</text>
<text top="29" left="556" width="8" height="6" font="font0" id="p12_t2" reading_order_no="1" segment_no="1" tag_type="text">12</text>
<text top="128" left="67" width="9" height="8" font="font10" id="p12_t3" reading_order_no="2" segment_no="4" tag_type="figure">(a)</text>
<text top="128" left="140" width="10" height="8" font="font10" id="p12_t4" reading_order_no="3" segment_no="4" tag_type="figure">(b)</text>
<text top="128" left="240" width="9" height="8" font="font10" id="p12_t5" reading_order_no="4" segment_no="4" tag_type="figure">(c)</text>
<text top="151" left="48" width="252" height="9" font="font11" id="p12_t6" reading_order_no="5" segment_no="5" tag_type="text">Fig. 13: Comparison of our results with VNect. (a) the input</text>
<text top="162" left="48" width="252" height="9" font="font11" id="p12_t7" reading_order_no="6" segment_no="5" tag_type="text">image; (b) the final results of VNect (left) and our method</text>
<text top="174" left="48" width="252" height="9" font="font11" id="p12_t8" reading_order_no="7" segment_no="5" tag_type="text">(right); (c) the raw network predictions of VNect (left) and</text>
<text top="185" left="48" width="82" height="9" font="font11" id="p12_t9" reading_order_no="8" segment_no="5" tag_type="text">our method (right).</text>
<text top="471" left="48" width="252" height="9" font="font11" id="p12_t10" reading_order_no="9" segment_no="10" tag_type="text">Fig. 14: Comparison of our method (middle) with SMPLify</text>
<text top="482" left="48" width="29" height="9" font="font11" id="p12_t11" reading_order_no="10" segment_no="10" tag_type="text">(right).</text>
<text top="518" left="62" width="200" height="9" font="font18" id="p12_t12" reading_order_no="11" segment_no="11" tag_type="text"><b>Quantitative analysis for multi-task network</b></text>
<text top="518" left="266" width="34" height="9" font="font11" id="p12_t13" reading_order_no="12" segment_no="11" tag_type="text">To eval-</text>
<text top="530" left="48" width="252" height="9" font="font11" id="p12_t14" reading_order_no="13" segment_no="11" tag_type="text">uate the importance of our multi-task design, we modify</text>
<text top="541" left="48" width="252" height="9" font="font11" id="p12_t15" reading_order_no="14" segment_no="11" tag_type="text">the network in Fig. 3 into 4 structures with different config-</text>
<text top="553" left="48" width="252" height="9" font="font11" id="p12_t16" reading_order_no="15" segment_no="11" tag_type="text">urations: a) 2D joint detection only, b) 2D joint detection</text>
<text top="564" left="48" width="252" height="9" font="font11" id="p12_t17" reading_order_no="16" segment_no="11" tag_type="text">+ IUV branch, c) 2D joint detection + POFs, d) 2D joint</text>
<text top="576" left="48" width="252" height="9" font="font11" id="p12_t18" reading_order_no="17" segment_no="11" tag_type="text">detection + IUV + POFs. All these networks are trained</text>
<text top="587" left="48" width="252" height="9" font="font11" id="p12_t19" reading_order_no="18" segment_no="11" tag_type="text">with the same training dataset, and tested on our validation</text>
<text top="599" left="48" width="252" height="9" font="font11" id="p12_t20" reading_order_no="19" segment_no="11" tag_type="text">dataset, which contains 11 different subjects not in the</text>
<text top="610" left="48" width="252" height="9" font="font11" id="p12_t21" reading_order_no="20" segment_no="11" tag_type="text">training dataset. For metrics of 2D joint positions, we report</text>
<text top="622" left="48" width="252" height="9" font="font11" id="p12_t22" reading_order_no="21" segment_no="11" tag_type="text">PCKh@0.5 [7] (the higher the better). For 3D part orientation,</text>
<text top="634" left="48" width="252" height="9" font="font11" id="p12_t23" reading_order_no="22" segment_no="11" tag_type="text">we scale the predicted 3D part orientation by the ground-</text>
<text top="645" left="48" width="252" height="9" font="font11" id="p12_t24" reading_order_no="23" segment_no="11" tag_type="text">truth limb length to obtain the 3D joint positions, then align</text>
<text top="657" left="48" width="252" height="9" font="font11" id="p12_t25" reading_order_no="24" segment_no="11" tag_type="text">the root joint position and compute the MPJPE (the lower</text>
<text top="668" left="48" width="252" height="9" font="font11" id="p12_t26" reading_order_no="25" segment_no="11" tag_type="text">the better). The results are reported in Table 3, which shows</text>
<text top="680" left="48" width="252" height="9" font="font11" id="p12_t27" reading_order_no="26" segment_no="11" tag_type="text">the power of mutual promotion of multi-task. We found</text>
<text top="691" left="48" width="252" height="9" font="font11" id="p12_t28" reading_order_no="27" segment_no="11" tag_type="text">that IUV information improves the accuracy of 3D POF</text>
<text top="703" left="48" width="252" height="9" font="font11" id="p12_t29" reading_order_no="28" segment_no="11" tag_type="text">orientation. The reason is that IUV maps provide the part</text>
<text top="714" left="48" width="252" height="9" font="font11" id="p12_t30" reading_order_no="29" segment_no="11" tag_type="text">occlusion relationship which conveys some 3D information.</text>
<text top="726" left="48" width="252" height="9" font="font11" id="p12_t31" reading_order_no="30" segment_no="11" tag_type="text">IUV maps are usually more abstract and more powerful</text>
<text top="737" left="48" width="252" height="9" font="font11" id="p12_t32" reading_order_no="31" segment_no="11" tag_type="text">than 2D landmarks in representing a human, and it is used</text>
<text top="45" left="312" width="68" height="9" font="font11" id="p12_t33" reading_order_no="32" segment_no="2" tag_type="text">by [59] as input.</text>
<text top="57" left="326" width="172" height="9" font="font18" id="p12_t34" reading_order_no="33" segment_no="3" tag_type="text"><b>Quantitative analysis for optimization</b></text>
<text top="57" left="502" width="62" height="9" font="font11" id="p12_t35" reading_order_no="34" segment_no="3" tag_type="text">Table 4 shows</text>
<text top="68" left="312" width="252" height="9" font="font11" id="p12_t36" reading_order_no="35" segment_no="3" tag_type="text">the quantitative performance, which reveals the importance</text>
<text top="80" left="312" width="252" height="9" font="font11" id="p12_t37" reading_order_no="36" segment_no="3" tag_type="text">of each energy term. We compare results under 5 different</text>
<text top="91" left="312" width="252" height="9" font="font11" id="p12_t38" reading_order_no="37" segment_no="3" tag_type="text">energy term settings: a) 2D position only; b) 2D position</text>
<text top="103" left="312" width="252" height="9" font="font11" id="p12_t39" reading_order_no="38" segment_no="3" tag_type="text">+ mask; c) 2D position + mask + 3D part orientation; d)</text>
<text top="114" left="312" width="252" height="9" font="font11" id="p12_t40" reading_order_no="39" segment_no="3" tag_type="text">2D position + mask + 3D part orientation + IUV; e) 2D</text>
<text top="126" left="312" width="252" height="9" font="font11" id="p12_t41" reading_order_no="40" segment_no="3" tag_type="text">position + mask + 3D part orientation + IUV + temporal. We</text>
<text top="137" left="312" width="252" height="9" font="font11" id="p12_t42" reading_order_no="41" segment_no="3" tag_type="text">report MPJPE on Human3.6M and 3DPW. The results shows</text>
<text top="149" left="312" width="252" height="9" font="font11" id="p12_t43" reading_order_no="42" segment_no="3" tag_type="text">that every energy term in our optimization is beneficial for</text>
<text top="160" left="312" width="252" height="9" font="font11" id="p12_t44" reading_order_no="43" segment_no="3" tag_type="text">human pose reconstruction. The result with temporal term</text>
<text top="172" left="312" width="252" height="9" font="font11" id="p12_t45" reading_order_no="44" segment_no="3" tag_type="text">shows higher errors, because it ensures temporal smooth</text>
<text top="184" left="312" width="244" height="9" font="font11" id="p12_t46" reading_order_no="45" segment_no="3" tag_type="text">rather than the consistency with the network output cues.</text>
<text top="195" left="326" width="138" height="9" font="font18" id="p12_t47" reading_order_no="46" segment_no="6" tag_type="text"><b>The mask term in optimization.</b></text>
<text top="195" left="466" width="98" height="9" font="font11" id="p12_t48" reading_order_no="47" segment_no="6" tag_type="text">We evaluate the impor-</text>
<text top="207" left="312" width="252" height="9" font="font11" id="p12_t49" reading_order_no="48" segment_no="6" tag_type="text">tance of the foreground segmentation mask by comparing</text>
<text top="218" left="312" width="252" height="9" font="font11" id="p12_t50" reading_order_no="49" segment_no="6" tag_type="text">the reconstructed bodies with and without this term. Fig. 15</text>
<text top="230" left="312" width="252" height="9" font="font11" id="p12_t51" reading_order_no="50" segment_no="6" tag_type="text">clearly shows the role of the mask when predicted 2D joints</text>
<text top="241" left="312" width="252" height="9" font="font11" id="p12_t52" reading_order_no="51" segment_no="6" tag_type="text">and 3D orientation are inaccurate, especially when some</text>
<text top="253" left="312" width="76" height="9" font="font11" id="p12_t53" reading_order_no="52" segment_no="6" tag_type="text">joints are missing.</text>
<text top="347" left="362" width="7" height="9" font="font54" id="p12_t54" reading_order_no="53" segment_no="7" tag_type="figure">(a)</text>
<text top="347" left="408" width="8" height="9" font="font54" id="p12_t55" reading_order_no="54" segment_no="7" tag_type="figure">(b)</text>
<text top="347" left="452" width="7" height="9" font="font54" id="p12_t56" reading_order_no="55" segment_no="7" tag_type="figure">(c)</text>
<text top="347" left="497" width="8" height="9" font="font54" id="p12_t57" reading_order_no="56" segment_no="7" tag_type="figure">(d)</text>
<text top="347" left="542" width="8" height="9" font="font54" id="p12_t58" reading_order_no="57" segment_no="7" tag_type="figure">(e)</text>
<text top="369" left="312" width="252" height="9" font="font11" id="p12_t59" reading_order_no="58" segment_no="8" tag_type="text">Fig. 15: Importance of the mask term. Given an image (a),</text>
<text top="380" left="312" width="252" height="9" font="font11" id="p12_t60" reading_order_no="59" segment_no="8" tag_type="text">the network predicts a foreground segmentation mask (b)</text>
<text top="392" left="312" width="252" height="9" font="font11" id="p12_t61" reading_order_no="60" segment_no="8" tag_type="text">and 2D joints (c) (note the left-wrist is missing). If the mask</text>
<text top="404" left="312" width="252" height="9" font="font11" id="p12_t62" reading_order_no="61" segment_no="8" tag_type="text">is not used, the reconstructed body is problematic (d); The</text>
<text top="415" left="312" width="149" height="9" font="font11" id="p12_t63" reading_order_no="62" segment_no="8" tag_type="text">mask helps build a correct pose (e).</text>
<text top="438" left="326" width="206" height="9" font="font18" id="p12_t64" reading_order_no="63" segment_no="9" tag_type="text"><b>The 3D part Orientation term in optimization.</b></text>
<text top="438" left="536" width="28" height="9" font="font11" id="p12_t65" reading_order_no="64" segment_no="9" tag_type="text">Fig. 16</text>
<text top="449" left="312" width="252" height="9" font="font11" id="p12_t66" reading_order_no="65" segment_no="9" tag_type="text">shows an example with and without the 3D orientation</text>
<text top="461" left="312" width="252" height="9" font="font11" id="p12_t67" reading_order_no="66" segment_no="9" tag_type="text">term. The use of the 3D orientation term significantly re-</text>
<text top="472" left="312" width="203" height="9" font="font11" id="p12_t68" reading_order_no="67" segment_no="9" tag_type="text">duces the reconstruction ambiguity of 3D poses.</text>
<text top="634" left="312" width="252" height="9" font="font11" id="p12_t69" reading_order_no="68" segment_no="12" tag_type="text">Fig. 16: Importance of the 3D part orientation term. (left)</text>
<text top="646" left="312" width="252" height="9" font="font11" id="p12_t70" reading_order_no="69" segment_no="12" tag_type="text">input image; (middle) result with 3D part orientation term;</text>
<text top="657" left="312" width="198" height="9" font="font11" id="p12_t71" reading_order_no="70" segment_no="12" tag_type="text">(right) result without 3D part orientation term.</text>
<text top="680" left="326" width="145" height="9" font="font18" id="p12_t72" reading_order_no="71" segment_no="13" tag_type="text"><b>The IUV term in optimization.</b></text>
<text top="680" left="477" width="87" height="9" font="font11" id="p12_t73" reading_order_no="72" segment_no="13" tag_type="text">An IUV map plays</text>
<text top="691" left="312" width="252" height="9" font="font11" id="p12_t74" reading_order_no="73" segment_no="13" tag_type="text">important roles in both 3D body geometry reconstruction</text>
<text top="703" left="312" width="252" height="9" font="font11" id="p12_t75" reading_order_no="74" segment_no="13" tag_type="text">and pose estimation. We evaluate the importance of IUV by</text>
<text top="714" left="312" width="252" height="9" font="font11" id="p12_t76" reading_order_no="75" segment_no="13" tag_type="text">dropping off this term in shape reconstruction and pose esti-</text>
<text top="726" left="312" width="252" height="9" font="font11" id="p12_t77" reading_order_no="76" segment_no="13" tag_type="text">mation, respectively. Fig. 17(a) shows a side-by-side compar-</text>
<text top="737" left="312" width="252" height="9" font="font11" id="p12_t78" reading_order_no="77" segment_no="13" tag_type="text">ison while reconstructing an over-weighted lady. Using IUV</text>
</page>
<page number="13" position="absolute" top="0" left="0" height="792" width="612">
<text top="29" left="48" width="334" height="6" font="font0" id="p13_t1" reading_order_no="0" segment_no="0" tag_type="title">IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS, VOL. XX, NO. , AUGUST 2020</text>
<text top="29" left="556" width="8" height="6" font="font0" id="p13_t2" reading_order_no="1" segment_no="1" tag_type="text">13</text>
<text top="182" left="59" width="229" height="8" font="font10" id="p13_t3" reading_order_no="2" segment_no="4" tag_type="text">(a) Shape reconstructed with the IUV term (middle) manifests</text>
<text top="191" left="59" width="221" height="8" font="font10" id="p13_t4" reading_order_no="3" segment_no="4" tag_type="text">the body weight better than that without the IUV term (right).</text>
<text top="339" left="59" width="229" height="8" font="font10" id="p13_t5" reading_order_no="4" segment_no="8" tag_type="text">(b) Pose reconstructed with (middle) and without (right) the IUV</text>
<text top="348" left="59" width="19" height="8" font="font10" id="p13_t6" reading_order_no="5" segment_no="8" tag_type="text">term.</text>
<text top="369" left="48" width="252" height="9" font="font11" id="p13_t7" reading_order_no="6" segment_no="10" tag_type="text">Fig. 17: The importance of IUV term for shape and pose</text>
<text top="381" left="48" width="63" height="9" font="font11" id="p13_t8" reading_order_no="7" segment_no="10" tag_type="text">reconstruction.</text>
<text top="420" left="48" width="252" height="9" font="font11" id="p13_t9" reading_order_no="8" segment_no="12" tag_type="text">term gives more accurate body model, because IUV terms</text>
<text top="432" left="48" width="252" height="9" font="font11" id="p13_t10" reading_order_no="9" segment_no="12" tag_type="text">impose detailed geometry model constraints from dense</text>
<text top="443" left="48" width="73" height="9" font="font11" id="p13_t11" reading_order_no="10" segment_no="12" tag_type="text">correspondences.</text>
<text top="457" left="62" width="238" height="9" font="font11" id="p13_t12" reading_order_no="11" segment_no="14" tag_type="text">For pose reconstruction, Fig. 17(b) shows that recon-</text>
<text top="469" left="48" width="252" height="9" font="font11" id="p13_t13" reading_order_no="12" segment_no="14" tag_type="text">structed examples with and without IUV term. It is obvious</text>
<text top="480" left="48" width="252" height="9" font="font11" id="p13_t14" reading_order_no="13" segment_no="14" tag_type="text">that IUV term helps recover more accurate result, especially</text>
<text top="492" left="48" width="88" height="9" font="font11" id="p13_t15" reading_order_no="14" segment_no="14" tag_type="text">for body orientation.</text>
<text top="541" left="48" width="13" height="9" font="font39" id="p13_t16" reading_order_no="15" segment_no="18" tag_type="title"><b>7.5</b></text>
<text top="541" left="71" width="51" height="9" font="font39" id="p13_t17" reading_order_no="16" segment_no="18" tag_type="title"><b>Limitations</b></text>
<text top="564" left="48" width="252" height="9" font="font11" id="p13_t18" reading_order_no="17" segment_no="20" tag_type="text">With no exceptions, our method suffers from several limita-</text>
<text top="576" left="48" width="252" height="9" font="font11" id="p13_t19" reading_order_no="18" segment_no="20" tag_type="text">tions. First, we observed failure cases when a significant part</text>
<text top="587" left="48" width="252" height="9" font="font11" id="p13_t20" reading_order_no="19" segment_no="20" tag_type="text">of the target person is either occluded by other objects or</text>
<text top="599" left="48" width="252" height="9" font="font11" id="p13_t21" reading_order_no="20" segment_no="20" tag_type="text">out of image boundary. Occlusion is the biggest issue and it</text>
<text top="610" left="48" width="252" height="9" font="font11" id="p13_t22" reading_order_no="21" segment_no="20" tag_type="text">imposes more challenge for RGB camera than depth camera</text>
<text top="622" left="48" width="252" height="9" font="font11" id="p13_t23" reading_order_no="22" segment_no="20" tag_type="text">based methods. Second, our method also fails for com-</text>
<text top="634" left="48" width="252" height="9" font="font11" id="p13_t24" reading_order_no="23" segment_no="20" tag_type="text">plicated or uncommon poses, particularly those in sports</text>
<text top="645" left="48" width="252" height="9" font="font11" id="p13_t25" reading_order_no="24" segment_no="20" tag_type="text">videos, such as gymnastics and skydiving. The main reason</text>
<text top="657" left="48" width="252" height="9" font="font11" id="p13_t26" reading_order_no="25" segment_no="20" tag_type="text">is that such data is not adequate in training dataset. Third,</text>
<text top="668" left="48" width="252" height="9" font="font11" id="p13_t27" reading_order_no="26" segment_no="20" tag_type="text">our system does not have specific hand pose detector (as</text>
<text top="680" left="48" width="252" height="9" font="font11" id="p13_t28" reading_order_no="27" segment_no="20" tag_type="text">did in [60]) and each hand is associated with only one joint,</text>
<text top="691" left="48" width="252" height="9" font="font11" id="p13_t29" reading_order_no="28" segment_no="20" tag_type="text">therefore the reconstructed hands are sometimes incorrectly</text>
<text top="703" left="48" width="252" height="9" font="font11" id="p13_t30" reading_order_no="29" segment_no="20" tag_type="text">oriented. Finally, our CNN does not handle multiple bodies</text>
<text top="714" left="48" width="252" height="9" font="font11" id="p13_t31" reading_order_no="30" segment_no="20" tag_type="text">at this moment, but can easily extended to support this.</text>
<text top="726" left="48" width="252" height="9" font="font11" id="p13_t32" reading_order_no="31" segment_no="20" tag_type="text">Solving the above mentioned problems points to interesting</text>
<text top="737" left="48" width="72" height="9" font="font11" id="p13_t33" reading_order_no="32" segment_no="20" tag_type="text">future directions.</text>
<text top="44" left="312" width="6" height="10" font="font7" id="p13_t34" reading_order_no="33" segment_no="2" tag_type="title"><b>8</b></text>
<text top="44" left="330" width="8" height="10" font="font7" id="p13_t35" reading_order_no="34" segment_no="2" tag_type="title"><b>C</b></text>
<text top="45" left="338" width="64" height="8" font="font8" id="p13_t36" reading_order_no="35" segment_no="2" tag_type="title"><b>ONCLUSIONS</b></text>
<text top="59" left="312" width="252" height="9" font="font11" id="p13_t37" reading_order_no="36" segment_no="3" tag_type="text">We have presented a method for reconstructing the 3D</text>
<text top="71" left="312" width="252" height="9" font="font11" id="p13_t38" reading_order_no="37" segment_no="3" tag_type="text">pose and shape of a human, in a stable and consistent</text>
<text top="83" left="312" width="252" height="9" font="font11" id="p13_t39" reading_order_no="38" segment_no="3" tag_type="text">manner, from a single RGB video stream at more than 20</text>
<text top="94" left="312" width="252" height="9" font="font11" id="p13_t40" reading_order_no="39" segment_no="3" tag_type="text">Hz. Our approach employs a multi-task CNN that regresses</text>
<text top="106" left="312" width="252" height="9" font="font11" id="p13_t41" reading_order_no="40" segment_no="3" tag_type="text">five human anatomical features simultaneously, which are</text>
<text top="117" left="312" width="252" height="9" font="font11" id="p13_t42" reading_order_no="41" segment_no="3" tag_type="text">further cooked with a kinematic pose reconstruction and</text>
<text top="129" left="312" width="252" height="9" font="font11" id="p13_t43" reading_order_no="42" segment_no="3" tag_type="text">shape modeling algorithm, producing a temporally stable</text>
<text top="140" left="312" width="252" height="9" font="font11" id="p13_t44" reading_order_no="43" segment_no="3" tag_type="text">3D reconstruction of the full-body. In contrast to most ex-</text>
<text top="152" left="312" width="252" height="9" font="font11" id="p13_t45" reading_order_no="44" segment_no="3" tag_type="text">isting approaches, our approach can operate on any input</text>
<text top="163" left="312" width="252" height="9" font="font11" id="p13_t46" reading_order_no="45" segment_no="3" tag_type="text">image fully automatically, without strict prescribed bound-</text>
<text top="175" left="312" width="252" height="9" font="font11" id="p13_t47" reading_order_no="46" segment_no="3" tag_type="text">ing boxes, and independent of expensive initialization. We</text>
<text top="186" left="312" width="252" height="9" font="font11" id="p13_t48" reading_order_no="47" segment_no="3" tag_type="text">test and evaluate our system in a variety of challenging re-</text>
<text top="198" left="312" width="252" height="9" font="font11" id="p13_t49" reading_order_no="48" segment_no="3" tag_type="text">altime scenarios, including live streaming from commercial</text>
<text top="209" left="312" width="252" height="9" font="font11" id="p13_t50" reading_order_no="49" segment_no="3" tag_type="text">cameras, as well as in community videos. Results demon-</text>
<text top="221" left="312" width="252" height="9" font="font11" id="p13_t51" reading_order_no="50" segment_no="3" tag_type="text">strate that our approach compares to offline state-of-the-</text>
<text top="233" left="312" width="252" height="9" font="font11" id="p13_t52" reading_order_no="51" segment_no="3" tag_type="text">art monocular RGB methods qualitatively and advances the</text>
<text top="244" left="312" width="252" height="9" font="font11" id="p13_t53" reading_order_no="52" segment_no="3" tag_type="text">realtime 3D body reconstruction methods with a significant</text>
<text top="256" left="312" width="20" height="9" font="font11" id="p13_t54" reading_order_no="53" segment_no="3" tag_type="text">step.</text>
<text top="281" left="312" width="8" height="10" font="font7" id="p13_t55" reading_order_no="54" segment_no="5" tag_type="title"><b>R</b></text>
<text top="282" left="321" width="58" height="8" font="font8" id="p13_t56" reading_order_no="55" segment_no="5" tag_type="title"><b>EFERENCES</b></text>
<text top="297" left="312" width="9" height="8" font="font10" id="p13_t57" reading_order_no="56" segment_no="6" tag_type="text">[1]</text>
<text top="297" left="330" width="234" height="8" font="font10" id="p13_t58" reading_order_no="57" segment_no="6" tag_type="text">R. A. G ¨uler, N. Neverova, and I. Kokkinos, “Densepose: Dense hu-</text>
<text top="306" left="330" width="131" height="8" font="font10" id="p13_t59" reading_order_no="58" segment_no="6" tag_type="text">man pose estimation in the wild,” in</text>
<text top="306" left="463" width="101" height="8" font="font13" id="p13_t60" reading_order_no="59" segment_no="6" tag_type="text">IEEE Conference on Computer</text>
<text top="315" left="330" width="103" height="8" font="font13" id="p13_t61" reading_order_no="60" segment_no="6" tag_type="text">Vision and Pattern Recognition</text>
<text top="315" left="433" width="76" height="8" font="font10" id="p13_t62" reading_order_no="61" segment_no="6" tag_type="text">, 2018, pp. 7297–7306.</text>
<text top="324" left="312" width="9" height="8" font="font10" id="p13_t63" reading_order_no="62" segment_no="7" tag_type="text">[2]</text>
<text top="324" left="330" width="234" height="8" font="font10" id="p13_t64" reading_order_no="63" segment_no="7" tag_type="text">N. Kolotouros, G. Pavlakos, M. J. Black, and K. Daniilidis, “Learn-</text>
<text top="333" left="330" width="234" height="8" font="font10" id="p13_t65" reading_order_no="64" segment_no="7" tag_type="text">ing to reconstruct 3d human pose and shape via model-fitting in</text>
<text top="342" left="330" width="44" height="8" font="font10" id="p13_t66" reading_order_no="65" segment_no="7" tag_type="text">the loop,” in</text>
<text top="342" left="376" width="188" height="8" font="font13" id="p13_t67" reading_order_no="66" segment_no="7" tag_type="text">Proceedings of the IEEE/CVF International Conference on</text>
<text top="351" left="330" width="55" height="8" font="font13" id="p13_t68" reading_order_no="67" segment_no="7" tag_type="text">Computer Vision</text>
<text top="351" left="386" width="76" height="8" font="font10" id="p13_t69" reading_order_no="68" segment_no="7" tag_type="text">, 2019, pp. 2252–2261.</text>
<text top="360" left="312" width="9" height="8" font="font10" id="p13_t70" reading_order_no="69" segment_no="9" tag_type="text">[3]</text>
<text top="360" left="330" width="234" height="8" font="font10" id="p13_t71" reading_order_no="70" segment_no="9" tag_type="text">D. Mehta, S. Sridhar, O. Sotnychenko, H. Rhodin, M. Shafiei, H.-</text>
<text top="369" left="330" width="234" height="8" font="font10" id="p13_t72" reading_order_no="71" segment_no="9" tag_type="text">P. Seidel, W. Xu, D. Casas, and C. Theobalt, “VNect: Real-time</text>
<text top="378" left="330" width="211" height="8" font="font10" id="p13_t73" reading_order_no="72" segment_no="9" tag_type="text">3D human pose estimation with a single RGB camera,”</text>
<text top="378" left="545" width="19" height="8" font="font13" id="p13_t74" reading_order_no="73" segment_no="9" tag_type="text">ACM</text>
<text top="387" left="330" width="107" height="8" font="font13" id="p13_t75" reading_order_no="74" segment_no="9" tag_type="text">Transactions on Graphics (TOG)</text>
<text top="387" left="437" width="93" height="8" font="font10" id="p13_t76" reading_order_no="75" segment_no="9" tag_type="text">, vol. 36, no. 4, p. 44, 2017.</text>
<text top="396" left="312" width="9" height="8" font="font10" id="p13_t77" reading_order_no="76" segment_no="11" tag_type="text">[4]</text>
<text top="396" left="330" width="234" height="8" font="font10" id="p13_t78" reading_order_no="77" segment_no="11" tag_type="text">F. Bogo, A. Kanazawa, C. Lassner, P. Gehler, J. Romero, and</text>
<text top="405" left="330" width="234" height="8" font="font10" id="p13_t79" reading_order_no="78" segment_no="11" tag_type="text">M. J. Black, “Keep it SMPL: Automatic estimation of 3D human</text>
<text top="414" left="330" width="150" height="8" font="font10" id="p13_t80" reading_order_no="79" segment_no="11" tag_type="text">pose and shape from a single image,” in</text>
<text top="414" left="483" width="81" height="8" font="font13" id="p13_t81" reading_order_no="80" segment_no="11" tag_type="text">European Conference on</text>
<text top="423" left="330" width="55" height="8" font="font13" id="p13_t82" reading_order_no="81" segment_no="11" tag_type="text">Computer Vision</text>
<text top="423" left="386" width="68" height="8" font="font10" id="p13_t83" reading_order_no="82" segment_no="11" tag_type="text">, 2016, pp. 561–578.</text>
<text top="432" left="312" width="9" height="8" font="font10" id="p13_t84" reading_order_no="83" segment_no="13" tag_type="text">[5]</text>
<text top="432" left="330" width="234" height="8" font="font10" id="p13_t85" reading_order_no="84" segment_no="13" tag_type="text">M. Kocabas, N. Athanasiou, and M. J. Black, “Vibe: Video inference</text>
<text top="441" left="330" width="172" height="8" font="font10" id="p13_t86" reading_order_no="85" segment_no="13" tag_type="text">for human body pose and shape estimation,” in</text>
<text top="441" left="505" width="59" height="8" font="font13" id="p13_t87" reading_order_no="86" segment_no="13" tag_type="text">Proceedings of the</text>
<text top="450" left="330" width="232" height="8" font="font13" id="p13_t88" reading_order_no="87" segment_no="13" tag_type="text">IEEE/CVF Conference on Computer Vision and Pattern Recognition</text>
<text top="450" left="562" width="2" height="8" font="font10" id="p13_t89" reading_order_no="88" segment_no="13" tag_type="text">,</text>
<text top="459" left="330" width="72" height="8" font="font10" id="p13_t90" reading_order_no="89" segment_no="13" tag_type="text">2020, pp. 5253–5263.</text>
<text top="468" left="312" width="9" height="8" font="font10" id="p13_t91" reading_order_no="90" segment_no="15" tag_type="text">[6]</text>
<text top="468" left="330" width="234" height="8" font="font10" id="p13_t92" reading_order_no="91" segment_no="15" tag_type="text">S.-E. Wei, V. Ramakrishna, T. Kanade, and Y. Sheikh, “Convo-</text>
<text top="477" left="330" width="100" height="8" font="font10" id="p13_t93" reading_order_no="92" segment_no="15" tag_type="text">lutional pose machines,” in</text>
<text top="477" left="433" width="131" height="8" font="font13" id="p13_t94" reading_order_no="93" segment_no="15" tag_type="text">Proceedings of the IEEE Conference on</text>
<text top="486" left="330" width="137" height="8" font="font13" id="p13_t95" reading_order_no="94" segment_no="15" tag_type="text">Computer Vision and Pattern Recognition</text>
<text top="486" left="467" width="76" height="8" font="font10" id="p13_t96" reading_order_no="95" segment_no="15" tag_type="text">, 2016, pp. 4724–4732.</text>
<text top="495" left="312" width="9" height="8" font="font10" id="p13_t97" reading_order_no="96" segment_no="16" tag_type="text">[7]</text>
<text top="495" left="330" width="234" height="8" font="font10" id="p13_t98" reading_order_no="97" segment_no="16" tag_type="text">A. Newell, K. Yang, and J. Deng, “Stacked hourglass networks for</text>
<text top="504" left="330" width="98" height="8" font="font10" id="p13_t99" reading_order_no="98" segment_no="16" tag_type="text">human pose estimation,” in</text>
<text top="504" left="431" width="131" height="8" font="font13" id="p13_t100" reading_order_no="99" segment_no="16" tag_type="text">European conference on computer vision</text>
<text top="504" left="562" width="2" height="8" font="font10" id="p13_t101" reading_order_no="100" segment_no="16" tag_type="text">,</text>
<text top="513" left="330" width="64" height="8" font="font10" id="p13_t102" reading_order_no="101" segment_no="16" tag_type="text">2016, pp. 483–499.</text>
<text top="522" left="312" width="9" height="8" font="font10" id="p13_t103" reading_order_no="102" segment_no="17" tag_type="text">[8]</text>
<text top="522" left="330" width="234" height="8" font="font10" id="p13_t104" reading_order_no="103" segment_no="17" tag_type="text">X. Nie, J. Feng, Y. Zuo, and S. Yan, “Human pose estimation with</text>
<text top="531" left="330" width="102" height="8" font="font10" id="p13_t105" reading_order_no="104" segment_no="17" tag_type="text">parsing induced learner,” in</text>
<text top="531" left="435" width="129" height="8" font="font13" id="p13_t106" reading_order_no="105" segment_no="17" tag_type="text">Proceedings of the IEEE Conference on</text>
<text top="540" left="330" width="137" height="8" font="font13" id="p13_t107" reading_order_no="106" segment_no="17" tag_type="text">Computer Vision and Pattern Recognition</text>
<text top="540" left="467" width="76" height="8" font="font10" id="p13_t108" reading_order_no="107" segment_no="17" tag_type="text">, 2018, pp. 2100–2108.</text>
<text top="549" left="312" width="9" height="8" font="font10" id="p13_t109" reading_order_no="108" segment_no="19" tag_type="text">[9]</text>
<text top="549" left="330" width="234" height="8" font="font10" id="p13_t110" reading_order_no="109" segment_no="19" tag_type="text">J. Martinez, R. Hossain, J. Romero, and J. J. Little, “A simple yet</text>
<text top="558" left="330" width="192" height="8" font="font10" id="p13_t111" reading_order_no="110" segment_no="19" tag_type="text">effective baseline for 3D human pose estimation,” in</text>
<text top="558" left="525" width="39" height="8" font="font13" id="p13_t112" reading_order_no="111" segment_no="19" tag_type="text">Proceedings</text>
<text top="567" left="330" width="196" height="8" font="font13" id="p13_t113" reading_order_no="112" segment_no="19" tag_type="text">of the IEEE International Conference on Computer Vision</text>
<text top="567" left="526" width="38" height="8" font="font10" id="p13_t114" reading_order_no="113" segment_no="19" tag_type="text">, 2017, pp.</text>
<text top="576" left="330" width="38" height="8" font="font10" id="p13_t115" reading_order_no="114" segment_no="19" tag_type="text">2640–2649.</text>
<text top="585" left="312" width="252" height="8" font="font10" id="p13_t116" reading_order_no="115" segment_no="21" tag_type="text">[10] H. Ci, C. Wang, X. Ma, and Y. Wang, “Optimizing network struc-</text>
<text top="594" left="330" width="137" height="8" font="font10" id="p13_t117" reading_order_no="116" segment_no="21" tag_type="text">ture for 3d human pose estimation,” in</text>
<text top="594" left="469" width="95" height="8" font="font13" id="p13_t118" reading_order_no="117" segment_no="21" tag_type="text">Proceedings of the IEEE/CVF</text>
<text top="603" left="330" width="148" height="8" font="font13" id="p13_t119" reading_order_no="118" segment_no="21" tag_type="text">International Conference on Computer Vision</text>
<text top="603" left="478" width="76" height="8" font="font10" id="p13_t120" reading_order_no="119" segment_no="21" tag_type="text">, 2019, pp. 2262–2271.</text>
<text top="612" left="312" width="252" height="8" font="font10" id="p13_t121" reading_order_no="120" segment_no="22" tag_type="text">[11] L. Zhao, X. Peng, Y. Tian, M. Kapadia, and D. N. Metaxas, “Seman-</text>
<text top="621" left="330" width="234" height="8" font="font10" id="p13_t122" reading_order_no="121" segment_no="22" tag_type="text">tic graph convolutional networks for 3d human pose regression,”</text>
<text top="630" left="330" width="7" height="8" font="font10" id="p13_t123" reading_order_no="122" segment_no="22" tag_type="text">in</text>
<text top="630" left="340" width="224" height="8" font="font13" id="p13_t124" reading_order_no="123" segment_no="22" tag_type="text">Proceedings of the IEEE/CVF Conference on Computer Vision and</text>
<text top="639" left="330" width="65" height="8" font="font13" id="p13_t125" reading_order_no="124" segment_no="22" tag_type="text">Pattern Recognition</text>
<text top="639" left="396" width="76" height="8" font="font10" id="p13_t126" reading_order_no="125" segment_no="22" tag_type="text">, 2019, pp. 3425–3435.</text>
<text top="648" left="312" width="252" height="8" font="font10" id="p13_t127" reading_order_no="126" segment_no="23" tag_type="text">[12] H.-S. Fang, Y. Xu, W. Wang, X. Liu, and S.-C. Zhu, “Learning</text>
<text top="657" left="330" width="234" height="8" font="font10" id="p13_t128" reading_order_no="127" segment_no="23" tag_type="text">pose grammar to encode human body configuration for 3d pose</text>
<text top="666" left="330" width="55" height="8" font="font10" id="p13_t129" reading_order_no="128" segment_no="23" tag_type="text">estimation,” in</text>
<text top="666" left="389" width="175" height="8" font="font13" id="p13_t130" reading_order_no="129" segment_no="23" tag_type="text">Proceedings of the AAAI Conference on Artificial</text>
<text top="675" left="330" width="37" height="8" font="font13" id="p13_t131" reading_order_no="130" segment_no="23" tag_type="text">Intelligence</text>
<text top="675" left="368" width="71" height="8" font="font10" id="p13_t132" reading_order_no="131" segment_no="23" tag_type="text">, vol. 32, no. 1, 2018.</text>
<text top="684" left="312" width="252" height="8" font="font10" id="p13_t133" reading_order_no="132" segment_no="24" tag_type="text">[13] G. Pavlakos, X. Zhou, and K. Daniilidis, “Ordinal depth super-</text>
<text top="693" left="330" width="160" height="8" font="font10" id="p13_t134" reading_order_no="133" segment_no="24" tag_type="text">vision for 3D human pose estimation,” in</text>
<text top="693" left="494" width="70" height="8" font="font13" id="p13_t135" reading_order_no="134" segment_no="24" tag_type="text">IEEE Conference on</text>
<text top="702" left="330" width="137" height="8" font="font13" id="p13_t136" reading_order_no="135" segment_no="24" tag_type="text">Computer Vision and Pattern Recognition</text>
<text top="702" left="467" width="76" height="8" font="font10" id="p13_t137" reading_order_no="136" segment_no="24" tag_type="text">, 2018, pp. 7307–7316.</text>
<text top="711" left="312" width="252" height="8" font="font10" id="p13_t138" reading_order_no="137" segment_no="25" tag_type="text">[14] T.-Y. Lin, M. Maire, S. Belongie, J. Hays, P. Perona, D. Ramanan,</text>
<text top="720" left="330" width="234" height="8" font="font10" id="p13_t139" reading_order_no="138" segment_no="25" tag_type="text">P. Doll´ar, and C. L. Zitnick, “Microsoft coco: Common objects</text>
<text top="729" left="330" width="54" height="8" font="font10" id="p13_t140" reading_order_no="139" segment_no="25" tag_type="text">in context,” in</text>
<text top="729" left="388" width="174" height="8" font="font13" id="p13_t141" reading_order_no="140" segment_no="25" tag_type="text">European Conference on Computer Vision (ECCV)</text>
<text top="729" left="562" width="2" height="8" font="font10" id="p13_t142" reading_order_no="141" segment_no="25" tag_type="text">,</text>
<text top="738" left="330" width="64" height="8" font="font10" id="p13_t143" reading_order_no="142" segment_no="25" tag_type="text">Z ¨urich, 2014, oral.</text>
</page>
<page number="14" position="absolute" top="0" left="0" height="792" width="612">
<text top="29" left="48" width="334" height="6" font="font0" id="p14_t1" reading_order_no="0" segment_no="0" tag_type="title">IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS, VOL. XX, NO. , AUGUST 2020</text>
<text top="29" left="556" width="8" height="6" font="font0" id="p14_t2" reading_order_no="1" segment_no="1" tag_type="text">14</text>
<text top="46" left="48" width="252" height="8" font="font10" id="p14_t3" reading_order_no="2" segment_no="2" tag_type="text">[15] M. Andriluka, L. Pishchulin, P. Gehler, and B. Schiele, “2d human</text>
<text top="55" left="66" width="234" height="8" font="font10" id="p14_t4" reading_order_no="3" segment_no="2" tag_type="text">pose estimation: New benchmark and state of the art analysis,” in</text>
<text top="64" left="66" width="232" height="8" font="font13" id="p14_t5" reading_order_no="4" segment_no="2" tag_type="text">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</text>
<text top="64" left="298" width="2" height="8" font="font10" id="p14_t6" reading_order_no="5" segment_no="2" tag_type="text">,</text>
<text top="73" left="66" width="36" height="8" font="font10" id="p14_t7" reading_order_no="6" segment_no="2" tag_type="text">June 2014.</text>
<text top="82" left="48" width="252" height="8" font="font10" id="p14_t8" reading_order_no="7" segment_no="4" tag_type="text">[16] X. Zhou, Q. Huang, X. Sun, X. Xue, and Y. Wei, “Towards 3d hu-</text>
<text top="91" left="66" width="234" height="8" font="font10" id="p14_t9" reading_order_no="8" segment_no="4" tag_type="text">man pose estimation in the wild: a weakly-supervised approach,”</text>
<text top="100" left="66" width="7" height="8" font="font10" id="p14_t10" reading_order_no="9" segment_no="4" tag_type="text">in</text>
<text top="100" left="78" width="222" height="8" font="font13" id="p14_t11" reading_order_no="10" segment_no="4" tag_type="text">Proceedings of the IEEE International Conference on Computer</text>
<text top="109" left="66" width="21" height="8" font="font13" id="p14_t12" reading_order_no="11" segment_no="4" tag_type="text">Vision</text>
<text top="109" left="87" width="68" height="8" font="font10" id="p14_t13" reading_order_no="12" segment_no="4" tag_type="text">, 2017, pp. 398–407.</text>
<text top="119" left="48" width="252" height="8" font="font10" id="p14_t14" reading_order_no="13" segment_no="6" tag_type="text">[17] R. Dabral, A. Mundhada, U. Kusupati, S. Afaque, A. Sharma, and</text>
<text top="128" left="66" width="234" height="8" font="font10" id="p14_t15" reading_order_no="14" segment_no="6" tag_type="text">A. Jain, “Learning 3d human pose from structure and motion,” in</text>
<text top="137" left="66" width="232" height="8" font="font13" id="p14_t16" reading_order_no="15" segment_no="6" tag_type="text">Proceedings of the European Conference on Computer Vision (ECCV)</text>
<text top="137" left="298" width="2" height="8" font="font10" id="p14_t17" reading_order_no="16" segment_no="6" tag_type="text">,</text>
<text top="146" left="66" width="64" height="8" font="font10" id="p14_t18" reading_order_no="17" segment_no="6" tag_type="text">2018, pp. 668–683.</text>
<text top="155" left="48" width="252" height="8" font="font10" id="p14_t19" reading_order_no="18" segment_no="8" tag_type="text">[18] D. Mehta, H. Rhodin, D. Casas, P. Fua, O. Sotnychenko, W. Xu,</text>
<text top="164" left="66" width="234" height="8" font="font10" id="p14_t20" reading_order_no="19" segment_no="8" tag_type="text">and C. Theobalt, “Monocular 3D human pose estimation in the</text>
<text top="173" left="66" width="166" height="8" font="font10" id="p14_t21" reading_order_no="20" segment_no="8" tag_type="text">wild using improved CNN supervision,” in</text>
<text top="173" left="237" width="63" height="8" font="font13" id="p14_t22" reading_order_no="21" segment_no="8" tag_type="text">2017 International</text>
<text top="182" left="66" width="105" height="8" font="font13" id="p14_t23" reading_order_no="22" segment_no="8" tag_type="text">Conference on 3D Vision (3DV)</text>
<text top="182" left="171" width="68" height="8" font="font10" id="p14_t24" reading_order_no="23" segment_no="8" tag_type="text">, 2017, pp. 506–516.</text>
<text top="192" left="48" width="252" height="8" font="font10" id="p14_t25" reading_order_no="24" segment_no="11" tag_type="text">[19] B. Tekin, P. M´arquez-Neila, M. Salzmann, and P. Fua, “Learning to</text>
<text top="201" left="66" width="234" height="8" font="font10" id="p14_t26" reading_order_no="25" segment_no="11" tag_type="text">fuse 2d and 3d image cues for monocular body pose estimation,”</text>
<text top="210" left="66" width="7" height="8" font="font10" id="p14_t27" reading_order_no="26" segment_no="11" tag_type="text">in</text>
<text top="210" left="78" width="222" height="8" font="font13" id="p14_t28" reading_order_no="27" segment_no="11" tag_type="text">Proceedings of the IEEE International Conference on Computer</text>
<text top="219" left="66" width="21" height="8" font="font13" id="p14_t29" reading_order_no="28" segment_no="11" tag_type="text">Vision</text>
<text top="219" left="87" width="76" height="8" font="font10" id="p14_t30" reading_order_no="29" segment_no="11" tag_type="text">, 2017, pp. 3941–3950.</text>
<text top="228" left="48" width="252" height="8" font="font10" id="p14_t31" reading_order_no="30" segment_no="13" tag_type="text">[20] I. Habibie, W. Xu, D. Mehta, G. Pons-Moll, and C. Theobalt, “In</text>
<text top="237" left="66" width="234" height="8" font="font10" id="p14_t32" reading_order_no="31" segment_no="13" tag_type="text">the wild human pose estimation using explicit 2d features and</text>
<text top="246" left="66" width="131" height="8" font="font10" id="p14_t33" reading_order_no="32" segment_no="13" tag_type="text">intermediate 3d representations,” in</text>
<text top="246" left="201" width="99" height="8" font="font13" id="p14_t34" reading_order_no="33" segment_no="13" tag_type="text">Proceedings of the IEEE/CVF</text>
<text top="255" left="66" width="195" height="8" font="font13" id="p14_t35" reading_order_no="34" segment_no="13" tag_type="text">Conference on Computer Vision and Pattern Recognition</text>
<text top="255" left="261" width="39" height="8" font="font10" id="p14_t36" reading_order_no="35" segment_no="13" tag_type="text">, 2019, pp.</text>
<text top="264" left="66" width="49" height="8" font="font10" id="p14_t37" reading_order_no="36" segment_no="13" tag_type="text">10 905–10 914.</text>
<text top="273" left="48" width="252" height="8" font="font10" id="p14_t38" reading_order_no="37" segment_no="16" tag_type="text">[21] X. Sun, J. Shang, S. Liang, and Y. Wei, “Compositional human</text>
<text top="282" left="66" width="70" height="8" font="font10" id="p14_t39" reading_order_no="38" segment_no="16" tag_type="text">pose regression,” in</text>
<text top="282" left="139" width="161" height="8" font="font13" id="p14_t40" reading_order_no="39" segment_no="16" tag_type="text">Proceedings of the IEEE International Conference</text>
<text top="291" left="66" width="66" height="8" font="font13" id="p14_t41" reading_order_no="40" segment_no="16" tag_type="text">on Computer Vision</text>
<text top="291" left="132" width="76" height="8" font="font10" id="p14_t42" reading_order_no="41" segment_no="16" tag_type="text">, 2017, pp. 2602–2611.</text>
<text top="301" left="48" width="252" height="8" font="font10" id="p14_t43" reading_order_no="42" segment_no="18" tag_type="text">[22] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis, “Coarse-</text>
<text top="310" left="66" width="234" height="8" font="font10" id="p14_t44" reading_order_no="43" segment_no="18" tag_type="text">to-fine volumetric prediction for single-image 3D human pose,” in</text>
<text top="319" left="66" width="211" height="8" font="font13" id="p14_t45" reading_order_no="44" segment_no="18" tag_type="text">IEEE Conference on Computer Vision and Pattern Recognition</text>
<text top="319" left="277" width="23" height="8" font="font10" id="p14_t46" reading_order_no="45" segment_no="18" tag_type="text">, 2017,</text>
<text top="328" left="66" width="52" height="8" font="font10" id="p14_t47" reading_order_no="46" segment_no="18" tag_type="text">pp. 7025–7034.</text>
<text top="337" left="48" width="252" height="8" font="font10" id="p14_t48" reading_order_no="47" segment_no="20" tag_type="text">[23] X. Sun, B. Xiao, F. Wei, S. Liang, and Y. Wei, “Integral human pose</text>
<text top="346" left="66" width="52" height="8" font="font10" id="p14_t49" reading_order_no="48" segment_no="20" tag_type="text">regression,” in</text>
<text top="346" left="121" width="179" height="8" font="font13" id="p14_t50" reading_order_no="49" segment_no="20" tag_type="text">Proceedings of the European Conference on Computer</text>
<text top="355" left="66" width="50" height="8" font="font13" id="p14_t51" reading_order_no="50" segment_no="20" tag_type="text">Vision (ECCV)</text>
<text top="355" left="116" width="68" height="8" font="font10" id="p14_t52" reading_order_no="51" segment_no="20" tag_type="text">, 2018, pp. 529–545.</text>
<text top="365" left="48" width="252" height="8" font="font10" id="p14_t53" reading_order_no="52" segment_no="22" tag_type="text">[24] C. Luo, X. Chu, and A. Yuille, “Orinet: A fully convolu-</text>
<text top="374" left="66" width="180" height="8" font="font10" id="p14_t54" reading_order_no="53" segment_no="22" tag_type="text">tional network for 3d human pose estimation,”</text>
<text top="374" left="250" width="50" height="8" font="font13" id="p14_t55" reading_order_no="54" segment_no="22" tag_type="text">arXiv preprint</text>
<text top="383" left="66" width="59" height="8" font="font13" id="p14_t56" reading_order_no="55" segment_no="22" tag_type="text">arXiv:1811.04989</text>
<text top="383" left="125" width="22" height="8" font="font10" id="p14_t57" reading_order_no="56" segment_no="22" tag_type="text">, 2018.</text>
<text top="392" left="48" width="252" height="8" font="font10" id="p14_t58" reading_order_no="57" segment_no="23" tag_type="text">[25] D. Anguelov, P. Srinivasan, D. Koller, S. Thrun, J. Rodgers, and</text>
<text top="401" left="66" width="234" height="8" font="font10" id="p14_t59" reading_order_no="58" segment_no="23" tag_type="text">J. Davis, “SCAPE: Shape completion and animation of people,”</text>
<text top="410" left="66" width="66" height="8" font="font13" id="p14_t60" reading_order_no="59" segment_no="23" tag_type="text">ACM Trans. Graph.</text>
<text top="410" left="132" width="118" height="8" font="font10" id="p14_t61" reading_order_no="60" segment_no="23" tag_type="text">, vol. 24, no. 3, pp. 408–416, 2005.</text>
<text top="419" left="48" width="252" height="8" font="font10" id="p14_t62" reading_order_no="61" segment_no="26" tag_type="text">[26] M. Loper, N. Mahmood, J. Romero, G. Pons-Moll, and M. J. Black,</text>
<text top="428" left="66" width="169" height="8" font="font10" id="p14_t63" reading_order_no="62" segment_no="26" tag_type="text">“Smpl: A skinned multi-person linear model,”</text>
<text top="428" left="239" width="61" height="8" font="font13" id="p14_t64" reading_order_no="63" segment_no="26" tag_type="text">ACM transactions</text>
<text top="437" left="66" width="62" height="8" font="font13" id="p14_t65" reading_order_no="64" segment_no="26" tag_type="text">on graphics (TOG)</text>
<text top="437" left="128" width="97" height="8" font="font10" id="p14_t66" reading_order_no="65" segment_no="26" tag_type="text">, vol. 34, no. 6, p. 248, 2015.</text>
<text top="447" left="48" width="252" height="8" font="font10" id="p14_t67" reading_order_no="66" segment_no="27" tag_type="text">[27] G. Pavlakos, V. Choutas, N. Ghorbani, T. Bolkart, A. A. A. Osman,</text>
<text top="456" left="66" width="234" height="8" font="font10" id="p14_t68" reading_order_no="67" segment_no="27" tag_type="text">D. Tzionas, and M. J. Black, “Expressive body capture: 3D hands,</text>
<text top="465" left="66" width="146" height="8" font="font10" id="p14_t69" reading_order_no="68" segment_no="27" tag_type="text">face, and body from a single image,” in</text>
<text top="465" left="215" width="85" height="8" font="font13" id="p14_t70" reading_order_no="69" segment_no="27" tag_type="text">IEEE Conf. on Computer</text>
<text top="474" left="66" width="132" height="8" font="font13" id="p14_t71" reading_order_no="70" segment_no="27" tag_type="text">Vision and Pattern Recognition (CVPR)</text>
<text top="474" left="198" width="22" height="8" font="font10" id="p14_t72" reading_order_no="71" segment_no="27" tag_type="text">, 2019.</text>
<text top="483" left="48" width="252" height="8" font="font10" id="p14_t73" reading_order_no="72" segment_no="29" tag_type="text">[28] P. Guan, A. Weiss, A. O. B˘alan, and M. J. Black, “Estimating</text>
<text top="492" left="66" width="170" height="8" font="font10" id="p14_t74" reading_order_no="73" segment_no="29" tag_type="text">human shape and pose from a single image,” in</text>
<text top="492" left="238" width="62" height="8" font="font13" id="p14_t75" reading_order_no="74" segment_no="29" tag_type="text">IEEE International</text>
<text top="501" left="66" width="103" height="8" font="font13" id="p14_t76" reading_order_no="75" segment_no="29" tag_type="text">Conference on Computer Vision</text>
<text top="501" left="170" width="76" height="8" font="font10" id="p14_t77" reading_order_no="76" segment_no="29" tag_type="text">, 2009, pp. 1381–1388.</text>
<text top="511" left="48" width="252" height="8" font="font10" id="p14_t78" reading_order_no="77" segment_no="31" tag_type="text">[29] C. Lassner, J. Romero, M. Kiefel, F. Bogo, M. J. Black, and P. V.</text>
<text top="520" left="66" width="234" height="8" font="font10" id="p14_t79" reading_order_no="78" segment_no="31" tag_type="text">Gehler, “Unite the people: Closing the loop between 3D and 2D</text>
<text top="529" left="66" width="101" height="8" font="font10" id="p14_t80" reading_order_no="79" segment_no="31" tag_type="text">human representations,” in</text>
<text top="529" left="171" width="129" height="8" font="font13" id="p14_t81" reading_order_no="80" segment_no="31" tag_type="text">IEEE Conf. on Computer Vision and</text>
<text top="538" left="66" width="94" height="8" font="font13" id="p14_t82" reading_order_no="81" segment_no="31" tag_type="text">Pattern Recognition (CVPR)</text>
<text top="538" left="160" width="76" height="8" font="font10" id="p14_t83" reading_order_no="82" segment_no="31" tag_type="text">, 2017, pp. 6050–6059.</text>
<text top="547" left="48" width="252" height="8" font="font10" id="p14_t84" reading_order_no="83" segment_no="33" tag_type="text">[30] A. Kanazawa, M. J. Black, D. W. Jacobs, and J. Malik, “End-to-</text>
<text top="556" left="66" width="163" height="8" font="font10" id="p14_t85" reading_order_no="84" segment_no="33" tag_type="text">end recovery of human shape and pose,” in</text>
<text top="556" left="232" width="68" height="8" font="font13" id="p14_t86" reading_order_no="85" segment_no="33" tag_type="text">IEEE Conference on</text>
<text top="565" left="66" width="137" height="8" font="font13" id="p14_t87" reading_order_no="86" segment_no="33" tag_type="text">Computer Vision and Pattern Recognition</text>
<text top="565" left="203" width="76" height="8" font="font10" id="p14_t88" reading_order_no="87" segment_no="33" tag_type="text">, 2018, pp. 7122–7131.</text>
<text top="574" left="48" width="252" height="8" font="font10" id="p14_t89" reading_order_no="88" segment_no="35" tag_type="text">[31] N. Kolotouros, G. Pavlakos, and K. Daniilidis, “Convolutional</text>
<text top="583" left="66" width="234" height="8" font="font10" id="p14_t90" reading_order_no="89" segment_no="35" tag_type="text">mesh regression for single-image human shape reconstruction,”</text>
<text top="592" left="66" width="7" height="8" font="font10" id="p14_t91" reading_order_no="90" segment_no="35" tag_type="text">in</text>
<text top="592" left="75" width="225" height="8" font="font13" id="p14_t92" reading_order_no="91" segment_no="35" tag_type="text">Proceedings of the IEEE Conference on Computer Vision and Pattern</text>
<text top="601" left="66" width="39" height="8" font="font13" id="p14_t93" reading_order_no="92" segment_no="35" tag_type="text">Recognition</text>
<text top="601" left="105" width="76" height="8" font="font10" id="p14_t94" reading_order_no="93" segment_no="35" tag_type="text">, 2019, pp. 4501–4510.</text>
<text top="611" left="48" width="252" height="8" font="font10" id="p14_t95" reading_order_no="94" segment_no="37" tag_type="text">[32] H. Joo, N. Neverova, and A. Vedaldi, “Exemplar fine-tuning</text>
<text top="620" left="66" width="234" height="8" font="font10" id="p14_t96" reading_order_no="95" segment_no="37" tag_type="text">for 3d human pose fitting towards in-the-wild 3d human pose</text>
<text top="629" left="66" width="43" height="8" font="font10" id="p14_t97" reading_order_no="96" segment_no="37" tag_type="text">estimation,”</text>
<text top="629" left="112" width="108" height="8" font="font13" id="p14_t98" reading_order_no="97" segment_no="37" tag_type="text">arXiv preprint arXiv:2004.03686</text>
<text top="629" left="220" width="22" height="8" font="font10" id="p14_t99" reading_order_no="98" segment_no="37" tag_type="text">, 2020.</text>
<text top="638" left="48" width="252" height="8" font="font10" id="p14_t100" reading_order_no="99" segment_no="39" tag_type="text">[33] C. Bregler, J. Malik, and K. Pullen, “Twist based acquisition and</text>
<text top="647" left="66" width="155" height="8" font="font10" id="p14_t101" reading_order_no="100" segment_no="39" tag_type="text">tracking of animal and human kinematics,”</text>
<text top="647" left="223" width="77" height="8" font="font13" id="p14_t102" reading_order_no="101" segment_no="39" tag_type="text">International Journal of</text>
<text top="656" left="66" width="55" height="8" font="font13" id="p14_t103" reading_order_no="102" segment_no="39" tag_type="text">Computer Vision</text>
<text top="656" left="122" width="118" height="8" font="font10" id="p14_t104" reading_order_no="103" segment_no="39" tag_type="text">, vol. 56, no. 3, pp. 179–194, 2004.</text>
<text top="666" left="48" width="252" height="8" font="font10" id="p14_t105" reading_order_no="104" segment_no="41" tag_type="text">[34] D. Xiang, H. Joo, and Y. Sheikh, “Monocular total capture: Posing</text>
<text top="675" left="66" width="146" height="8" font="font10" id="p14_t106" reading_order_no="105" segment_no="41" tag_type="text">face, body and hands in the wild,” in</text>
<text top="675" left="216" width="84" height="8" font="font13" id="p14_t107" reading_order_no="106" segment_no="41" tag_type="text">Proceedings of the IEEE</text>
<text top="684" left="66" width="195" height="8" font="font13" id="p14_t108" reading_order_no="107" segment_no="41" tag_type="text">Conference on Computer Vision and Pattern Recognition</text>
<text top="684" left="261" width="39" height="8" font="font10" id="p14_t109" reading_order_no="108" segment_no="41" tag_type="text">, 2019, pp.</text>
<text top="693" left="66" width="49" height="8" font="font10" id="p14_t110" reading_order_no="109" segment_no="41" tag_type="text">10 965–10 974.</text>
<text top="702" left="48" width="252" height="8" font="font10" id="p14_t111" reading_order_no="110" segment_no="43" tag_type="text">[35] D. P. Kingma and J. Ba, “Adam: A method for stochastic optimiza-</text>
<text top="711" left="66" width="20" height="8" font="font10" id="p14_t112" reading_order_no="111" segment_no="43" tag_type="text">tion,”</text>
<text top="711" left="88" width="104" height="8" font="font13" id="p14_t113" reading_order_no="112" segment_no="43" tag_type="text">arXiv preprint arXiv:1412.6980</text>
<text top="711" left="193" width="22" height="8" font="font10" id="p14_t114" reading_order_no="113" segment_no="43" tag_type="text">, 2014.</text>
<text top="720" left="48" width="252" height="8" font="font10" id="p14_t115" reading_order_no="114" segment_no="44" tag_type="text">[36] S. Shimada, V. Golyanik, W. Xu, and C. Theobalt, “Physcap:</text>
<text top="729" left="66" width="234" height="8" font="font10" id="p14_t116" reading_order_no="115" segment_no="44" tag_type="text">Physically plausible monocular 3d motion capture in real time,”</text>
<text top="738" left="66" width="103" height="8" font="font13" id="p14_t117" reading_order_no="116" segment_no="44" tag_type="text">ACM Transactions on Graphics</text>
<text top="738" left="170" width="86" height="8" font="font10" id="p14_t118" reading_order_no="117" segment_no="44" tag_type="text">, vol. 39, no. 6, dec 2020.</text>
<text top="46" left="312" width="252" height="8" font="font10" id="p14_t119" reading_order_no="118" segment_no="3" tag_type="text">[37] W. Xu, A. Chatterjee, M. Zollh ¨ofer, H. Rhodin, D. Mehta, H.-</text>
<text top="55" left="330" width="234" height="8" font="font10" id="p14_t120" reading_order_no="119" segment_no="3" tag_type="text">P. Seidel, and C. Theobalt, “MonoPerfCap: Human performance</text>
<text top="64" left="330" width="121" height="8" font="font10" id="p14_t121" reading_order_no="120" segment_no="3" tag_type="text">capture from monocular video,”</text>
<text top="64" left="455" width="109" height="8" font="font13" id="p14_t122" reading_order_no="121" segment_no="3" tag_type="text">ACM Transactions on Graphics</text>
<text top="73" left="330" width="22" height="8" font="font13" id="p14_t123" reading_order_no="122" segment_no="3" tag_type="text">(TOG)</text>
<text top="73" left="352" width="93" height="8" font="font10" id="p14_t124" reading_order_no="123" segment_no="3" tag_type="text">, vol. 37, no. 2, p. 27, 2018.</text>
<text top="83" left="312" width="252" height="8" font="font10" id="p14_t125" reading_order_no="124" segment_no="5" tag_type="text">[38] M. Habermann, W. Xu, M. Zollh ¨ofer, G. Pons-Moll, and</text>
<text top="92" left="330" width="234" height="8" font="font10" id="p14_t126" reading_order_no="125" segment_no="5" tag_type="text">C. Theobalt, “LiveCap: Real-time human performance capture</text>
<text top="101" left="330" width="89" height="8" font="font10" id="p14_t127" reading_order_no="126" segment_no="5" tag_type="text">from monocular video,”</text>
<text top="101" left="423" width="69" height="8" font="font13" id="p14_t128" reading_order_no="127" segment_no="5" tag_type="text">ACM Trans. Graph.</text>
<text top="101" left="491" width="73" height="8" font="font10" id="p14_t129" reading_order_no="128" segment_no="5" tag_type="text">, vol. 38, no. 2, pp.</text>
<text top="110" left="330" width="58" height="8" font="font10" id="p14_t130" reading_order_no="129" segment_no="5" tag_type="text">14:1–14:17, 2019.</text>
<text top="120" left="312" width="252" height="8" font="font10" id="p14_t131" reading_order_no="130" segment_no="7" tag_type="text">[39] M. Habermann, W. Xu, M. Zollhoefer, G. Ponsmoll, and</text>
<text top="129" left="330" width="234" height="8" font="font10" id="p14_t132" reading_order_no="131" segment_no="7" tag_type="text">C. Theobalt, “Deepcap: Monocular human performance capture</text>
<text top="138" left="330" width="90" height="8" font="font10" id="p14_t133" reading_order_no="132" segment_no="7" tag_type="text">using weak supervision,”</text>
<text top="138" left="422" width="142" height="8" font="font13" id="p14_t134" reading_order_no="133" segment_no="7" tag_type="text">arXiv: Computer Vision and Pattern Recog-</text>
<text top="147" left="330" width="20" height="8" font="font13" id="p14_t135" reading_order_no="134" segment_no="7" tag_type="text">nition</text>
<text top="147" left="350" width="22" height="8" font="font10" id="p14_t136" reading_order_no="135" segment_no="7" tag_type="text">, 2020.</text>
<text top="157" left="312" width="252" height="8" font="font10" id="p14_t137" reading_order_no="136" segment_no="9" tag_type="text">[40] J. Redmon, S. Divvala, R. Girshick, and A. Farhadi, “You only</text>
<text top="166" left="330" width="177" height="8" font="font10" id="p14_t138" reading_order_no="137" segment_no="9" tag_type="text">look once: Unified, real-time object detection,” in</text>
<text top="165" left="510" width="54" height="8" font="font13" id="p14_t139" reading_order_no="138" segment_no="9" tag_type="text">IEEE conference</text>
<text top="174" left="330" width="141" height="8" font="font13" id="p14_t140" reading_order_no="139" segment_no="9" tag_type="text">on computer vision and pattern recognition</text>
<text top="175" left="471" width="68" height="8" font="font10" id="p14_t141" reading_order_no="140" segment_no="9" tag_type="text">, 2016, pp. 779–788.</text>
<text top="184" left="312" width="62" height="8" font="font10" id="p14_t142" reading_order_no="141" segment_no="10" tag_type="text">[41] R. Caruana,</text>
<text top="184" left="378" width="60" height="8" font="font13" id="p14_t143" reading_order_no="142" segment_no="10" tag_type="text">Learning to learn</text>
<text top="184" left="438" width="2" height="8" font="font10" id="p14_t144" reading_order_no="143" segment_no="10" tag_type="text">.</text>
<text top="184" left="453" width="111" height="8" font="font10" id="p14_t145" reading_order_no="144" segment_no="10" tag_type="text">Springer, 1998, ch. ”Multitask</text>
<text top="193" left="330" width="78" height="8" font="font10" id="p14_t146" reading_order_no="145" segment_no="10" tag_type="text">learning”, pp. 95–133.</text>
<text top="203" left="312" width="252" height="8" font="font10" id="p14_t147" reading_order_no="146" segment_no="12" tag_type="text">[42] Z. Cao, T. Simon, S.-E. Wei, and Y. Sheikh, “Realtime multi-person</text>
<text top="212" left="330" width="175" height="8" font="font10" id="p14_t148" reading_order_no="147" segment_no="12" tag_type="text">2D pose estimation using part affinity fields,” in</text>
<text top="212" left="508" width="56" height="8" font="font13" id="p14_t149" reading_order_no="148" segment_no="12" tag_type="text">IEEE Conference</text>
<text top="221" left="330" width="148" height="8" font="font13" id="p14_t150" reading_order_no="149" segment_no="12" tag_type="text">on Computer Vision and Pattern Recognition</text>
<text top="221" left="478" width="76" height="8" font="font10" id="p14_t151" reading_order_no="150" segment_no="12" tag_type="text">, 2017, pp. 7291–7299.</text>
<text top="231" left="312" width="252" height="8" font="font10" id="p14_t152" reading_order_no="151" segment_no="14" tag_type="text">[43] S.-E. Wei, V. Ramakrishna, T. Kanade, and Y. Sheikh, “Convo-</text>
<text top="240" left="330" width="91" height="8" font="font10" id="p14_t153" reading_order_no="152" segment_no="14" tag_type="text">lutional pose machines,”</text>
<text top="240" left="425" width="139" height="8" font="font13" id="p14_t154" reading_order_no="153" segment_no="14" tag_type="text">IEEE conference on computer vision and</text>
<text top="249" left="330" width="62" height="8" font="font13" id="p14_t155" reading_order_no="154" segment_no="14" tag_type="text">pattern recognition</text>
<text top="249" left="392" width="22" height="8" font="font10" id="p14_t156" reading_order_no="155" segment_no="14" tag_type="text">, 2016.</text>
<text top="259" left="312" width="252" height="8" font="font10" id="p14_t157" reading_order_no="156" segment_no="15" tag_type="text">[44] A.-I. Popa, M. Zanfir, and C. Sminchisescu, “Deep multitask</text>
<text top="268" left="330" width="201" height="8" font="font10" id="p14_t158" reading_order_no="157" segment_no="15" tag_type="text">architecture for integrated 2D and 3D human sensing,” in</text>
<text top="268" left="533" width="31" height="8" font="font13" id="p14_t159" reading_order_no="158" segment_no="15" tag_type="text">The IEEE</text>
<text top="277" left="330" width="215" height="8" font="font13" id="p14_t160" reading_order_no="159" segment_no="15" tag_type="text">Conference on Computer Vision and Pattern Recognition (CVPR)</text>
<text top="277" left="545" width="19" height="8" font="font10" id="p14_t161" reading_order_no="160" segment_no="15" tag_type="text">, July</text>
<text top="286" left="330" width="18" height="8" font="font10" id="p14_t162" reading_order_no="161" segment_no="15" tag_type="text">2017.</text>
<text top="296" left="312" width="252" height="8" font="font10" id="p14_t163" reading_order_no="162" segment_no="17" tag_type="text">[45] P. Yao, Z. Fang, F. Wu, Y. Feng, and J. Li, “Densebody: Directly</text>
<text top="305" left="330" width="234" height="8" font="font10" id="p14_t164" reading_order_no="163" segment_no="17" tag_type="text">regressing dense 3d human pose and shape from a single color</text>
<text top="314" left="330" width="28" height="8" font="font10" id="p14_t165" reading_order_no="164" segment_no="17" tag_type="text">image,”</text>
<text top="314" left="360" width="108" height="8" font="font13" id="p14_t166" reading_order_no="165" segment_no="17" tag_type="text">arXiv preprint arXiv:1903.10153</text>
<text top="314" left="468" width="22" height="8" font="font10" id="p14_t167" reading_order_no="166" segment_no="17" tag_type="text">, 2019.</text>
<text top="324" left="312" width="252" height="8" font="font10" id="p14_t168" reading_order_no="167" segment_no="19" tag_type="text">[46] Z. Cao, G. Hidalgo, T. Simon, S.-E. Wei, and Y. Sheikh, “Open-</text>
<text top="333" left="330" width="234" height="8" font="font10" id="p14_t169" reading_order_no="168" segment_no="19" tag_type="text">Pose: realtime multi-person 2D pose estimation using part affinity</text>
<text top="342" left="330" width="25" height="8" font="font10" id="p14_t170" reading_order_no="169" segment_no="19" tag_type="text">fields,”</text>
<text top="341" left="359" width="203" height="8" font="font13" id="p14_t171" reading_order_no="170" segment_no="19" tag_type="text">IEEE conference on computer vision and pattern recognition</text>
<text top="342" left="562" width="2" height="8" font="font10" id="p14_t172" reading_order_no="171" segment_no="19" tag_type="text">,</text>
<text top="351" left="330" width="18" height="8" font="font10" id="p14_t173" reading_order_no="172" segment_no="19" tag_type="text">2018.</text>
<text top="360" left="312" width="252" height="8" font="font10" id="p14_t174" reading_order_no="173" segment_no="21" tag_type="text">[47] Y. Jia, E. Shelhamer, J. Donahue, S. Karayev, J. Long, R. Girshick,</text>
<text top="369" left="330" width="234" height="8" font="font10" id="p14_t175" reading_order_no="174" segment_no="21" tag_type="text">S. Guadarrama, and T. Darrell, “Caffe: Convolutional architecture</text>
<text top="378" left="330" width="111" height="8" font="font10" id="p14_t176" reading_order_no="175" segment_no="21" tag_type="text">for fast feature embedding,” in</text>
<text top="378" left="444" width="120" height="8" font="font13" id="p14_t177" reading_order_no="176" segment_no="21" tag_type="text">Proceedings of the 22nd ACM inter-</text>
<text top="387" left="330" width="113" height="8" font="font13" id="p14_t178" reading_order_no="177" segment_no="21" tag_type="text">national conference on Multimedia</text>
<text top="387" left="443" width="2" height="8" font="font10" id="p14_t179" reading_order_no="178" segment_no="21" tag_type="text">.</text>
<text top="387" left="453" width="88" height="8" font="font10" id="p14_t180" reading_order_no="179" segment_no="21" tag_type="text">ACM, 2014, pp. 675–678.</text>
<text top="397" left="312" width="231" height="8" font="font10" id="p14_t181" reading_order_no="180" segment_no="24" tag_type="text">[48] M. D. Zeiler, “Adadelta: an adaptive learning rate method,”</text>
<text top="397" left="545" width="19" height="8" font="font13" id="p14_t182" reading_order_no="181" segment_no="24" tag_type="text">arXiv</text>
<text top="406" left="330" width="83" height="8" font="font13" id="p14_t183" reading_order_no="182" segment_no="24" tag_type="text">preprint arXiv:1212.5701</text>
<text top="406" left="414" width="22" height="8" font="font10" id="p14_t184" reading_order_no="183" segment_no="24" tag_type="text">, 2012.</text>
<text top="416" left="312" width="252" height="8" font="font10" id="p14_t185" reading_order_no="184" segment_no="25" tag_type="text">[49] A. Kendall, Y. Gal, and R. Cipolla, “Multi-task learning using</text>
<text top="425" left="330" width="234" height="8" font="font10" id="p14_t186" reading_order_no="185" segment_no="25" tag_type="text">uncertainty to weigh losses for scene geometry and semantics,”</text>
<text top="434" left="330" width="7" height="8" font="font10" id="p14_t187" reading_order_no="186" segment_no="25" tag_type="text">in</text>
<text top="434" left="339" width="225" height="8" font="font13" id="p14_t188" reading_order_no="187" segment_no="25" tag_type="text">Proceedings of the IEEE Conference on Computer Vision and Pattern</text>
<text top="443" left="330" width="39" height="8" font="font13" id="p14_t189" reading_order_no="188" segment_no="25" tag_type="text">Recognition</text>
<text top="443" left="369" width="76" height="8" font="font10" id="p14_t190" reading_order_no="189" segment_no="25" tag_type="text">, 2018, pp. 7482–7491.</text>
<text top="453" left="312" width="252" height="8" font="font10" id="p14_t191" reading_order_no="190" segment_no="28" tag_type="text">[50] M. Sandler, A. Howard, M. Zhu, A. Zhmoginov, and L.-C. Chen,</text>
<text top="462" left="330" width="217" height="8" font="font10" id="p14_t192" reading_order_no="191" segment_no="28" tag_type="text">“Mobilenetv2: Inverted residuals and linear bottlenecks,” in</text>
<text top="462" left="550" width="14" height="8" font="font13" id="p14_t193" reading_order_no="192" segment_no="28" tag_type="text">Pro-</text>
<text top="471" left="330" width="234" height="8" font="font13" id="p14_t194" reading_order_no="193" segment_no="28" tag_type="text">ceedings of the IEEE conference on computer vision and pattern recogni-</text>
<text top="480" left="330" width="13" height="8" font="font13" id="p14_t195" reading_order_no="194" segment_no="28" tag_type="text">tion</text>
<text top="480" left="343" width="76" height="8" font="font10" id="p14_t196" reading_order_no="195" segment_no="28" tag_type="text">, 2018, pp. 4510–4520.</text>
<text top="490" left="312" width="252" height="8" font="font10" id="p14_t197" reading_order_no="196" segment_no="30" tag_type="text">[51] Y. Shi and R. C. Eberhart, “Empirical study of particle swarm</text>
<text top="499" left="330" width="62" height="8" font="font10" id="p14_t198" reading_order_no="197" segment_no="30" tag_type="text">optimization,” in</text>
<text top="499" left="395" width="169" height="8" font="font13" id="p14_t199" reading_order_no="198" segment_no="30" tag_type="text">Proceedings of the 1999 Congress on Evolutionary</text>
<text top="508" left="330" width="143" height="8" font="font13" id="p14_t200" reading_order_no="199" segment_no="30" tag_type="text">Computation-CEC99 (Cat. No. 99TH8406)</text>
<text top="508" left="473" width="27" height="8" font="font10" id="p14_t201" reading_order_no="200" segment_no="30" tag_type="text">, vol. 3.</text>
<text top="508" left="509" width="55" height="8" font="font10" id="p14_t202" reading_order_no="201" segment_no="30" tag_type="text">IEEE, 1999, pp.</text>
<text top="517" left="330" width="38" height="8" font="font10" id="p14_t203" reading_order_no="202" segment_no="30" tag_type="text">1945–1950.</text>
<text top="526" left="312" width="252" height="8" font="font10" id="p14_t204" reading_order_no="203" segment_no="32" tag_type="text">[52] I. Oikonomidis, N. Kyriazis, and A. A. Argyros, “Efficient model-</text>
<text top="535" left="330" width="218" height="8" font="font10" id="p14_t205" reading_order_no="204" segment_no="32" tag_type="text">based 3D tracking of hand articulations using kinect,” in</text>
<text top="535" left="552" width="12" height="8" font="font13" id="p14_t206" reading_order_no="205" segment_no="32" tag_type="text">The</text>
<text top="544" left="330" width="145" height="8" font="font13" id="p14_t207" reading_order_no="206" segment_no="32" tag_type="text">British Machine Vision Conference (BMVC)</text>
<text top="544" left="475" width="56" height="8" font="font10" id="p14_t208" reading_order_no="207" segment_no="32" tag_type="text">, 2011, pp. 1–11.</text>
<text top="554" left="312" width="252" height="8" font="font10" id="p14_t209" reading_order_no="208" segment_no="34" tag_type="text">[53] T. von Marcard, R. Henschel, M. J. Black, B. Rosenhahn, and</text>
<text top="563" left="330" width="234" height="8" font="font10" id="p14_t210" reading_order_no="209" segment_no="34" tag_type="text">G. Pons-Moll, “Recovering accurate 3d human pose in the wild</text>
<text top="572" left="330" width="138" height="8" font="font10" id="p14_t211" reading_order_no="210" segment_no="34" tag_type="text">using imus and a moving camera,” in</text>
<text top="572" left="470" width="94" height="8" font="font13" id="p14_t212" reading_order_no="211" segment_no="34" tag_type="text">Proceedings of the European</text>
<text top="581" left="330" width="132" height="8" font="font13" id="p14_t213" reading_order_no="212" segment_no="34" tag_type="text">Conference on Computer Vision (ECCV)</text>
<text top="581" left="462" width="62" height="8" font="font10" id="p14_t214" reading_order_no="213" segment_no="34" tag_type="text">, September 2018.</text>
<text top="591" left="312" width="252" height="8" font="font10" id="p14_t215" reading_order_no="214" segment_no="36" tag_type="text">[54] C. Ionescu, D. Papava, V. Olaru, and C. Sminchisescu, “Human3.</text>
<text top="600" left="330" width="234" height="8" font="font10" id="p14_t216" reading_order_no="215" segment_no="36" tag_type="text">6m: Large scale datasets and predictive methods for 3D human</text>
<text top="609" left="330" width="127" height="8" font="font10" id="p14_t217" reading_order_no="216" segment_no="36" tag_type="text">sensing in natural environments,”</text>
<text top="609" left="461" width="103" height="8" font="font13" id="p14_t218" reading_order_no="217" segment_no="36" tag_type="text">IEEE Transactions on Pattern</text>
<text top="618" left="330" width="111" height="8" font="font13" id="p14_t219" reading_order_no="218" segment_no="36" tag_type="text">Analysis and Machine Intelligence</text>
<text top="618" left="442" width="122" height="8" font="font10" id="p14_t220" reading_order_no="219" segment_no="36" tag_type="text">, vol. 36, no. 7, pp. 1325–1339, 2013.</text>
<text top="628" left="312" width="252" height="8" font="font10" id="p14_t221" reading_order_no="220" segment_no="38" tag_type="text">[55] Y. Cai, L. Ge, J. Cai, and J. Yuan, “Weakly-supervised 3D hand pose</text>
<text top="637" left="330" width="162" height="8" font="font10" id="p14_t222" reading_order_no="221" segment_no="38" tag_type="text">estimation from monocular RGB images,” in</text>
<text top="637" left="495" width="69" height="8" font="font13" id="p14_t223" reading_order_no="222" segment_no="38" tag_type="text">European Conference</text>
<text top="646" left="330" width="95" height="8" font="font13" id="p14_t224" reading_order_no="223" segment_no="38" tag_type="text">on Computer Vision (ECCV)</text>
<text top="646" left="425" width="68" height="8" font="font10" id="p14_t225" reading_order_no="224" segment_no="38" tag_type="text">, 2018, pp. 666–682.</text>
<text top="656" left="312" width="252" height="8" font="font10" id="p14_t226" reading_order_no="225" segment_no="40" tag_type="text">[56] M. Loper, N. Mahmood, and M. J. Black, “Mosh: Motion and</text>
<text top="665" left="330" width="130" height="8" font="font10" id="p14_t227" reading_order_no="226" segment_no="40" tag_type="text">shape capture from sparse markers,”</text>
<text top="665" left="462" width="102" height="8" font="font13" id="p14_t228" reading_order_no="227" segment_no="40" tag_type="text">ACM Transactions on Graphics</text>
<text top="674" left="330" width="22" height="8" font="font13" id="p14_t229" reading_order_no="228" segment_no="40" tag_type="text">(TOG)</text>
<text top="674" left="352" width="106" height="8" font="font10" id="p14_t230" reading_order_no="229" segment_no="40" tag_type="text">, vol. 33, no. 6, pp. 1–13, 2014.</text>
<text top="684" left="312" width="252" height="8" font="font10" id="p14_t231" reading_order_no="230" segment_no="42" tag_type="text">[57] K. Zhou, X. Han, N. Jiang, K. Jia, and J. Lu, “Hemlets pose:</text>
<text top="693" left="330" width="234" height="8" font="font10" id="p14_t232" reading_order_no="231" segment_no="42" tag_type="text">Learning part-centric heatmap triplets for accurate 3d human pose</text>
<text top="702" left="330" width="52" height="8" font="font10" id="p14_t233" reading_order_no="232" segment_no="42" tag_type="text">estimation,” in</text>
<text top="702" left="385" width="179" height="8" font="font13" id="p14_t234" reading_order_no="233" segment_no="42" tag_type="text">Proceedings of the IEEE/CVF International Conference</text>
<text top="711" left="330" width="66" height="8" font="font13" id="p14_t235" reading_order_no="234" segment_no="42" tag_type="text">on Computer Vision</text>
<text top="711" left="396" width="76" height="8" font="font10" id="p14_t236" reading_order_no="235" segment_no="42" tag_type="text">, 2019, pp. 2344–2353.</text>
<text top="720" left="312" width="252" height="8" font="font10" id="p14_t237" reading_order_no="236" segment_no="45" tag_type="text">[58] H. Joo, N. Neverova, and A. Vedaldi, “Exemplar fine-tuning</text>
<text top="729" left="330" width="234" height="8" font="font10" id="p14_t238" reading_order_no="237" segment_no="45" tag_type="text">for 3d human pose fitting towards in-the-wild 3d human pose</text>
<text top="738" left="330" width="43" height="8" font="font10" id="p14_t239" reading_order_no="238" segment_no="45" tag_type="text">estimation,”</text>
<text top="738" left="376" width="108" height="8" font="font13" id="p14_t240" reading_order_no="239" segment_no="45" tag_type="text">arXiv preprint arXiv:2004.03686</text>
<text top="738" left="484" width="22" height="8" font="font10" id="p14_t241" reading_order_no="240" segment_no="45" tag_type="text">, 2020.</text>
</page>
<page number="15" position="absolute" top="0" left="0" height="792" width="612">
<text top="29" left="48" width="334" height="6" font="font0" id="p15_t1" reading_order_no="0" segment_no="0" tag_type="title">IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS, VOL. XX, NO. , AUGUST 2020</text>
<text top="29" left="556" width="8" height="6" font="font0" id="p15_t2" reading_order_no="1" segment_no="1" tag_type="text">15</text>
<text top="46" left="48" width="252" height="8" font="font10" id="p15_t3" reading_order_no="2" segment_no="2" tag_type="text">[59] Y. Xu, S.-C. Zhu, and T. Tung, “Denserac: Joint 3d pose and shape</text>
<text top="55" left="66" width="168" height="8" font="font10" id="p15_t4" reading_order_no="3" segment_no="2" tag_type="text">estimation by dense render-and-compare,” in</text>
<text top="55" left="238" width="62" height="8" font="font13" id="p15_t5" reading_order_no="4" segment_no="2" tag_type="text">Proceedings of the</text>
<text top="64" left="66" width="173" height="8" font="font13" id="p15_t6" reading_order_no="5" segment_no="2" tag_type="text">IEEE International Conference on Computer Vision</text>
<text top="64" left="239" width="61" height="8" font="font10" id="p15_t7" reading_order_no="6" segment_no="2" tag_type="text">, 2019, pp. 7760–</text>
<text top="73" left="66" width="18" height="8" font="font10" id="p15_t8" reading_order_no="7" segment_no="2" tag_type="text">7770.</text>
<text top="82" left="48" width="252" height="8" font="font10" id="p15_t9" reading_order_no="8" segment_no="4" tag_type="text">[60] H. Joo, T. Simon, and Y. Sheikh, “Total capture: A 3d deformation</text>
<text top="91" left="66" width="172" height="8" font="font10" id="p15_t10" reading_order_no="9" segment_no="4" tag_type="text">model for tracking faces, hands, and bodies,” in</text>
<text top="91" left="241" width="59" height="8" font="font13" id="p15_t11" reading_order_no="10" segment_no="4" tag_type="text">Proceedings of the</text>
<text top="100" left="66" width="198" height="8" font="font13" id="p15_t12" reading_order_no="11" segment_no="4" tag_type="text">IEEE conference on computer vision and pattern recognition</text>
<text top="100" left="264" width="36" height="8" font="font10" id="p15_t13" reading_order_no="12" segment_no="4" tag_type="text">, 2018, pp.</text>
<text top="109" left="66" width="38" height="8" font="font10" id="p15_t14" reading_order_no="13" segment_no="4" tag_type="text">8320–8329.</text>
<text top="180" left="130" width="45" height="8" font="font3" id="p15_t15" reading_order_no="14" segment_no="5" tag_type="text"><b>Liguo Jiang</b></text>
<text top="180" left="178" width="122" height="7" font="font4" id="p15_t16" reading_order_no="15" segment_no="5" tag_type="text">received the B.Eng degree in soft-</text>
<text top="189" left="130" width="170" height="7" font="font4" id="p15_t17" reading_order_no="16" segment_no="5" tag_type="text">ware engineering from Chongqing University in</text>
<text top="198" left="130" width="170" height="7" font="font4" id="p15_t18" reading_order_no="17" segment_no="5" tag_type="text">2015. He is currently working toward the PhD</text>
<text top="207" left="130" width="170" height="7" font="font4" id="p15_t19" reading_order_no="18" segment_no="5" tag_type="text">degree in National Laboratory of Pattern Recog-</text>
<text top="216" left="130" width="170" height="7" font="font4" id="p15_t20" reading_order_no="19" segment_no="5" tag_type="text">nition, Institute of Automation, Chinese Academy</text>
<text top="225" left="130" width="170" height="7" font="font4" id="p15_t21" reading_order_no="20" segment_no="5" tag_type="text">of Sciences. His research interests include deep</text>
<text top="234" left="130" width="170" height="7" font="font4" id="p15_t22" reading_order_no="21" segment_no="5" tag_type="text">learning, human motion capture and cloth simu-</text>
<text top="243" left="130" width="21" height="7" font="font4" id="p15_t23" reading_order_no="22" segment_no="5" tag_type="text">lation.</text>
<text top="330" left="130" width="47" height="8" font="font3" id="p15_t24" reading_order_no="23" segment_no="7" tag_type="text"><b>Miaopeng Li</b></text>
<text top="330" left="179" width="121" height="7" font="font4" id="p15_t25" reading_order_no="24" segment_no="7" tag_type="text">is a Ph.D. student at the State Key</text>
<text top="339" left="130" width="170" height="7" font="font4" id="p15_t26" reading_order_no="25" segment_no="7" tag_type="text">Lab of CAD&amp;CG, Zhejiang University, China.</text>
<text top="348" left="130" width="170" height="7" font="font4" id="p15_t27" reading_order_no="26" segment_no="7" tag_type="text">She received her bachelor degree from North-</text>
<text top="357" left="130" width="170" height="7" font="font4" id="p15_t28" reading_order_no="27" segment_no="7" tag_type="text">western Polytechnical University in 2016. Her</text>
<text top="366" left="130" width="170" height="7" font="font4" id="p15_t29" reading_order_no="28" segment_no="7" tag_type="text">research interests include marker-less human</text>
<text top="375" left="130" width="170" height="7" font="font4" id="p15_t30" reading_order_no="29" segment_no="7" tag_type="text">motion capture, human pose estimation, 3D re-</text>
<text top="384" left="130" width="123" height="7" font="font4" id="p15_t31" reading_order_no="30" segment_no="7" tag_type="text">construction and their applications.</text>
<text top="482" left="130" width="51" height="8" font="font3" id="p15_t32" reading_order_no="31" segment_no="8" tag_type="text"><b>Jianjie Zhang</b></text>
<text top="482" left="183" width="117" height="7" font="font4" id="p15_t33" reading_order_no="32" segment_no="8" tag_type="text">received PhD degree in computer</text>
<text top="491" left="130" width="170" height="7" font="font4" id="p15_t34" reading_order_no="33" segment_no="8" tag_type="text">science from Texas A&amp;M Univeristy (TAMU). He</text>
<text top="500" left="130" width="170" height="7" font="font4" id="p15_t35" reading_order_no="34" segment_no="8" tag_type="text">is currently a R&amp;D director in Xmov ai Inc. His</text>
<text top="509" left="130" width="170" height="7" font="font4" id="p15_t36" reading_order_no="35" segment_no="8" tag_type="text">primary research is in the area of computer</text>
<text top="518" left="130" width="170" height="7" font="font4" id="p15_t37" reading_order_no="36" segment_no="8" tag_type="text">graphics and vision, including human body mod-</text>
<text top="527" left="130" width="170" height="7" font="font4" id="p15_t38" reading_order_no="37" segment_no="8" tag_type="text">eling and tracking, human body dynamics sim-</text>
<text top="536" left="130" width="170" height="7" font="font4" id="p15_t39" reading_order_no="38" segment_no="8" tag_type="text">ulation, human face modeling and tracking and</text>
<text top="545" left="130" width="13" height="7" font="font4" id="p15_t40" reading_order_no="39" segment_no="8" tag_type="text">etc.</text>
<text top="632" left="130" width="51" height="8" font="font3" id="p15_t41" reading_order_no="40" segment_no="10" tag_type="text"><b>Congyi Wang</b></text>
<text top="632" left="183" width="117" height="7" font="font4" id="p15_t42" reading_order_no="41" segment_no="10" tag_type="text">received the PhD degree in com-</text>
<text top="641" left="130" width="170" height="7" font="font4" id="p15_t43" reading_order_no="42" segment_no="10" tag_type="text">puter science from Institute of Computing Tech-</text>
<text top="650" left="130" width="170" height="7" font="font4" id="p15_t44" reading_order_no="43" segment_no="10" tag_type="text">nology, Chinese Academy of Sciences in Jan</text>
<text top="659" left="130" width="170" height="7" font="font4" id="p15_t45" reading_order_no="44" segment_no="10" tag_type="text">2017. Since 2018, he has been a research sci-</text>
<text top="668" left="130" width="170" height="7" font="font4" id="p15_t46" reading_order_no="45" segment_no="10" tag_type="text">entist at XMov, a startup company aiming at</text>
<text top="677" left="130" width="170" height="7" font="font4" id="p15_t47" reading_order_no="46" segment_no="10" tag_type="text">AI powered virtual production line. His research</text>
<text top="686" left="130" width="170" height="7" font="font4" id="p15_t48" reading_order_no="47" segment_no="10" tag_type="text">interests include computer animation, computer</text>
<text top="695" left="130" width="170" height="7" font="font4" id="p15_t49" reading_order_no="48" segment_no="10" tag_type="text">graphics, computer vision and speech signal</text>
<text top="704" left="130" width="41" height="7" font="font4" id="p15_t50" reading_order_no="49" segment_no="10" tag_type="text">processing.</text>
<text top="46" left="394" width="38" height="8" font="font3" id="p15_t51" reading_order_no="50" segment_no="3" tag_type="text"><b>Juntao Ye</b></text>
<text top="46" left="435" width="129" height="7" font="font4" id="p15_t52" reading_order_no="51" segment_no="3" tag_type="text">was awarded his B.Eng from Harbin</text>
<text top="55" left="394" width="170" height="7" font="font4" id="p15_t53" reading_order_no="52" segment_no="3" tag_type="text">Engineering University in 1994, MSc from Insti-</text>
<text top="64" left="394" width="170" height="7" font="font4" id="p15_t54" reading_order_no="53" segment_no="3" tag_type="text">tute of Computational Mathematics and Scien-</text>
<text top="73" left="394" width="170" height="7" font="font4" id="p15_t55" reading_order_no="54" segment_no="3" tag_type="text">tific/Engineering Computing, Chinese Academy</text>
<text top="82" left="394" width="170" height="7" font="font4" id="p15_t56" reading_order_no="55" segment_no="3" tag_type="text">of Sciences in 2000, and his PhD in Computer</text>
<text top="91" left="394" width="170" height="7" font="font4" id="p15_t57" reading_order_no="56" segment_no="3" tag_type="text">Science from The University of Western Ontario,</text>
<text top="100" left="394" width="170" height="7" font="font4" id="p15_t58" reading_order_no="57" segment_no="3" tag_type="text">Canada, in 2005. He is currently an associate</text>
<text top="109" left="394" width="170" height="7" font="font4" id="p15_t59" reading_order_no="58" segment_no="3" tag_type="text">professor with National Laboratory of Pattern</text>
<text top="118" left="394" width="170" height="7" font="font4" id="p15_t60" reading_order_no="59" segment_no="3" tag_type="text">Recognition of the Institute of Automation, Chi-</text>
<text top="127" left="394" width="170" height="7" font="font4" id="p15_t61" reading_order_no="60" segment_no="3" tag_type="text">nese Academy of Sciences. His research in-</text>
<text top="136" left="394" width="170" height="7" font="font4" id="p15_t62" reading_order_no="61" segment_no="3" tag_type="text">terests include graphics, particularly physically-</text>
<text top="145" left="312" width="248" height="7" font="font4" id="p15_t63" reading_order_no="62" segment_no="3" tag_type="text">based simulation of cloth and fluid, as well as image/video processing.</text>
<text top="295" left="394" width="42" height="8" font="font3" id="p15_t64" reading_order_no="63" segment_no="6" tag_type="text"><b>Xinguo Liu</b></text>
<text top="295" left="439" width="125" height="7" font="font4" id="p15_t65" reading_order_no="64" segment_no="6" tag_type="text">received the BS and PhD degrees</text>
<text top="304" left="394" width="170" height="7" font="font4" id="p15_t66" reading_order_no="65" segment_no="6" tag_type="text">in applied mathematics from Zhejiang University</text>
<text top="313" left="394" width="170" height="7" font="font4" id="p15_t67" reading_order_no="66" segment_no="6" tag_type="text">in 1995 and 2001, respectively. He is a pro-</text>
<text top="322" left="394" width="170" height="7" font="font4" id="p15_t68" reading_order_no="67" segment_no="6" tag_type="text">fessor at the School of Computer Science and</text>
<text top="331" left="394" width="170" height="7" font="font4" id="p15_t69" reading_order_no="68" segment_no="6" tag_type="text">Technology, Zhejiang University. He was with</text>
<text top="340" left="394" width="170" height="7" font="font4" id="p15_t70" reading_order_no="69" segment_no="6" tag_type="text">Microsoft Research Asia in Beijing during 2001-</text>
<text top="349" left="394" width="170" height="7" font="font4" id="p15_t71" reading_order_no="70" segment_no="6" tag_type="text">2006, and then joined in Zhejiang University. His</text>
<text top="358" left="394" width="170" height="7" font="font4" id="p15_t72" reading_order_no="71" segment_no="6" tag_type="text">main research interests are in graphics and vi-</text>
<text top="367" left="394" width="170" height="7" font="font4" id="p15_t73" reading_order_no="72" segment_no="6" tag_type="text">sion, particularly geometry processing, realistic</text>
<text top="376" left="394" width="170" height="7" font="font4" id="p15_t74" reading_order_no="73" segment_no="6" tag_type="text">and image-based rendering, and 3D reconstruc-</text>
<text top="385" left="394" width="15" height="7" font="font4" id="p15_t75" reading_order_no="74" segment_no="6" tag_type="text">tion.</text>
<text top="535" left="394" width="54" height="8" font="font3" id="p15_t76" reading_order_no="75" segment_no="9" tag_type="text"><b>Jinxiang Chai</b></text>
<text top="535" left="452" width="112" height="7" font="font4" id="p15_t77" reading_order_no="76" segment_no="9" tag_type="text">received PhD degree in com-</text>
<text top="544" left="394" width="170" height="7" font="font4" id="p15_t78" reading_order_no="77" segment_no="9" tag_type="text">puter science from Carnegie Mellon Univer-</text>
<text top="553" left="394" width="170" height="7" font="font4" id="p15_t79" reading_order_no="78" segment_no="9" tag_type="text">sity(CMU). He is currently an associate profes-</text>
<text top="562" left="394" width="170" height="7" font="font4" id="p15_t80" reading_order_no="79" segment_no="9" tag_type="text">sor in the Department of Computer Science and</text>
<text top="571" left="394" width="170" height="7" font="font4" id="p15_t81" reading_order_no="80" segment_no="9" tag_type="text">Engineering at Texas A&amp;M University. His pri-</text>
<text top="580" left="394" width="170" height="7" font="font4" id="p15_t82" reading_order_no="81" segment_no="9" tag_type="text">mary research is in the area of computer graph-</text>
<text top="589" left="394" width="170" height="7" font="font4" id="p15_t83" reading_order_no="82" segment_no="9" tag_type="text">ics and vision with broad applications in other</text>
<text top="598" left="394" width="170" height="7" font="font4" id="p15_t84" reading_order_no="83" segment_no="9" tag_type="text">disciplines such as virtual and augmented re-</text>
<text top="607" left="394" width="170" height="7" font="font4" id="p15_t85" reading_order_no="84" segment_no="9" tag_type="text">ality, robotics, human computer interaction, and</text>
<text top="616" left="394" width="170" height="7" font="font4" id="p15_t86" reading_order_no="85" segment_no="9" tag_type="text">biomechanics. He received an NSF CAREER</text>
<text top="625" left="394" width="170" height="7" font="font4" id="p15_t87" reading_order_no="86" segment_no="9" tag_type="text">award for his work on theory and practice of</text>
<text top="634" left="312" width="96" height="7" font="font4" id="p15_t88" reading_order_no="87" segment_no="9" tag_type="text">Bayesian motion synthesis.</text>
</page>
</pdf2xml>
