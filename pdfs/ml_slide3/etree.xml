<!DOCTYPE pdf2xml SYSTEM "pdf2xml.dtd">
<pdf2xml producer="poppler" version="23.04.0">
<page number="1" position="absolute" top="0" left="0" height="612" width="792">
	<fontspec id="font0" size="19" family="CMUSerif" color="#000000"/>
	<fontspec id="font1" size="11" family="CMUSerif" color="#000000"/>
	<fontspec id="font2" size="11" family="CMUSerif" color="#000000"/>
	<fontspec id="font3" size="13" family="CMUSerif" color="#000000"/>
<text top="85" left="262" width="274" height="20" font="font0" id="p1_t1" reading_order_no="0" segment_no="0" tag_type="title">Defense Against the Dark Arts: </text>
<text top="112" left="209" width="380" height="20" font="font0" id="p1_t2" reading_order_no="1" segment_no="0" tag_type="title">An overview of adversarial example security </text>
<text top="139" left="232" width="327" height="20" font="font0" id="p1_t3" reading_order_no="2" segment_no="0" tag_type="title">research and future research directions</text>
<text top="167" left="264" width="96" height="11" font="font1" id="p1_t4" reading_order_no="3" segment_no="1" tag_type="text">Ian Goodfellow, Sta</text>
<text top="167" left="360" width="6" height="12" font="font2" id="p1_t5" reading_order_no="4" segment_no="1" tag_type="text">ﬀ</text>
<text top="167" left="366" width="165" height="11" font="font1" id="p1_t6" reading_order_no="5" segment_no="1" tag_type="text"> Research Scientist, Google Brain </text>
<text top="182" left="243" width="306" height="11" font="font1" id="p1_t7" reading_order_no="6" segment_no="1" tag_type="text">1st IEEE Deep Learning and Security Workshop, May 24, 2018</text>
<text top="326" left="29" width="724" height="13" font="font3" id="p1_t8" reading_order_no="7" segment_no="2" tag_type="text">This document contains the slides for a keynote presentation at the 2018 IEEE Deep Learning and Security workshop, as well as </text>
<text top="347" left="29" width="725" height="13" font="font3" id="p1_t9" reading_order_no="8" segment_no="2" tag_type="text">lecture notes describing generally what the speaker planned to say. The notes are included so that readers can better understand </text>
<text top="368" left="29" width="449" height="13" font="font3" id="p1_t10" reading_order_no="9" segment_no="2" tag_type="text">the slides without attending the lecture and follow the accompanying references.</text>
</page>
<page number="2" position="absolute" top="0" left="0" height="612" width="792">
	<fontspec id="font4" size="5" family="CMUSerif" color="#000000"/>
	<fontspec id="font5" size="30" family="CMUSerif" color="#000000"/>
	<fontspec id="font6" size="9" family="CMR10" color="#000000"/>
	<fontspec id="font7" size="14" family="CMUSerif" color="#000000"/>
<text top="294" left="551" width="36" height="5" font="font4" id="p2_t1" reading_order_no="0" segment_no="6" tag_type="text">(Goodfellow 2018)</text>
<text top="46" left="235" width="318" height="31" font="font5" id="p2_t2" reading_order_no="1" segment_no="0" tag_type="title">I.I.D. Machine Learning</text>
<text top="100" left="247" width="21" height="6" font="font6" id="p2_t3" reading_order_no="2" segment_no="1" tag_type="figure">Train</text>
<text top="100" left="368" width="17" height="6" font="font6" id="p2_t4" reading_order_no="3" segment_no="1" tag_type="figure">Test</text>
<text top="101" left="433" width="92" height="14" font="font7" id="p2_t5" reading_order_no="4" segment_no="2" tag_type="text">I: Independent </text>
<text top="120" left="433" width="80" height="14" font="font7" id="p2_t6" reading_order_no="5" segment_no="3" tag_type="text">I: Identically </text>
<text top="139" left="433" width="91" height="14" font="font7" id="p2_t7" reading_order_no="6" segment_no="4" tag_type="text">D: Distributed </text>
<text top="176" left="433" width="135" height="11" font="font1" id="p2_t8" reading_order_no="7" segment_no="5" tag_type="text">All train and test examples </text>
<text top="191" left="433" width="130" height="11" font="font1" id="p2_t9" reading_order_no="8" segment_no="5" tag_type="text">drawn independently from </text>
<text top="206" left="433" width="87" height="11" font="font1" id="p2_t10" reading_order_no="9" segment_no="5" tag_type="text">same distribution </text>
<text top="326" left="29" width="559" height="13" font="font3" id="p2_t11" reading_order_no="10" segment_no="7" tag_type="text">Traditionally, most machine learning work has taken place in the context of the I.I.D. assumptions. </text>
<text top="347" left="29" width="703" height="13" font="font3" id="p2_t12" reading_order_no="11" segment_no="8" tag_type="text">“I.I.D.” stands for “independent and identically distributed”. It means that all of the examples in the training and test set are </text>
<text top="368" left="29" width="587" height="13" font="font3" id="p2_t13" reading_order_no="12" segment_no="8" tag_type="text">generated independently from each other, and are all drawn from the same data-generating distribution. </text>
<text top="389" left="29" width="722" height="13" font="font3" id="p2_t14" reading_order_no="13" segment_no="9" tag_type="text">This diagram illustrates this with an example training set and test set sampled for a classification problem with 2 input features </text>
<text top="409" left="29" width="574" height="13" font="font3" id="p2_t15" reading_order_no="14" segment_no="9" tag_type="text">(one plotted on horizontal axis, one plotted on vertical axis) and 2 classes (orange plus versus blue X).</text>
</page>
<page number="3" position="absolute" top="0" left="0" height="612" width="792">
	<fontspec id="font8" size="22" family="CMUSerif" color="#000000"/>
	<fontspec id="font9" size="7" family="CMUSerif" color="#000000"/>
	<fontspec id="font10" size="9" family="CMUSerif" color="#000000"/>
	<fontspec id="font11" size="13" family="CMUSerif" color="#000000"/>
<text top="294" left="551" width="36" height="5" font="font4" id="p3_t1" reading_order_no="0" segment_no="1" tag_type="text">(Goodfellow 2018)</text>
<text top="34" left="207" width="381" height="22" font="font8" id="p3_t2" reading_order_no="1" segment_no="0" tag_type="figure">ML reached “human-level performance” </text>
<text top="64" left="254" width="281" height="22" font="font8" id="p3_t3" reading_order_no="2" segment_no="0" tag_type="figure">on many IID tasks circa 2013</text>
<text top="223" left="394" width="83" height="7" font="font9" id="p3_t4" reading_order_no="3" segment_no="0" tag_type="figure">...solving CAPTCHAS and </text>
<text top="233" left="394" width="58" height="7" font="font9" id="p3_t5" reading_order_no="4" segment_no="0" tag_type="figure">reading addresses...</text>
<text top="141" left="374" width="83" height="9" font="font10" id="p3_t6" reading_order_no="5" segment_no="0" tag_type="figure">...recognizing objects </text>
<text top="154" left="374" width="45" height="9" font="font10" id="p3_t7" reading_order_no="6" segment_no="0" tag_type="figure">and faces….</text>
<text top="192" left="243" width="62" height="7" font="font9" id="p3_t8" reading_order_no="7" segment_no="0" tag_type="figure">(Szegedy et al, 2014)</text>
<text top="267" left="487" width="72" height="7" font="font9" id="p3_t9" reading_order_no="8" segment_no="0" tag_type="figure">(Goodfellow et al, 2013)</text>
<text top="192" left="478" width="64" height="7" font="font9" id="p3_t10" reading_order_no="9" segment_no="0" tag_type="figure">(Taigmen et al, 2013)</text>
<text top="264" left="249" width="72" height="7" font="font9" id="p3_t11" reading_order_no="10" segment_no="0" tag_type="figure">(Goodfellow et al, 2013)</text>
<text top="326" left="29" width="217" height="13" font="font3" id="p3_t12" reading_order_no="11" segment_no="2" tag_type="text">Until recently, machine learning was di</text>
<text top="326" left="246" width="11" height="14" font="font11" id="p3_t13" reading_order_no="12" segment_no="2" tag_type="text">ﬃ</text>
<text top="326" left="257" width="174" height="13" font="font3" id="p3_t14" reading_order_no="13" segment_no="2" tag_type="text">cult, even in the I.I.D. setting. </text>
<text top="347" left="29" width="634" height="13" font="font3" id="p3_t15" reading_order_no="14" segment_no="3" tag_type="text">Adversarial examples were not interesting to most researchers because mistakes were the rule, not the exception. </text>
<text top="368" left="29" width="710" height="13" font="font3" id="p3_t16" reading_order_no="15" segment_no="4" tag_type="text">In about 2013, machine learning started to reach human-level performance on several benchmark tasks (here I highlight vision </text>
<text top="389" left="29" width="698" height="13" font="font3" id="p3_t17" reading_order_no="16" segment_no="4" tag_type="text">tasks because they have nice pictures to put on a slide). These benchmarks are not particularly well-suited for comparing to </text>
<text top="409" left="29" width="633" height="13" font="font3" id="p3_t18" reading_order_no="17" segment_no="4" tag_type="text">humans, but they do show that machine learning has become quite advanced and impressive in the I.I.D. setting.</text>
</page>
<page number="4" position="absolute" top="0" left="0" height="612" width="792">
	<fontspec id="font12" size="23" family="CMUSerif" color="#000000"/>
<text top="294" left="551" width="36" height="5" font="font4" id="p4_t1" reading_order_no="0" segment_no="2" tag_type="text">(Goodfellow 2018)</text>
<text top="45" left="204" width="383" height="24" font="font12" id="p4_t2" reading_order_no="1" segment_no="0" tag_type="title">Caveats to “human-level” benchmarks</text>
<text top="253" left="217" width="164" height="14" font="font7" id="p4_t3" reading_order_no="2" segment_no="1" tag_type="figure">Humans are not very good </text>
<text top="272" left="237" width="125" height="14" font="font7" id="p4_t4" reading_order_no="3" segment_no="1" tag_type="figure">at some parts of the </text>
<text top="291" left="264" width="66" height="14" font="font7" id="p4_t5" reading_order_no="4" segment_no="1" tag_type="figure">benchmark</text>
<text top="233" left="410" width="153" height="14" font="font7" id="p4_t6" reading_order_no="5" segment_no="1" tag_type="figure">The test data is not very </text>
<text top="252" left="395" width="184" height="14" font="font7" id="p4_t7" reading_order_no="6" segment_no="1" tag_type="figure">diverse. ML models are fooled </text>
<text top="271" left="399" width="172" height="14" font="font7" id="p4_t8" reading_order_no="7" segment_no="1" tag_type="figure">by natural but unusual data.</text>
<text top="326" left="29" width="711" height="13" font="font3" id="p4_t9" reading_order_no="8" segment_no="3" tag_type="text">When we say that a machine learning model has reached human-level performance for a benchmark, it is important to keep in </text>
<text top="347" left="29" width="513" height="13" font="font3" id="p4_t10" reading_order_no="9" segment_no="3" tag_type="text">mind that benchmarks may not be able to capture performance on these tasks realistically. </text>
<text top="389" left="29" width="736" height="13" font="font3" id="p4_t11" reading_order_no="10" segment_no="4" tag_type="text">For example, humans are not necessarily very good at recognizing all of the obscure classes in ImageNet, such as this dhole (one of </text>
<text top="409" left="29" width="395" height="13" font="font3" id="p4_t12" reading_order_no="11" segment_no="4" tag_type="text">the 1000 ImageNet classes). Image from the Wikipedia article “dhole”. </text>
<text top="451" left="29" width="734" height="13" font="font3" id="p4_t13" reading_order_no="12" segment_no="5" tag_type="text">Just because the data is I.I.D. does not necessarily mean it captures the same distribution the model will face when it is deployed. </text>
<text top="472" left="29" width="711" height="13" font="font3" id="p4_t14" reading_order_no="13" segment_no="5" tag_type="text">For example, datasets tend to be somewhat curated, with relatively cleanly presented canonical examples. Users taking photos </text>
<text top="493" left="29" width="711" height="13" font="font3" id="p4_t15" reading_order_no="14" segment_no="5" tag_type="text">with phones take unusual pictures. Here is a picture I took with my phone of an apple in a mesh bag. A state of the art vision </text>
<text top="513" left="29" width="736" height="13" font="font3" id="p4_t16" reading_order_no="15" segment_no="5" tag_type="text">model tags this with only one tag: “material”. My family wasn’t sure it was an apple, but they could tell it was fruit and apple was </text>
<text top="534" left="29" width="713" height="13" font="font3" id="p4_t17" reading_order_no="16" segment_no="5" tag_type="text">their top guess. If the image is blurred the model successfully recognizes it as “still life photography” so the model is capable of </text>
<text top="555" left="29" width="376" height="13" font="font3" id="p4_t18" reading_order_no="17" segment_no="5" tag_type="text">processing this general kind of data; the bag is just too distracting.</text>
</page>
<page number="5" position="absolute" top="0" left="0" height="612" width="792">
	<fontspec id="font13" size="24" family="CMUSerif" color="#000000"/>
	<fontspec id="font14" size="8" family="CMUSerif" color="#000000"/>
	<fontspec id="font15" size="10" family="CMUSerif" color="#000000"/>
<text top="294" left="551" width="36" height="5" font="font4" id="p5_t1" reading_order_no="0" segment_no="4" tag_type="text">(Goodfellow 2018)</text>
<text top="32" left="263" width="273" height="24" font="font13" id="p5_t2" reading_order_no="1" segment_no="0" tag_type="title">Security Requires Moving </text>
<text top="65" left="326" width="140" height="24" font="font13" id="p5_t3" reading_order_no="2" segment_no="0" tag_type="title">Beyond I.I.D.</text>
<text top="97" left="232" width="4" height="8" font="font14" id="p5_t4" reading_order_no="3" segment_no="1" tag_type="list">•</text>
<text top="95" left="242" width="213" height="10" font="font15" id="p5_t5" reading_order_no="4" segment_no="1" tag_type="list">Not identical: attackers can use unusual inputs </text>
<text top="252" left="232" width="4" height="8" font="font14" id="p5_t6" reading_order_no="5" segment_no="3" tag_type="list">•</text>
<text top="251" left="242" width="314" height="10" font="font15" id="p5_t7" reading_order_no="6" segment_no="3" tag_type="list">Not independent: attacker can repeatedly send a single mistake (“test </text>
<text top="265" left="242" width="51" height="10" font="font15" id="p5_t8" reading_order_no="7" segment_no="3" tag_type="list">set attack”)</text>
<text top="234" left="329" width="124" height="14" font="font7" id="p5_t9" reading_order_no="8" segment_no="2" tag_type="text">(Eykholt et al, 2017)</text>
<text top="326" left="29" width="707" height="13" font="font3" id="p5_t10" reading_order_no="9" segment_no="5" tag_type="text">When we want to provide security guarantees for a machine learning system, we can no longer rely on the I.I.D. assumptions. </text>
<text top="368" left="29" width="711" height="13" font="font3" id="p5_t11" reading_order_no="10" segment_no="6" tag_type="text">In this presentation, I focus on attacks based on modifications of the input at test time. In this context, the two main relevant </text>
<text top="389" left="29" width="225" height="13" font="font3" id="p5_t12" reading_order_no="11" segment_no="6" tag_type="text">violations of the I.I.D. assumptions are: </text>
<text top="409" left="29" width="734" height="13" font="font3" id="p5_t13" reading_order_no="12" segment_no="7" tag_type="text">1) The test data is not drawn from the same distribution as the training data. The attacker intentionally shifts the distribution at </text>
<text top="430" left="47" width="710" height="13" font="font3" id="p5_t14" reading_order_no="13" segment_no="7" tag_type="text">test time toward unusual inputs such as this adversarial stop sign ( https://arxiv.org/abs/1707.08945  ) that will be processed </text>
<text top="451" left="47" width="66" height="13" font="font3" id="p5_t15" reading_order_no="14" segment_no="7" tag_type="text">incorrectly. </text>
<text top="472" left="29" width="725" height="13" font="font3" id="p5_t16" reading_order_no="15" segment_no="8" tag_type="text">2) The test examples are not necessarily drawn independently from each other. A real attacker can search for a single input that </text>
<text top="493" left="47" width="540" height="13" font="font3" id="p5_t17" reading_order_no="16" segment_no="8" tag_type="text">causes a mistake, and then send that input repeatedly, every time they interact with the system.</text>
</page>
<page number="6" position="absolute" top="0" left="0" height="612" width="792">
	<fontspec id="font16" size="13" family="CMUSerif,Italic" color="#000000"/>
<text top="294" left="551" width="36" height="5" font="font4" id="p6_t1" reading_order_no="0" segment_no="3" tag_type="text">(Goodfellow 2018)</text>
<text top="32" left="242" width="315" height="24" font="font13" id="p6_t2" reading_order_no="1" segment_no="0" tag_type="title">Good models make surprising </text>
<text top="65" left="255" width="283" height="24" font="font13" id="p6_t3" reading_order_no="2" segment_no="0" tag_type="title">mistakes in non-IID setting</text>
<text top="236" left="226" width="59" height="14" font="font7" id="p6_t4" reading_order_no="3" segment_no="1" tag_type="figure">Schoolbus</text>
<text top="236" left="357" width="81" height="14" font="font7" id="p6_t5" reading_order_no="4" segment_no="1" tag_type="figure">Perturbation </text>
<text top="255" left="347" width="96" height="8" font="font14" id="p6_t6" reading_order_no="5" segment_no="1" tag_type="figure">(rescaled for visualization)</text>
<text top="236" left="508" width="44" height="14" font="font7" id="p6_t7" reading_order_no="6" segment_no="1" tag_type="figure">Ostrich</text>
<text top="174" left="323" width="11" height="14" font="font7" id="p6_t8" reading_order_no="7" segment_no="1" tag_type="figure">+</text>
<text top="174" left="458" width="11" height="14" font="font7" id="p6_t9" reading_order_no="8" segment_no="1" tag_type="figure">=</text>
<text top="268" left="334" width="125" height="14" font="font7" id="p6_t10" reading_order_no="9" segment_no="2" tag_type="text">(Szegedy et al, 2013)</text>
<text top="113" left="328" width="135" height="14" font="font7" id="p6_t11" reading_order_no="10" segment_no="1" tag_type="figure">“Adversarial examples”</text>
<text top="326" left="29" width="726" height="13" font="font3" id="p6_t12" reading_order_no="11" segment_no="4" tag_type="text">The deep learning community first started to pay attention to surprising mistakes in the non-IID setting when Christian Szegedy </text>
<text top="347" left="29" width="101" height="13" font="font3" id="p6_t13" reading_order_no="12" segment_no="4" tag_type="text">showed that even </text>
<text top="347" left="130" width="72" height="12" font="font16" id="p6_t14" reading_order_no="13" segment_no="4" tag_type="text"><i>imperceptible</i></text>
<text top="347" left="201" width="410" height="13" font="font3" id="p6_t15" reading_order_no="14" segment_no="4" tag_type="text"> changes of IID test examples could result in consistent misclassification. </text>
<text top="389" left="29" width="715" height="13" font="font3" id="p6_t16" reading_order_no="15" segment_no="5" tag_type="text">The paper ( https://arxiv.org/abs/1312.6199 ) introduced the term “adversarial examples” to describe these images. They were </text>
<text top="409" left="29" width="737" height="13" font="font3" id="p6_t17" reading_order_no="16" segment_no="5" tag_type="text">formed by using gradient-based optimization to perturb a naturally occurring image to maximize the probability of a specific class. </text>
<text top="451" left="29" width="725" height="13" font="font3" id="p6_t18" reading_order_no="17" segment_no="6" tag_type="text">The discovery of these gradient-based attacks against neural networks was concurrent work  happening at roughly the same time </text>
<text top="472" left="29" width="732" height="13" font="font3" id="p6_t19" reading_order_no="18" segment_no="6" tag_type="text">as work done by Battista Biggio et al ( https://link.springer.com/chapter/10.1007%2F978-3-642-40994-3_25 ). Biggio et al’s work </text>
<text top="493" left="29" width="727" height="13" font="font3" id="p6_t20" reading_order_no="19" segment_no="6" tag_type="text">was published earlier in 2013 while Christian’s paper appeared on arxiv in late 2013. The first written record I personally have of </text>
<text top="513" left="29" width="303" height="13" font="font3" id="p6_t21" reading_order_no="20" segment_no="6" tag_type="text">Christian’s work is a 2012 e-mail from Yoshua Bengio.</text>
</page>
<page number="7" position="absolute" top="0" left="0" height="612" width="792">
	<fontspec id="font17" size="68" family="CMMIB10" color="#000000"/>
	<fontspec id="font18" size="69" family="CMMIB10" color="#000000"/>
	<fontspec id="font19" size="67" family="CMMIB10" color="#000000"/>
	<fontspec id="font20" size="68" family="CMR10" color="#000000"/>
	<fontspec id="font21" size="68" family="CMMIB10" color="#000000"/>
	<fontspec id="font22" size="14" family="CMUSerif" color="#70bf41"/>
	<fontspec id="font23" size="14" family="CMUSerif" color="#c82506"/>
	<fontspec id="font24" size="7" family="CMUSerif,Italic" color="#000000"/>
<text top="294" left="551" width="36" height="5" font="font4" id="p7_t1" reading_order_no="0" segment_no="2" tag_type="text">(Goodfellow 2018)</text>
<text top="32" left="274" width="253" height="24" font="font13" id="p7_t2" reading_order_no="1" segment_no="0" tag_type="title">Attacks on the machine </text>
<text top="65" left="310" width="171" height="24" font="font13" id="p7_t3" reading_order_no="2" segment_no="0" tag_type="title">learning pipeline</text>
<text top="135" left="265" width="64" height="70" font="font17" id="p7_t4" reading_order_no="3" segment_no="1" tag_type="figure">X</text>
<text top="134" left="376" width="38" height="49" font="font18" id="p7_t5" reading_order_no="4" segment_no="1" tag_type="figure">θ</text>
<text top="212" left="374" width="46" height="31" font="font19" id="p7_t6" reading_order_no="5" segment_no="1" tag_type="figure">x</text>
<text top="158" left="469" width="34" height="67" font="font20" id="p7_t7" reading_order_no="6" segment_no="1" tag_type="figure">ˆ</text>
<text top="171" left="460" width="40" height="44" font="font21" id="p7_t8" reading_order_no="7" segment_no="1" tag_type="figure">y</text>
<text top="222" left="219" width="81" height="14" font="font22" id="p7_t9" reading_order_no="8" segment_no="1" tag_type="figure">Training data</text>
<text top="107" left="304" width="115" height="14" font="font22" id="p7_t10" reading_order_no="9" segment_no="1" tag_type="figure">Learning algorithm</text>
<text top="91" left="438" width="118" height="14" font="font22" id="p7_t11" reading_order_no="10" segment_no="1" tag_type="figure">Learned parameters</text>
<text top="268" left="372" width="62" height="14" font="font22" id="p7_t12" reading_order_no="12" segment_no="1" tag_type="figure">Test input</text>
<text top="251" left="453" width="70" height="14" font="font22" id="p7_t13" reading_order_no="13" segment_no="1" tag_type="figure">Test output</text>
<text top="238" left="219" width="76" height="14" font="font23" id="p7_t14" reading_order_no="14" segment_no="1" tag_type="figure">Training set </text>
<text top="257" left="227" width="56" height="14" font="font23" id="p7_t15" reading_order_no="15" segment_no="1" tag_type="figure">poisoning</text>
<text top="268" left="467" width="70" height="14" font="font23" id="p7_t16" reading_order_no="16" segment_no="1" tag_type="figure">Model theft</text>
<text top="283" left="331" width="129" height="14" font="font23" id="p7_t17" reading_order_no="17" segment_no="1" tag_type="figure">Adversarial Examples</text>
<text top="100" left="451" width="129" height="14" font="font23" id="p7_t18" reading_order_no="11" segment_no="1" tag_type="figure">Recovery of sensitive </text>
<text top="119" left="474" width="78" height="14" font="font23" id="p7_t19" reading_order_no="18" segment_no="1" tag_type="figure">training data</text>
<text top="326" left="29" width="289" height="7" font="font9" id="p7_t20" reading_order_no="19" segment_no="3" tag_type="text">To define adversarial examples more clearly, we should consider some other security problems. </text>
<text top="337" left="29" width="628" height="7" font="font9" id="p7_t21" reading_order_no="20" segment_no="4" tag_type="text">Many machine learning algorithms can be described as a pipeline that takes training data X, learns parameters theta, and then uses those parameters to process test inputs x to produce test outputs y-hat. </text>
<text top="349" left="29" width="318" height="7" font="font9" id="p7_t22" reading_order_no="21" segment_no="5" tag_type="text">Attacks based on modifying the training data to cause the model to learn incorrect behaviors are called </text>
<text top="349" left="347" width="66" height="7" font="font24" id="p7_t23" reading_order_no="22" segment_no="5" tag_type="text"><i>training set poisoning</i></text>
<text top="349" left="413" width="4" height="7" font="font9" id="p7_t24" reading_order_no="23" segment_no="5" tag_type="text">. </text>
<text top="361" left="29" width="723" height="7" font="font9" id="p7_t25" reading_order_no="24" segment_no="6" tag_type="text">Attackers can study learned parameters theta to recover sensitive information from the training set (for example, recovering social security numbers from a trained language model as demonstrated by https://arxiv.org/abs/1802.08232 ). </text>
<text top="372" left="29" width="418" height="7" font="font9" id="p7_t26" reading_order_no="25" segment_no="6" tag_type="text">Attackers can send test inputs x and observe outputs y-hat to reverse engineer their model and train their own copy. This is known as a </text>
<text top="372" left="447" width="33" height="7" font="font24" id="p7_t27" reading_order_no="26" segment_no="6" tag_type="text"><i>model theft</i></text>
<text top="372" left="480" width="277" height="7" font="font9" id="p7_t28" reading_order_no="27" segment_no="6" tag_type="text"> attack. Model theft can then enable further attacks, like recovery of private training data </text>
<text top="384" left="29" width="106" height="7" font="font9" id="p7_t29" reading_order_no="28" segment_no="6" tag_type="text">or improved adversarial examples. </text>
<text top="395" left="29" width="474" height="7" font="font9" id="p7_t30" reading_order_no="29" segment_no="7" tag_type="text">Adversarial examples are distinct from these other security concerns: they are inputs supplied at test time, intended to cause the model to make a mistake.</text>
</page>
<page number="8" position="absolute" top="0" left="0" height="612" width="792">
	<fontspec id="font25" size="16" family="CMUSerif" color="#000000"/>
	<fontspec id="font26" size="16" family="CMUSerif" color="#000000"/>
<text top="294" left="551" width="36" height="5" font="font4" id="p8_t1" reading_order_no="0" segment_no="3" tag_type="text">(Goodfellow 2018)</text>
<text top="46" left="331" width="131" height="31" font="font5" id="p8_t2" reading_order_no="1" segment_no="0" tag_type="title">Definition</text>
<text top="104" left="217" width="156" height="17" font="font25" id="p8_t3" reading_order_no="2" segment_no="1" tag_type="text">“Adversarial examples</text>
<text top="104" left="379" width="97" height="17" font="font25" id="p8_t4" reading_order_no="3" segment_no="1" tag_type="text">are inputs to </text>
<text top="127" left="217" width="239" height="17" font="font25" id="p8_t5" reading_order_no="4" segment_no="1" tag_type="text">machine learning models that an </text>
<text top="150" left="217" width="252" height="17" font="font25" id="p8_t6" reading_order_no="5" segment_no="1" tag_type="text">attacker has intentionally designed </text>
<text top="173" left="217" width="216" height="17" font="font25" id="p8_t7" reading_order_no="6" segment_no="1" tag_type="text">to cause the model to make a </text>
<text top="195" left="217" width="60" height="17" font="font25" id="p8_t8" reading_order_no="7" segment_no="1" tag_type="text">mistake”</text>
<text top="218" left="228" width="140" height="14" font="font7" id="p8_t9" reading_order_no="8" segment_no="2" tag_type="text">(Goodfellow et al 2017)</text>
<text top="326" left="29" width="382" height="7" font="font9" id="p8_t10" reading_order_no="9" segment_no="4" tag_type="text">There is no standard community-accepted definition of the term “adversarial examples” and the usage has evolved over time. </text>
<text top="349" left="29" width="657" height="7" font="font9" id="p8_t11" reading_order_no="10" segment_no="5" tag_type="text">I personally coined the term “adversarial examples” while helping to write Christian’s paper (this was probably the most important thing I did, to be honest) so I feel somewhat within my rights to push a definition. </text>
<text top="372" left="29" width="390" height="7" font="font9" id="p8_t12" reading_order_no="11" segment_no="6" tag_type="text">The definition that I prefer today was introduced in an OpenAI blog post and developed with my co-authors of that blog post. </text>
<text top="395" left="29" width="192" height="7" font="font9" id="p8_t13" reading_order_no="12" segment_no="7" tag_type="text">There are three aspects of this definition I want to emphasize. </text>
<text top="418" left="29" width="6" height="7" font="font9" id="p8_t14" reading_order_no="13" segment_no="8" tag_type="text">1)</text>
<text top="418" left="47" width="716" height="7" font="font9" id="p8_t15" reading_order_no="14" segment_no="8" tag_type="text">There is no need for the adversarial example to be made by applying a small or imperceptible perturbation to a clean image. That was how we used the term in the original paper, but its usage has evolved over time. In particular, the </text>
<text top="430" left="47" width="365" height="7" font="font9" id="p8_t16" reading_order_no="15" segment_no="8" tag_type="text">picture of the apple in the mesh bag counts. I went out of my way to find a strange context that would fool the model. </text>
<text top="453" left="29" width="727" height="7" font="font9" id="p8_t17" reading_order_no="16" segment_no="9" tag_type="text">2) Adversarial examples are not defined in terms of deviation from human perception, but in terms of deviation from some absolute standard of correct behavior. In contexts like visual object recognition, human labelers might be the best </text>
<text top="464" left="29" width="728" height="7" font="font9" id="p8_t18" reading_order_no="17" segment_no="9" tag_type="text">approximation we have to the ground truth, but human perception is not the definition of truth. Humans are subject to mistakes and optical illusions too, and ideally we could make a machine learning system that is harder to fool than a </text>
<text top="476" left="29" width="25" height="7" font="font9" id="p8_t19" reading_order_no="18" segment_no="9" tag_type="text">human. </text>
<text top="499" left="29" width="89" height="7" font="font9" id="p8_t20" reading_order_no="19" segment_no="10" tag_type="text">3) An adversarial example is </text>
<text top="499" left="118" width="25" height="7" font="font24" id="p8_t21" reading_order_no="20" segment_no="10" tag_type="text"><i>intended</i></text>
<text top="499" left="144" width="616" height="7" font="font9" id="p8_t22" reading_order_no="21" segment_no="10" tag_type="text"> to be misclassified, but the attacker does not necessarily succeed. This makes it possible to discuss “error rate on adversarial examples”. If adversarial examples were defined to be actually misclassified, </text>
<text top="511" left="29" width="148" height="7" font="font9" id="p8_t23" reading_order_no="22" segment_no="10" tag_type="text">this error rate would always be 1 by definition.  </text>
<text top="534" left="29" width="185" height="7" font="font9" id="p8_t24" reading_order_no="23" segment_no="11" tag_type="text">For a longer discussion see https://arxiv.org/abs/1802.08195</text>
</page>
<page number="9" position="absolute" top="0" left="0" height="612" width="792">
	<fontspec id="font27" size="7" family="CMUSerif" color="#000000"/>
<text top="294" left="551" width="36" height="5" font="font4" id="p9_t1" reading_order_no="5" segment_no="7" tag_type="text">(Goodfellow 2018)</text>
<text top="46" left="302" width="188" height="31" font="font5" id="p9_t2" reading_order_no="6" segment_no="0" tag_type="title">Define a game</text>
<text top="96" left="232" width="5" height="10" font="font15" id="p9_t3" reading_order_no="7" segment_no="1" tag_type="list">•</text>
<text top="95" left="245" width="228" height="13" font="font3" id="p9_t4" reading_order_no="8" segment_no="1" tag_type="list">Define an action space for the defender </text>
<text top="129" left="232" width="5" height="10" font="font15" id="p9_t5" reading_order_no="9" segment_no="2" tag_type="list">•</text>
<text top="129" left="245" width="222" height="13" font="font3" id="p9_t6" reading_order_no="10" segment_no="2" tag_type="list">Define an action space for an attacker </text>
<text top="163" left="232" width="5" height="10" font="font15" id="p9_t7" reading_order_no="11" segment_no="3" tag_type="list">•</text>
<text top="162" left="245" width="191" height="13" font="font3" id="p9_t8" reading_order_no="12" segment_no="3" tag_type="list">Define cost function for defender </text>
<text top="196" left="232" width="5" height="10" font="font15" id="p9_t9" reading_order_no="13" segment_no="4" tag_type="list">•</text>
<text top="196" left="245" width="189" height="13" font="font3" id="p9_t10" reading_order_no="14" segment_no="4" tag_type="list">Define cost function for attacker </text>
<text top="230" left="245" width="5" height="10" font="font15" id="p9_t11" reading_order_no="15" segment_no="5" tag_type="list">•</text>
<text top="229" left="258" width="149" height="13" font="font3" id="p9_t12" reading_order_no="16" segment_no="5" tag_type="list">Not necessarily minimax. </text>
<text top="263" left="245" width="5" height="10" font="font15" id="p9_t13" reading_order_no="17" segment_no="6" tag_type="list">•</text>
<text top="263" left="258" width="133" height="13" font="font3" id="p9_t14" reading_order_no="18" segment_no="6" tag_type="list">Targeted vs untargeted</text>
<text top="326" left="29" width="266" height="7" font="font9" id="p9_t15" reading_order_no="19" segment_no="8" tag_type="text">To study machine learning in the adversarial setting, we must define a game, formally. </text>
<text top="349" left="29" width="310" height="7" font="font9" id="p9_t16" reading_order_no="20" segment_no="9" tag_type="text">This means we must define an action space and cost function for both the attacker and the defender. </text>
<text top="372" left="29" width="674" height="7" font="font9" id="p9_t17" reading_order_no="21" segment_no="10" tag_type="text">Usually, the defender’s action space is to output a class ID, but we can also imagine other variants of the game, where the defender can output a confidence value or can refuse to classify adversarially manipulated inputs. </text>
<text top="395" left="29" width="459" height="7" font="font9" id="p9_t18" reading_order_no="22" segment_no="11" tag_type="text">In the context of adversarial examples, the attacker’s action space describes the kind of inputs that the attacker can present to the defender's model.  </text>
<text top="418" left="29" width="342" height="7" font="font9" id="p9_t19" reading_order_no="0" segment_no="12" tag_type="text">The defender’s cost function, for the purpose of the game, is usually some kind of error rate. Note that this is di</text>
<text top="418" left="371" width="4" height="8" font="font27" id="p9_t20" reading_order_no="1" segment_no="12" tag_type="text">ﬀ</text>
<text top="418" left="376" width="285" height="7" font="font9" id="p9_t21" reading_order_no="2" segment_no="12" tag_type="text">erent from the cost used to train the neural net, which is designed with other concerns like di</text>
<text top="418" left="660" width="4" height="8" font="font27" id="p9_t22" reading_order_no="3" segment_no="12" tag_type="text">ﬀ</text>
<text top="418" left="664" width="95" height="7" font="font9" id="p9_t23" reading_order_no="4" segment_no="12" tag_type="text">erentiability in mind. The cost </text>
<text top="430" left="29" width="284" height="7" font="font9" id="p9_t24" reading_order_no="23" segment_no="12" tag_type="text">for the purpose of the game should directly measure the actual performance of the defender. </text>
<text top="453" left="29" width="728" height="7" font="font9" id="p9_t25" reading_order_no="24" segment_no="13" tag_type="text">Many people often think of adversarial settings as necessarily involving minimax games, but that is not always the case. In a minimax game, the attacker’s cost is just the negative cost of the defender. Other cost functions for the attacker </text>
<text top="464" left="29" width="491" height="7" font="font9" id="p9_t26" reading_order_no="25" segment_no="13" tag_type="text">often make sense. For example, the defender may want to get as many examples correct as possible while the attacker may gain an advantage only from causing </text>
<text top="464" left="520" width="24" height="7" font="font24" id="p9_t27" reading_order_no="26" segment_no="13" tag_type="text"><i>specific </i></text>
<text top="464" left="544" width="42" height="7" font="font9" id="p9_t28" reading_order_no="27" segment_no="13" tag_type="text">mistakes. An </text>
<text top="464" left="585" width="31" height="7" font="font24" id="p9_t29" reading_order_no="28" segment_no="13" tag_type="text"><i>untargeted</i></text>
<text top="464" left="617" width="138" height="7" font="font9" id="p9_t30" reading_order_no="29" segment_no="13" tag_type="text"> attacker just wants to cause mistakes, but a </text>
<text top="476" left="29" width="24" height="7" font="font24" id="p9_t31" reading_order_no="30" segment_no="13" tag_type="text"><i>targeted</i></text>
<text top="476" left="53" width="692" height="7" font="font9" id="p9_t32" reading_order_no="31" segment_no="13" tag_type="text"> attacker wants to cause an input to be recognized as coming from a specific class. For example, to sneak into a secure facility by fooling face recognition, it is not enough for the attacker to fool the face recognition system into </text>
<text top="488" left="29" width="386" height="7" font="font9" id="p9_t33" reading_order_no="32" segment_no="13" tag_type="text">guessing their identity incorrectly. The attacker must be recognized specifically as an individual who has access to the facility. </text>
</page>
<page number="10" position="absolute" top="0" left="0" height="612" width="792">
<text top="294" left="551" width="36" height="5" font="font4" id="p10_t1" reading_order_no="0" segment_no="12" tag_type="text">(Goodfellow 2018)</text>
<text top="32" left="264" width="271" height="24" font="font13" id="p10_t2" reading_order_no="1" segment_no="0" tag_type="title">Fifty Shades of Gray Box </text>
<text top="65" left="357" width="79" height="24" font="font13" id="p10_t3" reading_order_no="2" segment_no="0" tag_type="title">Attacks</text>
<text top="98" left="232" width="3" height="5" font="font4" id="p10_t4" reading_order_no="3" segment_no="1" tag_type="list">•</text>
<text top="97" left="238" width="152" height="7" font="font9" id="p10_t5" reading_order_no="4" segment_no="1" tag_type="list">Does the attacker go first, and the defender reacts? </text>
<text top="114" left="245" width="3" height="5" font="font4" id="p10_t6" reading_order_no="5" segment_no="2" tag_type="list">•</text>
<text top="114" left="252" width="248" height="7" font="font9" id="p10_t7" reading_order_no="6" segment_no="2" tag_type="list">This is easy, just train on the attacks, or design some preprocessing to remove them </text>
<text top="131" left="232" width="3" height="5" font="font4" id="p10_t8" reading_order_no="7" segment_no="3" tag_type="list">•</text>
<text top="131" left="238" width="74" height="7" font="font9" id="p10_t9" reading_order_no="8" segment_no="3" tag_type="list">If the defender goes first </text>
<text top="148" left="245" width="3" height="5" font="font4" id="p10_t10" reading_order_no="9" segment_no="4" tag_type="list">•</text>
<text top="148" left="252" width="174" height="7" font="font9" id="p10_t11" reading_order_no="10" segment_no="4" tag_type="list">Does the attacker have full knowledge? This is “white box” </text>
<text top="165" left="245" width="3" height="5" font="font4" id="p10_t12" reading_order_no="11" segment_no="5" tag_type="list">•</text>
<text top="165" left="252" width="94" height="7" font="font9" id="p10_t13" reading_order_no="12" segment_no="5" tag_type="list">Limited knowledge: “black box” </text>
<text top="182" left="258" width="3" height="5" font="font4" id="p10_t14" reading_order_no="13" segment_no="6" tag_type="list">•</text>
<text top="182" left="265" width="288" height="7" font="font9" id="p10_t15" reading_order_no="14" segment_no="6" tag_type="list">Does the attacker know the task the model is solving (input space, output space, defender cost) ? </text>
<text top="199" left="258" width="3" height="5" font="font4" id="p10_t16" reading_order_no="15" segment_no="7" tag_type="list">•</text>
<text top="198" left="265" width="201" height="7" font="font9" id="p10_t17" reading_order_no="16" segment_no="7" tag_type="list">Does the attacker know the machine learning algorithm being used? </text>
<text top="216" left="258" width="3" height="5" font="font4" id="p10_t18" reading_order_no="17" segment_no="8" tag_type="list">•</text>
<text top="215" left="265" width="165" height="7" font="font9" id="p10_t19" reading_order_no="18" segment_no="8" tag_type="list">Details of the algorithm? (Neural net architecture, etc.) </text>
<text top="233" left="258" width="3" height="5" font="font4" id="p10_t20" reading_order_no="19" segment_no="9" tag_type="list">•</text>
<text top="232" left="265" width="102" height="7" font="font9" id="p10_t21" reading_order_no="20" segment_no="9" tag_type="list">Learned parameters of the model? </text>
<text top="250" left="258" width="3" height="5" font="font4" id="p10_t22" reading_order_no="21" segment_no="10" tag_type="list">•</text>
<text top="249" left="265" width="198" height="7" font="font9" id="p10_t23" reading_order_no="22" segment_no="10" tag_type="list">Can the attacker send “probes” to see how the defender processes di</text>
<text top="249" left="463" width="4" height="7" font="font27" id="p10_t24" reading_order_no="23" segment_no="10" tag_type="list">ﬀ</text>
<text top="249" left="467" width="53" height="7" font="font9" id="p10_t25" reading_order_no="24" segment_no="10" tag_type="list">erent test inputs? </text>
<text top="266" left="272" width="3" height="5" font="font4" id="p10_t26" reading_order_no="25" segment_no="11" tag_type="list">•</text>
<text top="266" left="278" width="217" height="7" font="font9" id="p10_t27" reading_order_no="26" segment_no="11" tag_type="list">Does the attacker observe just the output class? Or also the probabilities?</text>
</page>
<page number="11" position="absolute" top="0" left="0" height="612" width="792">
</page>
<page number="12" position="absolute" top="0" left="0" height="612" width="792">
<text top="294" left="551" width="36" height="5" font="font4" id="p12_t1" reading_order_no="0" segment_no="2" tag_type="text">(Goodfellow 2018)</text>
<text top="48" left="234" width="324" height="25" font="font13" id="p12_t2" reading_order_no="1" segment_no="0" tag_type="title">Cross-technique transferability</text>
<text top="274" left="432" width="97" height="14" font="font7" id="p12_t3" reading_order_no="2" segment_no="1" tag_type="text">(Papernot 2016)</text>
</page>
<page number="13" position="absolute" top="0" left="0" height="612" width="792">
	<fontspec id="font28" size="14" family="CMUSerif" color="#000000"/>
<text top="294" left="551" width="36" height="5" font="font4" id="p13_t1" reading_order_no="0" segment_no="7" tag_type="text">(Goodfellow 2018)</text>
<text top="110" left="364" width="68" height="14" font="font22" id="p13_t2" reading_order_no="1" segment_no="3" tag_type="text">Train your </text>
<text top="129" left="364" width="64" height="14" font="font22" id="p13_t3" reading_order_no="2" segment_no="3" tag_type="text">own model</text>
<text top="46" left="292" width="209" height="31" font="font5" id="p13_t4" reading_order_no="3" segment_no="0" tag_type="title">Transfer Attack</text>
<text top="80" left="242" width="115" height="14" font="font7" id="p13_t5" reading_order_no="4" segment_no="1" tag_type="text">Target model with </text>
<text top="99" left="244" width="111" height="14" font="font7" id="p13_t6" reading_order_no="5" segment_no="1" tag_type="text">unknown weights, </text>
<text top="118" left="247" width="106" height="14" font="font7" id="p13_t7" reading_order_no="6" segment_no="1" tag_type="text">machine learning </text>
<text top="137" left="241" width="117" height="14" font="font7" id="p13_t8" reading_order_no="7" segment_no="1" tag_type="text">algorithm, training </text>
<text top="156" left="250" width="95" height="14" font="font7" id="p13_t9" reading_order_no="8" segment_no="1" tag_type="text">set; maybe non-</text>
<text top="175" left="259" width="11" height="14" font="font7" id="p13_t10" reading_order_no="9" segment_no="1" tag_type="text">di</text>
<text top="175" left="270" width="8" height="15" font="font28" id="p13_t11" reading_order_no="10" segment_no="1" tag_type="text">ﬀ</text>
<text top="175" left="278" width="58" height="14" font="font7" id="p13_t12" reading_order_no="11" segment_no="1" tag_type="text">erentiable</text>
<text top="99" left="442" width="106" height="14" font="font7" id="p13_t13" reading_order_no="12" segment_no="2" tag_type="text">Substitute model </text>
<text top="118" left="442" width="106" height="14" font="font7" id="p13_t14" reading_order_no="13" segment_no="2" tag_type="text">mimicking target </text>
<text top="137" left="436" width="118" height="14" font="font7" id="p13_t15" reading_order_no="14" segment_no="2" tag_type="text">model with known, </text>
<text top="156" left="428" width="11" height="14" font="font7" id="p13_t16" reading_order_no="15" segment_no="2" tag_type="text">di</text>
<text top="156" left="439" width="8" height="15" font="font28" id="p13_t17" reading_order_no="16" segment_no="2" tag_type="text">ﬀ</text>
<text top="156" left="447" width="111" height="14" font="font7" id="p13_t18" reading_order_no="17" segment_no="2" tag_type="text">erentiable function</text>
<text top="222" left="369" width="72" height="14" font="font7" id="p13_t19" reading_order_no="18" segment_no="6" tag_type="text">Adversarial </text>
<text top="241" left="376" width="54" height="14" font="font7" id="p13_t20" reading_order_no="19" segment_no="6" tag_type="text">examples</text>
<text top="198" left="466" width="122" height="14" font="font22" id="p13_t21" reading_order_no="20" segment_no="4" tag_type="text">Adversarial crafting </text>
<text top="217" left="471" width="106" height="14" font="font22" id="p13_t22" reading_order_no="21" segment_no="4" tag_type="text">against substitute</text>
<text top="203" left="221" width="115" height="14" font="font22" id="p13_t23" reading_order_no="22" segment_no="5" tag_type="text">Deploy adversarial </text>
<text top="222" left="214" width="129" height="14" font="font22" id="p13_t24" reading_order_no="23" segment_no="5" tag_type="text">examples against the </text>
<text top="241" left="212" width="132" height="14" font="font22" id="p13_t25" reading_order_no="24" segment_no="5" tag_type="text">target; transferability </text>
<text top="260" left="204" width="150" height="14" font="font22" id="p13_t26" reading_order_no="25" segment_no="5" tag_type="text">property results in them </text>
<text top="279" left="245" width="63" height="14" font="font22" id="p13_t27" reading_order_no="26" segment_no="5" tag_type="text">succeeding</text>
</page>
<page number="14" position="absolute" top="0" left="0" height="612" width="792">
<text top="294" left="551" width="36" height="5" font="font4" id="p14_t1" reading_order_no="0" segment_no="2" tag_type="text">(Goodfellow 2018)</text>
<text top="32" left="264" width="272" height="24" font="font13" id="p14_t2" reading_order_no="1" segment_no="0" tag_type="title">Enhancing Transfer With </text>
<text top="65" left="342" width="108" height="24" font="font13" id="p14_t3" reading_order_no="2" segment_no="0" tag_type="title">Ensembles</text>
<text top="270" left="359" width="97" height="14" font="font7" id="p14_t4" reading_order_no="3" segment_no="1" tag_type="text">(Liu et al, 2016)</text>
</page>
<page number="15" position="absolute" top="0" left="0" height="612" width="792">
	<fontspec id="font29" size="29" family="CMUSerif" color="#000000"/>
	<fontspec id="font30" size="9" family="CMUSerif,Italic" color="#000000"/>
	<fontspec id="font31" size="9" family="CMUSerif" color="#000000"/>
<text top="294" left="551" width="36" height="5" font="font4" id="p15_t1" reading_order_no="0" segment_no="9" tag_type="text">(Goodfellow 2018)</text>
<text top="46" left="233" width="326" height="30" font="font29" id="p15_t2" reading_order_no="1" segment_no="0" tag_type="title">Norm Balls: A Toy Game</text>
<text top="95" left="232" width="3" height="7" font="font9" id="p15_t3" reading_order_no="2" segment_no="1" tag_type="list">•</text>
<text top="94" left="241" width="310" height="9" font="font10" id="p15_t4" reading_order_no="3" segment_no="1" tag_type="list">How to benchmark performance on points that are not in the dataset and not </text>
<text top="106" left="241" width="35" height="9" font="font10" id="p15_t5" reading_order_no="4" segment_no="1" tag_type="list">labeled? </text>
<text top="130" left="232" width="3" height="7" font="font9" id="p15_t6" reading_order_no="5" segment_no="2" tag_type="list">•</text>
<text top="129" left="241" width="189" height="9" font="font10" id="p15_t7" reading_order_no="6" segment_no="2" tag_type="list">Propagate labels from nearby labeled examples </text>
<text top="153" left="232" width="3" height="7" font="font9" id="p15_t8" reading_order_no="7" segment_no="3" tag_type="list">•</text>
<text top="152" left="241" width="66" height="9" font="font10" id="p15_t9" reading_order_no="8" segment_no="3" tag_type="list">Attacker action: </text>
<text top="176" left="245" width="3" height="7" font="font9" id="p15_t10" reading_order_no="9" segment_no="4" tag_type="list">•</text>
<text top="175" left="254" width="264" height="9" font="font10" id="p15_t11" reading_order_no="10" segment_no="4" tag_type="list">Given a clean example, add a norm-constrained perturbation to it </text>
<text top="199" left="232" width="3" height="7" font="font9" id="p15_t12" reading_order_no="11" segment_no="5" tag_type="list">•</text>
<text top="198" left="241" width="18" height="9" font="font10" id="p15_t13" reading_order_no="12" segment_no="5" tag_type="list">The </text>
<text top="198" left="259" width="40" height="9" font="font30" id="p15_t14" reading_order_no="13" segment_no="5" tag_type="list"><i>drosophila</i></text>
<text top="198" left="299" width="129" height="9" font="font10" id="p15_t15" reading_order_no="14" segment_no="5" tag_type="list"> of adversarial machine learning </text>
<text top="222" left="232" width="3" height="7" font="font9" id="p15_t16" reading_order_no="15" segment_no="6" tag_type="list">•</text>
<text top="221" left="241" width="59" height="9" font="font10" id="p15_t17" reading_order_no="16" segment_no="6" tag_type="list">Interesting for </text>
<text top="221" left="300" width="54" height="9" font="font30" id="p15_t18" reading_order_no="17" segment_no="6" tag_type="list"><i>basic research</i></text>
<text top="221" left="353" width="149" height="9" font="font10" id="p15_t19" reading_order_no="18" segment_no="6" tag_type="list"> purposes because of its clarity and di</text>
<text top="221" left="503" width="7" height="10" font="font31" id="p15_t20" reading_order_no="19" segment_no="6" tag_type="list">ﬃ</text>
<text top="221" left="510" width="22" height="9" font="font10" id="p15_t21" reading_order_no="20" segment_no="6" tag_type="list">culty </text>
<text top="245" left="232" width="3" height="7" font="font9" id="p15_t22" reading_order_no="21" segment_no="7" tag_type="list">•</text>
<text top="244" left="241" width="188" height="9" font="font10" id="p15_t23" reading_order_no="22" segment_no="7" tag_type="list">Not relevant for most practical purposes: not a </text>
<text top="244" left="429" width="61" height="9" font="font30" id="p15_t24" reading_order_no="23" segment_no="7" tag_type="list"><i>current, applied</i></text>
<text top="244" left="491" width="72" height="9" font="font10" id="p15_t25" reading_order_no="24" segment_no="7" tag_type="list"> security problem </text>
<text top="268" left="232" width="3" height="7" font="font9" id="p15_t26" reading_order_no="25" segment_no="8" tag_type="list">•</text>
<text top="267" left="241" width="255" height="9" font="font10" id="p15_t27" reading_order_no="26" segment_no="8" tag_type="list">In my view, this shouldn’t be primarily about human perception</text>
<text top="326" left="29" width="354" height="7" font="font9" id="p15_t28" reading_order_no="27" segment_no="10" tag_type="text">Most adversarial example research today is based on a specific toy game in the context of visual object recognition. </text>
<text top="349" left="29" width="734" height="7" font="font9" id="p15_t29" reading_order_no="28" segment_no="11" tag_type="text">We want to evaluate the performance of a classifier on arbitrary inputs, since in most scenarios the attacker is not constrained to supply naturally occurring data is input. Unfortunately, for visual object recognition, it is not straightforward </text>
<text top="361" left="29" width="580" height="7" font="font9" id="p15_t30" reading_order_no="29" segment_no="11" tag_type="text">to evaluate the classifier on arbitrary inputs. We rely on human labelers to obtain ground truth labels, and it is slow and expensive to include a human in the loop to label all attack images. </text>
<text top="384" left="29" width="727" height="7" font="font9" id="p15_t31" reading_order_no="30" segment_no="12" tag_type="text">To obtain an inexpensive and automated evaluation, we can propagate labels from nearby points ( https://arxiv.org/abs/1412.6572 ). This suggests that for research purposes, a convenient game to study is one where the attacker’s action </text>
<text top="395" left="29" width="314" height="7" font="font9" id="p15_t32" reading_order_no="31" segment_no="12" tag_type="text">space is to take a clean test image and modify it by adding a norm-constrained perturbation. The size </text>
<text top="395" left="343" width="21" height="7" font="font24" id="p15_t33" reading_order_no="32" segment_no="12" tag_type="text"><i>epsilon</i></text>
<text top="395" left="364" width="377" height="7" font="font9" id="p15_t34" reading_order_no="33" segment_no="12" tag_type="text"> of this perturbation is chosen to ensure that the resulting adversarial examples have the same class as the clean examples. </text>
<text top="407" left="29" width="489" height="7" font="font9" id="p15_t35" reading_order_no="34" segment_no="12" tag_type="text">Epsilon should be made as large as possible while still preserving classes in order to benchmark performance on as large a subset of the input space as possible. </text>
<text top="430" left="29" width="308" height="7" font="font9" id="p15_t36" reading_order_no="35" segment_no="13" tag_type="text">These games have gained a lot of attention because, despite their simplicity, it has been extremely di</text>
<text top="430" left="337" width="6" height="8" font="font27" id="p15_t37" reading_order_no="36" segment_no="13" tag_type="text">ﬃ</text>
<text top="430" left="343" width="122" height="7" font="font9" id="p15_t38" reading_order_no="37" segment_no="13" tag_type="text">cult for a defender to win such a game. </text>
<text top="453" left="29" width="730" height="7" font="font9" id="p15_t39" reading_order_no="38" segment_no="14" tag_type="text">However, it is important to emphasize that these games are primarily tools for basic research, and not models of real-world security scenarios. One of the best things that one could do for adversarial machine learning research is to devise a </text>
<text top="464" left="29" width="223" height="7" font="font9" id="p15_t40" reading_order_no="39" segment_no="14" tag_type="text">practical means of benchmarking performance in more realistic scenarios.</text>
</page>
<page number="16" position="absolute" top="0" left="0" height="612" width="792">
	<fontspec id="font32" size="12" family="CMUSerif" color="#000000"/>
	<fontspec id="font33" size="12" family="CMUSerif,Italic" color="#000000"/>
	<fontspec id="font34" size="12" family="CMUSerif" color="#000000"/>
<text top="294" left="551" width="36" height="5" font="font4" id="p16_t1" reading_order_no="0" segment_no="7" tag_type="text">(Goodfellow 2018)</text>
<text top="46" left="293" width="207" height="31" font="font5" id="p16_t2" reading_order_no="1" segment_no="0" tag_type="title">Who goes first?</text>
<text top="97" left="232" width="4" height="9" font="font10" id="p16_t3" reading_order_no="2" segment_no="1" tag_type="list">•</text>
<text top="96" left="243" width="102" height="12" font="font32" id="p16_t4" reading_order_no="3" segment_no="1" tag_type="list">Attacker goes first: </text>
<text top="127" left="245" width="4" height="9" font="font10" id="p16_t5" reading_order_no="4" segment_no="2" tag_type="list">•</text>
<text top="126" left="257" width="306" height="12" font="font32" id="p16_t6" reading_order_no="5" segment_no="2" tag_type="list">Defender trains on the attacks. Usually the defender wins. </text>
<text top="157" left="245" width="4" height="9" font="font10" id="p16_t7" reading_order_no="6" segment_no="3" tag_type="list">•</text>
<text top="156" left="257" width="262" height="12" font="font32" id="p16_t8" reading_order_no="7" segment_no="3" tag_type="list">Not much more interesting than standard dataset </text>
<text top="173" left="257" width="75" height="12" font="font32" id="p16_t9" reading_order_no="8" segment_no="3" tag_type="list">augmentation </text>
<text top="204" left="232" width="4" height="9" font="font10" id="p16_t10" reading_order_no="9" segment_no="4" tag_type="list">•</text>
<text top="203" left="243" width="104" height="12" font="font32" id="p16_t11" reading_order_no="10" segment_no="4" tag_type="list">Defender goes first: </text>
<text top="234" left="245" width="4" height="9" font="font10" id="p16_t12" reading_order_no="11" segment_no="5" tag_type="list">•</text>
<text top="233" left="257" width="60" height="12" font="font32" id="p16_t13" reading_order_no="12" segment_no="5" tag_type="list">Attacker is </text>
<text top="233" left="317" width="43" height="12" font="font33" id="p16_t14" reading_order_no="13" segment_no="5" tag_type="list"><i>adaptive</i></text>
<text top="233" left="360" width="14" height="12" font="font32" id="p16_t15" reading_order_no="14" segment_no="5" tag_type="list"> / </text>
<text top="233" left="374" width="39" height="12" font="font33" id="p16_t16" reading_order_no="15" segment_no="5" tag_type="list"><i>reactive</i></text>
<text top="264" left="245" width="4" height="9" font="font10" id="p16_t17" reading_order_no="16" segment_no="6" tag_type="list">•</text>
<text top="263" left="257" width="67" height="12" font="font32" id="p16_t18" reading_order_no="17" segment_no="6" tag_type="list">Extremely di</text>
<text top="263" left="324" width="10" height="13" font="font34" id="p16_t19" reading_order_no="18" segment_no="6" tag_type="list">ﬃ</text>
<text top="263" left="334" width="207" height="12" font="font32" id="p16_t20" reading_order_no="19" segment_no="6" tag_type="list">cult. Main reason this topic is unsolved.</text>
<text top="326" left="29" width="717" height="13" font="font3" id="p16_t21" reading_order_no="20" segment_no="8" tag_type="text">An example of where the person trying to fool the neural net goes first is text CAPTCHAs. Text-based CAPTCHAs have been </text>
<text top="347" left="29" width="631" height="13" font="font3" id="p16_t22" reading_order_no="21" segment_no="8" tag_type="text">broken since 2013. https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42241.pdf</text>
</page>
<page number="17" position="absolute" top="0" left="0" height="612" width="792">
	<fontspec id="font35" size="8" family="CMR12" color="#000000"/>
	<fontspec id="font36" size="8" family="CMMI12" color="#000000"/>
	<fontspec id="font37" size="8" family="CMR12" color="#000000"/>
	<fontspec id="font38" size="30" family="CMUSerif" color="#000000"/>
<text top="294" left="551" width="36" height="5" font="font4" id="p17_t1" reading_order_no="7" segment_no="1" tag_type="text">(Goodfellow 2018)</text>
<text top="273" left="319" width="4" height="8" font="font35" id="p17_t2" reading_order_no="8" segment_no="0" tag_type="figure">0</text>
<text top="278" left="323" width="2" height="4" font="font36" id="p17_t3" reading_order_no="9" segment_no="0" tag_type="figure">.</text>
<text top="273" left="325" width="4" height="8" font="font35" id="p17_t4" reading_order_no="10" segment_no="0" tag_type="figure">0</text>
<text top="273" left="352" width="4" height="8" font="font35" id="p17_t5" reading_order_no="11" segment_no="0" tag_type="figure">0</text>
<text top="278" left="357" width="2" height="4" font="font36" id="p17_t6" reading_order_no="12" segment_no="0" tag_type="figure">.</text>
<text top="273" left="359" width="4" height="8" font="font35" id="p17_t7" reading_order_no="13" segment_no="0" tag_type="figure">2</text>
<text top="273" left="386" width="4" height="8" font="font35" id="p17_t8" reading_order_no="14" segment_no="0" tag_type="figure">0</text>
<text top="278" left="390" width="2" height="4" font="font36" id="p17_t9" reading_order_no="15" segment_no="0" tag_type="figure">.</text>
<text top="273" left="393" width="4" height="8" font="font35" id="p17_t10" reading_order_no="16" segment_no="0" tag_type="figure">4</text>
<text top="273" left="420" width="4" height="8" font="font35" id="p17_t11" reading_order_no="17" segment_no="0" tag_type="figure">0</text>
<text top="278" left="424" width="2" height="4" font="font36" id="p17_t12" reading_order_no="18" segment_no="0" tag_type="figure">.</text>
<text top="273" left="426" width="4" height="8" font="font35" id="p17_t13" reading_order_no="19" segment_no="0" tag_type="figure">6</text>
<text top="273" left="454" width="4" height="8" font="font35" id="p17_t14" reading_order_no="20" segment_no="0" tag_type="figure">0</text>
<text top="278" left="458" width="2" height="4" font="font36" id="p17_t15" reading_order_no="21" segment_no="0" tag_type="figure">.</text>
<text top="273" left="460" width="4" height="8" font="font35" id="p17_t16" reading_order_no="22" segment_no="0" tag_type="figure">8</text>
<text top="273" left="488" width="4" height="8" font="font35" id="p17_t17" reading_order_no="23" segment_no="0" tag_type="figure">1</text>
<text top="278" left="492" width="2" height="4" font="font36" id="p17_t18" reading_order_no="24" segment_no="0" tag_type="figure">.</text>
<text top="273" left="494" width="4" height="8" font="font35" id="p17_t19" reading_order_no="25" segment_no="0" tag_type="figure">0</text>
<text top="283" left="331" width="155" height="8" font="font35" id="p17_t20" reading_order_no="26" segment_no="0" tag_type="figure">Proportion of examples that are adversarial</text>
<text top="265" left="300" width="4" height="8" font="font35" id="p17_t21" reading_order_no="27" segment_no="0" tag_type="figure">0</text>
<text top="270" left="304" width="2" height="4" font="font36" id="p17_t22" reading_order_no="28" segment_no="0" tag_type="figure">.</text>
<text top="265" left="306" width="4" height="8" font="font35" id="p17_t23" reading_order_no="29" segment_no="0" tag_type="figure">0</text>
<text top="227" left="300" width="4" height="8" font="font35" id="p17_t24" reading_order_no="30" segment_no="0" tag_type="figure">0</text>
<text top="232" left="304" width="2" height="4" font="font36" id="p17_t25" reading_order_no="31" segment_no="0" tag_type="figure">.</text>
<text top="227" left="306" width="4" height="8" font="font35" id="p17_t26" reading_order_no="32" segment_no="0" tag_type="figure">2</text>
<text top="188" left="300" width="4" height="8" font="font35" id="p17_t27" reading_order_no="33" segment_no="0" tag_type="figure">0</text>
<text top="193" left="304" width="2" height="4" font="font36" id="p17_t28" reading_order_no="34" segment_no="0" tag_type="figure">.</text>
<text top="188" left="306" width="4" height="8" font="font35" id="p17_t29" reading_order_no="35" segment_no="0" tag_type="figure">4</text>
<text top="150" left="300" width="4" height="8" font="font35" id="p17_t30" reading_order_no="36" segment_no="0" tag_type="figure">0</text>
<text top="155" left="304" width="2" height="4" font="font36" id="p17_t31" reading_order_no="37" segment_no="0" tag_type="figure">.</text>
<text top="150" left="306" width="4" height="8" font="font35" id="p17_t32" reading_order_no="38" segment_no="0" tag_type="figure">6</text>
<text top="111" left="300" width="4" height="8" font="font35" id="p17_t33" reading_order_no="39" segment_no="0" tag_type="figure">0</text>
<text top="116" left="304" width="2" height="4" font="font36" id="p17_t34" reading_order_no="40" segment_no="0" tag_type="figure">.</text>
<text top="111" left="306" width="4" height="8" font="font35" id="p17_t35" reading_order_no="41" segment_no="0" tag_type="figure">8</text>
<text top="196" left="296" width="0" height="8" font="font37" id="p17_t36" reading_order_no="42" segment_no="0" tag_type="figure">T</text>
<text top="191" left="296" width="0" height="8" font="font37" id="p17_t37" reading_order_no="43" segment_no="0" tag_type="figure">op-5</text>
<text top="173" left="296" width="0" height="8" font="font37" id="p17_t38" reading_order_no="44" segment_no="0" tag_type="figure">Accuracy</text>
<text top="86" left="465" width="28" height="8" font="font35" id="p17_t39" reading_order_no="45" segment_no="0" tag_type="figure">M-PGD</text>
<text top="98" left="465" width="17" height="8" font="font35" id="p17_t40" reading_order_no="46" segment_no="0" tag_type="figure">ALP</text>
<text top="109" left="465" width="29" height="8" font="font35" id="p17_t41" reading_order_no="47" segment_no="0" tag_type="figure">Baseline</text>
<text top="46" left="341" width="92" height="31" font="font5" id="p17_t42" reading_order_no="48" segment_no="0" tag_type="figure">Tradeo</text>
<text top="46" left="433" width="18" height="34" font="font38" id="p17_t43" reading_order_no="49" segment_no="0" tag_type="figure">ﬀ</text>
<text top="120" left="518" width="59" height="14" font="font7" id="p17_t44" reading_order_no="50" segment_no="0" tag_type="figure">Accuracy </text>
<text top="139" left="504" width="88" height="14" font="font7" id="p17_t45" reading_order_no="51" segment_no="0" tag_type="figure">on adversarial </text>
<text top="158" left="519" width="54" height="14" font="font7" id="p17_t46" reading_order_no="52" segment_no="0" tag_type="figure">examples</text>
<text top="55" left="216" width="59" height="14" font="font7" id="p17_t47" reading_order_no="53" segment_no="0" tag_type="figure">Accuracy </text>
<text top="74" left="219" width="54" height="14" font="font7" id="p17_t48" reading_order_no="54" segment_no="0" tag_type="figure">on clean </text>
<text top="93" left="216" width="54" height="14" font="font7" id="p17_t49" reading_order_no="55" segment_no="0" tag_type="figure">examples</text>
<text top="217" left="323" width="101" height="14" font="font7" id="p17_t50" reading_order_no="56" segment_no="0" tag_type="figure">Transition point </text>
<text top="236" left="318" width="108" height="14" font="font7" id="p17_t51" reading_order_no="57" segment_no="0" tag_type="figure">(7.1% adversarial)</text>
<text top="326" left="29" width="488" height="7" font="font9" id="p17_t52" reading_order_no="58" segment_no="2" tag_type="text">In some cases, defenses against adversarial examples act as a regularizer and actually improve accuracy on the test set ( https://arxiv.org/abs/1412.6572 ). p p </text>
<text top="340" left="29" width="403" height="7" font="font9" id="p17_t53" reading_order_no="59" segment_no="2" tag_type="text">In most of the recent literature, the strongest defenses against adversarial examples tend to decrease accuracy on the clean test set. </text>
<text top="354" left="29" width="733" height="7" font="font9" id="p17_t54" reading_order_no="60" segment_no="3" tag_type="text">To choose a specific model to use on a particular task, we shoul p pd consider the cost it will incur when it is actually used in practice. To simplify the discussion, assume all errors are equally costly. If we believe a model will always receive </text>
<text top="365" left="29" width="721" height="7" font="font9" id="p17_t55" reading_order_no="61" segment_no="3" tag_type="text">adversarial examples, we should choose the model with the highest accuracy in the adversarial setting. If we believe it will receive only clean examples, then we should choose the model with the highest accuracy on the clean test set. In </text>
<text top="377" left="29" width="719" height="7" font="font9" id="p17_t56" reading_order_no="62" segment_no="3" tag_type="text">many settings, we probably expect the model to come under attack a certain percentage of the time. If we assume that this percentage is independent of the choice of model (in reality, models with greater vulnerability may be attacked </text>
<text top="388" left="29" width="399" height="7" font="font9" id="p17_t57" reading_order_no="63" segment_no="3" tag_type="text">more often) we should choose the model that performs the best on a test set consisting of this proportion of adversarial examples. </text>
<text top="402" left="29" width="724" height="7" font="font9" id="p17_t58" reading_order_no="64" segment_no="4" tag_type="text">For example, this plot shows the accuracy of an undefended baseline and two defenses, M-PGD and ALP ( https://arxiv.org/abs/1803.06373 ) on the ImageNet test set. The ALP model is more robust to adversarial examples, but at the </text>
<text top="413" left="29" width="726" height="7" font="font9" id="p17_t59" reading_order_no="65" segment_no="4" tag_type="text">cost of accuracy on the clean test set. For the ALP model to be preferable to the baseline, we need to expect that the model will face adversarial examples about 7.1% of the time on the test set. Another interesting thing we see from this </text>
<text top="425" left="29" width="109" height="7" font="font9" id="p17_t60" reading_order_no="66" segment_no="4" tag_type="text">plot is that it shows us some tradeo</text>
<text top="425" left="138" width="4" height="8" font="font27" id="p17_t61" reading_order_no="67" segment_no="4" tag_type="text">ﬀ</text>
<text top="425" left="142" width="156" height="7" font="font9" id="p17_t62" reading_order_no="68" segment_no="4" tag_type="text">s are just not worth it: M-PGD might look like it o</text>
<text top="425" left="298" width="4" height="8" font="font27" id="p17_t63" reading_order_no="69" segment_no="4" tag_type="text">ﬀ</text>
<text top="425" left="302" width="460" height="7" font="font9" id="p17_t64" reading_order_no="0" segment_no="4" tag_type="text">ers complementary advantages and disadvantages relative to ALP because it has higher accuracy on the clean test set, but there is actually never any </text>
<text top="436" left="29" width="298" height="7" font="font9" id="p17_t65" reading_order_no="1" segment_no="4" tag_type="text">point on the curve where M-PGD has the highest accuracy. We can optimally navigate the tradeo</text>
<text top="436" left="327" width="4" height="8" font="font27" id="p17_t66" reading_order_no="2" segment_no="4" tag_type="text">ﬀ</text>
<text top="436" left="331" width="198" height="7" font="font9" id="p17_t67" reading_order_no="3" segment_no="4" tag_type="text"> with only ALP and the undefended baseline as our two choices. </text>
<text top="450" left="29" width="735" height="7" font="font9" id="p17_t68" reading_order_no="70" segment_no="5" tag_type="text">The choice between these two models is complicated by the fact that accuracies in the adversarial setting are usually upper bounds, based on testing the defense against a particular attack algorithm. A smarter attack algorithm or an attack </text>
<text top="461" left="29" width="30" height="7" font="font9" id="p17_t69" reading_order_no="71" segment_no="5" tag_type="text">using a di</text>
<text top="461" left="59" width="4" height="8" font="font27" id="p17_t70" reading_order_no="72" segment_no="5" tag_type="text">ﬀ</text>
<text top="461" left="63" width="435" height="7" font="font9" id="p17_t71" reading_order_no="4" segment_no="5" tag_type="text">erent threat model could bring the accuracy of either model even lower in the adversarial setting, so there is uncertainty about the true tradeo</text>
<text top="461" left="498" width="4" height="8" font="font27" id="p17_t72" reading_order_no="5" segment_no="5" tag_type="text">ﬀ</text>
<text top="461" left="502" width="4" height="7" font="font9" id="p17_t73" reading_order_no="6" segment_no="5" tag_type="text">. </text>
<text top="474" left="29" width="682" height="7" font="font9" id="p17_t74" reading_order_no="73" segment_no="6" tag_type="text">Of course, for the purposes of basic research, it still makes sense to study how to obtain better accuracy in the completely adversarial setting, but we must not lose sight of the need to retain good performance on clean data.</text>
</page>
<page number="18" position="absolute" top="0" left="0" height="612" width="792">
<text top="294" left="551" width="36" height="5" font="font4" id="p18_t1" reading_order_no="0" segment_no="5" tag_type="text">(Goodfellow 2018)</text>
<text top="46" left="277" width="238" height="31" font="font5" id="p18_t2" reading_order_no="1" segment_no="0" tag_type="title">Gradient Masking</text>
<text top="97" left="232" width="5" height="10" font="font15" id="p18_t3" reading_order_no="2" segment_no="1" tag_type="list">•</text>
<text top="95" left="244" width="303" height="13" font="font3" id="p18_t4" reading_order_no="3" segment_no="1" tag_type="list">Some defenses look like they work because they break </text>
<text top="113" left="244" width="187" height="13" font="font3" id="p18_t5" reading_order_no="4" segment_no="1" tag_type="list">gradient-based white box attacks </text>
<text top="147" left="232" width="5" height="10" font="font15" id="p18_t6" reading_order_no="5" segment_no="2" tag_type="list">•</text>
<text top="145" left="244" width="283" height="13" font="font3" id="p18_t7" reading_order_no="6" segment_no="2" tag_type="list">But then they don’t break black box attacks (e.g., </text>
<text top="163" left="244" width="253" height="13" font="font3" id="p18_t8" reading_order_no="7" segment_no="2" tag_type="list">adversarial examples made for other models) </text>
<text top="197" left="232" width="5" height="10" font="font15" id="p18_t9" reading_order_no="8" segment_no="3" tag_type="list">•</text>
<text top="195" left="244" width="279" height="13" font="font3" id="p18_t10" reading_order_no="9" segment_no="3" tag_type="list">The defense denies the attacker access to a useful </text>
<text top="212" left="244" width="227" height="13" font="font3" id="p18_t11" reading_order_no="10" segment_no="3" tag_type="list">gradient but does not actually make the </text>
<text top="212" left="471" width="49" height="12" font="font16" id="p18_t12" reading_order_no="11" segment_no="3" tag_type="list"><i>decision </i></text>
<text top="230" left="244" width="50" height="12" font="font16" id="p18_t13" reading_order_no="12" segment_no="3" tag_type="list"><i>boundary</i></text>
<text top="230" left="294" width="42" height="13" font="font3" id="p18_t14" reading_order_no="13" segment_no="3" tag_type="list"> secure </text>
<text top="264" left="232" width="5" height="10" font="font15" id="p18_t15" reading_order_no="14" segment_no="4" tag_type="list">•</text>
<text top="262" left="244" width="78" height="13" font="font3" id="p18_t16" reading_order_no="15" segment_no="4" tag_type="list">This is called </text>
<text top="262" left="322" width="94" height="12" font="font16" id="p18_t17" reading_order_no="16" segment_no="4" tag_type="list"><i>gradient masking</i></text>
<text top="326" left="29" width="115" height="13" font="font3" id="p18_t18" reading_order_no="17" segment_no="6" tag_type="text">For further reading: </text>
<text top="347" left="29" width="191" height="13" font="font3" id="p18_t19" reading_order_no="18" segment_no="7" tag_type="text">https://arxiv.org/abs/1602.02697 </text>
<text top="368" left="29" width="191" height="13" font="font3" id="p18_t20" reading_order_no="19" segment_no="8" tag_type="text">https://arxiv.org/abs/1705.07204 </text>
<text top="389" left="29" width="191" height="13" font="font3" id="p18_t21" reading_order_no="20" segment_no="9" tag_type="text">https://arxiv.org/abs/1802.00420 </text>
</page>
<page number="19" position="absolute" top="0" left="0" height="612" width="792">
	<fontspec id="font39" size="14" family="CMUSerif,Italic" color="#000000"/>
	<fontspec id="font40" size="14" family="LucidaGrande,Bold" color="#000000"/>
	<fontspec id="font41" size="7" family="LucidaGrande,Bold" color="#000000"/>
	<fontspec id="font42" size="5" family="CMUSerif,Italic" color="#000000"/>
<text top="294" left="551" width="36" height="5" font="font4" id="p19_t1" reading_order_no="0" segment_no="3" tag_type="text">(Goodfellow 2018)</text>
<text top="32" left="289" width="203" height="24" font="font13" id="p19_t2" reading_order_no="1" segment_no="0" tag_type="title">Why not to use L2 </text>
<text top="71" left="213" width="369" height="14" font="font7" id="p19_t3" reading_order_no="2" segment_no="1" tag_type="text">Experiments excluding MNIST 1s, many of which look like 7s</text>
<text top="98" left="387" width="14" height="14" font="font7" id="p19_t4" reading_order_no="3" segment_no="2" tag_type="figure">Di</text>
<text top="98" left="401" width="8" height="15" font="font28" id="p19_t5" reading_order_no="4" segment_no="2" tag_type="figure">ﬀ</text>
<text top="98" left="328" width="25" height="14" font="font7" id="p19_t6" reading_order_no="5" segment_no="2" tag_type="figure">Pair</text>
<text top="131" left="221" width="50" height="14" font="font7" id="p19_t7" reading_order_no="6" segment_no="2" tag_type="figure">Nearest </text>
<text top="131" left="271" width="9" height="13" font="font39" id="p19_t8" reading_order_no="7" segment_no="2" tag_type="figure"><i>L</i></text>
<text top="131" left="279" width="7" height="14" font="font7" id="p19_t9" reading_order_no="8" segment_no="2" tag_type="figure">0</text>
<text top="165" left="221" width="50" height="14" font="font7" id="p19_t10" reading_order_no="9" segment_no="2" tag_type="figure">Nearest </text>
<text top="165" left="271" width="9" height="13" font="font39" id="p19_t11" reading_order_no="10" segment_no="2" tag_type="figure"><i>L</i></text>
<text top="165" left="279" width="7" height="14" font="font7" id="p19_t12" reading_order_no="11" segment_no="2" tag_type="figure">1</text>
<text top="202" left="221" width="50" height="14" font="font7" id="p19_t13" reading_order_no="12" segment_no="2" tag_type="figure">Nearest </text>
<text top="202" left="271" width="9" height="13" font="font39" id="p19_t14" reading_order_no="13" segment_no="2" tag_type="figure"><i>L</i></text>
<text top="202" left="279" width="7" height="14" font="font7" id="p19_t15" reading_order_no="14" segment_no="2" tag_type="figure">2</text>
<text top="239" left="218" width="50" height="14" font="font7" id="p19_t16" reading_order_no="15" segment_no="2" tag_type="figure">Nearest </text>
<text top="239" left="268" width="9" height="13" font="font39" id="p19_t17" reading_order_no="16" segment_no="2" tag_type="figure"><i>L</i></text>
<text top="240" left="276" width="12" height="13" font="font40" id="p19_t18" reading_order_no="17" segment_no="2" tag_type="figure"><b>∞</b></text>
<text top="263" left="203" width="106" height="14" font="font7" id="p19_t19" reading_order_no="18" segment_no="2" tag_type="figure">Clipped Random </text>
<text top="282" left="230" width="47" height="14" font="font7" id="p19_t20" reading_order_no="19" segment_no="2" tag_type="figure">uniform</text>
<text top="98" left="432" width="9" height="13" font="font39" id="p19_t21" reading_order_no="20" segment_no="2" tag_type="figure"><i>L</i></text>
<text top="98" left="441" width="7" height="14" font="font7" id="p19_t22" reading_order_no="21" segment_no="2" tag_type="figure">0</text>
<text top="98" left="468" width="9" height="13" font="font39" id="p19_t23" reading_order_no="22" segment_no="2" tag_type="figure"><i>L</i></text>
<text top="98" left="477" width="7" height="14" font="font7" id="p19_t24" reading_order_no="23" segment_no="2" tag_type="figure">1</text>
<text top="98" left="506" width="9" height="13" font="font39" id="p19_t25" reading_order_no="24" segment_no="2" tag_type="figure"><i>L</i></text>
<text top="98" left="515" width="7" height="14" font="font7" id="p19_t26" reading_order_no="25" segment_no="2" tag_type="figure">2</text>
<text top="98" left="545" width="9" height="13" font="font39" id="p19_t27" reading_order_no="26" segment_no="2" tag_type="figure"><i>L</i></text>
<text top="99" left="554" width="12" height="13" font="font40" id="p19_t28" reading_order_no="27" segment_no="2" tag_type="figure"><b>∞</b></text>
<text top="131" left="433" width="14" height="14" font="font23" id="p19_t29" reading_order_no="41" segment_no="2" tag_type="figure">63</text>
<text top="165" left="433" width="14" height="14" font="font23" id="p19_t30" reading_order_no="43" segment_no="2" tag_type="figure">91</text>
<text top="202" left="430" width="20" height="14" font="font23" id="p19_t31" reading_order_no="45" segment_no="2" tag_type="figure">110</text>
<text top="239" left="430" width="20" height="14" font="font23" id="p19_t32" reading_order_no="52" segment_no="2" tag_type="figure">121</text>
<text top="273" left="430" width="20" height="14" font="font7" id="p19_t33" reading_order_no="54" segment_no="2" tag_type="figure">784</text>
<text top="131" left="463" width="24" height="14" font="font23" id="p19_t34" reading_order_no="28" segment_no="2" tag_type="figure">35.0</text>
<text top="165" left="463" width="24" height="14" font="font23" id="p19_t35" reading_order_no="29" segment_no="2" tag_type="figure">19.9</text>
<text top="202" left="463" width="24" height="14" font="font23" id="p19_t36" reading_order_no="30" segment_no="2" tag_type="figure">21.7</text>
<text top="239" left="463" width="24" height="14" font="font23" id="p19_t37" reading_order_no="31" segment_no="2" tag_type="figure">34.0</text>
<text top="272" left="460" width="31" height="14" font="font7" id="p19_t38" reading_order_no="32" segment_no="2" tag_type="figure">116.0</text>
<text top="131" left="502" width="24" height="14" font="font22" id="p19_t39" reading_order_no="33" segment_no="2" tag_type="figure">4.86</text>
<text top="165" left="502" width="24" height="14" font="font23" id="p19_t40" reading_order_no="34" segment_no="2" tag_type="figure">3.21</text>
<text top="202" left="502" width="24" height="14" font="font23" id="p19_t41" reading_order_no="35" segment_no="2" tag_type="figure">2.83</text>
<text top="239" left="546" width="17" height="14" font="font22" id="p19_t42" reading_order_no="36" segment_no="2" tag_type="figure">.76</text>
<text top="273" left="550" width="11" height="14" font="font7" id="p19_t43" reading_order_no="37" segment_no="2" tag_type="figure">.3</text>
<text top="239" left="502" width="24" height="14" font="font23" id="p19_t44" reading_order_no="38" segment_no="2" tag_type="figure">3.82</text>
<text top="272" left="505" width="17" height="14" font="font7" id="p19_t45" reading_order_no="39" segment_no="2" tag_type="figure">4.8</text>
<text top="131" left="546" width="17" height="14" font="font22" id="p19_t46" reading_order_no="40" segment_no="2" tag_type="figure">1.0</text>
<text top="164" left="543" width="24" height="14" font="font22" id="p19_t47" reading_order_no="42" segment_no="2" tag_type="figure">.996</text>
<text top="201" left="546" width="17" height="14" font="font22" id="p19_t48" reading_order_no="44" segment_no="2" tag_type="figure">1.0</text>
<text top="326" left="29" width="236" height="7" font="font9" id="p19_t49" reading_order_no="46" segment_no="4" tag_type="text">To propagate labels from points in the dataset with known labels to nearby o</text>
<text top="326" left="265" width="4" height="8" font="font27" id="p19_t50" reading_order_no="47" segment_no="4" tag_type="text">ﬀ</text>
<text top="326" left="269" width="446" height="7" font="font9" id="p19_t51" reading_order_no="48" segment_no="4" tag_type="text">-dataset points with unknown labels, we need some way to measure distance. In most current work on adversarial examples, this is done with the </text>
<text top="326" left="715" width="4" height="7" font="font24" id="p19_t52" reading_order_no="49" segment_no="4" tag_type="text"><i>L</i></text>
<text top="327" left="720" width="6" height="7" font="font41" id="p19_t53" reading_order_no="50" segment_no="4" tag_type="text"><b>∞</b></text>
<text top="326" left="725" width="22" height="7" font="font9" id="p19_t54" reading_order_no="51" segment_no="4" tag_type="text"> norm, </text>
<text top="333" left="29" width="143" height="7" font="font9" id="p19_t55" reading_order_no="53" segment_no="4" tag_type="text">advocated by https://arxiv.org/abs/1412.6572 </text>
<text top="349" left="29" width="694" height="7" font="font9" id="p19_t56" reading_order_no="55" segment_no="5" tag_type="text">This is intended to be a way of guaranteeing that the label is known on new test points. Ideally we would like to propagate labels to as large a volume of space as possible. (A common misconception is that we want to keep the </text>
<text top="357" left="29" width="271" height="7" font="font9" id="p19_t57" reading_order_no="57" segment_no="5" tag_type="text">perturbations small, to be imperceptible—actually we would like to benchmark on all of </text>
<text top="357" left="300" width="5" height="7" font="font24" id="p19_t58" reading_order_no="58" segment_no="5" tag_type="text"><i>R</i></text>
<text top="355" left="305" width="3" height="5" font="font42" id="p19_t59" reading_order_no="56" segment_no="5" tag_type="text"><i>n</i></text>
<text top="357" left="308" width="96" height="7" font="font9" id="p19_t60" reading_order_no="59" segment_no="5" tag_type="text"> if we had a way of labeling it) </text>
<text top="369" left="29" width="543" height="7" font="font9" id="p19_t61" reading_order_no="60" segment_no="6" tag_type="text">Norms are convenient to implement and to study mathematically, but some norms are better than others for propagating labels. This is of course highly application-specific. The </text>
<text top="369" left="572" width="4" height="7" font="font24" id="p19_t62" reading_order_no="61" segment_no="6" tag_type="text"><i>L</i></text>
<text top="370" left="577" width="6" height="7" font="font41" id="p19_t63" reading_order_no="62" segment_no="6" tag_type="text"><b>∞</b></text>
<text top="369" left="583" width="172" height="7" font="font9" id="p19_t64" reading_order_no="63" segment_no="6" tag_type="text"> norm is relevant primarily for visual object recognition </text>
<text top="376" left="29" width="375" height="7" font="font9" id="p19_t65" reading_order_no="64" segment_no="6" tag_type="text">tasks. For other tasks like malware detection, we would be interested in transformations of code that preserve its function. </text>
<text top="388" left="29" width="351" height="7" font="font9" id="p19_t66" reading_order_no="65" segment_no="7" tag_type="text">In this example, we see that if we want to add large uniform noise (within the confines of the unit hypercube), the </text>
<text top="388" left="380" width="4" height="7" font="font24" id="p19_t67" reading_order_no="66" segment_no="7" tag_type="text"><i>L</i></text>
<text top="389" left="385" width="6" height="7" font="font41" id="p19_t68" reading_order_no="67" segment_no="7" tag_type="text"><b>∞</b></text>
<text top="388" left="391" width="349" height="7" font="font9" id="p19_t69" reading_order_no="68" segment_no="7" tag_type="text"> norm is the best at assigning larger distances to noisy perturbations than to perturbations that change the class. </text>
<text top="388" left="740" width="4" height="7" font="font24" id="p19_t70" reading_order_no="69" segment_no="7" tag_type="text"><i>L</i></text>
<text top="388" left="744" width="8" height="7" font="font9" id="p19_t71" reading_order_no="70" segment_no="7" tag_type="text">0, </text>
<text top="388" left="752" width="4" height="7" font="font24" id="p19_t72" reading_order_no="71" segment_no="7" tag_type="text"><i>L</i></text>
<text top="388" left="756" width="8" height="7" font="font9" id="p19_t73" reading_order_no="72" segment_no="7" tag_type="text">1, </text>
<text top="396" left="29" width="14" height="7" font="font9" id="p19_t74" reading_order_no="73" segment_no="7" tag_type="text">and </text>
<text top="396" left="43" width="4" height="7" font="font24" id="p19_t75" reading_order_no="74" segment_no="7" tag_type="text"><i>L</i></text>
<text top="396" left="47" width="167" height="7" font="font9" id="p19_t76" reading_order_no="75" segment_no="7" tag_type="text">2 all assign smaller distances to examples that lie in di</text>
<text top="396" left="213" width="4" height="8" font="font27" id="p19_t77" reading_order_no="76" segment_no="7" tag_type="text">ﬀ</text>
<text top="396" left="217" width="193" height="7" font="font9" id="p19_t78" reading_order_no="77" segment_no="7" tag_type="text">erent classes than to noisy versions of the example shown. The </text>
<text top="396" left="411" width="4" height="7" font="font24" id="p19_t79" reading_order_no="78" segment_no="7" tag_type="text"><i>L</i></text>
<text top="397" left="415" width="6" height="7" font="font41" id="p19_t80" reading_order_no="79" segment_no="7" tag_type="text"><b>∞</b></text>
<text top="396" left="421" width="218" height="7" font="font9" id="p19_t81" reading_order_no="80" segment_no="7" tag_type="text"> does not do this. We also see that if we constraint the input using the </text>
<text top="396" left="639" width="4" height="7" font="font24" id="p19_t82" reading_order_no="81" segment_no="7" tag_type="text"><i>L</i></text>
<text top="397" left="643" width="6" height="7" font="font41" id="p19_t83" reading_order_no="82" segment_no="7" tag_type="text"><b>∞</b></text>
<text top="396" left="649" width="104" height="7" font="font9" id="p19_t84" reading_order_no="83" segment_no="7" tag_type="text"> norm, we can get relatively large </text>
<text top="403" left="29" width="146" height="7" font="font9" id="p19_t85" reading_order_no="84" segment_no="7" tag_type="text">perturbations in terms of the other norms. Our </text>
<text top="403" left="175" width="4" height="7" font="font24" id="p19_t86" reading_order_no="85" segment_no="7" tag_type="text"><i>L</i></text>
<text top="404" left="180" width="6" height="7" font="font41" id="p19_t87" reading_order_no="86" segment_no="7" tag_type="text"><b>∞</b></text>
<text top="403" left="186" width="128" height="7" font="font9" id="p19_t88" reading_order_no="87" segment_no="7" tag_type="text">-constrained uniform perturbation has an </text>
<text top="403" left="314" width="4" height="7" font="font24" id="p19_t89" reading_order_no="88" segment_no="7" tag_type="text"><i>L</i></text>
<text top="403" left="318" width="375" height="7" font="font9" id="p19_t90" reading_order_no="89" segment_no="7" tag_type="text">2 norm larger than most of the class-changing perturbations shown here. Intuitively, restricting the perturbation using the </text>
<text top="403" left="694" width="4" height="7" font="font24" id="p19_t91" reading_order_no="90" segment_no="7" tag_type="text"><i>L</i></text>
<text top="404" left="698" width="6" height="7" font="font41" id="p19_t92" reading_order_no="91" segment_no="7" tag_type="text"><b>∞</b></text>
<text top="403" left="704" width="53" height="7" font="font9" id="p19_t93" reading_order_no="92" segment_no="7" tag_type="text"> makes sure that </text>
<text top="411" left="29" width="483" height="7" font="font9" id="p19_t94" reading_order_no="93" segment_no="7" tag_type="text">the adversary cannot focus the whole perturbation on a small number of pixels, to completely erase or completely draw in ink that changes the MNIST digit. </text>
<text top="423" left="29" width="114" height="7" font="font9" id="p19_t95" reading_order_no="94" segment_no="8" tag_type="text">The example of uniform noise makes </text>
<text top="423" left="143" width="4" height="7" font="font24" id="p19_t96" reading_order_no="95" segment_no="8" tag_type="text"><i>L</i></text>
<text top="423" left="147" width="8" height="7" font="font9" id="p19_t97" reading_order_no="96" segment_no="8" tag_type="text">0, </text>
<text top="423" left="155" width="4" height="7" font="font24" id="p19_t98" reading_order_no="97" segment_no="8" tag_type="text"><i>L</i></text>
<text top="423" left="159" width="21" height="7" font="font9" id="p19_t99" reading_order_no="98" segment_no="8" tag_type="text">1, and </text>
<text top="423" left="181" width="4" height="7" font="font24" id="p19_t100" reading_order_no="99" segment_no="8" tag_type="text"><i>L</i></text>
<text top="423" left="185" width="59" height="7" font="font9" id="p19_t101" reading_order_no="100" segment_no="8" tag_type="text">2 all look bad, but </text>
<text top="423" left="244" width="4" height="7" font="font24" id="p19_t102" reading_order_no="101" segment_no="8" tag_type="text"><i>L</i></text>
<text top="423" left="248" width="19" height="7" font="font9" id="p19_t103" reading_order_no="102" segment_no="8" tag_type="text">0 and </text>
<text top="423" left="267" width="4" height="7" font="font24" id="p19_t104" reading_order_no="103" segment_no="8" tag_type="text"><i>L</i></text>
<text top="423" left="272" width="161" height="7" font="font9" id="p19_t105" reading_order_no="104" segment_no="8" tag_type="text">1 can perform better in other examples. It is mostly </text>
<text top="423" left="433" width="4" height="7" font="font24" id="p19_t106" reading_order_no="105" segment_no="8" tag_type="text"><i>L</i></text>
<text top="423" left="437" width="107" height="7" font="font9" id="p19_t107" reading_order_no="106" segment_no="8" tag_type="text">2 that I intend to discourage here. </text>
<text top="435" left="29" width="727" height="7" font="font9" id="p19_t108" reading_order_no="107" segment_no="9" tag_type="text">It would be great if researchers could find an improved method of reliably propagating labels to more points in space than this norm-ball approach allows. It is important to remember that the goal to an improved evaluation should either </text>
<text top="442" left="29" width="650" height="7" font="font9" id="p19_t109" reading_order_no="108" segment_no="9" tag_type="text">be to label more points or to more realistically model an actual security threat. In particular, the goal is not to find a good model of human perceptual distance, unless that helps with either of the preceding goals.</text>
</page>
<page number="20" position="absolute" top="0" left="0" height="612" width="792">
<text top="294" left="551" width="36" height="5" font="font4" id="p20_t1" reading_order_no="0" segment_no="2" tag_type="text">(Goodfellow 2018)</text>
<text top="32" left="232" width="335" height="24" font="font13" id="p20_t2" reading_order_no="1" segment_no="0" tag_type="title">Real Attacks Will not be in the </text>
<text top="65" left="342" width="108" height="24" font="font13" id="p20_t3" reading_order_no="2" segment_no="0" tag_type="title">Norm Ball</text>
<text top="234" left="223" width="124" height="14" font="font7" id="p20_t4" reading_order_no="3" segment_no="1" tag_type="text">(Eykholt et al, 2017)</text>
<text top="326" left="29" width="736" height="13" font="font3" id="p20_t5" reading_order_no="4" segment_no="3" tag_type="text">The norm ball is a nice way of formalizing games for basic research purposes. We must remember though that the norm ball is not </text>
<text top="347" left="29" width="79" height="13" font="font3" id="p20_t6" reading_order_no="5" segment_no="3" tag_type="text">the real game.</text>
</page>
<page number="21" position="absolute" top="0" left="0" height="612" width="792">
	<fontspec id="font43" size="27" family="CMUSerif" color="#000000"/>
<text top="294" left="551" width="36" height="5" font="font4" id="p21_t1" reading_order_no="0" segment_no="7" tag_type="text">(Goodfellow 2018)</text>
<text top="47" left="233" width="326" height="27" font="font43" id="p21_t2" reading_order_no="1" segment_no="0" tag_type="title">Pipeline of Defense Failures</text>
<text top="282" left="242" width="28" height="14" font="font7" id="p21_t3" reading_order_no="2" segment_no="6" tag_type="text">No e</text>
<text top="282" left="270" width="8" height="15" font="font28" id="p21_t4" reading_order_no="3" segment_no="6" tag_type="text">ﬀ</text>
<text top="282" left="278" width="70" height="14" font="font7" id="p21_t5" reading_order_no="4" segment_no="6" tag_type="text">ect on advx</text>
<text top="255" left="261" width="311" height="14" font="font7" id="p21_t6" reading_order_no="5" segment_no="5" tag_type="text">Reduces advx, but reduces clean accuracy too much</text>
<text top="235" left="279" width="65" height="14" font="font7" id="p21_t7" reading_order_no="6" segment_no="4" tag_type="text">Does not a</text>
<text top="235" left="344" width="8" height="15" font="font28" id="p21_t8" reading_order_no="7" segment_no="4" tag_type="text">ﬀ</text>
<text top="235" left="352" width="125" height="14" font="font7" id="p21_t9" reading_order_no="8" segment_no="4" tag_type="text">ect adaptive attacker</text>
<text top="214" left="306" width="221" height="14" font="font7" id="p21_t10" reading_order_no="9" segment_no="3" tag_type="text">Does not generalize over attack algos</text>
<text top="190" left="328" width="233" height="14" font="font7" id="p21_t11" reading_order_no="10" segment_no="2" tag_type="text">Seems to generalize, but it’s an illusion</text>
<text top="174" left="355" width="232" height="14" font="font7" id="p21_t12" reading_order_no="11" segment_no="1" tag_type="text">Does not generalize over threat models</text>
</page>
<page number="22" position="absolute" top="0" left="0" height="612" width="792">
	<fontspec id="font44" size="14" family="CMUSerif" color="#c82506"/>
<text top="294" left="551" width="36" height="5" font="font4" id="p22_t1" reading_order_no="0" segment_no="8" tag_type="text">(Goodfellow 2018)</text>
<text top="47" left="233" width="326" height="27" font="font43" id="p22_t2" reading_order_no="1" segment_no="0" tag_type="title">Pipeline of Defense Failures</text>
<text top="282" left="242" width="28" height="14" font="font23" id="p22_t3" reading_order_no="2" segment_no="7" tag_type="text">No e</text>
<text top="282" left="270" width="8" height="15" font="font44" id="p22_t4" reading_order_no="3" segment_no="7" tag_type="text">ﬀ</text>
<text top="282" left="278" width="70" height="14" font="font23" id="p22_t5" reading_order_no="4" segment_no="7" tag_type="text">ect on advx</text>
<text top="255" left="261" width="311" height="14" font="font7" id="p22_t6" reading_order_no="5" segment_no="6" tag_type="text">Reduces advx, but reduces clean accuracy too much</text>
<text top="235" left="279" width="65" height="14" font="font7" id="p22_t7" reading_order_no="6" segment_no="5" tag_type="text">Does not a</text>
<text top="235" left="344" width="8" height="15" font="font28" id="p22_t8" reading_order_no="7" segment_no="5" tag_type="text">ﬀ</text>
<text top="235" left="352" width="125" height="14" font="font7" id="p22_t9" reading_order_no="8" segment_no="5" tag_type="text">ect adaptive attacker</text>
<text top="214" left="306" width="221" height="14" font="font7" id="p22_t10" reading_order_no="9" segment_no="4" tag_type="text">Does not generalize over attack algos</text>
<text top="190" left="328" width="233" height="14" font="font7" id="p22_t11" reading_order_no="10" segment_no="3" tag_type="text">Seems to generalize, but it’s an illusion</text>
<text top="174" left="355" width="232" height="14" font="font7" id="p22_t12" reading_order_no="11" segment_no="2" tag_type="text">Does not generalize over threat models</text>
<text top="112" left="326" width="139" height="14" font="font23" id="p22_t13" reading_order_no="12" segment_no="1" tag_type="text">Dropout at Train Time</text>
<text top="326" left="29" width="724" height="13" font="font3" id="p22_t14" reading_order_no="13" segment_no="9" tag_type="text">Many of the networks tested in early work on adversarial examples were trained with dropoout: https://arxiv.org/abs/1312.6199 </text>
<text top="347" left="29" width="185" height="13" font="font3" id="p22_t15" reading_order_no="14" segment_no="9" tag_type="text">https://arxiv.org/abs/1412.6572 </text>
<text top="389" left="29" width="300" height="13" font="font3" id="p22_t16" reading_order_no="15" segment_no="10" tag_type="text">Dropout is a good regularizer, but does not seem to o</text>
<text top="389" left="329" width="7" height="14" font="font11" id="p22_t17" reading_order_no="16" segment_no="10" tag_type="text">ﬀ</text>
<text top="389" left="337" width="165" height="13" font="font3" id="p22_t18" reading_order_no="17" segment_no="10" tag_type="text">er any adversarial robustness.</text>
</page>
<page number="23" position="absolute" top="0" left="0" height="612" width="792">
<text top="294" left="551" width="36" height="5" font="font4" id="p23_t1" reading_order_no="0" segment_no="8" tag_type="text">(Goodfellow 2018)</text>
<text top="47" left="233" width="326" height="27" font="font43" id="p23_t2" reading_order_no="1" segment_no="0" tag_type="title">Pipeline of Defense Failures</text>
<text top="282" left="242" width="28" height="14" font="font7" id="p23_t3" reading_order_no="2" segment_no="7" tag_type="text">No e</text>
<text top="282" left="270" width="8" height="15" font="font28" id="p23_t4" reading_order_no="3" segment_no="7" tag_type="text">ﬀ</text>
<text top="282" left="278" width="70" height="14" font="font7" id="p23_t5" reading_order_no="4" segment_no="7" tag_type="text">ect on advx</text>
<text top="255" left="261" width="311" height="14" font="font23" id="p23_t6" reading_order_no="5" segment_no="6" tag_type="text">Reduces advx, but reduces clean accuracy too much</text>
<text top="235" left="279" width="65" height="14" font="font7" id="p23_t7" reading_order_no="6" segment_no="5" tag_type="text">Does not a</text>
<text top="235" left="344" width="8" height="15" font="font28" id="p23_t8" reading_order_no="7" segment_no="5" tag_type="text">ﬀ</text>
<text top="235" left="352" width="125" height="14" font="font7" id="p23_t9" reading_order_no="8" segment_no="5" tag_type="text">ect adaptive attacker</text>
<text top="214" left="306" width="221" height="14" font="font7" id="p23_t10" reading_order_no="9" segment_no="4" tag_type="text">Does not generalize over attack algos</text>
<text top="190" left="328" width="233" height="14" font="font7" id="p23_t11" reading_order_no="10" segment_no="3" tag_type="text">Seems to generalize, but it’s an illusion</text>
<text top="174" left="355" width="232" height="14" font="font7" id="p23_t12" reading_order_no="11" segment_no="2" tag_type="text">Does not generalize over threat models</text>
<text top="112" left="355" width="83" height="14" font="font23" id="p23_t13" reading_order_no="12" segment_no="1" tag_type="text">Weight Decay</text>
<text top="326" left="29" width="282" height="13" font="font3" id="p23_t14" reading_order_no="13" segment_no="9" tag_type="text">Early work on adversarial examples explored the e</text>
<text top="326" left="311" width="7" height="14" font="font11" id="p23_t15" reading_order_no="14" segment_no="9" tag_type="text">ﬀ</text>
<text top="326" left="318" width="65" height="13" font="font3" id="p23_t16" reading_order_no="15" segment_no="9" tag_type="text">ect of both </text>
<text top="326" left="384" width="8" height="12" font="font16" id="p23_t17" reading_order_no="16" segment_no="9" tag_type="text"><i>L</i></text>
<text top="326" left="392" width="83" height="13" font="font3" id="p23_t18" reading_order_no="17" segment_no="9" tag_type="text">1 and squared </text>
<text top="326" left="474" width="8" height="12" font="font16" id="p23_t19" reading_order_no="18" segment_no="9" tag_type="text"><i>L</i></text>
<text top="326" left="482" width="275" height="13" font="font3" id="p23_t20" reading_order_no="19" segment_no="9" tag_type="text">2 weight decay: https://arxiv.org/abs/1312.6199 </text>
<text top="347" left="29" width="185" height="13" font="font3" id="p23_t21" reading_order_no="20" segment_no="9" tag_type="text">https://arxiv.org/abs/1412.6572 </text>
<text top="389" left="29" width="192" height="13" font="font3" id="p23_t22" reading_order_no="21" segment_no="10" tag_type="text">For large enough weight decay coe</text>
<text top="389" left="221" width="11" height="14" font="font11" id="p23_t23" reading_order_no="22" segment_no="10" tag_type="text">ﬃ</text>
<text top="389" left="231" width="517" height="13" font="font3" id="p23_t24" reading_order_no="23" segment_no="10" tag_type="text">cients weight decay does eventually make the weights small enough that the model becomes </text>
<text top="409" left="29" width="707" height="13" font="font3" id="p23_t25" reading_order_no="24" segment_no="10" tag_type="text">robust to adversarial examples, but it also makes the accuracy on clean data become relatively bad. Such claims are of course </text>
<text top="430" left="29" width="111" height="13" font="font3" id="p23_t26" reading_order_no="25" segment_no="10" tag_type="text">problem-dependent.</text>
</page>
<page number="24" position="absolute" top="0" left="0" height="612" width="792">
<text top="294" left="551" width="36" height="5" font="font4" id="p24_t1" reading_order_no="0" segment_no="8" tag_type="text">(Goodfellow 2018)</text>
<text top="47" left="233" width="326" height="27" font="font43" id="p24_t2" reading_order_no="1" segment_no="0" tag_type="title">Pipeline of Defense Failures</text>
<text top="282" left="242" width="28" height="14" font="font7" id="p24_t3" reading_order_no="2" segment_no="7" tag_type="text">No e</text>
<text top="282" left="270" width="8" height="15" font="font28" id="p24_t4" reading_order_no="3" segment_no="7" tag_type="text">ﬀ</text>
<text top="282" left="278" width="70" height="14" font="font7" id="p24_t5" reading_order_no="4" segment_no="7" tag_type="text">ect on advx</text>
<text top="255" left="261" width="311" height="14" font="font7" id="p24_t6" reading_order_no="5" segment_no="6" tag_type="text">Reduces advx, but reduces clean accuracy too much</text>
<text top="235" left="279" width="65" height="14" font="font23" id="p24_t7" reading_order_no="6" segment_no="5" tag_type="text">Does not a</text>
<text top="235" left="344" width="8" height="15" font="font44" id="p24_t8" reading_order_no="7" segment_no="5" tag_type="text">ﬀ</text>
<text top="235" left="352" width="125" height="14" font="font23" id="p24_t9" reading_order_no="8" segment_no="5" tag_type="text">ect adaptive attacker</text>
<text top="214" left="306" width="221" height="14" font="font7" id="p24_t10" reading_order_no="9" segment_no="4" tag_type="text">Does not generalize over attack algos</text>
<text top="190" left="328" width="233" height="14" font="font7" id="p24_t11" reading_order_no="10" segment_no="3" tag_type="text">Seems to generalize, but it’s an illusion</text>
<text top="174" left="355" width="232" height="14" font="font7" id="p24_t12" reading_order_no="11" segment_no="2" tag_type="text">Does not generalize over threat models</text>
<text top="112" left="294" width="182" height="14" font="font23" id="p24_t13" reading_order_no="12" segment_no="1" tag_type="text">Cropping / fovea  mechanisms</text>
<text top="326" left="29" width="720" height="13" font="font3" id="p24_t14" reading_order_no="13" segment_no="9" tag_type="text">Cropping and fovea mechanisms have been repeatedly proposed as defenses. Generating adversarial examples and then cropping </text>
<text top="347" left="29" width="715" height="13" font="font3" id="p24_t15" reading_order_no="14" segment_no="9" tag_type="text">them sometimes reduces error rate. The latest evaluations show that an attacker aware of the mechanism can defeat it. https://</text>
<text top="368" left="29" width="164" height="13" font="font3" id="p24_t16" reading_order_no="15" segment_no="9" tag_type="text">arxiv.org/pdf/1802.00420.pdf</text>
</page>
<page number="25" position="absolute" top="0" left="0" height="612" width="792">
<text top="294" left="551" width="36" height="5" font="font4" id="p25_t1" reading_order_no="0" segment_no="8" tag_type="text">(Goodfellow 2018)</text>
<text top="47" left="233" width="326" height="27" font="font43" id="p25_t2" reading_order_no="1" segment_no="0" tag_type="title">Pipeline of Defense Failures</text>
<text top="282" left="242" width="28" height="14" font="font7" id="p25_t3" reading_order_no="2" segment_no="7" tag_type="text">No e</text>
<text top="282" left="270" width="8" height="15" font="font28" id="p25_t4" reading_order_no="3" segment_no="7" tag_type="text">ﬀ</text>
<text top="282" left="278" width="70" height="14" font="font7" id="p25_t5" reading_order_no="4" segment_no="7" tag_type="text">ect on advx</text>
<text top="255" left="261" width="311" height="14" font="font7" id="p25_t6" reading_order_no="5" segment_no="6" tag_type="text">Reduces advx, but reduces clean accuracy too much</text>
<text top="235" left="279" width="65" height="14" font="font7" id="p25_t7" reading_order_no="6" segment_no="5" tag_type="text">Does not a</text>
<text top="235" left="344" width="8" height="15" font="font28" id="p25_t8" reading_order_no="7" segment_no="5" tag_type="text">ﬀ</text>
<text top="235" left="352" width="125" height="14" font="font7" id="p25_t9" reading_order_no="8" segment_no="5" tag_type="text">ect adaptive attacker</text>
<text top="214" left="306" width="221" height="14" font="font23" id="p25_t10" reading_order_no="9" segment_no="4" tag_type="text">Does not generalize over attack algos</text>
<text top="190" left="328" width="233" height="14" font="font7" id="p25_t11" reading_order_no="10" segment_no="3" tag_type="text">Seems to generalize, but it’s an illusion</text>
<text top="174" left="355" width="232" height="14" font="font7" id="p25_t12" reading_order_no="11" segment_no="2" tag_type="text">Does not generalize over threat models</text>
<text top="112" left="265" width="247" height="14" font="font23" id="p25_t13" reading_order_no="12" segment_no="1" tag_type="text">Adversarial Training with a Weak Attack</text>
<text top="326" left="29" width="724" height="13" font="font3" id="p25_t14" reading_order_no="13" segment_no="9" tag_type="text">One of the first successes in the defense literature was adversarial training, approximating the minimax optimization using a fast </text>
<text top="347" left="29" width="714" height="13" font="font3" id="p25_t15" reading_order_no="14" segment_no="9" tag_type="text">approximation for the adversarial example construction process to generate adversarial examples on the fly in the inner loop of </text>
<text top="368" left="29" width="712" height="13" font="font3" id="p25_t16" reading_order_no="15" segment_no="9" tag_type="text">training. This resulted in a model that was robust to adversarial examples made using the same attack algorithm but could be </text>
<text top="389" left="29" width="542" height="13" font="font3" id="p25_t17" reading_order_no="16" segment_no="9" tag_type="text">broken by other attack algorithms that used more computation. https://arxiv.org/abs/1412.6572</text>
</page>
<page number="26" position="absolute" top="0" left="0" height="612" width="792">
<text top="294" left="551" width="36" height="5" font="font4" id="p26_t1" reading_order_no="0" segment_no="8" tag_type="text">(Goodfellow 2018)</text>
<text top="47" left="233" width="326" height="27" font="font43" id="p26_t2" reading_order_no="1" segment_no="0" tag_type="title">Pipeline of Defense Failures</text>
<text top="282" left="242" width="28" height="14" font="font7" id="p26_t3" reading_order_no="2" segment_no="7" tag_type="text">No e</text>
<text top="282" left="270" width="8" height="15" font="font28" id="p26_t4" reading_order_no="3" segment_no="7" tag_type="text">ﬀ</text>
<text top="282" left="278" width="70" height="14" font="font7" id="p26_t5" reading_order_no="4" segment_no="7" tag_type="text">ect on advx</text>
<text top="255" left="261" width="311" height="14" font="font7" id="p26_t6" reading_order_no="5" segment_no="6" tag_type="text">Reduces advx, but reduces clean accuracy too much</text>
<text top="235" left="279" width="65" height="14" font="font7" id="p26_t7" reading_order_no="6" segment_no="5" tag_type="text">Does not a</text>
<text top="235" left="344" width="8" height="15" font="font28" id="p26_t8" reading_order_no="7" segment_no="5" tag_type="text">ﬀ</text>
<text top="235" left="352" width="125" height="14" font="font7" id="p26_t9" reading_order_no="8" segment_no="5" tag_type="text">ect adaptive attacker</text>
<text top="214" left="306" width="221" height="14" font="font7" id="p26_t10" reading_order_no="9" segment_no="4" tag_type="text">Does not generalize over attack algos</text>
<text top="190" left="328" width="233" height="14" font="font23" id="p26_t11" reading_order_no="10" segment_no="3" tag_type="text">Seems to generalize, but it’s an illusion</text>
<text top="174" left="355" width="232" height="14" font="font7" id="p26_t12" reading_order_no="11" segment_no="2" tag_type="text">Does not generalize over threat models</text>
<text top="112" left="325" width="127" height="14" font="font23" id="p26_t13" reading_order_no="12" segment_no="1" tag_type="text">Defensive Distillation</text>
<text top="326" left="29" width="737" height="13" font="font3" id="p26_t14" reading_order_no="13" segment_no="9" tag_type="text">Many defense algorithms seem to perform well against multiple adaptive attack algorithms, but then are later broken. This usually </text>
<text top="347" left="29" width="724" height="13" font="font3" id="p26_t15" reading_order_no="14" segment_no="9" tag_type="text">means that their apparent success was an illusion, for example due to gradient masking. In many cases, such broken defenses are </text>
<text top="368" left="29" width="717" height="13" font="font3" id="p26_t16" reading_order_no="15" segment_no="9" tag_type="text">still useful contributions to the literature, because they help to develop the stronger attacks that are used to reveal the illusion. </text>
<text top="409" left="29" width="191" height="13" font="font3" id="p26_t17" reading_order_no="16" segment_no="10" tag_type="text">https://arxiv.org/abs/1511.04508 </text>
<text top="430" left="29" width="191" height="13" font="font3" id="p26_t18" reading_order_no="17" segment_no="11" tag_type="text">https://arxiv.org/abs/1607.04311 </text>
</page>
<page number="27" position="absolute" top="0" left="0" height="612" width="792">
	<fontspec id="font45" size="13" family="LucidaGrande,Bold" color="#000000"/>
<text top="294" left="551" width="36" height="5" font="font4" id="p27_t1" reading_order_no="0" segment_no="8" tag_type="text">(Goodfellow 2018)</text>
<text top="47" left="233" width="326" height="27" font="font43" id="p27_t2" reading_order_no="1" segment_no="0" tag_type="title">Pipeline of Defense Failures</text>
<text top="282" left="242" width="28" height="14" font="font7" id="p27_t3" reading_order_no="2" segment_no="7" tag_type="text">No e</text>
<text top="282" left="270" width="8" height="15" font="font28" id="p27_t4" reading_order_no="3" segment_no="7" tag_type="text">ﬀ</text>
<text top="282" left="278" width="70" height="14" font="font7" id="p27_t5" reading_order_no="4" segment_no="7" tag_type="text">ect on advx</text>
<text top="255" left="261" width="311" height="14" font="font7" id="p27_t6" reading_order_no="5" segment_no="6" tag_type="text">Reduces advx, but reduces clean accuracy too much</text>
<text top="235" left="279" width="65" height="14" font="font7" id="p27_t7" reading_order_no="6" segment_no="5" tag_type="text">Does not a</text>
<text top="235" left="344" width="8" height="15" font="font28" id="p27_t8" reading_order_no="7" segment_no="5" tag_type="text">ﬀ</text>
<text top="235" left="352" width="125" height="14" font="font7" id="p27_t9" reading_order_no="8" segment_no="5" tag_type="text">ect adaptive attacker</text>
<text top="214" left="306" width="221" height="14" font="font7" id="p27_t10" reading_order_no="9" segment_no="4" tag_type="text">Does not generalize over attack algos</text>
<text top="190" left="328" width="233" height="14" font="font7" id="p27_t11" reading_order_no="10" segment_no="3" tag_type="text">Seems to generalize, but it’s an illusion</text>
<text top="174" left="355" width="232" height="14" font="font23" id="p27_t12" reading_order_no="11" segment_no="2" tag_type="text">Does not generalize over threat models</text>
<text top="92" left="261" width="253" height="14" font="font23" id="p27_t13" reading_order_no="12" segment_no="1" tag_type="text">Adversarial Training with a Strong Attack</text>
<text top="112" left="275" width="226" height="14" font="font23" id="p27_t14" reading_order_no="13" segment_no="1" tag_type="text">Current Certified / Provable Defenses</text>
<text top="326" left="29" width="711" height="13" font="font3" id="p27_t15" reading_order_no="14" segment_no="9" tag_type="text">The current state of the art defense ( https://arxiv.org/abs/1803.06373 ) is based on using a strong attack ( https://arxiv.org/</text>
<text top="347" left="29" width="629" height="13" font="font3" id="p27_t16" reading_order_no="15" segment_no="9" tag_type="text">abs/1706.06083 ) for adversarial training ( https://arxiv.org/abs/1412.6572 https://arxiv.org/abs/1611.01236 ). </text>
<text top="389" left="29" width="697" height="13" font="font3" id="p27_t17" reading_order_no="16" segment_no="10" tag_type="text">On MNIST in particular, Madry et al’s model is regarded as highly robust, after being subject to public scrutiny for several </text>
<text top="409" left="29" width="49" height="13" font="font3" id="p27_t18" reading_order_no="17" segment_no="10" tag_type="text">months. </text>
<text top="451" left="29" width="265" height="13" font="font3" id="p27_t19" reading_order_no="18" segment_no="11" tag_type="text">However, this robustness holds only within the </text>
<text top="451" left="294" width="8" height="12" font="font16" id="p27_t20" reading_order_no="19" segment_no="11" tag_type="text"><i>L</i></text>
<text top="453" left="302" width="11" height="12" font="font45" id="p27_t21" reading_order_no="20" segment_no="11" tag_type="text"><b>∞</b></text>
<text top="451" left="313" width="331" height="13" font="font3" id="p27_t22" reading_order_no="21" segment_no="11" tag_type="text"> ball. It is possible to break this model by switching to a di</text>
<text top="451" left="645" width="7" height="14" font="font11" id="p27_t23" reading_order_no="22" segment_no="11" tag_type="text">ﬀ</text>
<text top="451" left="652" width="112" height="13" font="font3" id="p27_t24" reading_order_no="23" segment_no="11" tag_type="text">erent threat model, </text>
<text top="472" left="29" width="302" height="13" font="font3" id="p27_t25" reading_order_no="24" segment_no="11" tag_type="text">even one that seems conceptually similar, such as the </text>
<text top="472" left="331" width="8" height="12" font="font16" id="p27_t26" reading_order_no="25" segment_no="11" tag_type="text"><i>L</i></text>
<text top="472" left="339" width="230" height="13" font="font3" id="p27_t27" reading_order_no="26" segment_no="11" tag_type="text">1 ball: https://arxiv.org/abs/1709.04114 </text>
<text top="513" left="29" width="723" height="13" font="font3" id="p27_t28" reading_order_no="27" segment_no="12" tag_type="text">This problem even applies to all existing certified defenses, because the certificates are specific to a particular norm ball: https://</text>
<text top="534" left="29" width="528" height="13" font="font3" id="p27_t29" reading_order_no="28" segment_no="12" tag_type="text">arxiv.org/abs/1801.09344 https://arxiv.org/abs/1803.06567 https://arxiv.org/abs/1711.00851 </text>
<text top="576" left="29" width="565" height="13" font="font3" id="p27_t30" reading_order_no="29" segment_no="13" tag_type="text">A late-breaking result is that GAN-based models can also produce adversarial examples that appear </text>
<text top="576" left="594" width="65" height="12" font="font16" id="p27_t31" reading_order_no="30" segment_no="13" tag_type="text"><i>unperturbed</i></text>
<text top="576" left="659" width="73" height="13" font="font3" id="p27_t32" reading_order_no="31" segment_no="13" tag_type="text"> to a human </text>
</page>
<page number="28" position="absolute" top="0" left="0" height="612" width="792">
	<fontspec id="font46" size="26" family="CMUSerif" color="#000000"/>
	<fontspec id="font47" size="9" family="CMUSerif" color="#000000"/>
	<fontspec id="font48" size="10" family="CMUSerif" color="#000000"/>
<text top="294" left="551" width="36" height="5" font="font4" id="p28_t1" reading_order_no="0" segment_no="5" tag_type="text">(Goodfellow 2018)</text>
<text top="47" left="211" width="371" height="26" font="font46" id="p28_t2" reading_order_no="1" segment_no="0" tag_type="title">Adversarial Logit Pairing (ALP)</text>
<text top="114" left="261" width="23" height="9" font="font47" id="p28_t3" reading_order_no="2" segment_no="1" tag_type="figure">clean </text>
<text top="127" left="261" width="21" height="9" font="font47" id="p28_t4" reading_order_no="3" segment_no="1" tag_type="figure">logits</text>
<text top="114" left="382" width="17" height="9" font="font47" id="p28_t5" reading_order_no="4" segment_no="1" tag_type="figure">adv </text>
<text top="127" left="379" width="21" height="9" font="font47" id="p28_t6" reading_order_no="5" segment_no="1" tag_type="figure">logits</text>
<text top="275" left="280" width="110" height="10" font="font48" id="p28_t7" reading_order_no="6" segment_no="1" tag_type="figure">Adversarial perturbation</text>
<text top="74" left="299" width="58" height="10" font="font48" id="p28_t8" reading_order_no="7" segment_no="1" tag_type="figure">Logit pairing</text>
<text top="89" left="464" width="92" height="14" font="font7" id="p28_t9" reading_order_no="8" segment_no="2" tag_type="text">First approach </text>
<text top="108" left="458" width="104" height="14" font="font7" id="p28_t10" reading_order_no="9" segment_no="2" tag_type="text">to achieve &gt;50% </text>
<text top="127" left="464" width="92" height="14" font="font7" id="p28_t11" reading_order_no="10" segment_no="2" tag_type="text">top-5 accuracy </text>
<text top="146" left="459" width="101" height="14" font="font7" id="p28_t12" reading_order_no="11" segment_no="2" tag_type="text">against iterative </text>
<text top="165" left="446" width="128" height="14" font="font7" id="p28_t13" reading_order_no="12" segment_no="2" tag_type="text">adversarial examples </text>
<text top="183" left="469" width="76" height="14" font="font7" id="p28_t14" reading_order_no="13" segment_no="2" tag_type="text">on ImageNet</text>
<text top="207" left="467" width="85" height="14" font="font7" id="p28_t15" reading_order_no="14" segment_no="3" tag_type="text">Current state </text>
<text top="226" left="479" width="56" height="14" font="font7" id="p28_t16" reading_order_no="15" segment_no="3" tag_type="text">of the art</text>
<text top="291" left="270" width="120" height="14" font="font7" id="p28_t17" reading_order_no="16" segment_no="4" tag_type="text">(Kannan et al 2018)</text>
<text top="326" left="29" width="335" height="13" font="font3" id="p28_t18" reading_order_no="17" segment_no="6" tag_type="text">For more information, see https://arxiv.org/abs/1803.06373</text>
</page>
<page number="29" position="absolute" top="0" left="0" height="612" width="792">
<text top="294" left="551" width="36" height="5" font="font4" id="p29_t1" reading_order_no="0" segment_no="7" tag_type="text">(Goodfellow 2018)</text>
<text top="32" left="245" width="309" height="24" font="font13" id="p29_t2" reading_order_no="1" segment_no="0" tag_type="title">Timeline of Defenses Against </text>
<text top="65" left="284" width="224" height="24" font="font13" id="p29_t3" reading_order_no="2" segment_no="0" tag_type="title">Adversarial Examples</text>
<text top="278" left="277" width="294" height="14" font="font7" id="p29_t4" reading_order_no="3" segment_no="6" tag_type="text">Szegedy et al 2013: train on adversarial examples</text>
<text top="230" left="303" width="293" height="14" font="font7" id="p29_t5" reading_order_no="4" segment_no="5" tag_type="text">Goodfellow et al 2014: generate them constantly </text>
<text top="249" left="303" width="234" height="14" font="font7" id="p29_t6" reading_order_no="5" segment_no="5" tag_type="text">in the inner loop of training (minimax)</text>
<text top="202" left="318" width="253" height="14" font="font7" id="p29_t7" reading_order_no="6" segment_no="3" tag_type="text">Kurakin et al 2016: use an iterative attack</text>
<text top="144" left="330" width="251" height="14" font="font7" id="p29_t8" reading_order_no="7" segment_no="2" tag_type="text">Madry et al 2017: randomize the starting </text>
<text top="163" left="330" width="251" height="14" font="font7" id="p29_t9" reading_order_no="8" segment_no="2" tag_type="text">point of the attack. 1st to generalize over </text>
<text top="182" left="330" width="105" height="14" font="font7" id="p29_t10" reading_order_no="9" segment_no="2" tag_type="text">attack algorithms</text>
<text top="115" left="371" width="191" height="14" font="font7" id="p29_t11" reading_order_no="10" segment_no="1" tag_type="text">Kannan et al 2018: logit pairing</text>
<text top="213" left="207" width="61" height="14" font="font7" id="p29_t12" reading_order_no="11" segment_no="4" tag_type="text">Pre-2013: </text>
<text top="232" left="207" width="76" height="14" font="font7" id="p29_t13" reading_order_no="12" segment_no="4" tag_type="text">Defenses for </text>
<text top="251" left="207" width="86" height="14" font="font7" id="p29_t14" reading_order_no="13" segment_no="4" tag_type="text">convex models</text>
<text top="326" left="29" width="218" height="13" font="font3" id="p29_t15" reading_order_no="14" segment_no="8" tag_type="text">2013: https://arxiv.org/abs/1312.6199 </text>
<text top="347" left="29" width="218" height="13" font="font3" id="p29_t16" reading_order_no="15" segment_no="9" tag_type="text">2014: https://arxiv.org/abs/1412.6572 </text>
<text top="368" left="29" width="224" height="13" font="font3" id="p29_t17" reading_order_no="16" segment_no="10" tag_type="text">2016: https://arxiv.org/abs/1611.01236 </text>
<text top="389" left="29" width="224" height="13" font="font3" id="p29_t18" reading_order_no="17" segment_no="11" tag_type="text">2017: https://arxiv.org/abs/1706.06083 </text>
<text top="409" left="29" width="224" height="13" font="font3" id="p29_t19" reading_order_no="18" segment_no="12" tag_type="text">2018: https://arxiv.org/abs/1803.06373 </text>
<text top="451" left="29" width="438" height="13" font="font3" id="p29_t20" reading_order_no="19" segment_no="13" tag_type="text">( There has also been earlier work on securing convex models, which is very di</text>
<text top="451" left="467" width="7" height="14" font="font11" id="p29_t21" reading_order_no="20" segment_no="13" tag_type="text">ﬀ</text>
<text top="451" left="475" width="254" height="13" font="font3" id="p29_t22" reading_order_no="21" segment_no="13" tag_type="text">erent from securing neural nets, e.g.: https://</text>
<text top="472" left="29" width="615" height="13" font="font3" id="p29_t23" reading_order_no="22" segment_no="13" tag_type="text">homes.cs.washington.edu/~pedrod/papers/kdd04.pdf https://cs.nyu.edu/~roweis/papers/robust_icml06.pdf )</text>
</page>
<page number="30" position="absolute" top="0" left="0" height="612" width="792">
<text top="294" left="551" width="36" height="5" font="font4" id="p30_t1" reading_order_no="0" segment_no="3" tag_type="text">(Goodfellow 2018)</text>
<text top="49" left="221" width="354" height="23" font="font12" id="p30_t2" reading_order_no="1" segment_no="0" tag_type="title">Disappointing outcome of toy game</text>
<text top="96" left="232" width="5" height="10" font="font15" id="p30_t3" reading_order_no="2" segment_no="1" tag_type="list">•</text>
<text top="95" left="245" width="303" height="14" font="font7" id="p30_t4" reading_order_no="3" segment_no="1" tag_type="list">My hope: something simple (Bayesian deep nets?) </text>
<text top="114" left="245" width="308" height="14" font="font7" id="p30_t5" reading_order_no="4" segment_no="1" tag_type="list">will solve the adversarial example problem, do well </text>
<text top="133" left="245" width="299" height="14" font="font7" id="p30_t6" reading_order_no="5" segment_no="1" tag_type="list">on the points we can measure via norm ball label </text>
<text top="152" left="245" width="314" height="14" font="font7" id="p30_t7" reading_order_no="6" segment_no="1" tag_type="list">propagation, also do well on points that are hard to </text>
<text top="171" left="245" width="53" height="14" font="font7" id="p30_t8" reading_order_no="7" segment_no="1" tag_type="list">measure </text>
<text top="207" left="232" width="5" height="10" font="font15" id="p30_t9" reading_order_no="8" segment_no="2" tag_type="list">•</text>
<text top="206" left="245" width="270" height="14" font="font7" id="p30_t10" reading_order_no="9" segment_no="2" tag_type="list">Outcome so far: best results are obtained by </text>
<text top="225" left="245" width="309" height="14" font="font7" id="p30_t11" reading_order_no="10" segment_no="2" tag_type="list">directly optimizing the performance measure. Both </text>
<text top="244" left="245" width="309" height="14" font="font7" id="p30_t12" reading_order_no="11" segment_no="2" tag_type="list">for empirical and for certified approaches. Defenses </text>
<text top="263" left="245" width="231" height="14" font="font7" id="p30_t13" reading_order_no="12" segment_no="2" tag_type="list">do not generalize out of the norm ball.</text>
</page>
<page number="31" position="absolute" top="0" left="0" height="612" width="792">
<text top="294" left="551" width="36" height="5" font="font4" id="p31_t1" reading_order_no="0" segment_no="7" tag_type="text">(Goodfellow 2018)</text>
<text top="32" left="258" width="284" height="24" font="font13" id="p31_t2" reading_order_no="1" segment_no="0" tag_type="title">Future Directions: Indirect </text>
<text top="65" left="351" width="89" height="24" font="font13" id="p31_t3" reading_order_no="2" segment_no="0" tag_type="title">Methods</text>
<text top="95" left="232" width="5" height="9" font="font10" id="p31_t4" reading_order_no="3" segment_no="1" tag_type="list">•</text>
<text top="94" left="244" width="290" height="12" font="font32" id="p31_t5" reading_order_no="4" segment_no="1" tag_type="list">Do not just optimize the performance measure exactly </text>
<text top="126" left="232" width="5" height="9" font="font10" id="p31_t6" reading_order_no="5" segment_no="2" tag_type="list">•</text>
<text top="125" left="244" width="112" height="12" font="font32" id="p31_t7" reading_order_no="6" segment_no="2" tag_type="list">Best methods so far: </text>
<text top="157" left="245" width="5" height="9" font="font10" id="p31_t8" reading_order_no="7" segment_no="3" tag_type="list">•</text>
<text top="156" left="257" width="166" height="12" font="font32" id="p31_t9" reading_order_no="8" segment_no="3" tag_type="list">Logit pairing (non-adversarial) </text>
<text top="187" left="245" width="5" height="9" font="font10" id="p31_t10" reading_order_no="9" segment_no="4" tag_type="list">•</text>
<text top="186" left="257" width="92" height="12" font="font32" id="p31_t11" reading_order_no="10" segment_no="4" tag_type="list">Label smoothing </text>
<text top="218" left="245" width="5" height="9" font="font10" id="p31_t12" reading_order_no="11" segment_no="5" tag_type="list">•</text>
<text top="217" left="257" width="85" height="12" font="font32" id="p31_t13" reading_order_no="12" segment_no="5" tag_type="list">Logit squeezing </text>
<text top="249" left="232" width="5" height="9" font="font10" id="p31_t14" reading_order_no="13" segment_no="6" tag_type="list">•</text>
<text top="248" left="244" width="305" height="12" font="font32" id="p31_t15" reading_order_no="14" segment_no="6" tag_type="list">Can we perform a lot better with other methods that are </text>
<text top="265" left="244" width="95" height="12" font="font32" id="p31_t16" reading_order_no="15" segment_no="6" tag_type="list">similarly indirect?</text>
<text top="326" left="29" width="187" height="13" font="font3" id="p31_t17" reading_order_no="16" segment_no="8" tag_type="text">https://books.google.com/books?</text>
<text top="347" left="29" width="731" height="13" font="font3" id="p31_t18" reading_order_no="17" segment_no="9" tag_type="text">hl=en&amp;lr=&amp;id=F4c3DwAAQBAJ&amp;oi=fnd&amp;pg=PA311&amp;dq=info:J1EtPob5tcoJ:scholar.google.com&amp;ots=idBTNGuyP8&amp;sig=HMrj</text>
<text top="368" left="29" width="660" height="13" font="font3" id="p31_t19" reading_order_no="18" segment_no="9" tag_type="text">cmrn_fs2-kyaAo-XNr1Expo#v=onepage&amp;q&amp;f=false observed that label smoothing helps resist adversarial examples. </text>
<text top="409" left="29" width="738" height="13" font="font3" id="p31_t20" reading_order_no="19" segment_no="10" tag_type="text">https://arxiv.org/abs/1803.06373 observed that a few non-adversarial methods of regularizing the logits of a model help it to resist </text>
<text top="430" left="29" width="123" height="13" font="font3" id="p31_t21" reading_order_no="20" segment_no="10" tag_type="text">adversarial examples. </text>
<text top="472" left="29" width="703" height="13" font="font3" id="p31_t22" reading_order_no="21" segment_no="11" tag_type="text">So far, these are the only methods of resisting adversarial examples I know of that are not based on directly optimizing some </text>
<text top="493" left="29" width="731" height="13" font="font3" id="p31_t23" reading_order_no="22" segment_no="11" tag_type="text">definition of adversarial error rate. I think an important research direction is to find other methods that are similarly indirect and </text>
<text top="513" left="29" width="696" height="13" font="font3" id="p31_t24" reading_order_no="23" segment_no="11" tag_type="text">yet perform well. These methods seem most likely to generalize beyond a specific attack model, because they do not involve </text>
<text top="534" left="29" width="348" height="13" font="font3" id="p31_t25" reading_order_no="24" segment_no="11" tag_type="text">optimizing directly for performance under that specific attack.</text>
</page>
<page number="32" position="absolute" top="0" left="0" height="612" width="792">
<text top="294" left="551" width="36" height="5" font="font4" id="p32_t1" reading_order_no="0" segment_no="5" tag_type="text">(Goodfellow 2018)</text>
<text top="32" left="265" width="269" height="24" font="font13" id="p32_t2" reading_order_no="1" segment_no="0" tag_type="title">Future Directions: Better </text>
<text top="65" left="320" width="151" height="24" font="font13" id="p32_t3" reading_order_no="2" segment_no="0" tag_type="title">Attack Models</text>
<text top="109" left="232" width="5" height="10" font="font15" id="p32_t4" reading_order_no="3" segment_no="1" tag_type="list">•</text>
<text top="108" left="245" width="280" height="14" font="font7" id="p32_t5" reading_order_no="4" segment_no="1" tag_type="list">Add new attack models other than norm balls </text>
<text top="143" left="232" width="5" height="10" font="font15" id="p32_t6" reading_order_no="5" segment_no="2" tag_type="list">•</text>
<text top="143" left="245" width="309" height="14" font="font7" id="p32_t7" reading_order_no="6" segment_no="2" tag_type="list">Study messy real problems in addition to clean toy </text>
<text top="162" left="245" width="58" height="14" font="font7" id="p32_t8" reading_order_no="7" segment_no="2" tag_type="list">problems </text>
<text top="197" left="232" width="5" height="10" font="font15" id="p32_t9" reading_order_no="8" segment_no="3" tag_type="list">•</text>
<text top="197" left="245" width="294" height="14" font="font7" id="p32_t10" reading_order_no="9" segment_no="3" tag_type="list">Study certification methods that use other proof </text>
<text top="215" left="245" width="212" height="14" font="font7" id="p32_t11" reading_order_no="10" segment_no="3" tag_type="list">strategies besides local smoothness </text>
<text top="251" left="232" width="5" height="10" font="font15" id="p32_t12" reading_order_no="11" segment_no="4" tag_type="list">•</text>
<text top="250" left="245" width="234" height="14" font="font7" id="p32_t13" reading_order_no="12" segment_no="4" tag_type="list">Study more problems other than vision</text>
</page>
<page number="33" position="absolute" top="0" left="0" height="612" width="792">
	<fontspec id="font49" size="18" family="CMUSerif" color="#000000"/>
<text top="294" left="551" width="36" height="5" font="font4" id="p33_t1" reading_order_no="0" segment_no="10" tag_type="text">(Goodfellow 2018)</text>
<text top="38" left="234" width="331" height="19" font="font49" id="p33_t2" reading_order_no="1" segment_no="0" tag_type="title">Future Directions: Security Independent </text>
<text top="64" left="244" width="304" height="19" font="font49" id="p33_t3" reading_order_no="2" segment_no="0" tag_type="title">from Traditional Supervised Learning</text>
<text top="98" left="232" width="4" height="8" font="font14" id="p33_t4" reading_order_no="3" segment_no="1" tag_type="list">•</text>
<text top="97" left="240" width="294" height="10" font="font15" id="p33_t5" reading_order_no="4" segment_no="1" tag_type="list">Until recently, both adversarial example research and traditional </text>
<text top="108" left="240" width="312" height="10" font="font15" id="p33_t6" reading_order_no="5" segment_no="1" tag_type="list">supervised learning seemed fully aligned: just make the model better </text>
<text top="123" left="232" width="4" height="8" font="font14" id="p33_t7" reading_order_no="6" segment_no="2" tag_type="list">•</text>
<text top="122" left="240" width="115" height="10" font="font15" id="p33_t8" reading_order_no="7" segment_no="2" tag_type="list">They still share this goal </text>
<text top="137" left="232" width="4" height="8" font="font14" id="p33_t9" reading_order_no="8" segment_no="3" tag_type="list">•</text>
<text top="135" left="240" width="307" height="10" font="font15" id="p33_t10" reading_order_no="9" segment_no="3" tag_type="list">It is now clear security research must have some independent goals. </text>
<text top="147" left="240" width="319" height="10" font="font15" id="p33_t11" reading_order_no="10" segment_no="3" tag_type="list">For two models with the same error volume, for reasons of security we </text>
<text top="159" left="240" width="32" height="10" font="font15" id="p33_t12" reading_order_no="11" segment_no="3" tag_type="list">prefer: </text>
<text top="173" left="245" width="4" height="8" font="font14" id="p33_t13" reading_order_no="12" segment_no="4" tag_type="list">•</text>
<text top="172" left="254" width="207" height="10" font="font15" id="p33_t14" reading_order_no="13" segment_no="4" tag_type="list">The model with lower confidence on mistakes </text>
<text top="187" left="245" width="4" height="8" font="font14" id="p33_t15" reading_order_no="14" segment_no="5" tag_type="list">•</text>
<text top="186" left="254" width="206" height="10" font="font15" id="p33_t16" reading_order_no="15" segment_no="5" tag_type="list">The model whose mistakes are harder to find </text>
<text top="200" left="245" width="4" height="8" font="font14" id="p33_t17" reading_order_no="16" segment_no="6" tag_type="list">•</text>
<text top="199" left="254" width="273" height="10" font="font15" id="p33_t18" reading_order_no="17" segment_no="6" tag_type="list">A stochastic model that does not repeatedly make the same </text>
<text top="211" left="254" width="123" height="10" font="font15" id="p33_t19" reading_order_no="18" segment_no="6" tag_type="list">mistake on the same input </text>
<text top="226" left="245" width="4" height="8" font="font14" id="p33_t20" reading_order_no="19" segment_no="7" tag_type="list">•</text>
<text top="224" left="254" width="298" height="10" font="font15" id="p33_t21" reading_order_no="20" segment_no="7" tag_type="list">A model whose mistakes are less valuable to the attacker / costly </text>
<text top="236" left="254" width="72" height="10" font="font15" id="p33_t22" reading_order_no="21" segment_no="7" tag_type="list">to the defender </text>
<text top="251" left="245" width="4" height="8" font="font14" id="p33_t23" reading_order_no="22" segment_no="8" tag_type="list">•</text>
<text top="250" left="254" width="250" height="10" font="font15" id="p33_t24" reading_order_no="23" segment_no="8" tag_type="list">A model that is harder to reverse engineer with probes </text>
<text top="264" left="245" width="4" height="8" font="font14" id="p33_t25" reading_order_no="24" segment_no="9" tag_type="list">•</text>
<text top="263" left="254" width="262" height="10" font="font15" id="p33_t26" reading_order_no="25" segment_no="9" tag_type="list">A model that is less prone to transfer from related models</text>
</page>
<page number="34" position="absolute" top="0" left="0" height="612" width="792">
<text top="294" left="551" width="36" height="5" font="font4" id="p34_t1" reading_order_no="1" segment_no="7" tag_type="text">(Goodfellow 2018)</text>
<text top="32" left="237" width="325" height="24" font="font13" id="p34_t2" reading_order_no="2" segment_no="0" tag_type="title">Some Non-Security Reasons to </text>
<text top="65" left="249" width="293" height="24" font="font13" id="p34_t3" reading_order_no="3" segment_no="0" tag_type="title">Study Adversarial Examples</text>
<text top="288" left="217" width="131" height="14" font="font7" id="p34_t4" reading_order_no="4" segment_no="6" tag_type="text">Gamaleldin et al 2018</text>
<text top="145" left="203" width="190" height="14" font="font7" id="p34_t5" reading_order_no="5" segment_no="4" tag_type="text">Understand Human Perception </text>
<text top="101" left="219" width="179" height="14" font="font7" id="p34_t6" reading_order_no="6" segment_no="1" tag_type="text">Improve Supervised Learning </text>
<text top="120" left="236" width="140" height="14" font="font7" id="p34_t7" reading_order_no="7" segment_no="1" tag_type="text">(Goodfellow et al 2014)</text>
<text top="101" left="420" width="155" height="14" font="font7" id="p34_t8" reading_order_no="8" segment_no="2" tag_type="text">Improve Semi-Supervised </text>
<text top="120" left="469" width="57" height="14" font="font7" id="p34_t9" reading_order_no="9" segment_no="2" tag_type="text">Learning </text>
<text top="139" left="438" width="115" height="14" font="font7" id="p34_t10" reading_order_no="0" segment_no="3" tag_type="text">(Miyato et al 2015)</text>
<text top="264" left="410" width="118" height="14" font="font7" id="p34_t11" reading_order_no="10" segment_no="5" tag_type="text">(Oliver+Odena+Ra</text>
<text top="264" left="528" width="8" height="15" font="font28" id="p34_t12" reading_order_no="11" segment_no="5" tag_type="text">ﬀ</text>
<text top="264" left="536" width="49" height="14" font="font7" id="p34_t13" reading_order_no="12" segment_no="5" tag_type="text">el et al, </text>
<text top="283" left="479" width="33" height="14" font="font7" id="p34_t14" reading_order_no="13" segment_no="5" tag_type="text">2018)</text>
<text top="326" left="29" width="510" height="13" font="font3" id="p34_t15" reading_order_no="14" segment_no="8" tag_type="text">My recommendations today have mostly focused on how to make machine learning secure. </text>
<text top="368" left="29" width="555" height="13" font="font3" id="p34_t16" reading_order_no="15" segment_no="9" tag_type="text">This is distinct from the question of what research should be done regarding adversarial examples. </text>
<text top="409" left="29" width="725" height="13" font="font3" id="p34_t17" reading_order_no="16" segment_no="10" tag_type="text">Studying adversarial examples has improved supervised learning temporarily in the past ( https://arxiv.org/abs/1412.6572 ) and </text>
<text top="430" left="29" width="720" height="13" font="font3" id="p34_t18" reading_order_no="17" segment_no="10" tag_type="text">may make a more lasting improvement to supervised learning in the future. Studying adversarial examples has certainly made a </text>
<text top="451" left="29" width="730" height="13" font="font3" id="p34_t19" reading_order_no="18" segment_no="10" tag_type="text">significant contribution to semi-supervised learning: virtual adversarial training ( https://arxiv.org/abs/1507.00677 ) was the best </text>
<text top="472" left="29" width="516" height="13" font="font3" id="p34_t20" reading_order_no="19" segment_no="10" tag_type="text">performing method in a recent exhaustive benchmark ( https://arxiv.org/abs/1804.09170 ). </text>
<text top="513" left="29" width="647" height="13" font="font3" id="p34_t21" reading_order_no="20" segment_no="11" tag_type="text">Studying adversarial examples may also help to understand the human brain ( https://arxiv.org/abs/1802.08195 ). </text>
<text top="555" left="29" width="562" height="13" font="font3" id="p34_t22" reading_order_no="21" segment_no="12" tag_type="text">Besides these applications, many other applications such as model-based optimization seem possible.</text>
</page>
<page number="35" position="absolute" top="0" left="0" height="612" width="792">
<text top="294" left="551" width="36" height="5" font="font4" id="p35_t1" reading_order_no="0" segment_no="2" tag_type="text">(Goodfellow 2018)</text>
<text top="46" left="316" width="161" height="31" font="font5" id="p35_t2" reading_order_no="1" segment_no="0" tag_type="title">Clever Hans</text>
<text top="94" left="492" width="91" height="14" font="font7" id="p35_t3" reading_order_no="2" segment_no="1" tag_type="text">(“Clever Hans, </text>
<text top="113" left="517" width="42" height="14" font="font7" id="p35_t4" reading_order_no="3" segment_no="1" tag_type="text">Clever </text>
<text top="132" left="498" width="79" height="14" font="font7" id="p35_t5" reading_order_no="4" segment_no="1" tag_type="text">Algorithms,” </text>
<text top="151" left="500" width="71" height="14" font="font7" id="p35_t6" reading_order_no="5" segment_no="1" tag_type="text">Bob Sturm)</text>
</page>
<page number="36" position="absolute" top="0" left="0" height="612" width="792">
<text top="294" left="551" width="36" height="5" font="font4" id="p36_t1" reading_order_no="0" segment_no="2" tag_type="text">(Goodfellow 2018)</text>
<text top="46" left="308" width="176" height="31" font="font5" id="p36_t2" reading_order_no="1" segment_no="0" tag_type="title">Get involved!</text>
<text top="82" left="288" width="250" height="14" font="font7" id="p36_t3" reading_order_no="2" segment_no="1" tag_type="text">https://github.com/tensorflow/cleverhans</text>
</page>
</pdf2xml>
