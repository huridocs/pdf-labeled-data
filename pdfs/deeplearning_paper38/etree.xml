<!DOCTYPE pdf2xml SYSTEM "pdf2xml.dtd">
<pdf2xml producer="poppler" version="23.04.0">
<page number="1" position="absolute" top="0" left="0" height="793" width="595">
	<fontspec id="font0" size="17" family="STIXGeneral" color="#000000"/>
	<fontspec id="font1" size="12" family="STIXGeneral" color="#000000"/>
	<fontspec id="font2" size="12" family="STIXGeneral" color="#7f7f7f"/>
	<fontspec id="font3" size="8" family="STIXGeneral,Italic" color="#000000"/>
	<fontspec id="font4" size="8" family="STIXGeneral" color="#000000"/>
	<fontspec id="font5" size="8" family="STIXMath" color="#000000"/>
	<fontspec id="font6" size="6" family="STIXGeneral,Italic" color="#000000"/>
	<fontspec id="font7" size="10" family="STIXGeneral" color="#000000"/>
	<fontspec id="font8" size="12" family="STIXGeneral,Bold" color="#000000"/>
	<fontspec id="font9" size="10" family="STIXGeneral" color="#2f4f4f"/>
	<fontspec id="font10" size="6" family="STIXMath" color="#000000"/>
	<fontspec id="font11" size="7" family="Inconsolatazi4" color="#000000"/>
	<fontspec id="font12" size="10" family="STIXGeneral,Italic" color="#000000"/>
	<fontspec id="font13" size="9" family="SFSS0900" color="#000000"/>
	<fontspec id="font14" size="9" family="STIXGeneral,Italic" color="#000000"/>
	<fontspec id="font15" size="20" family="Times" color="#7f7f7f"/>
<text top="51" left="51" width="493" height="22" font="font0" id="p1_t1" reading_order_no="1" segment_no="0" tag_type="title">A Comparison for Patch-level Classification of Deep Learning Methods</text>
<text top="72" left="51" width="491" height="22" font="font0" id="p1_t2" reading_order_no="2" segment_no="0" tag_type="title">on Transparent Images: from Convolutional Neural Networks to Visual</text>
<text top="94" left="51" width="92" height="22" font="font0" id="p1_t3" reading_order_no="3" segment_no="0" tag_type="title">Transformers</text>
<text top="125" left="51" width="36" height="16" font="font1" id="p1_t4" reading_order_no="4" segment_no="1" tag_type="text">Hechen</text>
<text top="125" left="91" width="25" height="16" font="font2" id="p1_t5" reading_order_no="5" segment_no="1" tag_type="text">Yang</text>
<text top="127" left="116" width="4" height="7" font="font3" id="p1_t6" reading_order_no="6" segment_no="1" tag_type="text"><i>a</i></text>
<text top="125" left="120" width="34" height="16" font="font1" id="p1_t7" reading_order_no="7" segment_no="1" tag_type="text">, Chen</text>
<text top="125" left="157" width="11" height="16" font="font2" id="p1_t8" reading_order_no="8" segment_no="1" tag_type="text">Li</text>
<text top="127" left="168" width="4" height="7" font="font3" id="p1_t9" reading_order_no="9" segment_no="1" tag_type="text"><i>a</i></text>
<text top="125" left="172" width="2" height="10" font="font4" id="p1_t10" reading_order_no="10" segment_no="1" tag_type="text">,</text>
<text top="127" left="174" width="4" height="7" font="font5" id="p1_t11" reading_order_no="11" segment_no="1" tag_type="text">∗</text>
<text top="125" left="179" width="33" height="16" font="font1" id="p1_t12" reading_order_no="12" segment_no="1" tag_type="text">, Peng</text>
<text top="125" left="214" width="25" height="16" font="font2" id="p1_t13" reading_order_no="13" segment_no="1" tag_type="text">Zhao</text>
<text top="127" left="239" width="4" height="7" font="font3" id="p1_t14" reading_order_no="14" segment_no="1" tag_type="text"><i>a</i></text>
<text top="125" left="243" width="23" height="16" font="font1" id="p1_t15" reading_order_no="15" segment_no="1" tag_type="text">, Ao</text>
<text top="125" left="270" width="25" height="16" font="font2" id="p1_t16" reading_order_no="16" segment_no="1" tag_type="text">Chen</text>
<text top="127" left="295" width="4" height="7" font="font3" id="p1_t17" reading_order_no="17" segment_no="1" tag_type="text"><i>a</i></text>
<text top="125" left="299" width="27" height="16" font="font1" id="p1_t18" reading_order_no="18" segment_no="1" tag_type="text">, Xin</text>
<text top="125" left="329" width="25" height="16" font="font2" id="p1_t19" reading_order_no="19" segment_no="1" tag_type="text">Zhao</text>
<text top="127" left="354" width="4" height="7" font="font3" id="p1_t20" reading_order_no="20" segment_no="1" tag_type="text"><i>a</i></text>
<text top="125" left="361" width="17" height="16" font="font1" id="p1_t21" reading_order_no="21" segment_no="1" tag_type="text">and</text>
<text top="125" left="384" width="35" height="16" font="font2" id="p1_t22" reading_order_no="22" segment_no="1" tag_type="text">Marcin</text>
<text top="125" left="422" width="56" height="16" font="font1" id="p1_t23" reading_order_no="23" segment_no="1" tag_type="text">Grzegorzek</text>
<text top="127" left="478" width="4" height="7" font="font3" id="p1_t24" reading_order_no="24" segment_no="1" tag_type="text"><i>b</i></text>
<text top="151" left="51" width="3" height="5" font="font6" id="p1_t25" reading_order_no="25" segment_no="2" tag_type="text"><i>a</i></text>
<text top="153" left="55" width="405" height="7" font="font3" id="p1_t26" reading_order_no="26" segment_no="2" tag_type="text"><i>Microscopic Image and Medical Image Analysis Group, MBIE College, Northeastern University, 110169, Shenyang, PR China</i></text>
<text top="163" left="51" width="3" height="5" font="font6" id="p1_t27" reading_order_no="27" segment_no="2" tag_type="text"><i>b</i></text>
<text top="164" left="55" width="239" height="7" font="font3" id="p1_t28" reading_order_no="28" segment_no="2" tag_type="text"><i>Institute of Medical Informatics, University of Luebeck, Luebeck, Germany</i></text>
<text top="187" left="51" width="85" height="13" font="font7" id="p1_t29" reading_order_no="29" segment_no="3" tag_type="title">A R T I C L E I N F O</text>
<text top="210" left="51" width="31" height="7" font="font3" id="p1_t30" reading_order_no="30" segment_no="5" tag_type="title"><i>Keywords</i></text>
<text top="207" left="83" width="2" height="10" font="font4" id="p1_t31" reading_order_no="31" segment_no="5" tag_type="title">:</text>
<text top="217" left="53" width="34" height="10" font="font4" id="p1_t32" reading_order_no="32" segment_no="7" tag_type="list">patch level</text>
<text top="226" left="53" width="63" height="10" font="font4" id="p1_t33" reading_order_no="33" segment_no="7" tag_type="list">image classification</text>
<text top="236" left="53" width="63" height="10" font="font4" id="p1_t34" reading_order_no="34" segment_no="7" tag_type="list">Transparent Images</text>
<text top="245" left="53" width="43" height="10" font="font4" id="p1_t35" reading_order_no="35" segment_no="7" tag_type="list">deep learning</text>
<text top="255" left="53" width="98" height="10" font="font4" id="p1_t36" reading_order_no="36" segment_no="7" tag_type="list">Convolutional Neural Network</text>
<text top="264" left="53" width="58" height="10" font="font4" id="p1_t37" reading_order_no="37" segment_no="7" tag_type="list">visual transformer</text>
<text top="188" left="224" width="64" height="13" font="font7" id="p1_t38" reading_order_no="38" segment_no="4" tag_type="title">A B S T R A C T</text>
<text top="207" left="224" width="320" height="10" font="font4" id="p1_t39" reading_order_no="39" segment_no="6" tag_type="text">Nowadays, analysis of transparent images in the field of computer vision has gradually become a</text>
<text top="217" left="224" width="320" height="10" font="font4" id="p1_t40" reading_order_no="40" segment_no="6" tag_type="text">hot spot. In this paper, we compare the classification performance of different deep learning for the</text>
<text top="226" left="224" width="320" height="10" font="font4" id="p1_t41" reading_order_no="41" segment_no="6" tag_type="text">problem that transparent images are difficult to analyze. We crop the transparent images into 8×8 and</text>
<text top="236" left="224" width="320" height="10" font="font4" id="p1_t42" reading_order_no="42" segment_no="6" tag_type="text">224×224 pixels patches in the same proportion, and then divide the two different pixels patches into</text>
<text top="245" left="224" width="320" height="10" font="font4" id="p1_t43" reading_order_no="43" segment_no="6" tag_type="text">foreground and background according to groundtruch. We also use 4 types of convolutional neural</text>
<text top="255" left="224" width="320" height="10" font="font4" id="p1_t44" reading_order_no="44" segment_no="6" tag_type="text">networks and a novel ViT network model to compare the foreground and background classification</text>
<text top="264" left="224" width="229" height="10" font="font4" id="p1_t45" reading_order_no="45" segment_no="6" tag_type="text">experiments. We conclude that ViT performs the worst in classifying</text>
<text top="266" left="455" width="18" height="7" font="font5" id="p1_t46" reading_order_no="46" segment_no="6" tag_type="text">8 × 8</text>
<text top="264" left="476" width="68" height="10" font="font4" id="p1_t47" reading_order_no="47" segment_no="6" tag_type="text">pixels patches, but it</text>
<text top="274" left="224" width="199" height="10" font="font4" id="p1_t48" reading_order_no="48" segment_no="6" tag_type="text">outperforms most convolutional neural networks in classifying</text>
<text top="276" left="425" width="33" height="7" font="font5" id="p1_t49" reading_order_no="49" segment_no="6" tag_type="text">224 × 224</text>
<text top="274" left="458" width="2" height="10" font="font4" id="p1_t50" reading_order_no="50" segment_no="6" tag_type="text">.</text>
<text top="307" left="51" width="80" height="11" font="font8" id="p1_t51" reading_order_no="51" segment_no="9" tag_type="title"><b>1. Introduction</b></text>
<text top="321" left="66" width="222" height="13" font="font7" id="p1_t52" reading_order_no="52" segment_no="10" tag_type="text">With the advent of the era of science and technology,</text>
<text top="333" left="51" width="237" height="13" font="font7" id="p1_t53" reading_order_no="53" segment_no="10" tag_type="text">the application of transparent images has become more and</text>
<text top="345" left="51" width="237" height="13" font="font7" id="p1_t54" reading_order_no="54" segment_no="10" tag_type="text">more widely used in various fields around humans, such as</text>
<text top="357" left="51" width="237" height="13" font="font7" id="p1_t55" reading_order_no="55" segment_no="10" tag_type="text">the segmentation of renal transparent cancer cell nuclei in</text>
<text top="369" left="51" width="42" height="13" font="font7" id="p1_t56" reading_order_no="56" segment_no="10" tag_type="text">medicine <a href="deeplearning_paper38.html#10">[</a></text>
<text top="369" left="93" width="5" height="13" font="font9" id="p1_t57" reading_order_no="57" segment_no="10" tag_type="text"><a href="deeplearning_paper38.html#10">1</a></text>
<text top="369" left="98" width="190" height="13" font="font7" id="p1_t58" reading_order_no="58" segment_no="10" tag_type="text"><a href="deeplearning_paper38.html#10">]. </a>The shape and location information of the cell</text>
<text top="381" left="51" width="237" height="13" font="font7" id="p1_t59" reading_order_no="59" segment_no="10" tag_type="text">nucleus is of great significance for the classification and di-</text>
<text top="393" left="51" width="237" height="13" font="font7" id="p1_t60" reading_order_no="60" segment_no="10" tag_type="text">agnosis of benign and malignant renal cancer. Another ex-</text>
<text top="405" left="51" width="237" height="13" font="font7" id="p1_t61" reading_order_no="61" segment_no="10" tag_type="text">ample is to identify the number of transparent microorgan-</text>
<text top="417" left="51" width="237" height="13" font="font7" id="p1_t62" reading_order_no="62" segment_no="10" tag_type="text">isms in environment, so as to judge the degree of environ-</text>
<text top="429" left="51" width="72" height="13" font="font7" id="p1_t63" reading_order_no="63" segment_no="10" tag_type="text">mental pollution <a href="deeplearning_paper38.html#10">[</a></text>
<text top="429" left="123" width="5" height="13" font="font9" id="p1_t64" reading_order_no="64" segment_no="10" tag_type="text"><a href="deeplearning_paper38.html#10">2</a></text>
<text top="429" left="128" width="161" height="13" font="font7" id="p1_t65" reading_order_no="65" segment_no="10" tag_type="text"><a href="deeplearning_paper38.html#10">]. </a>In recent years, the detection of trans-</text>
<text top="441" left="51" width="237" height="13" font="font7" id="p1_t66" reading_order_no="66" segment_no="10" tag_type="text">parent objects in images is also a hot spot in vision research.</text>
<text top="453" left="51" width="237" height="13" font="font7" id="p1_t67" reading_order_no="67" segment_no="10" tag_type="text">It is not an easy task to detect whether there are transpar-</text>
<text top="465" left="51" width="176" height="13" font="font7" id="p1_t68" reading_order_no="68" segment_no="10" tag_type="text">ent objects or translucent objects in images <a href="deeplearning_paper38.html#10">[</a></text>
<text top="465" left="227" width="5" height="13" font="font9" id="p1_t69" reading_order_no="69" segment_no="10" tag_type="text"><a href="deeplearning_paper38.html#10">3</a></text>
<text top="465" left="232" width="57" height="13" font="font7" id="p1_t70" reading_order_no="70" segment_no="10" tag_type="text"><a href="deeplearning_paper38.html#10">]. </a>Because the</text>
<text top="477" left="51" width="237" height="13" font="font7" id="p1_t71" reading_order_no="71" segment_no="10" tag_type="text">transparent target area to be observed is generally very small</text>
<text top="489" left="51" width="237" height="13" font="font7" id="p1_t72" reading_order_no="72" segment_no="10" tag_type="text">or very thin, the colors and contrast of foreground and back-</text>
<text top="501" left="51" width="237" height="13" font="font7" id="p1_t73" reading_order_no="73" segment_no="10" tag_type="text">ground are similar, and only the residual edge part leads to</text>
<text top="513" left="51" width="237" height="13" font="font7" id="p1_t74" reading_order_no="74" segment_no="10" tag_type="text">low resolution of foreground or background, which largely</text>
<text top="525" left="51" width="237" height="13" font="font7" id="p1_t75" reading_order_no="75" segment_no="10" tag_type="text">depends on its background and lighting conditions. There-</text>
<text top="537" left="51" width="237" height="13" font="font7" id="p1_t76" reading_order_no="76" segment_no="10" tag_type="text">fore, there is an urgent need for some effective methods to</text>
<text top="549" left="51" width="168" height="13" font="font7" id="p1_t77" reading_order_no="77" segment_no="10" tag_type="text">identify transparent or translucent images.</text>
<text top="561" left="66" width="222" height="13" font="font7" id="p1_t78" reading_order_no="78" segment_no="14" tag_type="text">In recent years, computer vision has good performance</text>
<text top="573" left="51" width="124" height="13" font="font7" id="p1_t79" reading_order_no="79" segment_no="14" tag_type="text">in computer vision acquisition <a href="deeplearning_paper38.html#10">[</a></text>
<text top="573" left="175" width="5" height="13" font="font9" id="p1_t80" reading_order_no="80" segment_no="14" tag_type="text"><a href="deeplearning_paper38.html#10">4</a></text>
<text top="573" left="180" width="77" height="13" font="font7" id="p1_t81" reading_order_no="81" segment_no="14" tag_type="text"><a href="deeplearning_paper38.html#10">], </a>contour tracking <a href="deeplearning_paper38.html#10">[</a></text>
<text top="573" left="257" width="5" height="13" font="font9" id="p1_t82" reading_order_no="82" segment_no="14" tag_type="text"><a href="deeplearning_paper38.html#10">5</a></text>
<text top="573" left="262" width="26" height="13" font="font7" id="p1_t83" reading_order_no="83" segment_no="14" tag_type="text"><a href="deeplearning_paper38.html#10">], </a>edge</text>
<text top="584" left="51" width="43" height="13" font="font7" id="p1_t84" reading_order_no="84" segment_no="14" tag_type="text">detection <a href="deeplearning_paper38.html#10">[</a></text>
<text top="584" left="94" width="5" height="13" font="font9" id="p1_t85" reading_order_no="85" segment_no="14" tag_type="text"><a href="deeplearning_paper38.html#10">6</a></text>
<text top="584" left="99" width="76" height="13" font="font7" id="p1_t86" reading_order_no="86" segment_no="14" tag_type="text"><a href="deeplearning_paper38.html#10">], </a>face recognition <a href="deeplearning_paper38.html#10">[</a></text>
<text top="584" left="175" width="5" height="13" font="font9" id="p1_t87" reading_order_no="87" segment_no="14" tag_type="text"><a href="deeplearning_paper38.html#10">7</a></text>
<text top="584" left="180" width="102" height="13" font="font7" id="p1_t88" reading_order_no="88" segment_no="14" tag_type="text"><a href="deeplearning_paper38.html#10">], </a>fingerprint recognition <a href="deeplearning_paper38.html#11">[</a></text>
<text top="584" left="282" width="5" height="13" font="font9" id="p1_t89" reading_order_no="89" segment_no="14" tag_type="text"><a href="deeplearning_paper38.html#11">8</a></text>
<text top="584" left="287" width="6" height="13" font="font7" id="p1_t90" reading_order_no="90" segment_no="14" tag_type="text"><a href="deeplearning_paper38.html#11">],</a></text>
<text top="596" left="51" width="77" height="13" font="font7" id="p1_t91" reading_order_no="91" segment_no="14" tag_type="text">automatic driving <a href="deeplearning_paper38.html#11">[</a></text>
<text top="596" left="128" width="5" height="13" font="font9" id="p1_t92" reading_order_no="92" segment_no="14" tag_type="text"><a href="deeplearning_paper38.html#11">9</a></text>
<text top="596" left="133" width="122" height="13" font="font7" id="p1_t93" reading_order_no="93" segment_no="14" tag_type="text"><a href="deeplearning_paper38.html#11">] </a>and medical image analysis <a href="deeplearning_paper38.html#11">[</a></text>
<text top="596" left="256" width="10" height="13" font="font9" id="p1_t94" reading_order_no="94" segment_no="14" tag_type="text"><a href="deeplearning_paper38.html#11">10</a></text>
<text top="596" left="266" width="23" height="13" font="font7" id="p1_t95" reading_order_no="95" segment_no="14" tag_type="text"><a href="deeplearning_paper38.html#11">]. </a>We</text>
<text top="608" left="51" width="237" height="13" font="font7" id="p1_t96" reading_order_no="96" segment_no="14" tag_type="text">considering the excellent performance of computer vision in</text>
<text top="620" left="51" width="237" height="13" font="font7" id="p1_t97" reading_order_no="97" segment_no="14" tag_type="text">image analysis, such as high speed, high accuracy, low con-</text>
<text top="632" left="51" width="237" height="13" font="font7" id="p1_t98" reading_order_no="98" segment_no="14" tag_type="text">sumption, high degree of quantification, strong objectivity</text>
<text top="644" left="51" width="3" height="13" font="font7" id="p1_t99" reading_order_no="99" segment_no="14" tag_type="text"><a href="deeplearning_paper38.html#11">[</a></text>
<text top="644" left="55" width="10" height="13" font="font9" id="p1_t100" reading_order_no="100" segment_no="14" tag_type="text"><a href="deeplearning_paper38.html#11">11</a></text>
<text top="644" left="65" width="224" height="13" font="font7" id="p1_t101" reading_order_no="101" segment_no="14" tag_type="text"><a href="deeplearning_paper38.html#11">], </a>therefore computer vision can make up the shortcom-</text>
<text top="656" left="51" width="237" height="13" font="font7" id="p1_t102" reading_order_no="102" segment_no="14" tag_type="text">ings of traditional morphological methods. It brings new op-</text>
<text top="668" left="51" width="237" height="13" font="font7" id="p1_t103" reading_order_no="103" segment_no="14" tag_type="text">portunities to transparent image analysis. Especially, when</text>
<text top="680" left="51" width="237" height="13" font="font7" id="p1_t104" reading_order_no="104" segment_no="14" tag_type="text">an image is transparent and short of visual information, we</text>
<text top="692" left="51" width="237" height="13" font="font7" id="p1_t105" reading_order_no="105" segment_no="14" tag_type="text">usually need to crop it into patches to discover more visual</text>
<text top="704" left="51" width="237" height="13" font="font7" id="p1_t106" reading_order_no="106" segment_no="14" tag_type="text">details to recover the lost information. Hence, research work</text>
<text top="724" left="66" width="3" height="5" font="font10" id="p1_t107" reading_order_no="171" segment_no="16" tag_type="footnote">∗</text>
<text top="723" left="69" width="70" height="10" font="font4" id="p1_t108" reading_order_no="172" segment_no="16" tag_type="footnote">Corresponding author</text>
<text top="737" left="79" width="81" height="6" font="font11" id="p1_t109" reading_order_no="173" segment_no="17" tag_type="footnote">lichen201096@hotmail.com</text>
<text top="734" left="162" width="22" height="10" font="font4" id="p1_t110" reading_order_no="174" segment_no="17" tag_type="footnote">(C. Li)</text>
<text top="303" left="307" width="237" height="13" font="font7" id="p1_t111" reading_order_no="107" segment_no="8" tag_type="text">on patch-level is significant for transparent image analysis,</text>
<text top="314" left="307" width="237" height="13" font="font7" id="p1_t112" reading_order_no="108" segment_no="8" tag_type="text">such as patch-level image segmentation and classification</text>
<text top="326" left="307" width="23" height="13" font="font7" id="p1_t113" reading_order_no="109" segment_no="8" tag_type="text">tasks.</text>
<text top="338" left="322" width="223" height="13" font="font7" id="p1_t114" reading_order_no="110" segment_no="11" tag_type="text">In recent years, deep learning is the most efficient method</text>
<text top="350" left="307" width="198" height="13" font="font7" id="p1_t115" reading_order_no="111" segment_no="11" tag_type="text">in the field of machine vision, such as the popular</text>
<text top="353" left="507" width="37" height="9" font="font12" id="p1_t116" reading_order_no="112" segment_no="11" tag_type="text"><i>Convolu-</i></text>
<text top="365" left="307" width="88" height="9" font="font12" id="p1_t117" reading_order_no="113" segment_no="11" tag_type="text"><i>tional Neural Network</i></text>
<text top="362" left="398" width="72" height="13" font="font7" id="p1_t118" reading_order_no="114" segment_no="11" tag_type="text">(CNN) Xception <a href="deeplearning_paper38.html#11">[</a></text>
<text top="362" left="470" width="10" height="13" font="font9" id="p1_t119" reading_order_no="115" segment_no="11" tag_type="text"><a href="deeplearning_paper38.html#11">12</a></text>
<text top="362" left="480" width="48" height="13" font="font7" id="p1_t120" reading_order_no="116" segment_no="11" tag_type="text"><a href="deeplearning_paper38.html#11">], </a>VGG-16 <a href="deeplearning_paper38.html#11">[</a></text>
<text top="362" left="528" width="10" height="13" font="font9" id="p1_t121" reading_order_no="117" segment_no="11" tag_type="text"><a href="deeplearning_paper38.html#11">13</a></text>
<text top="362" left="538" width="6" height="13" font="font7" id="p1_t122" reading_order_no="118" segment_no="11" tag_type="text"><a href="deeplearning_paper38.html#11">],</a></text>
<text top="374" left="307" width="42" height="13" font="font7" id="p1_t123" reading_order_no="119" segment_no="11" tag_type="text">Resnet50 <a href="deeplearning_paper38.html#11">[</a></text>
<text top="374" left="348" width="10" height="13" font="font9" id="p1_t124" reading_order_no="120" segment_no="11" tag_type="text"><a href="deeplearning_paper38.html#11">14</a></text>
<text top="374" left="358" width="65" height="13" font="font7" id="p1_t125" reading_order_no="121" segment_no="11" tag_type="text"><a href="deeplearning_paper38.html#11">], </a>Inception-V3 <a href="deeplearning_paper38.html#11">[</a></text>
<text top="374" left="423" width="10" height="13" font="font9" id="p1_t126" reading_order_no="122" segment_no="11" tag_type="text"><a href="deeplearning_paper38.html#11">15</a></text>
<text top="374" left="433" width="56" height="13" font="font7" id="p1_t127" reading_order_no="123" segment_no="11" tag_type="text"><a href="deeplearning_paper38.html#11">], </a>MobileNet <a href="deeplearning_paper38.html#11">[</a></text>
<text top="374" left="489" width="10" height="13" font="font9" id="p1_t128" reading_order_no="124" segment_no="11" tag_type="text"><a href="deeplearning_paper38.html#11">16</a></text>
<text top="374" left="499" width="42" height="13" font="font7" id="p1_t129" reading_order_no="125" segment_no="11" tag_type="text"><a href="deeplearning_paper38.html#11">], </a>NasNet <a href="deeplearning_paper38.html#11">[</a></text>
<text top="374" left="541" width="10" height="13" font="font9" id="p1_t130" reading_order_no="126" segment_no="11" tag_type="text"><a href="deeplearning_paper38.html#11">17</a></text>
<text top="374" left="551" width="6" height="13" font="font7" id="p1_t131" reading_order_no="127" segment_no="11" tag_type="text"><a href="deeplearning_paper38.html#11">],</a></text>
<text top="386" left="307" width="38" height="13" font="font7" id="p1_t132" reading_order_no="128" segment_no="11" tag_type="text">and novel</text>
<text top="389" left="347" width="80" height="9" font="font12" id="p1_t133" reading_order_no="129" segment_no="11" tag_type="text"><i>Visual Transformers</i></text>
<text top="386" left="429" width="29" height="13" font="font7" id="p1_t134" reading_order_no="130" segment_no="11" tag_type="text">(VTs) <a href="deeplearning_paper38.html#11">[</a></text>
<text top="386" left="458" width="10" height="13" font="font9" id="p1_t135" reading_order_no="131" segment_no="11" tag_type="text"><a href="deeplearning_paper38.html#11">18</a></text>
<text top="386" left="468" width="76" height="13" font="font7" id="p1_t136" reading_order_no="132" segment_no="11" tag_type="text"><a href="deeplearning_paper38.html#11">]. </a>CNNs slowly ex-</text>
<text top="398" left="307" width="237" height="13" font="font7" id="p1_t137" reading_order_no="133" segment_no="11" tag_type="text">pand the receptive field until it covers the whole image by</text>
<text top="410" left="307" width="237" height="13" font="font7" id="p1_t138" reading_order_no="134" segment_no="11" tag_type="text">accumulating convolution layers, so CNNs complete the ex-</text>
<text top="422" left="307" width="237" height="13" font="font7" id="p1_t139" reading_order_no="135" segment_no="11" tag_type="text">traction of graphics from local to global information. In con-</text>
<text top="434" left="307" width="237" height="13" font="font7" id="p1_t140" reading_order_no="136" segment_no="11" tag_type="text">trast, transformers can obtain global information from the</text>
<text top="446" left="307" width="237" height="13" font="font7" id="p1_t141" reading_order_no="137" segment_no="11" tag_type="text">beginning, so they are more difficult to learn, but their abil-</text>
<text top="458" left="307" width="189" height="13" font="font7" id="p1_t142" reading_order_no="138" segment_no="11" tag_type="text">ity to learn long-term dependence is stronger <a href="deeplearning_paper38.html#11">[</a></text>
<text top="458" left="495" width="10" height="13" font="font9" id="p1_t143" reading_order_no="139" segment_no="11" tag_type="text"><a href="deeplearning_paper38.html#11">18</a></text>
<text top="458" left="505" width="39" height="13" font="font7" id="p1_t144" reading_order_no="140" segment_no="11" tag_type="text"><a href="deeplearning_paper38.html#11">]. </a>Hence,</text>
<text top="470" left="307" width="237" height="13" font="font7" id="p1_t145" reading_order_no="141" segment_no="11" tag_type="text">CNNs and Transformers have advantages and disadvantages</text>
<text top="482" left="307" width="237" height="13" font="font7" id="p1_t146" reading_order_no="142" segment_no="11" tag_type="text">in dealing with visual information. Therefore, this paper</text>
<text top="494" left="307" width="237" height="13" font="font7" id="p1_t147" reading_order_no="143" segment_no="11" tag_type="text">compares the patch-level classification performance of trans-</text>
<text top="506" left="307" width="237" height="13" font="font7" id="p1_t148" reading_order_no="144" segment_no="11" tag_type="text">parent images with different CNN and VT methods, where</text>
<text top="518" left="307" width="237" height="13" font="font7" id="p1_t149" reading_order_no="145" segment_no="11" tag_type="text">it aims to discover the adaptability of different deep learning</text>
<text top="530" left="307" width="129" height="13" font="font7" id="p1_t150" reading_order_no="146" segment_no="11" tag_type="text">models on this research domain.</text>
<text top="542" left="322" width="222" height="13" font="font7" id="p1_t151" reading_order_no="147" segment_no="12" tag_type="text">This paper uses EMDS5 as an example of transparent</text>
<text top="554" left="307" width="237" height="13" font="font7" id="p1_t152" reading_order_no="148" segment_no="12" tag_type="text">images. First, the transparent images are divided into train-</text>
<text top="566" left="307" width="237" height="13" font="font7" id="p1_t153" reading_order_no="149" segment_no="12" tag_type="text">ing, validation, and test sets according to a ratio of 2:2:4.</text>
<text top="577" left="307" width="237" height="13" font="font7" id="p1_t154" reading_order_no="150" segment_no="12" tag_type="text">The workflow of patch-level image classification is shown in</text>
<text top="589" left="307" width="16" height="13" font="font7" id="p1_t155" reading_order_no="151" segment_no="12" tag_type="text">Fig.</text>
<text top="589" left="324" width="5" height="13" font="font9" id="p1_t156" reading_order_no="152" segment_no="12" tag_type="text"><a href="deeplearning_paper38.html#2">1</a></text>
<text top="589" left="329" width="215" height="13" font="font7" id="p1_t157" reading_order_no="153" segment_no="12" tag_type="text"><a href="deeplearning_paper38.html#2">, </a>where (a) is the training set, including original images</text>
<text top="601" left="307" width="237" height="13" font="font7" id="p1_t158" reading_order_no="154" segment_no="12" tag_type="text">and ground truth (GT) images with multi-scale settings. (b)</text>
<text top="613" left="307" width="237" height="13" font="font7" id="p1_t159" reading_order_no="155" segment_no="12" tag_type="text">is the training process of deep learning models where several</text>
<text top="625" left="307" width="237" height="13" font="font7" id="p1_t160" reading_order_no="156" segment_no="12" tag_type="text">typical deep learning methods are selected and trained. (c)</text>
<text top="637" left="307" width="237" height="13" font="font7" id="p1_t161" reading_order_no="157" segment_no="12" tag_type="text">is the test set. (d) is the patch-level classification prediction</text>
<text top="649" left="307" width="25" height="13" font="font7" id="p1_t162" reading_order_no="158" segment_no="12" tag_type="text">result.</text>
<text top="661" left="322" width="200" height="13" font="font7" id="p1_t163" reading_order_no="159" segment_no="15" tag_type="text">The structure of this paper is as follows: In Section</text>
<text top="661" left="523" width="5" height="13" font="font9" id="p1_t164" reading_order_no="160" segment_no="15" tag_type="text"><a href="deeplearning_paper38.html#2">2</a></text>
<text top="661" left="528" width="16" height="13" font="font7" id="p1_t165" reading_order_no="161" segment_no="15" tag_type="text"><a href="deeplearning_paper38.html#2">, </a>re-</text>
<text top="673" left="307" width="237" height="13" font="font7" id="p1_t166" reading_order_no="162" segment_no="15" tag_type="text">lated work about deep learning in the classification of trans-</text>
<text top="685" left="307" width="159" height="13" font="font7" id="p1_t167" reading_order_no="163" segment_no="15" tag_type="text">parent images is introduced. In Section</text>
<text top="685" left="469" width="5" height="13" font="font9" id="p1_t168" reading_order_no="164" segment_no="15" tag_type="text"><a href="deeplearning_paper38.html#4">3</a></text>
<text top="685" left="474" width="70" height="13" font="font7" id="p1_t169" reading_order_no="165" segment_no="15" tag_type="text"><a href="deeplearning_paper38.html#4">, </a>comparative ex-</text>
<text top="697" left="307" width="237" height="13" font="font7" id="p1_t170" reading_order_no="166" segment_no="15" tag_type="text">periments about transparent images classification on multi-</text>
<text top="709" left="307" width="237" height="13" font="font7" id="p1_t171" reading_order_no="167" segment_no="15" tag_type="text">scale patches with deep learning methods are carried out. In</text>
<text top="721" left="307" width="30" height="13" font="font7" id="p1_t172" reading_order_no="168" segment_no="15" tag_type="text">Section</text>
<text top="721" left="339" width="5" height="13" font="font9" id="p1_t173" reading_order_no="169" segment_no="15" tag_type="text"><a href="deeplearning_paper38.html#9">4</a></text>
<text top="721" left="344" width="200" height="13" font="font7" id="p1_t174" reading_order_no="170" segment_no="15" tag_type="text"><a href="deeplearning_paper38.html#9">, </a>the conclusion and future work about transparent</text>
<text top="760" left="51" width="78" height="8" font="font13" id="p1_t175" reading_order_no="175" segment_no="19" tag_type="footnote">HeChen Yang et al.:</text>
<text top="760" left="133" width="108" height="8" font="font14" id="p1_t176" reading_order_no="176" segment_no="19" tag_type="footnote"><i>Preprint submitted to Elsevier</i></text>
<text top="757" left="494" width="50" height="13" font="font7" id="p1_t177" reading_order_no="177" segment_no="18" tag_type="text">Page 1 of 12</text>
<text top="548" left="32" width="0" height="18" font="font15" id="p1_t178" reading_order_no="0" segment_no="13" tag_type="title">arXiv:2106.11582v1  [cs.CV]  22 Jun 2021</text>
</page>
<page number="2" position="absolute" top="0" left="0" height="793" width="595">
	<fontspec id="font16" size="12" family="ArialMT" color="#ffffff"/>
	<fontspec id="font17" size="8" family="TimesNewRomanPSMT" color="#000000"/>
	<fontspec id="font18" size="9" family="TimesNewRomanPS,Bold" color="#000000"/>
	<fontspec id="font19" size="6" family="TimesNewRomanPSMT" color="#000000"/>
	<fontspec id="font20" size="9" family="SFSX0900" color="#000000"/>
	<fontspec id="font21" size="11" family="STIXGeneral,Bold" color="#000000"/>
<text top="37" left="241" width="113" height="8" font="font13" id="p2_t1" reading_order_no="0" segment_no="0" tag_type="text">Leveraging social media news</text>
<text top="231" left="425" width="99" height="16" font="font16" id="p2_t2" reading_order_no="16" segment_no="1" tag_type="figure">Data augmentation</text>
<text top="97" left="424" width="99" height="16" font="font16" id="p2_t3" reading_order_no="14" segment_no="1" tag_type="figure">Data augmentation</text>
<text top="164" left="251" width="99" height="16" font="font16" id="p2_t4" reading_order_no="6" segment_no="1" tag_type="figure">Data augmentation</text>
<text top="155" left="451" width="49" height="10" font="font17" id="p2_t5" reading_order_no="15" segment_no="1" tag_type="figure">(c) Text images</text>
<text top="143" left="271" width="59" height="10" font="font17" id="p2_t6" reading_order_no="5" segment_no="1" tag_type="figure">Data augmentation</text>
<text top="220" left="275" width="51" height="13" font="font18" id="p2_t7" reading_order_no="7" segment_no="1" tag_type="figure"><b>Data balance</b></text>
<text top="268" left="78" width="115" height="9" font="font19" id="p2_t8" reading_order_no="3" segment_no="1" tag_type="figure">Convert the original images into multi-scale</text>
<text top="127" left="110" width="50" height="10" font="font17" id="p2_t9" reading_order_no="1" segment_no="1" tag_type="figure">Original images</text>
<text top="192" left="102" width="65" height="10" font="font17" id="p2_t10" reading_order_no="2" segment_no="1" tag_type="figure">Ground truth images</text>
<text top="252" left="250" width="23" height="9" font="font19" id="p2_t11" reading_order_no="8" segment_no="1" tag_type="figure">VGG-16</text>
<text top="252" left="286" width="28" height="9" font="font19" id="p2_t12" reading_order_no="9" segment_no="1" tag_type="figure">ResNet-50</text>
<text top="252" left="324" width="24" height="9" font="font19" id="p2_t13" reading_order_no="10" segment_no="1" tag_type="figure">Xception</text>
<text top="265" left="253" width="35" height="9" font="font19" id="p2_t14" reading_order_no="11" segment_no="1" tag_type="figure">Inception-V3</text>
<text top="265" left="324" width="10" height="9" font="font19" id="p2_t15" reading_order_no="12" segment_no="1" tag_type="figure">ViT</text>
<text top="295" left="102" width="58" height="10" font="font17" id="p2_t16" reading_order_no="4" segment_no="1" tag_type="figure">(a) Training image</text>
<text top="295" left="267" width="72" height="10" font="font17" id="p2_t17" reading_order_no="13" segment_no="1" tag_type="figure">(b) Patch-level training</text>
<text top="295" left="422" width="111" height="10" font="font17" id="p2_t18" reading_order_no="17" segment_no="1" tag_type="figure">(d)  Patch-level classification result</text>
<text top="331" left="55" width="35" height="8" font="font20" id="p2_t19" reading_order_no="18" segment_no="2" tag_type="text">Figure 1:</text>
<text top="331" left="94" width="447" height="8" font="font13" id="p2_t20" reading_order_no="19" segment_no="2" tag_type="text">Workflow of patch-level classification in transparent images (using environmental microorganism EMDS-5 images as</text>
<text top="342" left="277" width="41" height="8" font="font13" id="p2_t21" reading_order_no="20" segment_no="2" tag_type="text">examples).</text>
<text top="377" left="51" width="237" height="13" font="font7" id="p2_t22" reading_order_no="21" segment_no="3" tag_type="text">images are summarized in patch-level classification of deep</text>
<text top="389" left="51" width="237" height="13" font="font7" id="p2_t23" reading_order_no="22" segment_no="3" tag_type="text">learning methods results, and future development of deep</text>
<text top="401" left="51" width="204" height="13" font="font7" id="p2_t24" reading_order_no="23" segment_no="3" tag_type="text">learning methods for analyzing transparent images.</text>
<text top="434" left="51" width="86" height="11" font="font8" id="p2_t25" reading_order_no="24" segment_no="5" tag_type="title"><b>2. Related Work</b></text>
<text top="448" left="66" width="222" height="13" font="font7" id="p2_t26" reading_order_no="25" segment_no="6" tag_type="text">This section introduces some common analysis methods,</text>
<text top="460" left="51" width="237" height="13" font="font7" id="p2_t27" reading_order_no="26" segment_no="6" tag_type="text">application scenarios and research purposes of transparent</text>
<text top="472" left="51" width="237" height="13" font="font7" id="p2_t28" reading_order_no="27" segment_no="6" tag_type="text">images. The advantages and disadvantages of some popular</text>
<text top="484" left="51" width="167" height="13" font="font7" id="p2_t29" reading_order_no="28" segment_no="6" tag_type="text">deep learning methods are also discussed.</text>
<text top="509" left="51" width="228" height="10" font="font21" id="p2_t30" reading_order_no="29" segment_no="8" tag_type="title"><b>2.1. Introduction to Transparent Image Analysis</b></text>
<text top="519" left="66" width="222" height="13" font="font7" id="p2_t31" reading_order_no="30" segment_no="9" tag_type="text">Object analysis is one of the important branches in the</text>
<text top="531" left="51" width="237" height="13" font="font7" id="p2_t32" reading_order_no="31" segment_no="9" tag_type="text">field of robot vision, especially the analysis of transparent</text>
<text top="543" left="51" width="222" height="13" font="font7" id="p2_t33" reading_order_no="32" segment_no="9" tag_type="text">images of objects (transparent images) is challenging <a href="deeplearning_paper38.html#11">[</a></text>
<text top="543" left="273" width="10" height="13" font="font9" id="p2_t34" reading_order_no="33" segment_no="9" tag_type="text"><a href="deeplearning_paper38.html#11">19</a></text>
<text top="543" left="283" width="6" height="13" font="font7" id="p2_t35" reading_order_no="34" segment_no="9" tag_type="text"><a href="deeplearning_paper38.html#11">].</a></text>
<text top="555" left="51" width="237" height="13" font="font7" id="p2_t36" reading_order_no="35" segment_no="9" tag_type="text">In traditional machine analysis methods, the flexibility of</text>
<text top="567" left="51" width="241" height="13" font="font7" id="p2_t37" reading_order_no="36" segment_no="9" tag_type="text">transparent image features obtained by integrating multi-class</text>
<text top="579" left="51" width="237" height="13" font="font7" id="p2_t38" reading_order_no="37" segment_no="9" tag_type="text">algorithms is poor, and the analysis performance is diffi-</text>
<text top="591" left="51" width="237" height="13" font="font7" id="p2_t39" reading_order_no="38" segment_no="9" tag_type="text">cult to improve. For example, home robots can’t see things</text>
<text top="603" left="51" width="237" height="13" font="font7" id="p2_t40" reading_order_no="39" segment_no="9" tag_type="text">at all when they are detecting some transparent glassware.</text>
<text top="615" left="51" width="237" height="13" font="font7" id="p2_t41" reading_order_no="40" segment_no="9" tag_type="text">The ClearGrasp machine learning algorithm performs well</text>
<text top="627" left="51" width="133" height="13" font="font7" id="p2_t42" reading_order_no="41" segment_no="9" tag_type="text">in analysing transparent objects <a href="deeplearning_paper38.html#11">[</a></text>
<text top="627" left="185" width="10" height="13" font="font9" id="p2_t43" reading_order_no="42" segment_no="9" tag_type="text"><a href="deeplearning_paper38.html#11">20</a></text>
<text top="627" left="195" width="94" height="13" font="font7" id="p2_t44" reading_order_no="43" segment_no="9" tag_type="text"><a href="deeplearning_paper38.html#11">]. </a>It can estimate high-</text>
<text top="639" left="51" width="237" height="13" font="font7" id="p2_t45" reading_order_no="44" segment_no="9" tag_type="text">precision data of transparent objects from RGB-D transpar-</text>
<text top="651" left="51" width="242" height="13" font="font7" id="p2_t46" reading_order_no="45" segment_no="9" tag_type="text">ent images, thereby improving the accuracy of detecting trans-</text>
<text top="663" left="51" width="58" height="13" font="font7" id="p2_t47" reading_order_no="46" segment_no="9" tag_type="text">parent objects.</text>
<text top="675" left="66" width="222" height="13" font="font7" id="p2_t48" reading_order_no="47" segment_no="11" tag_type="text">As an important technical means for analysing objects,</text>
<text top="687" left="51" width="237" height="13" font="font7" id="p2_t49" reading_order_no="48" segment_no="11" tag_type="text">photoelectric sensors are widely used in the fields of indus-</text>
<text top="699" left="51" width="237" height="13" font="font7" id="p2_t50" reading_order_no="49" segment_no="11" tag_type="text">trial automation, mechanization and intelligence. It uses the</text>
<text top="710" left="51" width="237" height="13" font="font7" id="p2_t51" reading_order_no="50" segment_no="11" tag_type="text">properties of light to detect the position and change of the ob-</text>
<text top="722" left="51" width="237" height="13" font="font7" id="p2_t52" reading_order_no="51" segment_no="11" tag_type="text">ject, but when detecting transparent color objects, the light</text>
<text top="377" left="307" width="237" height="13" font="font7" id="p2_t53" reading_order_no="52" segment_no="4" tag_type="text">beam of the traditional diffuse reflection photoelectric sen-</text>
<text top="389" left="307" width="237" height="13" font="font7" id="p2_t54" reading_order_no="53" segment_no="4" tag_type="text">sor penetrate the transparent material, causing the sensor to</text>
<text top="401" left="307" width="237" height="13" font="font7" id="p2_t55" reading_order_no="54" segment_no="4" tag_type="text">fail. Diffuse reflection photoelectric sensor adopts a phase-</text>
<text top="413" left="307" width="237" height="13" font="font7" id="p2_t56" reading_order_no="55" segment_no="4" tag_type="text">locked loop narrowband filter frequency selection technol-</text>
<text top="425" left="307" width="237" height="13" font="font7" id="p2_t57" reading_order_no="56" segment_no="4" tag_type="text">ogy, which improves the sensitivity to self-returning light</text>
<text top="437" left="307" width="182" height="13" font="font7" id="p2_t58" reading_order_no="57" segment_no="4" tag_type="text">and stability of detecting transparent objects <a href="deeplearning_paper38.html#11">[</a></text>
<text top="437" left="489" width="10" height="13" font="font9" id="p2_t59" reading_order_no="58" segment_no="4" tag_type="text"><a href="deeplearning_paper38.html#11">21</a></text>
<text top="437" left="499" width="6" height="13" font="font7" id="p2_t60" reading_order_no="59" segment_no="4" tag_type="text"><a href="deeplearning_paper38.html#11">].</a></text>
<text top="449" left="322" width="222" height="13" font="font7" id="p2_t61" reading_order_no="60" segment_no="7" tag_type="text">There are many transparent objects in the industrial field.</text>
<text top="461" left="307" width="237" height="13" font="font7" id="p2_t62" reading_order_no="61" segment_no="7" tag_type="text">Such as transparent plastics, transparent colloids, and liquid</text>
<text top="473" left="307" width="237" height="13" font="font7" id="p2_t63" reading_order_no="62" segment_no="7" tag_type="text">drops. These transparent objects bring a lot of uncertainty</text>
<text top="485" left="307" width="237" height="13" font="font7" id="p2_t64" reading_order_no="63" segment_no="7" tag_type="text">to products. If factories want to have high-quality products,</text>
<text top="497" left="307" width="237" height="13" font="font7" id="p2_t65" reading_order_no="64" segment_no="7" tag_type="text">sometimes it is very important to analysis these transparent</text>
<text top="509" left="307" width="237" height="13" font="font7" id="p2_t66" reading_order_no="65" segment_no="7" tag_type="text">objects and control shapes of the transparent objects. How-</text>
<text top="521" left="307" width="237" height="13" font="font7" id="p2_t67" reading_order_no="66" segment_no="7" tag_type="text">ever, it is a difficult problem to segmentation the shape of</text>
<text top="533" left="307" width="237" height="13" font="font7" id="p2_t68" reading_order_no="67" segment_no="7" tag_type="text">transparent objects through morphological methods. For in-</text>
<text top="545" left="307" width="237" height="13" font="font7" id="p2_t69" reading_order_no="68" segment_no="7" tag_type="text">stance, Hata et al. used a genetic algorithm to segmentation</text>
<text top="557" left="307" width="237" height="13" font="font7" id="p2_t70" reading_order_no="69" segment_no="7" tag_type="text">the transparent paste drop shape in the industry and obtained</text>
<text top="569" left="307" width="79" height="13" font="font7" id="p2_t71" reading_order_no="70" segment_no="7" tag_type="text">good performance <a href="deeplearning_paper38.html#11">[</a></text>
<text top="569" left="385" width="10" height="13" font="font9" id="p2_t72" reading_order_no="71" segment_no="7" tag_type="text"><a href="deeplearning_paper38.html#11">22</a></text>
<text top="569" left="395" width="6" height="13" font="font7" id="p2_t73" reading_order_no="72" segment_no="7" tag_type="text"><a href="deeplearning_paper38.html#11">].</a></text>
<text top="581" left="322" width="222" height="13" font="font7" id="p2_t74" reading_order_no="73" segment_no="10" tag_type="text">The segmentation of transparent objects is very useful in</text>
<text top="593" left="307" width="237" height="13" font="font7" id="p2_t75" reading_order_no="74" segment_no="10" tag_type="text">computer vision applications. However, the foreground of a</text>
<text top="605" left="307" width="237" height="13" font="font7" id="p2_t76" reading_order_no="75" segment_no="10" tag_type="text">transparent image is usually similar to its background en-</text>
<text top="617" left="307" width="237" height="13" font="font7" id="p2_t77" reading_order_no="76" segment_no="10" tag_type="text">vironment, which leads to the general image segmentation</text>
<text top="629" left="307" width="237" height="13" font="font7" id="p2_t78" reading_order_no="77" segment_no="10" tag_type="text">methods in dealing with transparent images in general. The</text>
<text top="640" left="307" width="237" height="13" font="font7" id="p2_t79" reading_order_no="78" segment_no="10" tag_type="text">light field image segmentation method can accurately and</text>
<text top="652" left="307" width="237" height="13" font="font7" id="p2_t80" reading_order_no="79" segment_no="10" tag_type="text">automatically segment transparent images with a small depth</text>
<text top="664" left="307" width="237" height="13" font="font7" id="p2_t81" reading_order_no="80" segment_no="10" tag_type="text">of field difference and improve the accuracy of the segmen-</text>
<text top="676" left="307" width="190" height="13" font="font7" id="p2_t82" reading_order_no="81" segment_no="10" tag_type="text">tation and it has a small amount of calculation <a href="deeplearning_paper38.html#11">[</a></text>
<text top="676" left="497" width="10" height="13" font="font9" id="p2_t83" reading_order_no="82" segment_no="10" tag_type="text"><a href="deeplearning_paper38.html#11">23</a></text>
<text top="676" left="507" width="37" height="13" font="font7" id="p2_t84" reading_order_no="83" segment_no="10" tag_type="text"><a href="deeplearning_paper38.html#11">]. </a>Hence,</text>
<text top="688" left="307" width="236" height="13" font="font7" id="p2_t85" reading_order_no="84" segment_no="10" tag_type="text">it is widely used in the segmentation of transparent images.</text>
<text top="700" left="322" width="233" height="13" font="font7" id="p2_t86" reading_order_no="85" segment_no="12" tag_type="text">The correct segmentation of zebrafish in biology has greatly</text>
<text top="712" left="307" width="237" height="13" font="font7" id="p2_t87" reading_order_no="86" segment_no="12" tag_type="text">promoted the development of life sciences. However, the</text>
<text top="724" left="307" width="237" height="13" font="font7" id="p2_t88" reading_order_no="87" segment_no="12" tag_type="text">zebrafish’s transparency makes the edges blurred in the seg-</text>
<text top="759" left="51" width="78" height="8" font="font13" id="p2_t89" reading_order_no="88" segment_no="13" tag_type="footnote">HeChen Yang et al.:</text>
<text top="759" left="133" width="108" height="8" font="font14" id="p2_t90" reading_order_no="89" segment_no="13" tag_type="footnote"><i>Preprint submitted to Elsevier</i></text>
<text top="759" left="495" width="49" height="8" font="font13" id="p2_t91" reading_order_no="90" segment_no="14" tag_type="text">Page 2 of 12</text>
</page>
<page number="3" position="absolute" top="0" left="0" height="793" width="595">
<text top="37" left="241" width="113" height="8" font="font13" id="p3_t1" reading_order_no="0" segment_no="0" tag_type="text">Leveraging social media news</text>
<text top="56" left="51" width="237" height="13" font="font7" id="p3_t2" reading_order_no="1" segment_no="1" tag_type="text">mentation. Mean shift algorithm can enhance the color rep-</text>
<text top="68" left="51" width="237" height="13" font="font7" id="p3_t3" reading_order_no="2" segment_no="1" tag_type="text">resentation in the image and improve the discrimination of</text>
<text top="80" left="51" width="152" height="13" font="font7" id="p3_t4" reading_order_no="3" segment_no="1" tag_type="text">the specimen against the background <a href="deeplearning_paper38.html#12">[</a></text>
<text top="80" left="203" width="10" height="13" font="font9" id="p3_t5" reading_order_no="4" segment_no="1" tag_type="text"><a href="deeplearning_paper38.html#12">24</a></text>
<text top="80" left="213" width="75" height="13" font="font7" id="p3_t6" reading_order_no="5" segment_no="1" tag_type="text"><a href="deeplearning_paper38.html#12">]. </a>This method im-</text>
<text top="92" left="51" width="239" height="13" font="font7" id="p3_t7" reading_order_no="6" segment_no="1" tag_type="text">proves the efficiency and accuracy of zebrafish specimen seg-</text>
<text top="104" left="51" width="42" height="13" font="font7" id="p3_t8" reading_order_no="7" segment_no="1" tag_type="text">mentation.</text>
<text top="116" left="66" width="222" height="13" font="font7" id="p3_t9" reading_order_no="8" segment_no="3" tag_type="text">Visual object classification is very important for robotics</text>
<text top="128" left="51" width="237" height="13" font="font7" id="p3_t10" reading_order_no="9" segment_no="3" tag_type="text">and computer vision applications. Commonly used statisti-</text>
<text top="139" left="51" width="208" height="13" font="font7" id="p3_t11" reading_order_no="10" segment_no="3" tag_type="text">cal classification methods such as bag-of-features <a href="deeplearning_paper38.html#12">[</a></text>
<text top="139" left="260" width="10" height="13" font="font9" id="p3_t12" reading_order_no="11" segment_no="3" tag_type="text"><a href="deeplearning_paper38.html#12">25</a></text>
<text top="139" left="270" width="19" height="13" font="font7" id="p3_t13" reading_order_no="12" segment_no="3" tag_type="text"><a href="deeplearning_paper38.html#12">] </a>are</text>
<text top="151" left="51" width="237" height="13" font="font7" id="p3_t14" reading_order_no="13" segment_no="3" tag_type="text">often applied to image classification. The principle is to</text>
<text top="163" left="51" width="237" height="13" font="font7" id="p3_t15" reading_order_no="14" segment_no="3" tag_type="text">extract local features of the image for classification. How-</text>
<text top="175" left="51" width="237" height="13" font="font7" id="p3_t16" reading_order_no="15" segment_no="3" tag_type="text">ever, these methods cannot be applied to the classification of</text>
<text top="187" left="51" width="237" height="13" font="font7" id="p3_t17" reading_order_no="16" segment_no="3" tag_type="text">transparent images, because transparent images largely de-</text>
<text top="199" left="51" width="237" height="13" font="font7" id="p3_t18" reading_order_no="17" segment_no="3" tag_type="text">pend on the background. Foreground transparent objects do</text>
<text top="211" left="51" width="237" height="13" font="font7" id="p3_t19" reading_order_no="18" segment_no="3" tag_type="text">not have their own complete characteristics, and it is difficult</text>
<text top="223" left="51" width="237" height="13" font="font7" id="p3_t20" reading_order_no="19" segment_no="3" tag_type="text">to accurately classify them. The more popular method is the</text>
<text top="235" left="51" width="116" height="13" font="font7" id="p3_t21" reading_order_no="20" segment_no="3" tag_type="text">light field distortion feature <a href="deeplearning_paper38.html#12">[</a></text>
<text top="235" left="168" width="10" height="13" font="font9" id="p3_t22" reading_order_no="21" segment_no="3" tag_type="text"><a href="deeplearning_paper38.html#12">26</a></text>
<text top="235" left="177" width="111" height="13" font="font7" id="p3_t23" reading_order_no="22" segment_no="3" tag_type="text"><a href="deeplearning_paper38.html#12">], </a>which can describe trans-</text>
<text top="247" left="51" width="237" height="13" font="font7" id="p3_t24" reading_order_no="23" segment_no="3" tag_type="text">parent objects without knowing the texture of the scene, thus</text>
<text top="259" left="51" width="230" height="13" font="font7" id="p3_t25" reading_order_no="24" segment_no="3" tag_type="text">improving the accuracy of classifying transparent images.</text>
<text top="284" left="51" width="92" height="10" font="font21" id="p3_t26" reading_order_no="25" segment_no="5" tag_type="title"><b>2.2. Deep Learning</b></text>
<text top="294" left="66" width="222" height="13" font="font7" id="p3_t27" reading_order_no="26" segment_no="6" tag_type="text">Simonyan et al. propose the VGG series of deep learning</text>
<text top="306" left="51" width="237" height="13" font="font7" id="p3_t28" reading_order_no="27" segment_no="6" tag_type="text">network models (VGG-Net), of which VGG-16 is the most</text>
<text top="318" left="51" width="62" height="13" font="font7" id="p3_t29" reading_order_no="28" segment_no="6" tag_type="text">representative <a href="deeplearning_paper38.html#12">[</a></text>
<text top="318" left="113" width="10" height="13" font="font9" id="p3_t30" reading_order_no="29" segment_no="6" tag_type="text"><a href="deeplearning_paper38.html#12">27</a></text>
<text top="318" left="123" width="166" height="13" font="font7" id="p3_t31" reading_order_no="30" segment_no="6" tag_type="text"><a href="deeplearning_paper38.html#12">]. </a>VGG-Net can imitate a larger receptive</text>
<text top="330" left="51" width="237" height="13" font="font7" id="p3_t32" reading_order_no="31" segment_no="6" tag_type="text">field by using multiple 3×3 filters, which enhances nonlin-</text>
<text top="342" left="51" width="237" height="13" font="font7" id="p3_t33" reading_order_no="32" segment_no="6" tag_type="text">ear mapping, reduces parameters and improves the network</text>
<text top="354" left="51" width="237" height="13" font="font7" id="p3_t34" reading_order_no="33" segment_no="6" tag_type="text">to be more judgmental. Meanwhile, VGG-16 continue to</text>
<text top="366" left="51" width="237" height="13" font="font7" id="p3_t35" reading_order_no="34" segment_no="6" tag_type="text">deepen the depth of the previous VGG-Net, with 13 convo-</text>
<text top="378" left="51" width="237" height="13" font="font7" id="p3_t36" reading_order_no="35" segment_no="6" tag_type="text">lutional layers and 3 fully connected layers. With the con-</text>
<text top="390" left="51" width="237" height="13" font="font7" id="p3_t37" reading_order_no="36" segment_no="6" tag_type="text">tinuous increase of convolution kernel and convolution layer,</text>
<text top="402" left="51" width="237" height="13" font="font7" id="p3_t38" reading_order_no="37" segment_no="6" tag_type="text">the nonlinear ability of the model is stronger. VGG-16 can</text>
<text top="414" left="51" width="237" height="13" font="font7" id="p3_t39" reading_order_no="38" segment_no="6" tag_type="text">better learn the features in images and achieve good perfor-</text>
<text top="425" left="51" width="237" height="13" font="font7" id="p3_t40" reading_order_no="39" segment_no="6" tag_type="text">mance in the analysis of images classification, segmentation</text>
<text top="437" left="51" width="237" height="13" font="font7" id="p3_t41" reading_order_no="40" segment_no="6" tag_type="text">and detection. Simonyan proves that as the depth of the</text>
<text top="449" left="51" width="237" height="13" font="font7" id="p3_t42" reading_order_no="41" segment_no="6" tag_type="text">network increases, it promotes the accuracy of image anal-</text>
<text top="461" left="51" width="22" height="13" font="font7" id="p3_t43" reading_order_no="42" segment_no="6" tag_type="text">ysis <a href="deeplearning_paper38.html#12">[</a></text>
<text top="461" left="74" width="10" height="13" font="font9" id="p3_t44" reading_order_no="43" segment_no="6" tag_type="text"><a href="deeplearning_paper38.html#12">27</a></text>
<text top="461" left="84" width="205" height="13" font="font7" id="p3_t45" reading_order_no="44" segment_no="6" tag_type="text"><a href="deeplearning_paper38.html#12">]. </a>But this increase in depth is not without limit.</text>
<text top="473" left="51" width="237" height="13" font="font7" id="p3_t46" reading_order_no="45" segment_no="6" tag_type="text">Excessively increasing the depth of the network will lead to</text>
<text top="485" left="51" width="237" height="13" font="font7" id="p3_t47" reading_order_no="46" segment_no="6" tag_type="text">network degradation problems. Therefore, the optimal net-</text>
<text top="497" left="51" width="237" height="13" font="font7" id="p3_t48" reading_order_no="47" segment_no="6" tag_type="text">work depth of VGG-Net is set to 16-19 layers. Moreover,</text>
<text top="509" left="51" width="237" height="13" font="font7" id="p3_t49" reading_order_no="48" segment_no="6" tag_type="text">VGG-16 has three fully connected layers, which causes more</text>
<text top="521" left="51" width="237" height="13" font="font7" id="p3_t50" reading_order_no="49" segment_no="6" tag_type="text">memory to be occupied, too long training time and difficulty</text>
<text top="533" left="51" width="84" height="13" font="font7" id="p3_t51" reading_order_no="50" segment_no="6" tag_type="text">in tuning parameters.</text>
<text top="545" left="66" width="222" height="13" font="font7" id="p3_t52" reading_order_no="51" segment_no="8" tag_type="text">He et al. propose the ResNet series of networks and</text>
<text top="557" left="51" width="237" height="13" font="font7" id="p3_t53" reading_order_no="52" segment_no="8" tag_type="text">add a residual structure in networks to solve the problem of</text>
<text top="569" left="51" width="89" height="13" font="font7" id="p3_t54" reading_order_no="53" segment_no="8" tag_type="text">network degradation <a href="deeplearning_paper38.html#12">[</a></text>
<text top="569" left="140" width="10" height="13" font="font9" id="p3_t55" reading_order_no="54" segment_no="8" tag_type="text"><a href="deeplearning_paper38.html#12">28</a></text>
<text top="569" left="150" width="139" height="13" font="font7" id="p3_t56" reading_order_no="55" segment_no="8" tag_type="text"><a href="deeplearning_paper38.html#12">]. </a>The ResNet model introduces a</text>
<text top="581" left="51" width="237" height="13" font="font7" id="p3_t57" reading_order_no="56" segment_no="8" tag_type="text">jumpy connection method "shortcut connection". This con-</text>
<text top="593" left="51" width="237" height="13" font="font7" id="p3_t58" reading_order_no="57" segment_no="8" tag_type="text">nection method allows the residual structure to skip some</text>
<text top="605" left="51" width="237" height="13" font="font7" id="p3_t59" reading_order_no="58" segment_no="8" tag_type="text">levels that have not be fully trained in the feature extraction</text>
<text top="617" left="51" width="237" height="13" font="font7" id="p3_t60" reading_order_no="59" segment_no="8" tag_type="text">process, and increases the model’s utilization of feature in-</text>
<text top="629" left="51" width="237" height="13" font="font7" id="p3_t61" reading_order_no="60" segment_no="8" tag_type="text">formation during the training process. As the most classical</text>
<text top="641" left="51" width="237" height="13" font="font7" id="p3_t62" reading_order_no="61" segment_no="8" tag_type="text">model in the ResNet series, ResNet50 has a 50-layer network</text>
<text top="653" left="51" width="237" height="13" font="font7" id="p3_t63" reading_order_no="62" segment_no="8" tag_type="text">structure. This model adopts the highway network structure,</text>
<text top="665" left="51" width="237" height="13" font="font7" id="p3_t64" reading_order_no="63" segment_no="8" tag_type="text">which makes the network have strong expression capabilities</text>
<text top="677" left="51" width="237" height="13" font="font7" id="p3_t65" reading_order_no="64" segment_no="8" tag_type="text">and the ability to acquire more advanced features. Therefore,</text>
<text top="689" left="51" width="237" height="13" font="font7" id="p3_t66" reading_order_no="65" segment_no="8" tag_type="text">it is widely used in the field of image analysis. However, the</text>
<text top="700" left="51" width="237" height="13" font="font7" id="p3_t67" reading_order_no="66" segment_no="8" tag_type="text">network model is too deep and complicate, so how to judge</text>
<text top="712" left="51" width="237" height="13" font="font7" id="p3_t68" reading_order_no="67" segment_no="8" tag_type="text">which layers in the deep network have not be fully trained,</text>
<text top="724" left="51" width="209" height="13" font="font7" id="p3_t69" reading_order_no="68" segment_no="8" tag_type="text">and then optimize the network is a difficult problem.</text>
<text top="56" left="322" width="222" height="13" font="font7" id="p3_t70" reading_order_no="69" segment_no="2" tag_type="text">Szegedy et al. propose the GoogLeNet network model,</text>
<text top="68" left="307" width="237" height="13" font="font7" id="p3_t71" reading_order_no="70" segment_no="2" tag_type="text">which has the advantage of reducing the complexity of the</text>
<text top="80" left="307" width="244" height="13" font="font7" id="p3_t72" reading_order_no="71" segment_no="2" tag_type="text">network on the basis of ResNet. They first proposed Inception-</text>
<text top="92" left="307" width="237" height="13" font="font7" id="p3_t73" reading_order_no="72" segment_no="2" tag_type="text">v1, whose network is 22 layers deep and consists of multiple</text>
<text top="104" left="307" width="237" height="13" font="font7" id="p3_t74" reading_order_no="73" segment_no="2" tag_type="text">Inception structures cascade as basic modules. Each Incep-</text>
<text top="116" left="307" width="237" height="13" font="font7" id="p3_t75" reading_order_no="74" segment_no="2" tag_type="text">tion module consists of a 1×1, 3×3, 5×5 convolution kernel</text>
<text top="128" left="307" width="237" height="13" font="font7" id="p3_t76" reading_order_no="75" segment_no="2" tag_type="text">and a 3×3 maximum pooling, which is similar to the idea</text>
<text top="139" left="307" width="237" height="13" font="font7" id="p3_t77" reading_order_no="76" segment_no="2" tag_type="text">of multi-scale and increases the adaptability of the network</text>
<text top="151" left="307" width="80" height="13" font="font7" id="p3_t78" reading_order_no="77" segment_no="2" tag_type="text">to different scales <a href="deeplearning_paper38.html#12">[</a></text>
<text top="151" left="387" width="10" height="13" font="font9" id="p3_t79" reading_order_no="78" segment_no="2" tag_type="text"><a href="deeplearning_paper38.html#12">29</a></text>
<text top="151" left="397" width="147" height="13" font="font7" id="p3_t80" reading_order_no="79" segment_no="2" tag_type="text"><a href="deeplearning_paper38.html#12">]. </a>With the continuous improvement</text>
<text top="163" left="307" width="237" height="13" font="font7" id="p3_t81" reading_order_no="80" segment_no="2" tag_type="text">of the inception module, the inception-v2 network uses two</text>
<text top="175" left="307" width="237" height="13" font="font7" id="p3_t82" reading_order_no="81" segment_no="2" tag_type="text">3×3 convolutions instead of 5×5 convolutions and increases</text>
<text top="187" left="307" width="237" height="13" font="font7" id="p3_t83" reading_order_no="82" segment_no="2" tag_type="text">the BN method, which reduces the amount of calculation and</text>
<text top="199" left="307" width="114" height="13" font="font7" id="p3_t84" reading_order_no="83" segment_no="2" tag_type="text">speeds up the training time <a href="deeplearning_paper38.html#12">[</a></text>
<text top="199" left="421" width="10" height="13" font="font9" id="p3_t85" reading_order_no="84" segment_no="2" tag_type="text"><a href="deeplearning_paper38.html#12">30</a></text>
<text top="199" left="431" width="113" height="13" font="font7" id="p3_t86" reading_order_no="85" segment_no="2" tag_type="text"><a href="deeplearning_paper38.html#12">]. </a>The Inception-v3 network</text>
<text top="211" left="307" width="237" height="13" font="font7" id="p3_t87" reading_order_no="86" segment_no="2" tag_type="text">introduces the idea of decomposing convolution, splitting a</text>
<text top="223" left="307" width="237" height="13" font="font7" id="p3_t88" reading_order_no="87" segment_no="2" tag_type="text">larger two-dimensional convolution into two smaller one-</text>
<text top="235" left="307" width="237" height="13" font="font7" id="p3_t89" reading_order_no="88" segment_no="2" tag_type="text">dimensional convolutions, further reducing the amount of</text>
<text top="247" left="307" width="50" height="13" font="font7" id="p3_t90" reading_order_no="89" segment_no="2" tag_type="text">calculation <a href="deeplearning_paper38.html#12">[</a></text>
<text top="247" left="357" width="10" height="13" font="font9" id="p3_t91" reading_order_no="90" segment_no="2" tag_type="text"><a href="deeplearning_paper38.html#12">31</a></text>
<text top="247" left="367" width="177" height="13" font="font7" id="p3_t92" reading_order_no="91" segment_no="2" tag_type="text"><a href="deeplearning_paper38.html#12">]. </a>At the same time, Inception-v3 optimizes</text>
<text top="259" left="307" width="237" height="13" font="font7" id="p3_t93" reading_order_no="92" segment_no="2" tag_type="text">the Inception module, embeds the branch in the branch and</text>
<text top="271" left="307" width="145" height="13" font="font7" id="p3_t94" reading_order_no="93" segment_no="2" tag_type="text">improves the accuracy of the model.</text>
<text top="283" left="322" width="208" height="13" font="font7" id="p3_t95" reading_order_no="94" segment_no="4" tag_type="text">Xception is another improvement after Inception-v3 <a href="deeplearning_paper38.html#12">[</a></text>
<text top="283" left="530" width="10" height="13" font="font9" id="p3_t96" reading_order_no="95" segment_no="4" tag_type="text"><a href="deeplearning_paper38.html#12">32</a></text>
<text top="283" left="540" width="6" height="13" font="font7" id="p3_t97" reading_order_no="96" segment_no="4" tag_type="text"><a href="deeplearning_paper38.html#12">].</a></text>
<text top="295" left="307" width="237" height="13" font="font7" id="p3_t98" reading_order_no="97" segment_no="4" tag_type="text">It mainly uses depthwise separable convolution to replace</text>
<text top="307" left="307" width="237" height="13" font="font7" id="p3_t99" reading_order_no="98" segment_no="4" tag_type="text">the convolution operation in Inception-v3. The Xception</text>
<text top="319" left="307" width="237" height="13" font="font7" id="p3_t100" reading_order_no="99" segment_no="4" tag_type="text">model uses deep separable convolution to increase the width</text>
<text top="331" left="307" width="237" height="13" font="font7" id="p3_t101" reading_order_no="100" segment_no="4" tag_type="text">of the network, which not only improves the accuracy of</text>
<text top="343" left="307" width="237" height="13" font="font7" id="p3_t102" reading_order_no="101" segment_no="4" tag_type="text">classification but also improves the network’s ability to learn</text>
<text top="355" left="307" width="237" height="13" font="font7" id="p3_t103" reading_order_no="102" segment_no="4" tag_type="text">subtle features. Meanwhile, Xception adds a residual mech-</text>
<text top="367" left="307" width="237" height="13" font="font7" id="p3_t104" reading_order_no="103" segment_no="4" tag_type="text">anism similar to ResNet to significantly improve the speed of</text>
<text top="379" left="307" width="237" height="13" font="font7" id="p3_t105" reading_order_no="104" segment_no="4" tag_type="text">convergence during training and the accuracy of the model.</text>
<text top="391" left="307" width="237" height="13" font="font7" id="p3_t106" reading_order_no="105" segment_no="4" tag_type="text">However, Xception is relatively fragmented in the calcula-</text>
<text top="402" left="307" width="237" height="13" font="font7" id="p3_t107" reading_order_no="106" segment_no="4" tag_type="text">tion process, which results in a slower iteration speed during</text>
<text top="414" left="307" width="33" height="13" font="font7" id="p3_t108" reading_order_no="107" segment_no="4" tag_type="text">training.</text>
<text top="426" left="322" width="222" height="13" font="font7" id="p3_t109" reading_order_no="108" segment_no="7" tag_type="text">Transformer is a deep neural network based on the self-</text>
<text top="438" left="307" width="237" height="13" font="font7" id="p3_t110" reading_order_no="109" segment_no="7" tag_type="text">attention mechanism, which enables the model to be trained</text>
<text top="450" left="307" width="237" height="13" font="font7" id="p3_t111" reading_order_no="110" segment_no="7" tag_type="text">in parallel and can obtain the global information of the train-</text>
<text top="462" left="307" width="237" height="13" font="font7" id="p3_t112" reading_order_no="111" segment_no="7" tag_type="text">ing data. Due to its computational efficiency and scalabil-</text>
<text top="474" left="307" width="237" height="13" font="font7" id="p3_t113" reading_order_no="112" segment_no="7" tag_type="text">ity, it is widely used in the field of Natural Language Pro-</text>
<text top="486" left="307" width="237" height="13" font="font7" id="p3_t114" reading_order_no="113" segment_no="7" tag_type="text">cessing. Recently, Dosovitskiy et al. proposed the Vision</text>
<text top="498" left="307" width="237" height="13" font="font7" id="p3_t115" reading_order_no="114" segment_no="7" tag_type="text">Transformer (ViT) model and found that it performs very</text>
<text top="510" left="307" width="143" height="13" font="font7" id="p3_t116" reading_order_no="115" segment_no="7" tag_type="text">well on image classification tasks <a href="deeplearning_paper38.html#12">[</a></text>
<text top="510" left="449" width="10" height="13" font="font9" id="p3_t117" reading_order_no="116" segment_no="7" tag_type="text"><a href="deeplearning_paper38.html#12">33</a></text>
<text top="510" left="459" width="85" height="13" font="font7" id="p3_t118" reading_order_no="117" segment_no="7" tag_type="text"><a href="deeplearning_paper38.html#12">]. </a>In the first step of</text>
<text top="522" left="307" width="237" height="13" font="font7" id="p3_t119" reading_order_no="118" segment_no="7" tag_type="text">training, the ViT model divides pictures into fixed-size im-</text>
<text top="534" left="307" width="237" height="13" font="font7" id="p3_t120" reading_order_no="119" segment_no="7" tag_type="text">age patches and uses its linear sequence as the input of the</text>
<text top="546" left="307" width="237" height="13" font="font7" id="p3_t121" reading_order_no="120" segment_no="7" tag_type="text">transformer model. In the second step, position embeddings</text>
<text top="558" left="307" width="237" height="13" font="font7" id="p3_t122" reading_order_no="121" segment_no="7" tag_type="text">are added to the embeddings patches to retain the position in-</text>
<text top="570" left="307" width="237" height="13" font="font7" id="p3_t123" reading_order_no="122" segment_no="7" tag_type="text">formation, and then the image features are extracted through</text>
<text top="582" left="307" width="237" height="13" font="font7" id="p3_t124" reading_order_no="123" segment_no="7" tag_type="text">the multi-head attention mechanism. Finally, the classifi-</text>
<text top="594" left="307" width="237" height="13" font="font7" id="p3_t125" reading_order_no="124" segment_no="7" tag_type="text">cation model is trained. ViT breaks through the limitation</text>
<text top="606" left="307" width="237" height="13" font="font7" id="p3_t126" reading_order_no="125" segment_no="7" tag_type="text">that RNNs model cannot be calculated in parallel and self-</text>
<text top="618" left="307" width="237" height="13" font="font7" id="p3_t127" reading_order_no="126" segment_no="7" tag_type="text">attention can produce a more interpretable model. ViT can</text>
<text top="630" left="307" width="237" height="13" font="font7" id="p3_t128" reading_order_no="127" segment_no="7" tag_type="text">be suitable for solving image processing tasks, but experi-</text>
<text top="642" left="307" width="237" height="13" font="font7" id="p3_t129" reading_order_no="128" segment_no="7" tag_type="text">ments have proved that large data samples are needed to im-</text>
<text top="654" left="307" width="97" height="13" font="font7" id="p3_t130" reading_order_no="129" segment_no="7" tag_type="text">prove the training effect.</text>
<text top="678" left="307" width="68" height="10" font="font21" id="p3_t131" reading_order_no="130" segment_no="9" tag_type="title"><b>2.3. Summary</b></text>
<text top="689" left="322" width="222" height="13" font="font7" id="p3_t132" reading_order_no="131" segment_no="10" tag_type="text">Transparent image analysis is used in various fields, but</text>
<text top="700" left="307" width="237" height="13" font="font7" id="p3_t133" reading_order_no="132" segment_no="10" tag_type="text">the foreground and background of transparent images are</text>
<text top="712" left="307" width="237" height="13" font="font7" id="p3_t134" reading_order_no="133" segment_no="10" tag_type="text">too similar to make analysis difficult. Compared with deep</text>
<text top="724" left="307" width="237" height="13" font="font7" id="p3_t135" reading_order_no="134" segment_no="10" tag_type="text">learning methods, the general traditional analysis methods</text>
<text top="759" left="51" width="78" height="8" font="font13" id="p3_t136" reading_order_no="135" segment_no="11" tag_type="footnote">HeChen Yang et al.:</text>
<text top="759" left="133" width="108" height="8" font="font14" id="p3_t137" reading_order_no="136" segment_no="11" tag_type="footnote"><i>Preprint submitted to Elsevier</i></text>
<text top="759" left="495" width="49" height="8" font="font13" id="p3_t138" reading_order_no="137" segment_no="12" tag_type="text">Page 3 of 12</text>
</page>
<page number="4" position="absolute" top="0" left="0" height="793" width="595">
	<fontspec id="font22" size="10" family="STIXGeneral,BoldItalic" color="#000000"/>
	<fontspec id="font23" size="10" family="STIXMath" color="#000000"/>
<text top="37" left="241" width="113" height="8" font="font13" id="p4_t1" reading_order_no="0" segment_no="0" tag_type="text">Leveraging social media news</text>
<text top="112" left="75" width="31" height="8" font="font19" id="p4_t2" reading_order_no="1" segment_no="1" tag_type="figure">Actinophrys</text>
<text top="112" left="149" width="19" height="8" font="font19" id="p4_t3" reading_order_no="2" segment_no="1" tag_type="figure">Arcella</text>
<text top="112" left="214" width="25" height="8" font="font19" id="p4_t4" reading_order_no="3" segment_no="1" tag_type="figure">Aspidisca</text>
<text top="112" left="283" width="24" height="8" font="font19" id="p4_t5" reading_order_no="4" segment_no="1" tag_type="figure">Codosiga</text>
<text top="112" left="352" width="21" height="8" font="font19" id="p4_t6" reading_order_no="5" segment_no="1" tag_type="figure">Colpoda</text>
<text top="112" left="420" width="22" height="8" font="font19" id="p4_t7" reading_order_no="6" segment_no="1" tag_type="figure">Epistylis</text>
<text top="112" left="488" width="24" height="8" font="font19" id="p4_t8" reading_order_no="7" segment_no="1" tag_type="figure">Euglypha</text>
<text top="175" left="78" width="23" height="8" font="font19" id="p4_t9" reading_order_no="8" segment_no="1" tag_type="figure">Ceratium</text>
<text top="175" left="148" width="21" height="8" font="font19" id="p4_t10" reading_order_no="9" segment_no="1" tag_type="figure">Rotifera</text>
<text top="175" left="218" width="18" height="8" font="font19" id="p4_t11" reading_order_no="10" segment_no="1" tag_type="figure">Stentor</text>
<text top="175" left="279" width="31" height="8" font="font19" id="p4_t12" reading_order_no="11" segment_no="1" tag_type="figure">Paramecium</text>
<text top="175" left="352" width="22" height="8" font="font19" id="p4_t13" reading_order_no="12" segment_no="1" tag_type="figure">Vorticlla</text>
<text top="175" left="414" width="34" height="8" font="font19" id="p4_t14" reading_order_no="13" segment_no="1" tag_type="figure">Siprostomum</text>
<text top="175" left="487" width="24" height="8" font="font19" id="p4_t15" reading_order_no="14" segment_no="1" tag_type="figure">Noctiluca</text>
<text top="236" left="80" width="21" height="8" font="font19" id="p4_t16" reading_order_no="15" segment_no="1" tag_type="figure">Euglena</text>
<text top="235" left="145" width="28" height="8" font="font19" id="p4_t17" reading_order_no="16" segment_no="1" tag_type="figure">Gonyaulax</text>
<text top="236" left="206" width="37" height="8" font="font19" id="p4_t18" reading_order_no="17" segment_no="1" tag_type="figure">Gymnodinium</text>
<text top="236" left="279" width="29" height="8" font="font19" id="p4_t19" reading_order_no="18" segment_no="1" tag_type="figure">K.Quadrala</text>
<text top="235" left="353" width="18" height="8" font="font19" id="p4_t20" reading_order_no="19" segment_no="1" tag_type="figure">Phacus</text>
<text top="235" left="417" width="30" height="8" font="font19" id="p4_t21" reading_order_no="20" segment_no="1" tag_type="figure">Stylonychia</text>
<text top="235" left="486" width="26" height="8" font="font19" id="p4_t22" reading_order_no="21" segment_no="1" tag_type="figure">Synchaeta</text>
<text top="261" left="188" width="35" height="8" font="font20" id="p4_t23" reading_order_no="22" segment_no="2" tag_type="text">Figure 2:</text>
<text top="261" left="228" width="179" height="8" font="font13" id="p4_t24" reading_order_no="23" segment_no="2" tag_type="text">Environmental microorganism EMDS5 images.</text>
<text top="296" left="51" width="237" height="13" font="font7" id="p4_t25" reading_order_no="24" segment_no="3" tag_type="text">are time-consuming, labor-intensive and costly. So this pa-</text>
<text top="308" left="51" width="239" height="13" font="font7" id="p4_t26" reading_order_no="25" segment_no="3" tag_type="text">per compares the performance of several classical deep learn-</text>
<text top="320" left="51" width="175" height="13" font="font7" id="p4_t27" reading_order_no="26" segment_no="3" tag_type="text">ing networks for transparent image analysis.</text>
<text top="351" left="51" width="145" height="11" font="font8" id="p4_t28" reading_order_no="27" segment_no="7" tag_type="title"><b>3. Comparative Experiment</b></text>
<text top="366" left="66" width="222" height="13" font="font7" id="p4_t29" reading_order_no="28" segment_no="8" tag_type="text">This section introduces the patch-level classification ex-</text>
<text top="377" left="51" width="237" height="13" font="font7" id="p4_t30" reading_order_no="29" segment_no="8" tag_type="text">periment process and classification results of transparent im-</text>
<text top="389" left="51" width="171" height="13" font="font7" id="p4_t31" reading_order_no="30" segment_no="8" tag_type="text">ages under several deep learning networks.</text>
<text top="414" left="51" width="113" height="10" font="font21" id="p4_t32" reading_order_no="31" segment_no="9" tag_type="title"><b>3.1. Experiment Setting</b></text>
<text top="426" left="51" width="87" height="9" font="font22" id="p4_t33" reading_order_no="32" segment_no="10" tag_type="title"><i><b>3.1.1. Data Settings</b></i></text>
<text top="436" left="66" width="222" height="13" font="font7" id="p4_t34" reading_order_no="33" segment_no="11" tag_type="text">In our work, we use Environmental Microorganism Data</text>
<text top="448" left="51" width="237" height="13" font="font7" id="p4_t35" reading_order_no="34" segment_no="11" tag_type="text">Set Fifth Version (EMDS-5) as transparent images for anal-</text>
<text top="460" left="51" width="21" height="13" font="font7" id="p4_t36" reading_order_no="35" segment_no="11" tag_type="text">ysis <a href="deeplearning_paper38.html#10">[</a></text>
<text top="460" left="73" width="5" height="13" font="font9" id="p4_t37" reading_order_no="36" segment_no="11" tag_type="text"><a href="deeplearning_paper38.html#10">2</a></text>
<text top="460" left="78" width="211" height="13" font="font7" id="p4_t38" reading_order_no="37" segment_no="11" tag_type="text"><a href="deeplearning_paper38.html#10">]. </a>It is a newly released version of the EMDS series,</text>
<text top="472" left="51" width="237" height="13" font="font7" id="p4_t39" reading_order_no="38" segment_no="11" tag_type="text">which contains 21 types of EMs, each of which contains 20</text>
<text top="484" left="51" width="237" height="13" font="font7" id="p4_t40" reading_order_no="39" segment_no="11" tag_type="text">original microscopic images and their corresponding ground</text>
<text top="496" left="51" width="185" height="13" font="font7" id="p4_t41" reading_order_no="40" segment_no="11" tag_type="text">truth (GT) images (examples are shown in F<a href="deeplearning_paper38.html#4">ig.</a></text>
<text top="496" left="236" width="5" height="13" font="font9" id="p4_t42" reading_order_no="41" segment_no="11" tag_type="text"><a href="deeplearning_paper38.html#4">2</a></text>
<text top="496" left="243" width="32" height="13" font="font7" id="p4_t43" reading_order_no="42" segment_no="11" tag_type="text">and Fig.</text>
<text top="496" left="278" width="5" height="13" font="font9" id="p4_t44" reading_order_no="43" segment_no="11" tag_type="text"><a href="deeplearning_paper38.html#5">3</a></text>
<text top="496" left="283" width="6" height="13" font="font7" id="p4_t45" reading_order_no="44" segment_no="11" tag_type="text"><a href="deeplearning_paper38.html#5">).</a></text>
<text top="507" left="51" width="237" height="13" font="font7" id="p4_t46" reading_order_no="45" segment_no="11" tag_type="text">We randomly divide each category of EMDS-5 into train-</text>
<text top="519" left="51" width="237" height="13" font="font7" id="p4_t47" reading_order_no="46" segment_no="11" tag_type="text">ing, validation, and test data sets at a ratio of 1:1:2. There-</text>
<text top="531" left="51" width="237" height="13" font="font7" id="p4_t48" reading_order_no="47" segment_no="11" tag_type="text">fore, we have 105 original images and their corresponding</text>
<text top="543" left="51" width="237" height="13" font="font7" id="p4_t49" reading_order_no="48" segment_no="11" tag_type="text">GT images for training and validation respectively, and 210</text>
<text top="555" left="51" width="171" height="13" font="font7" id="p4_t50" reading_order_no="49" segment_no="11" tag_type="text">original images for testing as shown in Tab</text>
<text top="555" left="225" width="5" height="13" font="font9" id="p4_t51" reading_order_no="50" segment_no="11" tag_type="text"><a href="deeplearning_paper38.html#4">1</a></text>
<text top="555" left="230" width="2" height="13" font="font7" id="p4_t52" reading_order_no="51" segment_no="11" tag_type="text"><a href="deeplearning_paper38.html#4">.</a></text>
<text top="579" left="51" width="113" height="9" font="font22" id="p4_t53" reading_order_no="52" segment_no="12" tag_type="title"><i><b>3.1.2. Data Preprocessing</b></i></text>
<text top="589" left="66" width="222" height="13" font="font7" id="p4_t54" reading_order_no="53" segment_no="13" tag_type="text">In the first step, we uniformly convert all images sizes to</text>
<text top="604" left="51" width="38" height="9" font="font23" id="p4_t55" reading_order_no="54" segment_no="13" tag_type="text">224 × 224</text>
<text top="601" left="91" width="197" height="13" font="font7" id="p4_t56" reading_order_no="55" segment_no="13" tag_type="text">pixels and 7168×7168 pixels to keep that each im-</text>
<text top="613" left="51" width="237" height="13" font="font7" id="p4_t57" reading_order_no="56" segment_no="13" tag_type="text">age is cropped into the same number of multi-scale patches.</text>
<text top="625" left="51" width="237" height="13" font="font7" id="p4_t58" reading_order_no="57" segment_no="13" tag_type="text">In the second step, we gray-scale EMDS-5 images to facili-</text>
<text top="637" left="51" width="237" height="13" font="font7" id="p4_t59" reading_order_no="58" segment_no="13" tag_type="text">tate the calculation of gradients and feature extraction during</text>
<text top="649" left="51" width="237" height="13" font="font7" id="p4_t60" reading_order_no="59" segment_no="13" tag_type="text">training. In the third step, the training and validation images,</text>
<text top="661" left="51" width="237" height="13" font="font7" id="p4_t61" reading_order_no="60" segment_no="13" tag_type="text">and their corresponding GT images are cropped into patches</text>
<text top="673" left="51" width="3" height="13" font="font7" id="p4_t62" reading_order_no="61" segment_no="13" tag_type="text">(</text>
<text top="675" left="55" width="17" height="9" font="font23" id="p4_t63" reading_order_no="62" segment_no="13" tag_type="text">8×8</text>
<text top="673" left="73" width="40" height="13" font="font7" id="p4_t64" reading_order_no="63" segment_no="13" tag_type="text">pixels and</text>
<text top="675" left="115" width="37" height="9" font="font23" id="p4_t65" reading_order_no="64" segment_no="13" tag_type="text">224×224</text>
<text top="673" left="153" width="56" height="13" font="font7" id="p4_t66" reading_order_no="65" segment_no="13" tag_type="text">pixels), where</text>
<text top="675" left="210" width="42" height="9" font="font23" id="p4_t67" reading_order_no="66" segment_no="13" tag_type="text">105×1024</text>
<text top="673" left="252" width="37" height="13" font="font7" id="p4_t68" reading_order_no="67" segment_no="13" tag_type="text">=107520</text>
<text top="685" left="51" width="237" height="13" font="font7" id="p4_t69" reading_order_no="68" segment_no="13" tag_type="text">patches are obtained. We divide these small patches into two</text>
<text top="697" left="51" width="237" height="13" font="font7" id="p4_t70" reading_order_no="69" segment_no="13" tag_type="text">categories according to the corresponding GT image small</text>
<text top="709" left="51" width="237" height="13" font="font7" id="p4_t71" reading_order_no="70" segment_no="13" tag_type="text">patches: foreground and background. The classification ba-</text>
<text top="721" left="51" width="172" height="13" font="font7" id="p4_t72" reading_order_no="71" segment_no="13" tag_type="text">sis is that the target area is greater than 50</text>
<text top="723" left="223" width="7" height="9" font="font23" id="p4_t73" reading_order_no="72" segment_no="13" tag_type="text">%</text>
<text top="721" left="230" width="58" height="13" font="font7" id="p4_t74" reading_order_no="73" segment_no="13" tag_type="text">, which means</text>
<text top="733" left="51" width="237" height="13" font="font7" id="p4_t75" reading_order_no="74" segment_no="13" tag_type="text">there is foreground, otherwise it is background. In the fourth</text>
<text top="301" left="307" width="29" height="8" font="font20" id="p4_t76" reading_order_no="75" segment_no="4" tag_type="title">Table 1</text>
<text top="312" left="307" width="109" height="8" font="font13" id="p4_t77" reading_order_no="76" segment_no="5" tag_type="text">EMDS-5 Experimental data.</text>
<text top="330" left="377" width="47" height="8" font="font13" id="p4_t78" reading_order_no="77" segment_no="6" tag_type="table">Training Set</text>
<text top="330" left="441" width="54" height="8" font="font13" id="p4_t79" reading_order_no="78" segment_no="6" tag_type="table">Validation Set</text>
<text top="330" left="512" width="32" height="8" font="font13" id="p4_t80" reading_order_no="79" segment_no="6" tag_type="table">Test Set</text>
<text top="346" left="307" width="45" height="8" font="font13" id="p4_t81" reading_order_no="80" segment_no="6" tag_type="table">Actinophrys</text>
<text top="346" left="391" width="5" height="8" font="font13" id="p4_t82" reading_order_no="81" segment_no="6" tag_type="table">5</text>
<text top="346" left="457" width="5" height="8" font="font13" id="p4_t83" reading_order_no="82" segment_no="6" tag_type="table">5</text>
<text top="346" left="520" width="9" height="8" font="font13" id="p4_t84" reading_order_no="83" segment_no="6" tag_type="table">10</text>
<text top="357" left="307" width="26" height="8" font="font13" id="p4_t85" reading_order_no="84" segment_no="6" tag_type="table">Arcella</text>
<text top="357" left="391" width="5" height="8" font="font13" id="p4_t86" reading_order_no="85" segment_no="6" tag_type="table">5</text>
<text top="357" left="457" width="5" height="8" font="font13" id="p4_t87" reading_order_no="86" segment_no="6" tag_type="table">5</text>
<text top="357" left="520" width="9" height="8" font="font13" id="p4_t88" reading_order_no="87" segment_no="6" tag_type="table">10</text>
<text top="368" left="307" width="36" height="8" font="font13" id="p4_t89" reading_order_no="88" segment_no="6" tag_type="table">Aspidisca</text>
<text top="368" left="391" width="5" height="8" font="font13" id="p4_t90" reading_order_no="89" segment_no="6" tag_type="table">5</text>
<text top="368" left="457" width="5" height="8" font="font13" id="p4_t91" reading_order_no="90" segment_no="6" tag_type="table">5</text>
<text top="368" left="520" width="9" height="8" font="font13" id="p4_t92" reading_order_no="91" segment_no="6" tag_type="table">10</text>
<text top="379" left="307" width="35" height="8" font="font13" id="p4_t93" reading_order_no="92" segment_no="6" tag_type="table">Codosiga</text>
<text top="379" left="391" width="5" height="8" font="font13" id="p4_t94" reading_order_no="93" segment_no="6" tag_type="table">5</text>
<text top="379" left="457" width="5" height="8" font="font13" id="p4_t95" reading_order_no="94" segment_no="6" tag_type="table">5</text>
<text top="379" left="520" width="9" height="8" font="font13" id="p4_t96" reading_order_no="95" segment_no="6" tag_type="table">10</text>
<text top="390" left="307" width="32" height="8" font="font13" id="p4_t97" reading_order_no="96" segment_no="6" tag_type="table">Colpoda</text>
<text top="390" left="391" width="5" height="8" font="font13" id="p4_t98" reading_order_no="97" segment_no="6" tag_type="table">5</text>
<text top="390" left="457" width="5" height="8" font="font13" id="p4_t99" reading_order_no="98" segment_no="6" tag_type="table">5</text>
<text top="390" left="520" width="9" height="8" font="font13" id="p4_t100" reading_order_no="99" segment_no="6" tag_type="table">10</text>
<text top="401" left="307" width="31" height="8" font="font13" id="p4_t101" reading_order_no="100" segment_no="6" tag_type="table">Epistylis</text>
<text top="401" left="391" width="5" height="8" font="font13" id="p4_t102" reading_order_no="101" segment_no="6" tag_type="table">5</text>
<text top="401" left="457" width="5" height="8" font="font13" id="p4_t103" reading_order_no="102" segment_no="6" tag_type="table">5</text>
<text top="401" left="520" width="9" height="8" font="font13" id="p4_t104" reading_order_no="103" segment_no="6" tag_type="table">10</text>
<text top="412" left="307" width="35" height="8" font="font13" id="p4_t105" reading_order_no="104" segment_no="6" tag_type="table">Euglypha</text>
<text top="412" left="391" width="5" height="8" font="font13" id="p4_t106" reading_order_no="105" segment_no="6" tag_type="table">5</text>
<text top="412" left="457" width="5" height="8" font="font13" id="p4_t107" reading_order_no="106" segment_no="6" tag_type="table">5</text>
<text top="412" left="520" width="9" height="8" font="font13" id="p4_t108" reading_order_no="107" segment_no="6" tag_type="table">10</text>
<text top="423" left="307" width="47" height="8" font="font13" id="p4_t109" reading_order_no="108" segment_no="6" tag_type="table">Paramecium</text>
<text top="423" left="391" width="5" height="8" font="font13" id="p4_t110" reading_order_no="109" segment_no="6" tag_type="table">5</text>
<text top="423" left="457" width="5" height="8" font="font13" id="p4_t111" reading_order_no="110" segment_no="6" tag_type="table">5</text>
<text top="423" left="520" width="9" height="8" font="font13" id="p4_t112" reading_order_no="111" segment_no="6" tag_type="table">10</text>
<text top="434" left="307" width="31" height="8" font="font13" id="p4_t113" reading_order_no="112" segment_no="6" tag_type="table">Rotifera</text>
<text top="434" left="391" width="5" height="8" font="font13" id="p4_t114" reading_order_no="113" segment_no="6" tag_type="table">5</text>
<text top="434" left="457" width="5" height="8" font="font13" id="p4_t115" reading_order_no="114" segment_no="6" tag_type="table">5</text>
<text top="434" left="520" width="9" height="8" font="font13" id="p4_t116" reading_order_no="115" segment_no="6" tag_type="table">10</text>
<text top="445" left="307" width="32" height="8" font="font13" id="p4_t117" reading_order_no="116" segment_no="6" tag_type="table">Vorticlla</text>
<text top="445" left="391" width="5" height="8" font="font13" id="p4_t118" reading_order_no="117" segment_no="6" tag_type="table">5</text>
<text top="445" left="457" width="5" height="8" font="font13" id="p4_t119" reading_order_no="118" segment_no="6" tag_type="table">5</text>
<text top="445" left="520" width="9" height="8" font="font13" id="p4_t120" reading_order_no="119" segment_no="6" tag_type="table">10</text>
<text top="456" left="307" width="36" height="8" font="font13" id="p4_t121" reading_order_no="120" segment_no="6" tag_type="table">Noctiluca</text>
<text top="456" left="391" width="5" height="8" font="font13" id="p4_t122" reading_order_no="121" segment_no="6" tag_type="table">5</text>
<text top="456" left="457" width="5" height="8" font="font13" id="p4_t123" reading_order_no="122" segment_no="6" tag_type="table">5</text>
<text top="456" left="520" width="9" height="8" font="font13" id="p4_t124" reading_order_no="123" segment_no="6" tag_type="table">10</text>
<text top="467" left="307" width="35" height="8" font="font13" id="p4_t125" reading_order_no="124" segment_no="6" tag_type="table">Ceratium</text>
<text top="467" left="391" width="5" height="8" font="font13" id="p4_t126" reading_order_no="125" segment_no="6" tag_type="table">5</text>
<text top="467" left="457" width="5" height="8" font="font13" id="p4_t127" reading_order_no="126" segment_no="6" tag_type="table">5</text>
<text top="467" left="520" width="9" height="8" font="font13" id="p4_t128" reading_order_no="127" segment_no="6" tag_type="table">10</text>
<text top="478" left="307" width="28" height="8" font="font13" id="p4_t129" reading_order_no="128" segment_no="6" tag_type="table">Stentor</text>
<text top="478" left="391" width="5" height="8" font="font13" id="p4_t130" reading_order_no="129" segment_no="6" tag_type="table">5</text>
<text top="478" left="457" width="5" height="8" font="font13" id="p4_t131" reading_order_no="130" segment_no="6" tag_type="table">5</text>
<text top="478" left="520" width="9" height="8" font="font13" id="p4_t132" reading_order_no="131" segment_no="6" tag_type="table">10</text>
<text top="489" left="307" width="50" height="8" font="font13" id="p4_t133" reading_order_no="132" segment_no="6" tag_type="table">Siprostomum</text>
<text top="489" left="391" width="5" height="8" font="font13" id="p4_t134" reading_order_no="133" segment_no="6" tag_type="table">5</text>
<text top="489" left="457" width="5" height="8" font="font13" id="p4_t135" reading_order_no="134" segment_no="6" tag_type="table">5</text>
<text top="489" left="520" width="9" height="8" font="font13" id="p4_t136" reading_order_no="135" segment_no="6" tag_type="table">10</text>
<text top="500" left="307" width="44" height="8" font="font13" id="p4_t137" reading_order_no="136" segment_no="6" tag_type="table">K.Quadrala</text>
<text top="500" left="391" width="5" height="8" font="font13" id="p4_t138" reading_order_no="137" segment_no="6" tag_type="table">5</text>
<text top="500" left="457" width="5" height="8" font="font13" id="p4_t139" reading_order_no="138" segment_no="6" tag_type="table">5</text>
<text top="500" left="520" width="9" height="8" font="font13" id="p4_t140" reading_order_no="139" segment_no="6" tag_type="table">10</text>
<text top="511" left="307" width="30" height="8" font="font13" id="p4_t141" reading_order_no="140" segment_no="6" tag_type="table">Euglena</text>
<text top="511" left="391" width="5" height="8" font="font13" id="p4_t142" reading_order_no="141" segment_no="6" tag_type="table">5</text>
<text top="511" left="457" width="5" height="8" font="font13" id="p4_t143" reading_order_no="142" segment_no="6" tag_type="table">5</text>
<text top="511" left="520" width="9" height="8" font="font13" id="p4_t144" reading_order_no="143" segment_no="6" tag_type="table">10</text>
<text top="522" left="307" width="53" height="8" font="font13" id="p4_t145" reading_order_no="144" segment_no="6" tag_type="table">Gymnodinium</text>
<text top="522" left="391" width="5" height="8" font="font13" id="p4_t146" reading_order_no="145" segment_no="6" tag_type="table">5</text>
<text top="522" left="457" width="5" height="8" font="font13" id="p4_t147" reading_order_no="146" segment_no="6" tag_type="table">5</text>
<text top="522" left="520" width="9" height="8" font="font13" id="p4_t148" reading_order_no="147" segment_no="6" tag_type="table">10</text>
<text top="533" left="307" width="40" height="8" font="font13" id="p4_t149" reading_order_no="148" segment_no="6" tag_type="table">Gonyaulax</text>
<text top="533" left="391" width="5" height="8" font="font13" id="p4_t150" reading_order_no="149" segment_no="6" tag_type="table">5</text>
<text top="533" left="457" width="5" height="8" font="font13" id="p4_t151" reading_order_no="150" segment_no="6" tag_type="table">5</text>
<text top="533" left="520" width="9" height="8" font="font13" id="p4_t152" reading_order_no="151" segment_no="6" tag_type="table">10</text>
<text top="544" left="307" width="27" height="8" font="font13" id="p4_t153" reading_order_no="152" segment_no="6" tag_type="table">Phacus</text>
<text top="544" left="391" width="5" height="8" font="font13" id="p4_t154" reading_order_no="153" segment_no="6" tag_type="table">5</text>
<text top="544" left="457" width="5" height="8" font="font13" id="p4_t155" reading_order_no="154" segment_no="6" tag_type="table">5</text>
<text top="544" left="520" width="9" height="8" font="font13" id="p4_t156" reading_order_no="155" segment_no="6" tag_type="table">10</text>
<text top="555" left="307" width="44" height="8" font="font13" id="p4_t157" reading_order_no="156" segment_no="6" tag_type="table">Stylonychia</text>
<text top="555" left="391" width="5" height="8" font="font13" id="p4_t158" reading_order_no="157" segment_no="6" tag_type="table">5</text>
<text top="555" left="457" width="5" height="8" font="font13" id="p4_t159" reading_order_no="158" segment_no="6" tag_type="table">5</text>
<text top="555" left="520" width="9" height="8" font="font13" id="p4_t160" reading_order_no="159" segment_no="6" tag_type="table">10</text>
<text top="566" left="307" width="39" height="8" font="font13" id="p4_t161" reading_order_no="160" segment_no="6" tag_type="table">Synchaeta</text>
<text top="566" left="391" width="5" height="8" font="font13" id="p4_t162" reading_order_no="161" segment_no="6" tag_type="table">5</text>
<text top="566" left="457" width="5" height="8" font="font13" id="p4_t163" reading_order_no="162" segment_no="6" tag_type="table">5</text>
<text top="566" left="520" width="9" height="8" font="font13" id="p4_t164" reading_order_no="163" segment_no="6" tag_type="table">10</text>
<text top="577" left="307" width="18" height="8" font="font13" id="p4_t165" reading_order_no="164" segment_no="6" tag_type="table">total</text>
<text top="577" left="388" width="14" height="8" font="font13" id="p4_t166" reading_order_no="165" segment_no="6" tag_type="table">105</text>
<text top="577" left="454" width="14" height="8" font="font13" id="p4_t167" reading_order_no="166" segment_no="6" tag_type="table">105</text>
<text top="577" left="518" width="14" height="8" font="font13" id="p4_t168" reading_order_no="167" segment_no="6" tag_type="table">210</text>
<text top="610" left="307" width="87" height="13" font="font7" id="p4_t169" reading_order_no="168" segment_no="14" tag_type="text">step, we find that the</text>
<text top="613" left="397" width="43" height="9" font="font23" id="p4_t170" reading_order_no="169" segment_no="14" tag_type="text">224 × 224</text>
<text top="610" left="443" width="101" height="13" font="font7" id="p4_t171" reading_order_no="170" segment_no="14" tag_type="text">pixels patches with fore-</text>
<text top="622" left="307" width="237" height="13" font="font7" id="p4_t172" reading_order_no="171" segment_no="14" tag_type="text">ground and background are 16630 and 90890, respectively.</text>
<text top="634" left="307" width="237" height="13" font="font7" id="p4_t173" reading_order_no="172" segment_no="14" tag_type="text">In order to avoid data imbalance during training, we rotate</text>
<text top="646" left="307" width="237" height="13" font="font7" id="p4_t174" reading_order_no="173" segment_no="14" tag_type="text">the training set image small patches by 0, 90, 180, 270 de-</text>
<text top="658" left="307" width="237" height="13" font="font7" id="p4_t175" reading_order_no="174" segment_no="14" tag_type="text">grees and mirror them for data augmentation. Then we fur-</text>
<text top="670" left="307" width="237" height="13" font="font7" id="p4_t176" reading_order_no="175" segment_no="14" tag_type="text">ther obtain 16630×8=133040 patches, from which 90890</text>
<text top="682" left="307" width="237" height="13" font="font7" id="p4_t177" reading_order_no="176" segment_no="14" tag_type="text">patches are randomly selected as the target patches in the</text>
<text top="694" left="307" width="155" height="13" font="font7" id="p4_t178" reading_order_no="177" segment_no="14" tag_type="text">training set. We expand the data of the</text>
<text top="696" left="464" width="21" height="9" font="font23" id="p4_t179" reading_order_no="178" segment_no="14" tag_type="text">8 × 8</text>
<text top="694" left="488" width="56" height="13" font="font7" id="p4_t180" reading_order_no="179" segment_no="14" tag_type="text">pixels patches</text>
<text top="706" left="307" width="237" height="13" font="font7" id="p4_t181" reading_order_no="180" segment_no="14" tag_type="text">according to the same process. An example of the augment</text>
<text top="718" left="307" width="82" height="13" font="font7" id="p4_t182" reading_order_no="181" segment_no="14" tag_type="text">data is shown in Tab</text>
<text top="718" left="391" width="5" height="13" font="font9" id="p4_t183" reading_order_no="182" segment_no="14" tag_type="text"><a href="deeplearning_paper38.html#5">2</a></text>
<text top="718" left="396" width="2" height="13" font="font7" id="p4_t184" reading_order_no="183" segment_no="14" tag_type="text"><a href="deeplearning_paper38.html#5">.</a></text>
<text top="759" left="51" width="78" height="8" font="font13" id="p4_t185" reading_order_no="184" segment_no="15" tag_type="footnote">HeChen Yang et al.:</text>
<text top="759" left="133" width="108" height="8" font="font14" id="p4_t186" reading_order_no="185" segment_no="15" tag_type="footnote"><i>Preprint submitted to Elsevier</i></text>
<text top="759" left="495" width="49" height="8" font="font13" id="p4_t187" reading_order_no="186" segment_no="16" tag_type="text">Page 4 of 12</text>
</page>
<page number="5" position="absolute" top="0" left="0" height="793" width="595">
	<fontspec id="font24" size="9" family="STIXMath" color="#000000"/>
	<fontspec id="font25" size="9" family="STIXMath,Italic" color="#000000"/>
	<fontspec id="font26" size="6" family="STIXMath,Italic" color="#000000"/>
<text top="37" left="241" width="113" height="8" font="font13" id="p5_t1" reading_order_no="0" segment_no="0" tag_type="text">Leveraging social media news</text>
<text top="112" left="76" width="31" height="8" font="font19" id="p5_t2" reading_order_no="1" segment_no="1" tag_type="figure">Actinophrys</text>
<text top="112" left="150" width="19" height="8" font="font19" id="p5_t3" reading_order_no="2" segment_no="1" tag_type="figure">Arcella</text>
<text top="112" left="214" width="25" height="8" font="font19" id="p5_t4" reading_order_no="3" segment_no="1" tag_type="figure">Aspidisca</text>
<text top="112" left="283" width="24" height="8" font="font19" id="p5_t5" reading_order_no="4" segment_no="1" tag_type="figure">Codosiga</text>
<text top="112" left="352" width="21" height="8" font="font19" id="p5_t6" reading_order_no="5" segment_no="1" tag_type="figure">Colpoda</text>
<text top="112" left="419" width="22" height="8" font="font19" id="p5_t7" reading_order_no="6" segment_no="1" tag_type="figure">Epistylis</text>
<text top="112" left="486" width="24" height="8" font="font19" id="p5_t8" reading_order_no="7" segment_no="1" tag_type="figure">Euglypha</text>
<text top="174" left="80" width="23" height="8" font="font19" id="p5_t9" reading_order_no="8" segment_no="1" tag_type="figure">Ceratium</text>
<text top="174" left="149" width="21" height="8" font="font19" id="p5_t10" reading_order_no="9" segment_no="1" tag_type="figure">Rotifera</text>
<text top="174" left="218" width="18" height="8" font="font19" id="p5_t11" reading_order_no="10" segment_no="1" tag_type="figure">Stentor</text>
<text top="174" left="279" width="31" height="8" font="font19" id="p5_t12" reading_order_no="11" segment_no="1" tag_type="figure">Paramecium</text>
<text top="174" left="351" width="22" height="8" font="font19" id="p5_t13" reading_order_no="12" segment_no="1" tag_type="figure">Vorticlla</text>
<text top="174" left="413" width="34" height="8" font="font19" id="p5_t14" reading_order_no="13" segment_no="1" tag_type="figure">Siprostomum</text>
<text top="174" left="486" width="24" height="8" font="font19" id="p5_t15" reading_order_no="14" segment_no="1" tag_type="figure">Noctiluca</text>
<text top="236" left="81" width="21" height="8" font="font19" id="p5_t16" reading_order_no="15" segment_no="1" tag_type="figure">Euglena</text>
<text top="236" left="145" width="28" height="8" font="font19" id="p5_t17" reading_order_no="16" segment_no="1" tag_type="figure">Gonyaulax</text>
<text top="236" left="209" width="37" height="8" font="font19" id="p5_t18" reading_order_no="17" segment_no="1" tag_type="figure">Gymnodinium</text>
<text top="236" left="280" width="29" height="8" font="font19" id="p5_t19" reading_order_no="18" segment_no="1" tag_type="figure">K.Quadrala</text>
<text top="236" left="353" width="18" height="8" font="font19" id="p5_t20" reading_order_no="19" segment_no="1" tag_type="figure">Phacus</text>
<text top="236" left="415" width="30" height="8" font="font19" id="p5_t21" reading_order_no="20" segment_no="1" tag_type="figure">Stylonychia</text>
<text top="236" left="485" width="26" height="8" font="font19" id="p5_t22" reading_order_no="21" segment_no="1" tag_type="figure">Synchaeta</text>
<text top="261" left="181" width="35" height="8" font="font20" id="p5_t23" reading_order_no="22" segment_no="2" tag_type="text">Figure 3:</text>
<text top="261" left="220" width="195" height="8" font="font13" id="p5_t24" reading_order_no="23" segment_no="2" tag_type="text">Environmental microorganism EMDS5-GT images.</text>
<text top="301" left="51" width="29" height="8" font="font20" id="p5_t25" reading_order_no="24" segment_no="3" tag_type="title">Table 2</text>
<text top="312" left="51" width="231" height="8" font="font13" id="p5_t26" reading_order_no="25" segment_no="5" tag_type="text">Data augmentation. FG (foreground) and BG (background)</text>
<text top="337" left="70" width="34" height="8" font="font13" id="p5_t27" reading_order_no="26" segment_no="8" tag_type="table">Data Set</text>
<text top="337" left="164" width="47" height="8" font="font13" id="p5_t28" reading_order_no="27" segment_no="8" tag_type="table">Training Set</text>
<text top="337" left="234" width="54" height="8" font="font13" id="p5_t29" reading_order_no="28" segment_no="8" tag_type="table">Validation Set</text>
<text top="362" left="63" width="19" height="8" font="font24" id="p5_t30" reading_order_no="29" segment_no="8" tag_type="table">8 × 8</text>
<text top="361" left="84" width="35" height="8" font="font13" id="p5_t31" reading_order_no="30" segment_no="8" tag_type="table">pixels FG</text>
<text top="361" left="173" width="23" height="8" font="font13" id="p5_t32" reading_order_no="31" segment_no="8" tag_type="table">16554</text>
<text top="361" left="245" width="23" height="8" font="font13" id="p5_t33" reading_order_no="32" segment_no="8" tag_type="table">17356</text>
<text top="381" left="62" width="19" height="8" font="font24" id="p5_t34" reading_order_no="33" segment_no="8" tag_type="table">8 × 8</text>
<text top="381" left="84" width="36" height="8" font="font13" id="p5_t35" reading_order_no="34" segment_no="8" tag_type="table">pixels BG</text>
<text top="381" left="173" width="23" height="8" font="font13" id="p5_t36" reading_order_no="35" segment_no="8" tag_type="table">90966</text>
<text top="381" left="245" width="23" height="8" font="font13" id="p5_t37" reading_order_no="36" segment_no="8" tag_type="table">90164</text>
<text top="401" left="51" width="91" height="8" font="font13" id="p5_t38" reading_order_no="37" segment_no="8" tag_type="table">Augmentation With FG</text>
<text top="401" left="173" width="23" height="8" font="font13" id="p5_t39" reading_order_no="38" segment_no="8" tag_type="table">90966</text>
<text top="401" left="251" width="5" height="8" font="font24" id="p5_t40" reading_order_no="39" segment_no="8" tag_type="table">∖</text>
<text top="421" left="68" width="19" height="8" font="font24" id="p5_t41" reading_order_no="40" segment_no="8" tag_type="table">8 × 8</text>
<text top="421" left="89" width="20" height="8" font="font13" id="p5_t42" reading_order_no="41" segment_no="8" tag_type="table">Total</text>
<text top="421" left="171" width="28" height="8" font="font13" id="p5_t43" reading_order_no="42" segment_no="8" tag_type="table">181932</text>
<text top="421" left="243" width="28" height="8" font="font13" id="p5_t44" reading_order_no="43" segment_no="8" tag_type="table">107520</text>
<text top="446" left="57" width="37" height="8" font="font24" id="p5_t45" reading_order_no="44" segment_no="8" tag_type="table">224 × 224</text>
<text top="445" left="96" width="35" height="8" font="font13" id="p5_t46" reading_order_no="45" segment_no="8" tag_type="table">pixels FG</text>
<text top="445" left="173" width="23" height="8" font="font13" id="p5_t47" reading_order_no="46" segment_no="8" tag_type="table">16630</text>
<text top="445" left="245" width="23" height="8" font="font13" id="p5_t48" reading_order_no="47" segment_no="8" tag_type="table">17459</text>
<text top="465" left="56" width="37" height="8" font="font24" id="p5_t49" reading_order_no="48" segment_no="8" tag_type="table">224 × 224</text>
<text top="465" left="96" width="36" height="8" font="font13" id="p5_t50" reading_order_no="49" segment_no="8" tag_type="table">pixels BG</text>
<text top="465" left="173" width="23" height="8" font="font13" id="p5_t51" reading_order_no="50" segment_no="8" tag_type="table">90890</text>
<text top="465" left="245" width="23" height="8" font="font13" id="p5_t52" reading_order_no="51" segment_no="8" tag_type="table">90061</text>
<text top="485" left="51" width="91" height="8" font="font13" id="p5_t53" reading_order_no="52" segment_no="8" tag_type="table">Augmentation With FG</text>
<text top="485" left="173" width="23" height="8" font="font13" id="p5_t54" reading_order_no="53" segment_no="8" tag_type="table">90890</text>
<text top="485" left="251" width="5" height="8" font="font24" id="p5_t55" reading_order_no="54" segment_no="8" tag_type="table">∖</text>
<text top="505" left="62" width="37" height="8" font="font24" id="p5_t56" reading_order_no="55" segment_no="8" tag_type="table">224 × 224</text>
<text top="504" left="101" width="20" height="8" font="font13" id="p5_t57" reading_order_no="56" segment_no="8" tag_type="table">Total</text>
<text top="504" left="171" width="28" height="8" font="font13" id="p5_t58" reading_order_no="57" segment_no="8" tag_type="table">181780</text>
<text top="504" left="243" width="28" height="8" font="font13" id="p5_t59" reading_order_no="58" segment_no="8" tag_type="table">107520</text>
<text top="542" left="51" width="147" height="9" font="font22" id="p5_t60" reading_order_no="59" segment_no="12" tag_type="title"><i><b>3.1.3. Experimental Environment</b></i></text>
<text top="552" left="66" width="222" height="13" font="font7" id="p5_t61" reading_order_no="60" segment_no="13" tag_type="text">Our classification comparison experiment is conducted</text>
<text top="564" left="51" width="237" height="13" font="font7" id="p5_t62" reading_order_no="61" segment_no="13" tag_type="text">on a local computer with Win10 Professional operating sys-</text>
<text top="576" left="51" width="237" height="13" font="font7" id="p5_t63" reading_order_no="62" segment_no="13" tag_type="text">tem, the computer runs 16 GB RAM i7-10700 CPU and 8</text>
<text top="588" left="51" width="237" height="13" font="font7" id="p5_t64" reading_order_no="63" segment_no="13" tag_type="text">GB NVIDIA Quadro RTX 4000 GPU. The CNNs model we</text>
<text top="600" left="51" width="237" height="13" font="font7" id="p5_t65" reading_order_no="64" segment_no="13" tag_type="text">use in this paper is based on the Keras 2.3.1 framework us-</text>
<text top="612" left="51" width="237" height="13" font="font7" id="p5_t66" reading_order_no="65" segment_no="13" tag_type="text">ing Tensorflow 2.0.0 as the backend; in the ViT model, we</text>
<text top="624" left="51" width="237" height="13" font="font7" id="p5_t67" reading_order_no="66" segment_no="13" tag_type="text">use the Pytorch 1.7.1 and Torchvision 8.0.2 operating envi-</text>
<text top="636" left="51" width="36" height="13" font="font7" id="p5_t68" reading_order_no="67" segment_no="13" tag_type="text">ronment.</text>
<text top="660" left="51" width="107" height="9" font="font22" id="p5_t69" reading_order_no="68" segment_no="14" tag_type="title"><i><b>3.1.4. Hyper Parameters</b></i></text>
<text top="670" left="66" width="225" height="13" font="font7" id="p5_t70" reading_order_no="69" segment_no="15" tag_type="text">This experiment uses Adam optimizer, with 0.0002 learn-</text>
<text top="682" left="51" width="237" height="13" font="font7" id="p5_t71" reading_order_no="70" segment_no="15" tag_type="text">ing rate and sets the batch size to 32 in our training process.</text>
<text top="693" left="51" width="27" height="13" font="font7" id="p5_t72" reading_order_no="71" segment_no="15" tag_type="text">In Fig.</text>
<text top="693" left="82" width="5" height="13" font="font9" id="p5_t73" reading_order_no="72" segment_no="15" tag_type="text"><a href="deeplearning_paper38.html#6">4</a></text>
<text top="693" left="90" width="33" height="13" font="font7" id="p5_t74" reading_order_no="73" segment_no="15" tag_type="text">and Fig.</text>
<text top="693" left="126" width="5" height="13" font="font9" id="p5_t75" reading_order_no="74" segment_no="15" tag_type="text"><a href="deeplearning_paper38.html#6">5</a></text>
<text top="693" left="134" width="155" height="13" font="font7" id="p5_t76" reading_order_no="75" segment_no="15" tag_type="text">we show the accuracy and loss curves</text>
<text top="705" left="51" width="237" height="13" font="font7" id="p5_t77" reading_order_no="76" segment_no="15" tag_type="text">of different deep learning models in this experiment. We</text>
<text top="717" left="51" width="237" height="13" font="font7" id="p5_t78" reading_order_no="77" segment_no="15" tag_type="text">find that the loss and accuracy curves of the training set are</text>
<text top="729" left="51" width="237" height="13" font="font7" id="p5_t79" reading_order_no="78" segment_no="15" tag_type="text">converging after training for 40 layers. Therefore, consider-</text>
<text top="301" left="307" width="29" height="8" font="font20" id="p5_t80" reading_order_no="79" segment_no="4" tag_type="title">Table 3</text>
<text top="312" left="307" width="168" height="8" font="font13" id="p5_t81" reading_order_no="80" segment_no="6" tag_type="text">Evaluation metrics for images classification.</text>
<text top="336" left="307" width="47" height="8" font="font13" id="p5_t82" reading_order_no="81" segment_no="7" tag_type="table">Assessments</text>
<text top="336" left="504" width="31" height="8" font="font13" id="p5_t83" reading_order_no="82" segment_no="7" tag_type="table">Formula</text>
<text top="361" left="318" width="14" height="8" font="font13" id="p5_t84" reading_order_no="83" segment_no="7" tag_type="table">Acc</text>
<text top="359" left="512" width="19" height="5" font="font10" id="p5_t85" reading_order_no="84" segment_no="7" tag_type="table">TP+TN</text>
<text top="367" left="501" width="42" height="5" font="font10" id="p5_t86" reading_order_no="85" segment_no="7" tag_type="table">TP+TN+FP+FN</text>
<text top="381" left="312" width="20" height="8" font="font13" id="p5_t87" reading_order_no="86" segment_no="7" tag_type="table">Pre (</text>
<text top="381" left="332" width="5" height="8" font="font25" id="p5_t88" reading_order_no="87" segment_no="7" tag_type="table"><i>𝑃</i></text>
<text top="381" left="339" width="4" height="8" font="font13" id="p5_t89" reading_order_no="88" segment_no="7" tag_type="table">)</text>
<text top="378" left="515" width="7" height="5" font="font10" id="p5_t90" reading_order_no="89" segment_no="7" tag_type="table">TP</text>
<text top="387" left="509" width="18" height="5" font="font10" id="p5_t91" reading_order_no="90" segment_no="7" tag_type="table">TP+FP</text>
<text top="400" left="312" width="21" height="8" font="font13" id="p5_t92" reading_order_no="91" segment_no="7" tag_type="table">Rec (</text>
<text top="401" left="333" width="7" height="8" font="font25" id="p5_t93" reading_order_no="92" segment_no="7" tag_type="table"><i>𝑅</i></text>
<text top="400" left="340" width="4" height="8" font="font13" id="p5_t94" reading_order_no="93" segment_no="7" tag_type="table">)</text>
<text top="398" left="515" width="7" height="5" font="font10" id="p5_t95" reading_order_no="94" segment_no="7" tag_type="table">TP</text>
<text top="407" left="509" width="19" height="5" font="font10" id="p5_t96" reading_order_no="95" segment_no="7" tag_type="table">TP+FN</text>
<text top="420" left="318" width="14" height="8" font="font13" id="p5_t97" reading_order_no="96" segment_no="7" tag_type="table">Spe</text>
<text top="418" left="514" width="8" height="5" font="font10" id="p5_t98" reading_order_no="97" segment_no="7" tag_type="table">TN</text>
<text top="426" left="509" width="19" height="5" font="font10" id="p5_t99" reading_order_no="98" segment_no="7" tag_type="table">TN+FP</text>
<text top="440" left="319" width="10" height="8" font="font13" id="p5_t100" reading_order_no="99" segment_no="7" tag_type="table">F1</text>
<text top="440" left="505" width="12" height="8" font="font24" id="p5_t101" reading_order_no="100" segment_no="7" tag_type="table">2 ×</text>
<text top="438" left="520" width="4" height="5" font="font26" id="p5_t102" reading_order_no="101" segment_no="7" tag_type="table"><i>𝑃</i></text>
<text top="438" left="525" width="4" height="5" font="font10" id="p5_t103" reading_order_no="102" segment_no="7" tag_type="table">×</text>
<text top="438" left="529" width="4" height="5" font="font26" id="p5_t104" reading_order_no="103" segment_no="7" tag_type="table"><i>𝑅</i></text>
<text top="446" left="520" width="4" height="5" font="font26" id="p5_t105" reading_order_no="104" segment_no="7" tag_type="table"><i>𝑃</i></text>
<text top="446" left="525" width="4" height="5" font="font10" id="p5_t106" reading_order_no="105" segment_no="7" tag_type="table">+</text>
<text top="446" left="529" width="4" height="5" font="font26" id="p5_t107" reading_order_no="106" segment_no="7" tag_type="table"><i>𝑅</i></text>
<text top="475" left="307" width="237" height="13" font="font7" id="p5_t108" reading_order_no="107" segment_no="9" tag_type="text">ing the computational performance of the workstation, we</text>
<text top="487" left="307" width="131" height="13" font="font7" id="p5_t109" reading_order_no="108" segment_no="9" tag_type="text">finally set 50 epochs for training.</text>
<text top="512" left="307" width="112" height="10" font="font21" id="p5_t110" reading_order_no="109" segment_no="10" tag_type="title"><b>3.2. Evaluation Metrics</b></text>
<text top="522" left="322" width="222" height="13" font="font7" id="p5_t111" reading_order_no="110" segment_no="11" tag_type="text">To compare the classification performance of different</text>
<text top="534" left="307" width="237" height="13" font="font7" id="p5_t112" reading_order_no="111" segment_no="11" tag_type="text">methods, we used the commonly used deep learning classi-</text>
<text top="546" left="307" width="237" height="13" font="font7" id="p5_t113" reading_order_no="112" segment_no="11" tag_type="text">fication indicators Accuracy (Acc), Precision (Pre), Recall</text>
<text top="558" left="307" width="237" height="13" font="font7" id="p5_t114" reading_order_no="113" segment_no="11" tag_type="text">(Rec), Specificity (Spe), and F1-Score (F1) to evaluate the</text>
<text top="570" left="307" width="237" height="13" font="font7" id="p5_t115" reading_order_no="114" segment_no="11" tag_type="text">classification results. Acc reflects the ratio of correct classi-</text>
<text top="582" left="307" width="237" height="13" font="font7" id="p5_t116" reading_order_no="115" segment_no="11" tag_type="text">fication samples to total samples. Pre reflects the proportion</text>
<text top="594" left="307" width="237" height="13" font="font7" id="p5_t117" reading_order_no="116" segment_no="11" tag_type="text">of correctly predict positive samples in the positive samples</text>
<text top="606" left="307" width="237" height="13" font="font7" id="p5_t118" reading_order_no="117" segment_no="11" tag_type="text">of model classification. Rec reflects the correct proportion</text>
<text top="618" left="307" width="237" height="13" font="font7" id="p5_t119" reading_order_no="118" segment_no="11" tag_type="text">of model classification in total positive samples Spe reflects</text>
<text top="630" left="307" width="237" height="13" font="font7" id="p5_t120" reading_order_no="119" segment_no="11" tag_type="text">the proportion of the model correctly classifying the nega-</text>
<text top="642" left="307" width="237" height="13" font="font7" id="p5_t121" reading_order_no="120" segment_no="11" tag_type="text">tive samples in the total negative samples. F1 is a calcula-</text>
<text top="654" left="307" width="237" height="13" font="font7" id="p5_t122" reading_order_no="121" segment_no="11" tag_type="text">tion result that comprehensively considers the Pre and Rec of</text>
<text top="666" left="307" width="228" height="13" font="font7" id="p5_t123" reading_order_no="122" segment_no="11" tag_type="text">the model. These evaluation indicators are defined in Tab</text>
<text top="666" left="537" width="5" height="13" font="font9" id="p5_t124" reading_order_no="123" segment_no="11" tag_type="text"><a href="deeplearning_paper38.html#5">3</a></text>
<text top="666" left="541" width="2" height="13" font="font7" id="p5_t125" reading_order_no="124" segment_no="11" tag_type="text"><a href="deeplearning_paper38.html#5">.</a></text>
<text top="678" left="307" width="237" height="13" font="font7" id="p5_t126" reading_order_no="125" segment_no="11" tag_type="text">TP (True Positive), FN (False Negative), FP (False Positive),</text>
<text top="689" left="307" width="237" height="13" font="font7" id="p5_t127" reading_order_no="126" segment_no="11" tag_type="text">and TN (True Negative) are concept in the confusion matrix.</text>
<text top="759" left="51" width="78" height="8" font="font13" id="p5_t128" reading_order_no="127" segment_no="16" tag_type="footnote">HeChen Yang et al.:</text>
<text top="759" left="133" width="108" height="8" font="font14" id="p5_t129" reading_order_no="128" segment_no="16" tag_type="footnote"><i>Preprint submitted to Elsevier</i></text>
<text top="759" left="495" width="49" height="8" font="font13" id="p5_t130" reading_order_no="129" segment_no="17" tag_type="text">Page 5 of 12</text>
</page>
<page number="6" position="absolute" top="0" left="0" height="793" width="595">
	<fontspec id="font27" size="7" family="TimesNewRomanPSMT" color="#000000"/>
	<fontspec id="font28" size="11" family="STIXGeneral,BoldItalic" color="#000000"/>
<text top="37" left="241" width="113" height="8" font="font13" id="p6_t1" reading_order_no="0" segment_no="0" tag_type="text">Leveraging social media news</text>
<text top="150" left="191" width="39" height="10" font="font27" id="p6_t2" reading_order_no="1" segment_no="1" tag_type="figure">Inception-V3</text>
<text top="150" left="508" width="11" height="10" font="font27" id="p6_t3" reading_order_no="2" segment_no="1" tag_type="figure">ViT</text>
<text top="150" left="299" width="25" height="10" font="font27" id="p6_t4" reading_order_no="3" segment_no="1" tag_type="figure">VGG-16</text>
<text top="150" left="395" width="35" height="10" font="font27" id="p6_t5" reading_order_no="4" segment_no="1" tag_type="figure">X-Inception</text>
<text top="150" left="95" width="31" height="10" font="font27" id="p6_t6" reading_order_no="5" segment_no="1" tag_type="figure">ResNet-50</text>
<text top="186" left="57" width="35" height="8" font="font20" id="p6_t7" reading_order_no="6" segment_no="2" tag_type="text">Figure 4:</text>
<text top="186" left="96" width="292" height="8" font="font13" id="p6_t8" reading_order_no="7" segment_no="2" tag_type="text">Compare the results of the loss and accuracy curves of deep learning on the</text>
<text top="187" left="391" width="19" height="8" font="font24" id="p6_t9" reading_order_no="8" segment_no="2" tag_type="text">8 × 8</text>
<text top="186" left="413" width="126" height="8" font="font13" id="p6_t10" reading_order_no="9" segment_no="2" tag_type="text">pixels training and the validation</text>
<text top="197" left="289" width="17" height="8" font="font13" id="p6_t11" reading_order_no="10" segment_no="2" tag_type="text">sets.</text>
<text top="317" left="191" width="39" height="10" font="font27" id="p6_t12" reading_order_no="11" segment_no="3" tag_type="figure">Inception-V3</text>
<text top="317" left="508" width="11" height="10" font="font27" id="p6_t13" reading_order_no="12" segment_no="3" tag_type="figure">ViT</text>
<text top="316" left="299" width="25" height="10" font="font27" id="p6_t14" reading_order_no="13" segment_no="3" tag_type="figure">VGG-16</text>
<text top="317" left="395" width="35" height="10" font="font27" id="p6_t15" reading_order_no="14" segment_no="3" tag_type="figure">X-Inception</text>
<text top="317" left="95" width="31" height="10" font="font27" id="p6_t16" reading_order_no="15" segment_no="3" tag_type="figure">ResNet-50</text>
<text top="353" left="68" width="35" height="8" font="font20" id="p6_t17" reading_order_no="16" segment_no="4" tag_type="text">Figure 5:</text>
<text top="353" left="107" width="292" height="8" font="font13" id="p6_t18" reading_order_no="17" segment_no="4" tag_type="text">Compare the results of the loss and accuracy curves of deep learning on the</text>
<text top="353" left="402" width="37" height="8" font="font24" id="p6_t19" reading_order_no="18" segment_no="4" tag_type="text">224 × 224</text>
<text top="353" left="442" width="86" height="8" font="font13" id="p6_t20" reading_order_no="19" segment_no="4" tag_type="text">pixels training and the</text>
<text top="364" left="269" width="57" height="8" font="font13" id="p6_t21" reading_order_no="20" segment_no="4" tag_type="text">validation sets.</text>
<text top="399" left="51" width="141" height="10" font="font21" id="p6_t22" reading_order_no="21" segment_no="5" tag_type="title"><b>3.3. Comparative Experiment</b></text>
<text top="411" left="51" width="148" height="9" font="font22" id="p6_t23" reading_order_no="22" segment_no="7" tag_type="text"><i><b>3.3.1. Comparative Experiment of</b></i></text>
<text top="411" left="202" width="22" height="10" font="font23" id="p6_t24" reading_order_no="23" segment_no="7" tag_type="text">8 × 8</text>
<text top="411" left="227" width="62" height="9" font="font22" id="p6_t25" reading_order_no="24" segment_no="7" tag_type="text"><i><b>Pixels Patches</b></i></text>
<text top="423" left="51" width="209" height="10" font="font28" id="p6_t26" reading_order_no="25" segment_no="7" tag_type="text"><i><b>Comparison on Training and Validation Sets:</b></i></text>
<text top="421" left="266" width="23" height="13" font="font7" id="p6_t27" reading_order_no="26" segment_no="7" tag_type="text">In or-</text>
<text top="433" left="51" width="237" height="13" font="font7" id="p6_t28" reading_order_no="27" segment_no="7" tag_type="text">der to compare the classification performance of CNNs and</text>
<text top="445" left="51" width="237" height="13" font="font7" id="p6_t29" reading_order_no="28" segment_no="7" tag_type="text">ViT models, we calculate Pre, Rec, Spe, F1, Acc, Max Acc.</text>
<text top="457" left="51" width="25" height="13" font="font7" id="p6_t30" reading_order_no="29" segment_no="7" tag_type="text">In Tab</text>
<text top="457" left="79" width="5" height="13" font="font9" id="p6_t31" reading_order_no="30" segment_no="7" tag_type="text"><a href="deeplearning_paper38.html#6">4</a></text>
<text top="457" left="84" width="115" height="13" font="font7" id="p6_t32" reading_order_no="31" segment_no="7" tag_type="text"><a href="deeplearning_paper38.html#6">, </a>we summarize the results of</text>
<text top="459" left="201" width="19" height="9" font="font23" id="p6_t33" reading_order_no="32" segment_no="7" tag_type="text">8 × 8</text>
<text top="457" left="221" width="67" height="13" font="font7" id="p6_t34" reading_order_no="33" segment_no="7" tag_type="text">pixels patches on</text>
<text top="469" left="51" width="237" height="13" font="font7" id="p6_t35" reading_order_no="34" segment_no="7" tag_type="text">validation set for each model. Overall, the Pre of the deep</text>
<text top="481" left="51" width="237" height="13" font="font7" id="p6_t36" reading_order_no="35" segment_no="7" tag_type="text">learning network in classifying the transparent image back-</text>
<text top="492" left="51" width="237" height="13" font="font7" id="p6_t37" reading_order_no="36" segment_no="7" tag_type="text">ground is higher than the foreground. Besides, the ability of</text>
<text top="504" left="51" width="237" height="13" font="font7" id="p6_t38" reading_order_no="37" segment_no="7" tag_type="text">the five models to classify transparent images backgrounds is</text>
<text top="516" left="51" width="39" height="13" font="font7" id="p6_t39" reading_order_no="38" segment_no="7" tag_type="text">almost 97</text>
<text top="519" left="90" width="7" height="9" font="font23" id="p6_t40" reading_order_no="39" segment_no="7" tag_type="text">%</text>
<text top="516" left="98" width="164" height="13" font="font7" id="p6_t41" reading_order_no="40" segment_no="7" tag_type="text">, the highest is the VGG-16 value of 97.6</text>
<text top="519" left="262" width="7" height="9" font="font23" id="p6_t42" reading_order_no="41" segment_no="7" tag_type="text">%</text>
<text top="516" left="269" width="19" height="13" font="font7" id="p6_t43" reading_order_no="42" segment_no="7" tag_type="text">, and</text>
<text top="528" left="51" width="227" height="13" font="font7" id="p6_t44" reading_order_no="43" segment_no="7" tag_type="text">the lowest is the X-Inception and the ViT value of 96.7</text>
<text top="531" left="279" width="7" height="9" font="font23" id="p6_t45" reading_order_no="44" segment_no="7" tag_type="text">%</text>
<text top="528" left="286" width="2" height="13" font="font7" id="p6_t46" reading_order_no="45" segment_no="7" tag_type="text">.</text>
<text top="540" left="51" width="237" height="13" font="font7" id="p6_t47" reading_order_no="46" segment_no="7" tag_type="text">Meanwhile, the Pre rate of classification foreground VGG-</text>
<text top="552" left="51" width="145" height="13" font="font7" id="p6_t48" reading_order_no="47" segment_no="7" tag_type="text">16 is the best and the Pre rate is 63.1</text>
<text top="555" left="196" width="7" height="9" font="font23" id="p6_t49" reading_order_no="48" segment_no="7" tag_type="text">%</text>
<text top="552" left="204" width="85" height="13" font="font7" id="p6_t50" reading_order_no="49" segment_no="7" tag_type="text">. The Inception-V3 is</text>
<text top="564" left="51" width="61" height="13" font="font7" id="p6_t51" reading_order_no="50" segment_no="7" tag_type="text">the lowest 53.3</text>
<text top="567" left="113" width="7" height="9" font="font23" id="p6_t52" reading_order_no="51" segment_no="7" tag_type="text">%</text>
<text top="564" left="120" width="169" height="13" font="font7" id="p6_t53" reading_order_no="52" segment_no="7" tag_type="text">. For transparent images foreground clas-</text>
<text top="576" left="51" width="237" height="13" font="font7" id="p6_t54" reading_order_no="53" segment_no="7" tag_type="text">sification, the highest Rec rate is the X-Inception value of</text>
<text top="588" left="51" width="17" height="13" font="font7" id="p6_t55" reading_order_no="54" segment_no="7" tag_type="text">89.2</text>
<text top="591" left="69" width="7" height="9" font="font23" id="p6_t56" reading_order_no="55" segment_no="7" tag_type="text">%</text>
<text top="588" left="76" width="136" height="13" font="font7" id="p6_t57" reading_order_no="56" segment_no="7" tag_type="text">, and the lowest Vit value is 84.1</text>
<text top="591" left="212" width="7" height="9" font="font23" id="p6_t58" reading_order_no="57" segment_no="7" tag_type="text">%</text>
<text top="588" left="219" width="69" height="13" font="font7" id="p6_t59" reading_order_no="58" segment_no="7" tag_type="text">. For transparent</text>
<text top="600" left="51" width="237" height="13" font="font7" id="p6_t60" reading_order_no="59" segment_no="7" tag_type="text">images background classification, the highest Rec rate is the</text>
<text top="612" left="51" width="69" height="13" font="font7" id="p6_t61" reading_order_no="60" segment_no="7" tag_type="text">Vit value of 90.3</text>
<text top="615" left="120" width="7" height="9" font="font23" id="p6_t62" reading_order_no="61" segment_no="7" tag_type="text">%</text>
<text top="612" left="130" width="158" height="13" font="font7" id="p6_t63" reading_order_no="62" segment_no="7" tag_type="text">and the lowest is the X-Inception value</text>
<text top="624" left="51" width="29" height="13" font="font7" id="p6_t64" reading_order_no="63" segment_no="7" tag_type="text">of 85.0</text>
<text top="627" left="80" width="7" height="9" font="font23" id="p6_t65" reading_order_no="64" segment_no="7" tag_type="text">%</text>
<text top="624" left="87" width="201" height="13" font="font7" id="p6_t66" reading_order_no="65" segment_no="7" tag_type="text">. The Spe performance result of the classify back-</text>
<text top="636" left="51" width="237" height="13" font="font7" id="p6_t67" reading_order_no="66" segment_no="7" tag_type="text">ground is opposite to the Rec performance result of the clas-</text>
<text top="648" left="51" width="237" height="13" font="font7" id="p6_t68" reading_order_no="67" segment_no="7" tag_type="text">sify foreground. Among the five models, the highest Acc is</text>
<text top="660" left="51" width="123" height="13" font="font7" id="p6_t69" reading_order_no="68" segment_no="7" tag_type="text">ResNet50 with a value of 92.87</text>
<text top="662" left="174" width="7" height="9" font="font23" id="p6_t70" reading_order_no="69" segment_no="7" tag_type="text">%</text>
<text top="660" left="182" width="107" height="13" font="font7" id="p6_t71" reading_order_no="70" segment_no="7" tag_type="text">, and the lowest is ViT with</text>
<text top="672" left="51" width="64" height="13" font="font7" id="p6_t72" reading_order_no="71" segment_no="7" tag_type="text">a value of 89.26</text>
<text top="674" left="115" width="7" height="9" font="font23" id="p6_t73" reading_order_no="72" segment_no="7" tag_type="text">%</text>
<text top="672" left="123" width="2" height="13" font="font7" id="p6_t74" reading_order_no="73" segment_no="7" tag_type="text">.</text>
<text top="696" left="51" width="111" height="10" font="font28" id="p6_t75" reading_order_no="74" segment_no="12" tag_type="text"><i><b>Comparison on Test Set:</b></i></text>
<text top="694" left="168" width="26" height="13" font="font7" id="p6_t76" reading_order_no="75" segment_no="12" tag_type="text">In Tab</text>
<text top="694" left="196" width="5" height="13" font="font9" id="p6_t77" reading_order_no="76" segment_no="12" tag_type="text"><a href="deeplearning_paper38.html#8">6</a></text>
<text top="694" left="203" width="85" height="13" font="font7" id="p6_t78" reading_order_no="77" segment_no="12" tag_type="text">we summarize the re-</text>
<text top="706" left="51" width="237" height="13" font="font7" id="p6_t79" reading_order_no="78" segment_no="12" tag_type="text">sults of these five network predictions. It can be seen that</text>
<text top="718" left="51" width="214" height="13" font="font7" id="p6_t80" reading_order_no="79" segment_no="12" tag_type="text">ResNet50 prediction Acc rate is the highest at 90.00</text>
<text top="720" left="265" width="7" height="9" font="font23" id="p6_t81" reading_order_no="80" segment_no="12" tag_type="text">%</text>
<text top="718" left="273" width="16" height="13" font="font7" id="p6_t82" reading_order_no="81" segment_no="12" tag_type="text">, X-</text>
<text top="730" left="51" width="206" height="13" font="font7" id="p6_t83" reading_order_no="82" segment_no="12" tag_type="text">Inception prediction Acc rate is the lowest at 85.85</text>
<text top="732" left="257" width="7" height="9" font="font23" id="p6_t84" reading_order_no="83" segment_no="12" tag_type="text">%</text>
<text top="730" left="265" width="24" height="13" font="font7" id="p6_t85" reading_order_no="84" segment_no="12" tag_type="text">. Fur-</text>
<text top="402" left="307" width="29" height="8" font="font20" id="p6_t86" reading_order_no="85" segment_no="6" tag_type="title">Table 4</text>
<text top="413" left="307" width="237" height="8" font="font13" id="p6_t87" reading_order_no="86" segment_no="8" tag_type="text">A comparison of the classification results on validation set of</text>
<text top="424" left="307" width="19" height="8" font="font24" id="p6_t88" reading_order_no="87" segment_no="8" tag_type="text">8 × 8</text>
<text top="424" left="329" width="215" height="8" font="font13" id="p6_t89" reading_order_no="88" segment_no="8" tag_type="text">pixels patches. MAcc (Max Acc), FG (foreground) and</text>
<text top="435" left="307" width="103" height="8" font="font13" id="p6_t90" reading_order_no="89" segment_no="8" tag_type="text">BG (background) (In [%].)</text>
<text top="453" left="314" width="24" height="8" font="font13" id="p6_t91" reading_order_no="90" segment_no="9" tag_type="table">Model</text>
<text top="453" left="369" width="20" height="8" font="font13" id="p6_t92" reading_order_no="91" segment_no="9" tag_type="table">Class</text>
<text top="453" left="401" width="13" height="8" font="font13" id="p6_t93" reading_order_no="92" segment_no="9" tag_type="table">Pre</text>
<text top="453" left="429" width="14" height="8" font="font13" id="p6_t94" reading_order_no="93" segment_no="9" tag_type="table">Rec</text>
<text top="453" left="457" width="14" height="8" font="font13" id="p6_t95" reading_order_no="94" segment_no="9" tag_type="table">Spe</text>
<text top="453" left="486" width="10" height="8" font="font13" id="p6_t96" reading_order_no="95" segment_no="9" tag_type="table">F1</text>
<text top="453" left="514" width="22" height="8" font="font13" id="p6_t97" reading_order_no="96" segment_no="9" tag_type="table">MAcc</text>
<text top="475" left="308" width="37" height="8" font="font13" id="p6_t98" reading_order_no="97" segment_no="9" tag_type="table">ResNet50</text>
<text top="469" left="369" width="11" height="8" font="font13" id="p6_t99" reading_order_no="98" segment_no="9" tag_type="table">FG</text>
<text top="469" left="401" width="16" height="8" font="font13" id="p6_t100" reading_order_no="99" segment_no="9" tag_type="table">62.3</text>
<text top="469" left="429" width="16" height="8" font="font13" id="p6_t101" reading_order_no="100" segment_no="9" tag_type="table">88.2</text>
<text top="469" left="457" width="16" height="8" font="font13" id="p6_t102" reading_order_no="101" segment_no="9" tag_type="table">89.7</text>
<text top="469" left="486" width="16" height="8" font="font13" id="p6_t103" reading_order_no="102" segment_no="9" tag_type="table">73.0</text>
<text top="475" left="514" width="21" height="8" font="font13" id="p6_t104" reading_order_no="103" segment_no="9" tag_type="table">92.87</text>
<text top="480" left="369" width="12" height="8" font="font13" id="p6_t105" reading_order_no="104" segment_no="9" tag_type="table">BG</text>
<text top="480" left="401" width="16" height="8" font="font13" id="p6_t106" reading_order_no="105" segment_no="9" tag_type="table">97.5</text>
<text top="480" left="429" width="16" height="8" font="font13" id="p6_t107" reading_order_no="106" segment_no="9" tag_type="table">89.7</text>
<text top="480" left="457" width="16" height="8" font="font13" id="p6_t108" reading_order_no="107" segment_no="9" tag_type="table">88.2</text>
<text top="480" left="486" width="16" height="8" font="font13" id="p6_t109" reading_order_no="108" segment_no="9" tag_type="table">93.4</text>
<text top="497" left="308" width="49" height="8" font="font13" id="p6_t110" reading_order_no="109" segment_no="9" tag_type="table">Inception-V3</text>
<text top="491" left="369" width="11" height="8" font="font13" id="p6_t111" reading_order_no="110" segment_no="9" tag_type="table">FG</text>
<text top="491" left="401" width="16" height="8" font="font13" id="p6_t112" reading_order_no="111" segment_no="9" tag_type="table">61.8</text>
<text top="491" left="429" width="16" height="8" font="font13" id="p6_t113" reading_order_no="112" segment_no="9" tag_type="table">88.6</text>
<text top="491" left="457" width="16" height="8" font="font13" id="p6_t114" reading_order_no="113" segment_no="9" tag_type="table">89.5</text>
<text top="491" left="486" width="16" height="8" font="font13" id="p6_t115" reading_order_no="114" segment_no="9" tag_type="table">72.8</text>
<text top="497" left="514" width="21" height="8" font="font13" id="p6_t116" reading_order_no="115" segment_no="9" tag_type="table">90.24</text>
<text top="502" left="369" width="12" height="8" font="font13" id="p6_t117" reading_order_no="116" segment_no="9" tag_type="table">BG</text>
<text top="502" left="401" width="16" height="8" font="font13" id="p6_t118" reading_order_no="117" segment_no="9" tag_type="table">97.6</text>
<text top="502" left="429" width="16" height="8" font="font13" id="p6_t119" reading_order_no="118" segment_no="9" tag_type="table">89.5</text>
<text top="502" left="457" width="16" height="8" font="font13" id="p6_t120" reading_order_no="119" segment_no="9" tag_type="table">88.6</text>
<text top="502" left="486" width="16" height="8" font="font13" id="p6_t121" reading_order_no="120" segment_no="9" tag_type="table">93.4</text>
<text top="519" left="308" width="30" height="8" font="font13" id="p6_t122" reading_order_no="121" segment_no="9" tag_type="table">VGG-16</text>
<text top="513" left="369" width="11" height="8" font="font13" id="p6_t123" reading_order_no="122" segment_no="9" tag_type="table">FG</text>
<text top="513" left="401" width="16" height="8" font="font13" id="p6_t124" reading_order_no="123" segment_no="9" tag_type="table">63.1</text>
<text top="513" left="429" width="16" height="8" font="font13" id="p6_t125" reading_order_no="124" segment_no="9" tag_type="table">88.6</text>
<text top="513" left="457" width="16" height="8" font="font13" id="p6_t126" reading_order_no="125" segment_no="9" tag_type="table">90.0</text>
<text top="513" left="486" width="16" height="8" font="font13" id="p6_t127" reading_order_no="126" segment_no="9" tag_type="table">73.7</text>
<text top="519" left="514" width="21" height="8" font="font13" id="p6_t128" reading_order_no="127" segment_no="9" tag_type="table">92.09</text>
<text top="524" left="369" width="12" height="8" font="font13" id="p6_t129" reading_order_no="128" segment_no="9" tag_type="table">BG</text>
<text top="524" left="401" width="16" height="8" font="font13" id="p6_t130" reading_order_no="129" segment_no="9" tag_type="table">97.6</text>
<text top="524" left="429" width="16" height="8" font="font13" id="p6_t131" reading_order_no="130" segment_no="9" tag_type="table">90.0</text>
<text top="524" left="457" width="16" height="8" font="font13" id="p6_t132" reading_order_no="131" segment_no="9" tag_type="table">88.6</text>
<text top="524" left="486" width="16" height="8" font="font13" id="p6_t133" reading_order_no="132" segment_no="9" tag_type="table">93.6</text>
<text top="541" left="308" width="44" height="8" font="font13" id="p6_t134" reading_order_no="133" segment_no="9" tag_type="table">X-Inception</text>
<text top="535" left="369" width="11" height="8" font="font13" id="p6_t135" reading_order_no="134" segment_no="9" tag_type="table">FG</text>
<text top="535" left="401" width="16" height="8" font="font13" id="p6_t136" reading_order_no="135" segment_no="9" tag_type="table">53.3</text>
<text top="535" left="429" width="16" height="8" font="font13" id="p6_t137" reading_order_no="136" segment_no="9" tag_type="table">89.2</text>
<text top="535" left="457" width="16" height="8" font="font13" id="p6_t138" reading_order_no="137" segment_no="9" tag_type="table">85.0</text>
<text top="535" left="486" width="16" height="8" font="font13" id="p6_t139" reading_order_no="138" segment_no="9" tag_type="table">66.7</text>
<text top="541" left="514" width="21" height="8" font="font13" id="p6_t140" reading_order_no="139" segment_no="9" tag_type="table">91.10</text>
<text top="546" left="369" width="12" height="8" font="font13" id="p6_t141" reading_order_no="140" segment_no="9" tag_type="table">BG</text>
<text top="546" left="401" width="16" height="8" font="font13" id="p6_t142" reading_order_no="141" segment_no="9" tag_type="table">96.7</text>
<text top="546" left="429" width="16" height="8" font="font13" id="p6_t143" reading_order_no="142" segment_no="9" tag_type="table">85.0</text>
<text top="546" left="457" width="16" height="8" font="font13" id="p6_t144" reading_order_no="143" segment_no="9" tag_type="table">89.2</text>
<text top="546" left="486" width="16" height="8" font="font13" id="p6_t145" reading_order_no="144" segment_no="9" tag_type="table">90.9</text>
<text top="563" left="308" width="15" height="8" font="font13" id="p6_t146" reading_order_no="145" segment_no="9" tag_type="table">ViT</text>
<text top="557" left="369" width="11" height="8" font="font13" id="p6_t147" reading_order_no="146" segment_no="9" tag_type="table">FG</text>
<text top="557" left="401" width="16" height="8" font="font13" id="p6_t148" reading_order_no="147" segment_no="9" tag_type="table">62.4</text>
<text top="557" left="429" width="16" height="8" font="font13" id="p6_t149" reading_order_no="148" segment_no="9" tag_type="table">84.1</text>
<text top="557" left="457" width="16" height="8" font="font13" id="p6_t150" reading_order_no="149" segment_no="9" tag_type="table">90.3</text>
<text top="557" left="486" width="16" height="8" font="font13" id="p6_t151" reading_order_no="150" segment_no="9" tag_type="table">71.6</text>
<text top="563" left="514" width="21" height="8" font="font13" id="p6_t152" reading_order_no="151" segment_no="9" tag_type="table">89.26</text>
<text top="568" left="369" width="12" height="8" font="font13" id="p6_t153" reading_order_no="152" segment_no="9" tag_type="table">BG</text>
<text top="568" left="401" width="16" height="8" font="font13" id="p6_t154" reading_order_no="153" segment_no="9" tag_type="table">96.7</text>
<text top="568" left="429" width="16" height="8" font="font13" id="p6_t155" reading_order_no="154" segment_no="9" tag_type="table">90.3</text>
<text top="568" left="457" width="16" height="8" font="font13" id="p6_t156" reading_order_no="155" segment_no="9" tag_type="table">84.1</text>
<text top="568" left="486" width="16" height="8" font="font13" id="p6_t157" reading_order_no="156" segment_no="9" tag_type="table">93.4</text>
<text top="601" left="307" width="237" height="13" font="font7" id="p6_t158" reading_order_no="157" segment_no="10" tag_type="text">thermore , the lowest prediction Acc of the transparent fore-</text>
<text top="613" left="307" width="156" height="13" font="font7" id="p6_t159" reading_order_no="158" segment_no="10" tag_type="text">ground is the X-Inception value of 51.8</text>
<text top="615" left="463" width="7" height="9" font="font23" id="p6_t160" reading_order_no="159" segment_no="10" tag_type="text">%</text>
<text top="613" left="470" width="74" height="13" font="font7" id="p6_t161" reading_order_no="160" segment_no="10" tag_type="text">, and the highest is</text>
<text top="625" left="307" width="108" height="13" font="font7" id="p6_t162" reading_order_no="161" segment_no="10" tag_type="text">the ResNet50 value of 62.2</text>
<text top="627" left="415" width="7" height="9" font="font23" id="p6_t163" reading_order_no="162" segment_no="10" tag_type="text">%</text>
<text top="625" left="422" width="2" height="13" font="font7" id="p6_t164" reading_order_no="163" segment_no="10" tag_type="text">.</text>
<text top="637" left="322" width="222" height="13" font="font7" id="p6_t165" reading_order_no="164" segment_no="11" tag_type="text">In order to more intuitively express the classification re-</text>
<text top="649" left="307" width="237" height="13" font="font7" id="p6_t166" reading_order_no="165" segment_no="11" tag_type="text">sults of CNNs and ViT models for transparent image patches,</text>
<text top="661" left="307" width="237" height="13" font="font7" id="p6_t167" reading_order_no="166" segment_no="11" tag_type="text">we summarize the confusion matrices predicted by five mod-</text>
<text top="672" left="307" width="79" height="13" font="font7" id="p6_t168" reading_order_no="167" segment_no="11" tag_type="text">els is shown in Fig.</text>
<text top="672" left="388" width="5" height="13" font="font9" id="p6_t169" reading_order_no="168" segment_no="11" tag_type="text"><a href="deeplearning_paper38.html#8">7</a></text>
<text top="672" left="393" width="151" height="13" font="font7" id="p6_t170" reading_order_no="169" segment_no="11" tag_type="text"><a href="deeplearning_paper38.html#8">. </a>We find that the ability of CNNs to</text>
<text top="684" left="307" width="237" height="13" font="font7" id="p6_t171" reading_order_no="170" segment_no="11" tag_type="text">classify foreground patches of transparent images is higher</text>
<text top="696" left="307" width="255" height="13" font="font7" id="p6_t172" reading_order_no="171" segment_no="11" tag_type="text">than that of ViT. Among them, the best CNNs model is Inception-</text>
<text top="708" left="306" width="238" height="13" font="font7" id="p6_t173" reading_order_no="172" segment_no="11" tag_type="text">V3, which correctly classified 29686 foreground patches, ac-</text>
<text top="720" left="307" width="73" height="13" font="font7" id="p6_t174" reading_order_no="173" segment_no="11" tag_type="text">counting for 91.50</text>
<text top="723" left="380" width="7" height="9" font="font23" id="p6_t175" reading_order_no="174" segment_no="11" tag_type="text">%</text>
<text top="720" left="390" width="154" height="13" font="font7" id="p6_t176" reading_order_no="175" segment_no="11" tag_type="text">of the total correct foreground patches.</text>
<text top="732" left="307" width="237" height="13" font="font7" id="p6_t177" reading_order_no="176" segment_no="11" tag_type="text">ViT correctly classified 27177 foreground patches, account-</text>
<text top="759" left="51" width="78" height="8" font="font13" id="p6_t178" reading_order_no="177" segment_no="13" tag_type="footnote">HeChen Yang et al.:</text>
<text top="759" left="133" width="108" height="8" font="font14" id="p6_t179" reading_order_no="178" segment_no="13" tag_type="footnote"><i>Preprint submitted to Elsevier</i></text>
<text top="759" left="495" width="49" height="8" font="font13" id="p6_t180" reading_order_no="179" segment_no="14" tag_type="text">Page 6 of 12</text>
</page>
<page number="7" position="absolute" top="0" left="0" height="793" width="595">
	<fontspec id="font29" size="7" family="Calibri" color="#000000"/>
<text top="37" left="241" width="113" height="8" font="font13" id="p7_t1" reading_order_no="0" segment_no="0" tag_type="text">Leveraging social media news</text>
<text top="67" left="108" width="27" height="9" font="font29" id="p7_t2" reading_order_no="1" segment_no="1" tag_type="figure">Resnet50</text>
<text top="67" left="146" width="37" height="9" font="font29" id="p7_t3" reading_order_no="2" segment_no="1" tag_type="figure">Inception-V3</text>
<text top="67" left="193" width="22" height="9" font="font29" id="p7_t4" reading_order_no="3" segment_no="1" tag_type="figure">VGG-16</text>
<text top="67" left="234" width="33" height="9" font="font29" id="p7_t5" reading_order_no="4" segment_no="1" tag_type="figure">X-Inception</text>
<text top="67" left="285" width="9" height="9" font="font29" id="p7_t6" reading_order_no="5" segment_no="1" tag_type="figure">ViT</text>
<text top="66" left="359" width="27" height="9" font="font29" id="p7_t7" reading_order_no="6" segment_no="1" tag_type="figure">Resnet50</text>
<text top="66" left="398" width="37" height="9" font="font29" id="p7_t8" reading_order_no="7" segment_no="1" tag_type="figure">Inception-V3</text>
<text top="66" left="447" width="22" height="9" font="font29" id="p7_t9" reading_order_no="8" segment_no="1" tag_type="figure">VGG-16</text>
<text top="66" left="487" width="33" height="9" font="font29" id="p7_t10" reading_order_no="9" segment_no="1" tag_type="figure">X-Inception</text>
<text top="66" left="535" width="9" height="9" font="font29" id="p7_t11" reading_order_no="10" segment_no="1" tag_type="figure">ViT</text>
<text top="474" left="143" width="35" height="8" font="font20" id="p7_t12" reading_order_no="11" segment_no="2" tag_type="text">Figure 6:</text>
<text top="474" left="182" width="68" height="8" font="font13" id="p7_t13" reading_order_no="12" segment_no="2" tag_type="text">Reconstruction of</text>
<text top="475" left="253" width="19" height="8" font="font24" id="p7_t14" reading_order_no="13" segment_no="2" tag_type="text">8 × 8</text>
<text top="474" left="274" width="178" height="8" font="font13" id="p7_t15" reading_order_no="14" segment_no="2" tag_type="text">pixels transparent images classification results.</text>
<text top="509" left="51" width="53" height="13" font="font7" id="p7_t16" reading_order_no="15" segment_no="3" tag_type="text">ing for 83.76</text>
<text top="512" left="104" width="7" height="9" font="font23" id="p7_t17" reading_order_no="16" segment_no="3" tag_type="text">%</text>
<text top="509" left="115" width="173" height="13" font="font7" id="p7_t18" reading_order_no="17" segment_no="3" tag_type="text">of the total correct foreground patches. In</text>
<text top="521" left="51" width="237" height="13" font="font7" id="p7_t19" reading_order_no="18" segment_no="3" tag_type="text">addition, the number of correctly classified backgrounds in</text>
<text top="533" left="51" width="203" height="13" font="font7" id="p7_t20" reading_order_no="19" segment_no="3" tag_type="text">ResNet50 is at most 165369, accounting for 90.57</text>
<text top="535" left="255" width="7" height="9" font="font23" id="p7_t21" reading_order_no="20" segment_no="3" tag_type="text">%</text>
<text top="533" left="265" width="24" height="13" font="font7" id="p7_t22" reading_order_no="21" segment_no="3" tag_type="text">of the</text>
<text top="545" left="51" width="237" height="13" font="font7" id="p7_t23" reading_order_no="22" segment_no="3" tag_type="text">total correct background patches, and the Pre of the classi-</text>
<text top="557" left="51" width="129" height="13" font="font7" id="p7_t24" reading_order_no="23" segment_no="3" tag_type="text">fied background patches is 97.55</text>
<text top="559" left="181" width="7" height="9" font="font23" id="p7_t25" reading_order_no="24" segment_no="3" tag_type="text">%</text>
<text top="557" left="188" width="101" height="13" font="font7" id="p7_t26" reading_order_no="25" segment_no="3" tag_type="text">. Among the five models,</text>
<text top="569" left="51" width="230" height="13" font="font7" id="p7_t27" reading_order_no="26" segment_no="3" tag_type="text">ResNet50 has the highest prediction accuracy rate of 90.06</text>
<text top="571" left="281" width="7" height="9" font="font23" id="p7_t28" reading_order_no="27" segment_no="3" tag_type="text">%</text>
<text top="581" left="51" width="237" height="13" font="font7" id="p7_t29" reading_order_no="28" segment_no="3" tag_type="text">To better show the classification results, we reconstruct the</text>
<text top="593" left="51" width="148" height="13" font="font7" id="p7_t30" reading_order_no="29" segment_no="3" tag_type="text">transparent image after dicing in Fig.</text>
<text top="593" left="201" width="5" height="13" font="font9" id="p7_t31" reading_order_no="30" segment_no="3" tag_type="text"><a href="deeplearning_paper38.html#7">6</a></text>
<text top="593" left="206" width="2" height="13" font="font7" id="p7_t32" reading_order_no="31" segment_no="3" tag_type="text"><a href="deeplearning_paper38.html#7">.</a></text>
<text top="605" left="66" width="26" height="13" font="font7" id="p7_t33" reading_order_no="32" segment_no="7" tag_type="text">In Tab</text>
<text top="605" left="95" width="5" height="13" font="font9" id="p7_t34" reading_order_no="33" segment_no="7" tag_type="text"><a href="deeplearning_paper38.html#7">5</a></text>
<text top="605" left="103" width="186" height="13" font="font7" id="p7_t35" reading_order_no="34" segment_no="7" tag_type="text">we calculate the model training and prediction</text>
<text top="617" left="51" width="237" height="13" font="font7" id="p7_t36" reading_order_no="35" segment_no="7" tag_type="text">time and the size of the model during the experiment. From</text>
<text top="629" left="51" width="237" height="13" font="font7" id="p7_t37" reading_order_no="36" segment_no="7" tag_type="text">the perspective of model training time, the ViT model is</text>
<text top="640" left="51" width="237" height="13" font="font7" id="p7_t38" reading_order_no="37" segment_no="7" tag_type="text">much lower than CNNs models, where the ViT training time</text>
<text top="652" left="51" width="237" height="13" font="font7" id="p7_t39" reading_order_no="38" segment_no="7" tag_type="text">is 12418 seconds, and the X-Inception training time is the</text>
<text top="664" left="51" width="237" height="13" font="font7" id="p7_t40" reading_order_no="39" segment_no="7" tag_type="text">longest 45897 seconds. From the perspective of the size of</text>
<text top="676" left="51" width="237" height="13" font="font7" id="p7_t41" reading_order_no="40" segment_no="7" tag_type="text">the model, the minimum size of the ViT model is 31.2M,</text>
<text top="688" left="51" width="237" height="13" font="font7" id="p7_t42" reading_order_no="41" segment_no="7" tag_type="text">and the maximum size of the ResNet50 model is 114M. We</text>
<text top="700" left="51" width="237" height="13" font="font7" id="p7_t43" reading_order_no="42" segment_no="7" tag_type="text">calculate the time of the five prediction models. The fastest</text>
<text top="712" left="51" width="237" height="13" font="font7" id="p7_t44" reading_order_no="43" segment_no="7" tag_type="text">prediction time of VGG-16 is 757 seconds and the prediction</text>
<text top="724" left="51" width="237" height="13" font="font7" id="p7_t45" reading_order_no="44" segment_no="7" tag_type="text">time of a single picture is 0.0063 second. The slowest time</text>
<text top="514" left="307" width="29" height="8" font="font20" id="p7_t46" reading_order_no="45" segment_no="4" tag_type="title">Table 5</text>
<text top="525" left="307" width="237" height="8" font="font13" id="p7_t47" reading_order_no="46" segment_no="5" tag_type="text">A comparison of the classification results on train and test sets</text>
<text top="536" left="307" width="7" height="8" font="font13" id="p7_t48" reading_order_no="47" segment_no="5" tag_type="text">of</text>
<text top="537" left="317" width="18" height="8" font="font24" id="p7_t49" reading_order_no="48" segment_no="5" tag_type="text">8 × 8</text>
<text top="536" left="338" width="206" height="8" font="font13" id="p7_t50" reading_order_no="49" segment_no="5" tag_type="text">pixels patches. Train (Train times), Test (Test times)</text>
<text top="547" left="307" width="187" height="8" font="font13" id="p7_t51" reading_order_no="50" segment_no="5" tag_type="text">and Avg (Single picture prediction time )(In [s].)</text>
<text top="566" left="322" width="23" height="8" font="font13" id="p7_t52" reading_order_no="51" segment_no="6" tag_type="table">model</text>
<text top="566" left="383" width="20" height="8" font="font13" id="p7_t53" reading_order_no="52" segment_no="6" tag_type="table">Train</text>
<text top="566" left="418" width="16" height="8" font="font13" id="p7_t54" reading_order_no="53" segment_no="6" tag_type="table">Test</text>
<text top="566" left="448" width="15" height="8" font="font13" id="p7_t55" reading_order_no="54" segment_no="6" tag_type="table">Avg</text>
<text top="566" left="486" width="37" height="8" font="font13" id="p7_t56" reading_order_no="55" segment_no="6" tag_type="table">Size(MB)</text>
<text top="582" left="322" width="37" height="8" font="font13" id="p7_t57" reading_order_no="56" segment_no="6" tag_type="table">ResNet50</text>
<text top="582" left="383" width="23" height="8" font="font13" id="p7_t58" reading_order_no="57" segment_no="6" tag_type="table">48762</text>
<text top="582" left="418" width="18" height="8" font="font13" id="p7_t59" reading_order_no="58" segment_no="6" tag_type="table">1448</text>
<text top="582" left="448" width="26" height="8" font="font13" id="p7_t60" reading_order_no="59" segment_no="6" tag_type="table">0.0067</text>
<text top="582" left="486" width="14" height="8" font="font13" id="p7_t61" reading_order_no="60" segment_no="6" tag_type="table">114</text>
<text top="593" left="322" width="49" height="8" font="font13" id="p7_t62" reading_order_no="61" segment_no="6" tag_type="table">Inception-V3</text>
<text top="593" left="383" width="23" height="8" font="font13" id="p7_t63" reading_order_no="62" segment_no="6" tag_type="table">61443</text>
<text top="593" left="418" width="18" height="8" font="font13" id="p7_t64" reading_order_no="63" segment_no="6" tag_type="table">1186</text>
<text top="593" left="448" width="26" height="8" font="font13" id="p7_t65" reading_order_no="64" segment_no="6" tag_type="table">0.0055</text>
<text top="593" left="486" width="14" height="8" font="font13" id="p7_t66" reading_order_no="65" segment_no="6" tag_type="table">107</text>
<text top="604" left="322" width="30" height="8" font="font13" id="p7_t67" reading_order_no="66" segment_no="6" tag_type="table">VGG-16</text>
<text top="604" left="383" width="23" height="8" font="font13" id="p7_t68" reading_order_no="67" segment_no="6" tag_type="table">49477</text>
<text top="604" left="418" width="14" height="8" font="font13" id="p7_t69" reading_order_no="68" segment_no="6" tag_type="table">757</text>
<text top="604" left="448" width="26" height="8" font="font13" id="p7_t70" reading_order_no="69" segment_no="6" tag_type="table">0.0035</text>
<text top="604" left="486" width="16" height="8" font="font13" id="p7_t71" reading_order_no="70" segment_no="6" tag_type="table">62.2</text>
<text top="615" left="322" width="44" height="8" font="font13" id="p7_t72" reading_order_no="71" segment_no="6" tag_type="table">X-inception</text>
<text top="615" left="383" width="23" height="8" font="font13" id="p7_t73" reading_order_no="72" segment_no="6" tag_type="table">61247</text>
<text top="615" left="418" width="14" height="8" font="font13" id="p7_t74" reading_order_no="73" segment_no="6" tag_type="table">999</text>
<text top="615" left="448" width="26" height="8" font="font13" id="p7_t75" reading_order_no="74" segment_no="6" tag_type="table">0.0046</text>
<text top="615" left="486" width="14" height="8" font="font13" id="p7_t76" reading_order_no="75" segment_no="6" tag_type="table">103</text>
<text top="626" left="322" width="15" height="8" font="font13" id="p7_t77" reading_order_no="76" segment_no="6" tag_type="table">ViT</text>
<text top="626" left="383" width="23" height="8" font="font13" id="p7_t78" reading_order_no="77" segment_no="6" tag_type="table">22133</text>
<text top="626" left="418" width="18" height="8" font="font13" id="p7_t79" reading_order_no="78" segment_no="6" tag_type="table">1670</text>
<text top="626" left="448" width="26" height="8" font="font13" id="p7_t80" reading_order_no="79" segment_no="6" tag_type="table">0.0078</text>
<text top="626" left="486" width="16" height="8" font="font13" id="p7_t81" reading_order_no="80" segment_no="6" tag_type="table">31.2</text>
<text top="658" left="307" width="237" height="13" font="font7" id="p7_t82" reading_order_no="81" segment_no="8" tag_type="text">of ViT is 1670 seconds and the prediction time of a single</text>
<text top="670" left="307" width="99" height="13" font="font7" id="p7_t83" reading_order_no="82" segment_no="8" tag_type="text">picture is 0.0078 second.</text>
<text top="694" left="307" width="148" height="9" font="font22" id="p7_t84" reading_order_no="83" segment_no="9" tag_type="title"><i><b>3.3.2. Comparative Experiment of</b></i></text>
<text top="694" left="458" width="43" height="10" font="font23" id="p7_t85" reading_order_no="84" segment_no="9" tag_type="title">224 × 224</text>
<text top="694" left="503" width="26" height="9" font="font22" id="p7_t86" reading_order_no="85" segment_no="9" tag_type="title"><i><b>Pixels</b></i></text>
<text top="706" left="335" width="33" height="9" font="font22" id="p7_t87" reading_order_no="86" segment_no="9" tag_type="title"><i><b>Patches</b></i></text>
<text top="718" left="307" width="202" height="10" font="font28" id="p7_t88" reading_order_no="87" segment_no="10" tag_type="text"><i><b>Comparison on Training and Validation Sets:</b></i></text>
<text top="716" left="514" width="35" height="13" font="font7" id="p7_t89" reading_order_no="88" segment_no="10" tag_type="text">We com-</text>
<text top="728" left="307" width="32" height="13" font="font7" id="p7_t90" reading_order_no="89" segment_no="10" tag_type="text">pare the</text>
<text top="731" left="341" width="41" height="9" font="font23" id="p7_t91" reading_order_no="90" segment_no="10" tag_type="text">224 × 224</text>
<text top="728" left="385" width="159" height="13" font="font7" id="p7_t92" reading_order_no="91" segment_no="10" tag_type="text">pixels patches in the same way as in the</text>
<text top="759" left="51" width="78" height="8" font="font13" id="p7_t93" reading_order_no="92" segment_no="11" tag_type="footnote">HeChen Yang et al.:</text>
<text top="759" left="133" width="108" height="8" font="font14" id="p7_t94" reading_order_no="93" segment_no="11" tag_type="footnote"><i>Preprint submitted to Elsevier</i></text>
<text top="759" left="495" width="49" height="8" font="font13" id="p7_t95" reading_order_no="94" segment_no="12" tag_type="text">Page 7 of 12</text>
</page>
<page number="8" position="absolute" top="0" left="0" height="793" width="595">
	<fontspec id="font30" size="8" family="DengXian" color="#000000"/>
	<fontspec id="font31" size="8" family="DengXian,Bold" color="#c00000"/>
	<fontspec id="font32" size="7" family="DengXian" color="#000000"/>
	<fontspec id="font33" size="9" family="DengXian" color="#000000"/>
	<fontspec id="font34" size="9" family="TimesNewRomanPSMT" color="#000000"/>
<text top="37" left="241" width="113" height="8" font="font13" id="p8_t1" reading_order_no="0" segment_no="0" tag_type="text">Leveraging social media news</text>
<text top="72" left="98" width="25" height="10" font="font30" id="p8_t2" reading_order_no="23" segment_no="1" tag_type="figure">165369</text>
<text top="82" left="98" width="24" height="10" font="font31" id="p8_t3" reading_order_no="24" segment_no="1" tag_type="figure"><b>76.90%</b></text>
<text top="72" left="145" width="17" height="10" font="font30" id="p8_t4" reading_order_no="25" segment_no="1" tag_type="figure">4156</text>
<text top="82" left="144" width="19" height="10" font="font31" id="p8_t5" reading_order_no="26" segment_no="1" tag_type="figure"><b>1.93%</b></text>
<text top="67" left="184" width="27" height="10" font="font31" id="p8_t6" reading_order_no="27" segment_no="1" tag_type="figure"><b>169525</b></text>
<text top="77" left="186" width="24" height="10" font="font31" id="p8_t7" reading_order_no="28" segment_no="1" tag_type="figure"><b>97.54%</b></text>
<text top="86" left="188" width="19" height="10" font="font31" id="p8_t8" reading_order_no="29" segment_no="1" tag_type="figure"><b>2.46%</b></text>
<text top="115" left="100" width="21" height="10" font="font30" id="p8_t9" reading_order_no="30" segment_no="1" tag_type="figure">17226</text>
<text top="125" left="101" width="19" height="10" font="font31" id="p8_t10" reading_order_no="31" segment_no="1" tag_type="figure"><b>8.01%</b></text>
<text top="115" left="143" width="21" height="10" font="font30" id="p8_t11" reading_order_no="32" segment_no="1" tag_type="figure">28289</text>
<text top="125" left="142" width="24" height="10" font="font31" id="p8_t12" reading_order_no="33" segment_no="1" tag_type="figure"><b>13.16%</b></text>
<text top="110" left="186" width="22" height="10" font="font31" id="p8_t13" reading_order_no="34" segment_no="1" tag_type="figure"><b>45515</b></text>
<text top="120" left="186" width="24" height="10" font="font31" id="p8_t14" reading_order_no="35" segment_no="1" tag_type="figure"><b>62.15%</b></text>
<text top="129" left="186" width="24" height="10" font="font31" id="p8_t15" reading_order_no="36" segment_no="1" tag_type="figure"><b>37.85%</b></text>
<text top="153" left="97" width="27" height="10" font="font31" id="p8_t16" reading_order_no="37" segment_no="1" tag_type="figure"><b>182595</b></text>
<text top="163" left="98" width="24" height="10" font="font31" id="p8_t17" reading_order_no="38" segment_no="1" tag_type="figure"><b>90.57%</b></text>
<text top="172" left="101" width="19" height="10" font="font31" id="p8_t18" reading_order_no="39" segment_no="1" tag_type="figure"><b>9.43%</b></text>
<text top="153" left="143" width="22" height="10" font="font31" id="p8_t19" reading_order_no="40" segment_no="1" tag_type="figure"><b>32445</b></text>
<text top="163" left="142" width="24" height="10" font="font31" id="p8_t20" reading_order_no="41" segment_no="1" tag_type="figure"><b>87.19%</b></text>
<text top="172" left="142" width="24" height="10" font="font31" id="p8_t21" reading_order_no="42" segment_no="1" tag_type="figure"><b>12.81%</b></text>
<text top="153" left="184" width="27" height="10" font="font31" id="p8_t22" reading_order_no="43" segment_no="1" tag_type="figure"><b>215040</b></text>
<text top="163" left="186" width="24" height="10" font="font31" id="p8_t23" reading_order_no="44" segment_no="1" tag_type="figure"><b>90.06%</b></text>
<text top="172" left="188" width="19" height="10" font="font31" id="p8_t24" reading_order_no="45" segment_no="1" tag_type="figure"><b>9.94%</b></text>
<text top="192" left="93" width="36" height="8" font="font32" id="p8_t25" reading_order_no="46" segment_no="1" tag_type="figure">background</text>
<text top="199" left="133" width="38" height="10" font="font33" id="p8_t26" reading_order_no="49" segment_no="1" tag_type="figure">True Label</text>
<text top="146" left="72" width="0" height="10" font="font33" id="p8_t27" reading_order_no="8" segment_no="1" tag_type="figure">Pr</text>
<text top="138" left="72" width="0" height="10" font="font33" id="p8_t28" reading_order_no="7" segment_no="1" tag_type="figure">ed</text>
<text top="129" left="72" width="0" height="10" font="font33" id="p8_t29" reading_order_no="6" segment_no="1" tag_type="figure">ic</text>
<text top="123" left="72" width="0" height="10" font="font33" id="p8_t30" reading_order_no="5" segment_no="1" tag_type="figure">te</text>
<text top="116" left="72" width="0" height="10" font="font33" id="p8_t31" reading_order_no="4" segment_no="1" tag_type="figure">d </text>
<text top="109" left="72" width="0" height="10" font="font33" id="p8_t32" reading_order_no="3" segment_no="1" tag_type="figure">La</text>
<text top="100" left="72" width="0" height="10" font="font33" id="p8_t33" reading_order_no="2" segment_no="1" tag_type="figure">be</text>
<text top="91" left="72" width="0" height="10" font="font33" id="p8_t34" reading_order_no="1" segment_no="1" tag_type="figure">l</text>
<text top="210" left="135" width="34" height="12" font="font34" id="p8_t35" reading_order_no="50" segment_no="1" tag_type="figure">ResNet50</text>
<text top="191" left="136" width="34" height="8" font="font32" id="p8_t36" reading_order_no="47" segment_no="1" tag_type="figure">foreground</text>
<text top="192" left="186" width="23" height="8" font="font32" id="p8_t37" reading_order_no="48" segment_no="1" tag_type="figure">sum-lin</text>
<text top="95" left="84" width="0" height="8" font="font32" id="p8_t38" reading_order_no="13" segment_no="1" tag_type="figure">ba</text>
<text top="87" left="84" width="0" height="8" font="font32" id="p8_t39" reading_order_no="12" segment_no="1" tag_type="figure">ck</text>
<text top="81" left="84" width="0" height="8" font="font32" id="p8_t40" reading_order_no="11" segment_no="1" tag_type="figure">gr</text>
<text top="74" left="84" width="0" height="8" font="font32" id="p8_t41" reading_order_no="10" segment_no="1" tag_type="figure">ou</text>
<text top="66" left="84" width="0" height="8" font="font32" id="p8_t42" reading_order_no="9" segment_no="1" tag_type="figure">nd</text>
<text top="136" left="84" width="0" height="8" font="font32" id="p8_t43" reading_order_no="18" segment_no="1" tag_type="figure">fo</text>
<text top="130" left="84" width="0" height="8" font="font32" id="p8_t44" reading_order_no="17" segment_no="1" tag_type="figure">re</text>
<text top="124" left="84" width="0" height="8" font="font32" id="p8_t45" reading_order_no="16" segment_no="1" tag_type="figure">gr</text>
<text top="117" left="84" width="0" height="8" font="font32" id="p8_t46" reading_order_no="15" segment_no="1" tag_type="figure">ou</text>
<text top="109" left="84" width="0" height="8" font="font32" id="p8_t47" reading_order_no="14" segment_no="1" tag_type="figure">nd</text>
<text top="174" left="84" width="0" height="8" font="font32" id="p8_t48" reading_order_no="22" segment_no="1" tag_type="figure">su</text>
<text top="167" left="84" width="0" height="8" font="font32" id="p8_t49" reading_order_no="21" segment_no="1" tag_type="figure">m</text>
<text top="161" left="84" width="0" height="8" font="font32" id="p8_t50" reading_order_no="20" segment_no="1" tag_type="figure">-c</text>
<text top="155" left="84" width="0" height="8" font="font32" id="p8_t51" reading_order_no="19" segment_no="1" tag_type="figure">ol</text>
<text top="73" left="267" width="25" height="10" font="font30" id="p8_t52" reading_order_no="73" segment_no="1" tag_type="figure">155890</text>
<text top="82" left="268" width="24" height="10" font="font31" id="p8_t53" reading_order_no="74" segment_no="1" tag_type="figure"><b>72.49%</b></text>
<text top="73" left="315" width="17" height="10" font="font30" id="p8_t54" reading_order_no="75" segment_no="1" tag_type="figure">2759</text>
<text top="82" left="314" width="19" height="10" font="font31" id="p8_t55" reading_order_no="76" segment_no="1" tag_type="figure"><b>1.28%</b></text>
<text top="68" left="354" width="27" height="10" font="font31" id="p8_t56" reading_order_no="77" segment_no="1" tag_type="figure"><b>158649</b></text>
<text top="77" left="355" width="24" height="10" font="font31" id="p8_t57" reading_order_no="78" segment_no="1" tag_type="figure"><b>98.26%</b></text>
<text top="87" left="357" width="19" height="10" font="font31" id="p8_t58" reading_order_no="79" segment_no="1" tag_type="figure"><b>1.74%</b></text>
<text top="116" left="269" width="21" height="10" font="font30" id="p8_t59" reading_order_no="80" segment_no="1" tag_type="figure">26705</text>
<text top="125" left="268" width="24" height="10" font="font31" id="p8_t60" reading_order_no="81" segment_no="1" tag_type="figure"><b>12.42%</b></text>
<text top="116" left="313" width="21" height="10" font="font30" id="p8_t61" reading_order_no="82" segment_no="1" tag_type="figure">29686</text>
<text top="125" left="312" width="24" height="10" font="font31" id="p8_t62" reading_order_no="83" segment_no="1" tag_type="figure"><b>13.81%</b></text>
<text top="111" left="356" width="22" height="10" font="font31" id="p8_t63" reading_order_no="84" segment_no="1" tag_type="figure"><b>56391</b></text>
<text top="120" left="355" width="24" height="10" font="font31" id="p8_t64" reading_order_no="85" segment_no="1" tag_type="figure"><b>52.64%</b></text>
<text top="130" left="355" width="24" height="10" font="font31" id="p8_t65" reading_order_no="86" segment_no="1" tag_type="figure"><b>47.36%</b></text>
<text top="154" left="267" width="27" height="10" font="font31" id="p8_t66" reading_order_no="87" segment_no="1" tag_type="figure"><b>182595</b></text>
<text top="163" left="268" width="24" height="10" font="font31" id="p8_t67" reading_order_no="88" segment_no="1" tag_type="figure"><b>85.37%</b></text>
<text top="173" left="268" width="24" height="10" font="font31" id="p8_t68" reading_order_no="89" segment_no="1" tag_type="figure"><b>14.63%</b></text>
<text top="154" left="312" width="22" height="10" font="font31" id="p8_t69" reading_order_no="90" segment_no="1" tag_type="figure"><b>32445</b></text>
<text top="163" left="312" width="24" height="10" font="font31" id="p8_t70" reading_order_no="91" segment_no="1" tag_type="figure"><b>91.50%</b></text>
<text top="173" left="314" width="19" height="10" font="font31" id="p8_t71" reading_order_no="92" segment_no="1" tag_type="figure"><b>8.50%</b></text>
<text top="154" left="354" width="27" height="10" font="font31" id="p8_t72" reading_order_no="93" segment_no="1" tag_type="figure"><b>215040</b></text>
<text top="163" left="355" width="24" height="10" font="font31" id="p8_t73" reading_order_no="94" segment_no="1" tag_type="figure"><b>86.30%</b></text>
<text top="173" left="355" width="24" height="10" font="font31" id="p8_t74" reading_order_no="95" segment_no="1" tag_type="figure"><b>13.70%</b></text>
<text top="192" left="262" width="36" height="8" font="font32" id="p8_t75" reading_order_no="96" segment_no="1" tag_type="figure">background</text>
<text top="199" left="304" width="38" height="10" font="font33" id="p8_t76" reading_order_no="99" segment_no="1" tag_type="figure">True Label</text>
<text top="146" left="241" width="0" height="10" font="font33" id="p8_t77" reading_order_no="58" segment_no="1" tag_type="figure">Pr</text>
<text top="139" left="241" width="0" height="10" font="font33" id="p8_t78" reading_order_no="57" segment_no="1" tag_type="figure">ed</text>
<text top="130" left="241" width="0" height="10" font="font33" id="p8_t79" reading_order_no="56" segment_no="1" tag_type="figure">ic</text>
<text top="124" left="241" width="0" height="10" font="font33" id="p8_t80" reading_order_no="55" segment_no="1" tag_type="figure">te</text>
<text top="117" left="241" width="0" height="10" font="font33" id="p8_t81" reading_order_no="54" segment_no="1" tag_type="figure">d </text>
<text top="109" left="241" width="0" height="10" font="font33" id="p8_t82" reading_order_no="53" segment_no="1" tag_type="figure">La</text>
<text top="101" left="241" width="0" height="10" font="font33" id="p8_t83" reading_order_no="52" segment_no="1" tag_type="figure">be</text>
<text top="92" left="241" width="0" height="10" font="font33" id="p8_t84" reading_order_no="51" segment_no="1" tag_type="figure">l</text>
<text top="210" left="301" width="46" height="12" font="font34" id="p8_t85" reading_order_no="100" segment_no="1" tag_type="figure">Inception-V3</text>
<text top="192" left="306" width="34" height="8" font="font32" id="p8_t86" reading_order_no="97" segment_no="1" tag_type="figure">foreground</text>
<text top="192" left="356" width="23" height="8" font="font32" id="p8_t87" reading_order_no="98" segment_no="1" tag_type="figure">sum-lin</text>
<text top="95" left="254" width="0" height="8" font="font32" id="p8_t88" reading_order_no="63" segment_no="1" tag_type="figure">ba</text>
<text top="88" left="254" width="0" height="8" font="font32" id="p8_t89" reading_order_no="62" segment_no="1" tag_type="figure">ck</text>
<text top="81" left="254" width="0" height="8" font="font32" id="p8_t90" reading_order_no="61" segment_no="1" tag_type="figure">gr</text>
<text top="75" left="254" width="0" height="8" font="font32" id="p8_t91" reading_order_no="60" segment_no="1" tag_type="figure">ou</text>
<text top="67" left="254" width="0" height="8" font="font32" id="p8_t92" reading_order_no="59" segment_no="1" tag_type="figure">nd</text>
<text top="137" left="254" width="0" height="8" font="font32" id="p8_t93" reading_order_no="68" segment_no="1" tag_type="figure">fo</text>
<text top="131" left="254" width="0" height="8" font="font32" id="p8_t94" reading_order_no="67" segment_no="1" tag_type="figure">re</text>
<text top="125" left="254" width="0" height="8" font="font32" id="p8_t95" reading_order_no="66" segment_no="1" tag_type="figure">gr</text>
<text top="118" left="254" width="0" height="8" font="font32" id="p8_t96" reading_order_no="65" segment_no="1" tag_type="figure">ou</text>
<text top="110" left="254" width="0" height="8" font="font32" id="p8_t97" reading_order_no="64" segment_no="1" tag_type="figure">nd</text>
<text top="175" left="254" width="0" height="8" font="font32" id="p8_t98" reading_order_no="72" segment_no="1" tag_type="figure">su</text>
<text top="168" left="254" width="0" height="8" font="font32" id="p8_t99" reading_order_no="71" segment_no="1" tag_type="figure">m</text>
<text top="162" left="254" width="0" height="8" font="font32" id="p8_t100" reading_order_no="70" segment_no="1" tag_type="figure">-c</text>
<text top="156" left="254" width="0" height="8" font="font32" id="p8_t101" reading_order_no="69" segment_no="1" tag_type="figure">ol</text>
<text top="73" left="429" width="25" height="10" font="font30" id="p8_t102" reading_order_no="123" segment_no="1" tag_type="figure">163829</text>
<text top="82" left="430" width="24" height="10" font="font31" id="p8_t103" reading_order_no="124" segment_no="1" tag_type="figure"><b>76.18%</b></text>
<text top="73" left="477" width="17" height="10" font="font30" id="p8_t104" reading_order_no="125" segment_no="1" tag_type="figure">3432</text>
<text top="82" left="476" width="19" height="10" font="font31" id="p8_t105" reading_order_no="126" segment_no="1" tag_type="figure"><b>1.60%</b></text>
<text top="68" left="516" width="27" height="10" font="font31" id="p8_t106" reading_order_no="127" segment_no="1" tag_type="figure"><b>167261</b></text>
<text top="77" left="517" width="24" height="10" font="font31" id="p8_t107" reading_order_no="128" segment_no="1" tag_type="figure"><b>97.94%</b></text>
<text top="87" left="519" width="19" height="10" font="font31" id="p8_t108" reading_order_no="129" segment_no="1" tag_type="figure"><b>2.06%</b></text>
<text top="116" left="431" width="21" height="10" font="font30" id="p8_t109" reading_order_no="130" segment_no="1" tag_type="figure">18766</text>
<text top="125" left="432" width="19" height="10" font="font31" id="p8_t110" reading_order_no="131" segment_no="1" tag_type="figure"><b>8.73%</b></text>
<text top="116" left="475" width="21" height="10" font="font30" id="p8_t111" reading_order_no="132" segment_no="1" tag_type="figure">29013</text>
<text top="125" left="474" width="24" height="10" font="font31" id="p8_t112" reading_order_no="133" segment_no="1" tag_type="figure"><b>13.49%</b></text>
<text top="111" left="518" width="22" height="10" font="font31" id="p8_t113" reading_order_no="134" segment_no="1" tag_type="figure"><b>47779</b></text>
<text top="120" left="517" width="24" height="10" font="font31" id="p8_t114" reading_order_no="135" segment_no="1" tag_type="figure"><b>60.72%</b></text>
<text top="130" left="517" width="24" height="10" font="font31" id="p8_t115" reading_order_no="136" segment_no="1" tag_type="figure"><b>39.28%</b></text>
<text top="154" left="428" width="27" height="10" font="font31" id="p8_t116" reading_order_no="137" segment_no="1" tag_type="figure"><b>182595</b></text>
<text top="163" left="430" width="24" height="10" font="font31" id="p8_t117" reading_order_no="138" segment_no="1" tag_type="figure"><b>89.72%</b></text>
<text top="173" left="430" width="24" height="10" font="font31" id="p8_t118" reading_order_no="139" segment_no="1" tag_type="figure"><b>10.28%</b></text>
<text top="154" left="474" width="22" height="10" font="font31" id="p8_t119" reading_order_no="140" segment_no="1" tag_type="figure"><b>32445</b></text>
<text top="163" left="474" width="24" height="10" font="font31" id="p8_t120" reading_order_no="141" segment_no="1" tag_type="figure"><b>89.42%</b></text>
<text top="173" left="474" width="24" height="10" font="font31" id="p8_t121" reading_order_no="142" segment_no="1" tag_type="figure"><b>10.58%</b></text>
<text top="154" left="516" width="27" height="10" font="font31" id="p8_t122" reading_order_no="143" segment_no="1" tag_type="figure"><b>215040</b></text>
<text top="163" left="517" width="24" height="10" font="font31" id="p8_t123" reading_order_no="144" segment_no="1" tag_type="figure"><b>89.68%</b></text>
<text top="173" left="517" width="24" height="10" font="font31" id="p8_t124" reading_order_no="145" segment_no="1" tag_type="figure"><b>10.32%</b></text>
<text top="192" left="425" width="36" height="8" font="font32" id="p8_t125" reading_order_no="146" segment_no="1" tag_type="figure">background</text>
<text top="199" left="466" width="38" height="10" font="font33" id="p8_t126" reading_order_no="149" segment_no="1" tag_type="figure">True Label</text>
<text top="147" left="404" width="0" height="10" font="font33" id="p8_t127" reading_order_no="108" segment_no="1" tag_type="figure">Pr</text>
<text top="139" left="404" width="0" height="10" font="font33" id="p8_t128" reading_order_no="107" segment_no="1" tag_type="figure">ed</text>
<text top="130" left="404" width="0" height="10" font="font33" id="p8_t129" reading_order_no="106" segment_no="1" tag_type="figure">ic</text>
<text top="124" left="404" width="0" height="10" font="font33" id="p8_t130" reading_order_no="105" segment_no="1" tag_type="figure">te</text>
<text top="117" left="404" width="0" height="10" font="font33" id="p8_t131" reading_order_no="104" segment_no="1" tag_type="figure">d </text>
<text top="110" left="404" width="0" height="10" font="font33" id="p8_t132" reading_order_no="103" segment_no="1" tag_type="figure">La</text>
<text top="102" left="404" width="0" height="10" font="font33" id="p8_t133" reading_order_no="102" segment_no="1" tag_type="figure">be</text>
<text top="92" left="404" width="0" height="10" font="font33" id="p8_t134" reading_order_no="101" segment_no="1" tag_type="figure">l</text>
<text top="210" left="471" width="30" height="12" font="font34" id="p8_t135" reading_order_no="150" segment_no="1" tag_type="figure">VGG-16</text>
<text top="191" left="469" width="34" height="8" font="font32" id="p8_t136" reading_order_no="147" segment_no="1" tag_type="figure">foreground</text>
<text top="192" left="519" width="23" height="8" font="font32" id="p8_t137" reading_order_no="148" segment_no="1" tag_type="figure">sum-lin</text>
<text top="96" left="416" width="0" height="8" font="font32" id="p8_t138" reading_order_no="113" segment_no="1" tag_type="figure">ba</text>
<text top="88" left="416" width="0" height="8" font="font32" id="p8_t139" reading_order_no="112" segment_no="1" tag_type="figure">ck</text>
<text top="82" left="416" width="0" height="8" font="font32" id="p8_t140" reading_order_no="111" segment_no="1" tag_type="figure">gr</text>
<text top="76" left="416" width="0" height="8" font="font32" id="p8_t141" reading_order_no="110" segment_no="1" tag_type="figure">ou</text>
<text top="68" left="416" width="0" height="8" font="font32" id="p8_t142" reading_order_no="109" segment_no="1" tag_type="figure">nd</text>
<text top="137" left="416" width="0" height="8" font="font32" id="p8_t143" reading_order_no="118" segment_no="1" tag_type="figure">fo</text>
<text top="131" left="416" width="0" height="8" font="font32" id="p8_t144" reading_order_no="117" segment_no="1" tag_type="figure">re</text>
<text top="125" left="416" width="0" height="8" font="font32" id="p8_t145" reading_order_no="116" segment_no="1" tag_type="figure">gr</text>
<text top="119" left="416" width="0" height="8" font="font32" id="p8_t146" reading_order_no="115" segment_no="1" tag_type="figure">ou</text>
<text top="111" left="416" width="0" height="8" font="font32" id="p8_t147" reading_order_no="114" segment_no="1" tag_type="figure">nd</text>
<text top="175" left="416" width="0" height="8" font="font32" id="p8_t148" reading_order_no="122" segment_no="1" tag_type="figure">su</text>
<text top="169" left="416" width="0" height="8" font="font32" id="p8_t149" reading_order_no="121" segment_no="1" tag_type="figure">m</text>
<text top="163" left="416" width="0" height="8" font="font32" id="p8_t150" reading_order_no="120" segment_no="1" tag_type="figure">-c</text>
<text top="156" left="416" width="0" height="8" font="font32" id="p8_t151" reading_order_no="119" segment_no="1" tag_type="figure">ol</text>
<text top="236" left="182" width="25" height="10" font="font30" id="p8_t152" reading_order_no="173" segment_no="1" tag_type="figure">155186</text>
<text top="245" left="183" width="24" height="10" font="font31" id="p8_t153" reading_order_no="174" segment_no="1" tag_type="figure"><b>72.17%</b></text>
<text top="236" left="230" width="17" height="10" font="font30" id="p8_t154" reading_order_no="175" segment_no="1" tag_type="figure">3019</text>
<text top="245" left="229" width="19" height="10" font="font31" id="p8_t155" reading_order_no="176" segment_no="1" tag_type="figure"><b>1.40%</b></text>
<text top="231" left="269" width="27" height="10" font="font31" id="p8_t156" reading_order_no="177" segment_no="1" tag_type="figure"><b>158205</b></text>
<text top="241" left="270" width="24" height="10" font="font31" id="p8_t157" reading_order_no="178" segment_no="1" tag_type="figure"><b>98.09%</b></text>
<text top="250" left="273" width="19" height="10" font="font31" id="p8_t158" reading_order_no="179" segment_no="1" tag_type="figure"><b>1.91%</b></text>
<text top="279" left="184" width="21" height="10" font="font30" id="p8_t159" reading_order_no="180" segment_no="1" tag_type="figure">27409</text>
<text top="288" left="183" width="24" height="10" font="font31" id="p8_t160" reading_order_no="181" segment_no="1" tag_type="figure"><b>12.75%</b></text>
<text top="279" left="228" width="21" height="10" font="font30" id="p8_t161" reading_order_no="182" segment_no="1" tag_type="figure">29426</text>
<text top="288" left="227" width="24" height="10" font="font31" id="p8_t162" reading_order_no="183" segment_no="1" tag_type="figure"><b>13.68%</b></text>
<text top="274" left="271" width="22" height="10" font="font31" id="p8_t163" reading_order_no="184" segment_no="1" tag_type="figure"><b>56835</b></text>
<text top="284" left="270" width="24" height="10" font="font31" id="p8_t164" reading_order_no="185" segment_no="1" tag_type="figure"><b>51.77%</b></text>
<text top="293" left="270" width="24" height="10" font="font31" id="p8_t165" reading_order_no="186" segment_no="1" tag_type="figure"><b>48.23%</b></text>
<text top="317" left="182" width="27" height="10" font="font31" id="p8_t166" reading_order_no="187" segment_no="1" tag_type="figure"><b>182595</b></text>
<text top="327" left="183" width="24" height="10" font="font31" id="p8_t167" reading_order_no="188" segment_no="1" tag_type="figure"><b>84.99%</b></text>
<text top="336" left="183" width="24" height="10" font="font31" id="p8_t168" reading_order_no="189" segment_no="1" tag_type="figure"><b>15.01%</b></text>
<text top="317" left="228" width="22" height="10" font="font31" id="p8_t169" reading_order_no="190" segment_no="1" tag_type="figure"><b>32445</b></text>
<text top="327" left="227" width="24" height="10" font="font31" id="p8_t170" reading_order_no="191" segment_no="1" tag_type="figure"><b>90.70%</b></text>
<text top="336" left="229" width="19" height="10" font="font31" id="p8_t171" reading_order_no="192" segment_no="1" tag_type="figure"><b>9.30%</b></text>
<text top="317" left="269" width="27" height="10" font="font31" id="p8_t172" reading_order_no="193" segment_no="1" tag_type="figure"><b>215040</b></text>
<text top="327" left="270" width="24" height="10" font="font31" id="p8_t173" reading_order_no="194" segment_no="1" tag_type="figure"><b>85.85%</b></text>
<text top="336" left="270" width="24" height="10" font="font31" id="p8_t174" reading_order_no="195" segment_no="1" tag_type="figure"><b>14.15%</b></text>
<text top="355" left="178" width="36" height="8" font="font32" id="p8_t175" reading_order_no="196" segment_no="1" tag_type="figure">background</text>
<text top="367" left="220" width="38" height="10" font="font33" id="p8_t176" reading_order_no="199" segment_no="1" tag_type="figure">True Label</text>
<text top="311" left="157" width="0" height="10" font="font33" id="p8_t177" reading_order_no="158" segment_no="1" tag_type="figure">Pr</text>
<text top="303" left="157" width="0" height="10" font="font33" id="p8_t178" reading_order_no="157" segment_no="1" tag_type="figure">ed</text>
<text top="294" left="157" width="0" height="10" font="font33" id="p8_t179" reading_order_no="156" segment_no="1" tag_type="figure">ic</text>
<text top="288" left="157" width="0" height="10" font="font33" id="p8_t180" reading_order_no="155" segment_no="1" tag_type="figure">te</text>
<text top="281" left="157" width="0" height="10" font="font33" id="p8_t181" reading_order_no="154" segment_no="1" tag_type="figure">d </text>
<text top="274" left="157" width="0" height="10" font="font33" id="p8_t182" reading_order_no="153" segment_no="1" tag_type="figure">La</text>
<text top="265" left="157" width="0" height="10" font="font33" id="p8_t183" reading_order_no="152" segment_no="1" tag_type="figure">be</text>
<text top="256" left="157" width="0" height="10" font="font33" id="p8_t184" reading_order_no="151" segment_no="1" tag_type="figure">l</text>
<text top="381" left="218" width="41" height="12" font="font34" id="p8_t185" reading_order_no="200" segment_no="1" tag_type="figure">X-Inception</text>
<text top="355" left="222" width="34" height="8" font="font32" id="p8_t186" reading_order_no="197" segment_no="1" tag_type="figure">foreground</text>
<text top="355" left="272" width="23" height="8" font="font32" id="p8_t187" reading_order_no="198" segment_no="1" tag_type="figure">sum-lin</text>
<text top="260" left="169" width="0" height="8" font="font32" id="p8_t188" reading_order_no="163" segment_no="1" tag_type="figure">ba</text>
<text top="252" left="169" width="0" height="8" font="font32" id="p8_t189" reading_order_no="162" segment_no="1" tag_type="figure">ck</text>
<text top="246" left="169" width="0" height="8" font="font32" id="p8_t190" reading_order_no="161" segment_no="1" tag_type="figure">gr</text>
<text top="239" left="169" width="0" height="8" font="font32" id="p8_t191" reading_order_no="160" segment_no="1" tag_type="figure">ou</text>
<text top="232" left="169" width="0" height="8" font="font32" id="p8_t192" reading_order_no="159" segment_no="1" tag_type="figure">nd</text>
<text top="301" left="169" width="0" height="8" font="font32" id="p8_t193" reading_order_no="168" segment_no="1" tag_type="figure">fo</text>
<text top="295" left="169" width="0" height="8" font="font32" id="p8_t194" reading_order_no="167" segment_no="1" tag_type="figure">re</text>
<text top="289" left="169" width="0" height="8" font="font32" id="p8_t195" reading_order_no="166" segment_no="1" tag_type="figure">gr</text>
<text top="283" left="169" width="0" height="8" font="font32" id="p8_t196" reading_order_no="165" segment_no="1" tag_type="figure">ou</text>
<text top="275" left="169" width="0" height="8" font="font32" id="p8_t197" reading_order_no="164" segment_no="1" tag_type="figure">nd</text>
<text top="339" left="169" width="0" height="8" font="font32" id="p8_t198" reading_order_no="172" segment_no="1" tag_type="figure">su</text>
<text top="333" left="169" width="0" height="8" font="font32" id="p8_t199" reading_order_no="171" segment_no="1" tag_type="figure">m</text>
<text top="327" left="169" width="0" height="8" font="font32" id="p8_t200" reading_order_no="170" segment_no="1" tag_type="figure">-c</text>
<text top="320" left="169" width="0" height="8" font="font32" id="p8_t201" reading_order_no="169" segment_no="1" tag_type="figure">ol</text>
<text top="237" left="357" width="25" height="10" font="font30" id="p8_t202" reading_order_no="223" segment_no="1" tag_type="figure">164744</text>
<text top="246" left="358" width="24" height="10" font="font31" id="p8_t203" reading_order_no="224" segment_no="1" tag_type="figure"><b>76.61%</b></text>
<text top="237" left="405" width="17" height="10" font="font30" id="p8_t204" reading_order_no="225" segment_no="1" tag_type="figure">5268</text>
<text top="246" left="404" width="19" height="10" font="font31" id="p8_t205" reading_order_no="226" segment_no="1" tag_type="figure"><b>2.45%</b></text>
<text top="232" left="444" width="27" height="10" font="font31" id="p8_t206" reading_order_no="227" segment_no="1" tag_type="figure"><b>170012</b></text>
<text top="242" left="445" width="24" height="10" font="font31" id="p8_t207" reading_order_no="228" segment_no="1" tag_type="figure"><b>96.90%</b></text>
<text top="251" left="447" width="19" height="10" font="font31" id="p8_t208" reading_order_no="229" segment_no="1" tag_type="figure"><b>3.10%</b></text>
<text top="280" left="359" width="21" height="10" font="font30" id="p8_t209" reading_order_no="230" segment_no="1" tag_type="figure">17851</text>
<text top="289" left="360" width="19" height="10" font="font31" id="p8_t210" reading_order_no="231" segment_no="1" tag_type="figure"><b>8.30%</b></text>
<text top="280" left="403" width="21" height="10" font="font30" id="p8_t211" reading_order_no="232" segment_no="1" tag_type="figure">27177</text>
<text top="289" left="401" width="24" height="10" font="font31" id="p8_t212" reading_order_no="233" segment_no="1" tag_type="figure"><b>12.64%</b></text>
<text top="275" left="446" width="22" height="10" font="font31" id="p8_t213" reading_order_no="234" segment_no="1" tag_type="figure"><b>45028</b></text>
<text top="285" left="445" width="24" height="10" font="font31" id="p8_t214" reading_order_no="235" segment_no="1" tag_type="figure"><b>60.36%</b></text>
<text top="294" left="445" width="24" height="10" font="font31" id="p8_t215" reading_order_no="236" segment_no="1" tag_type="figure"><b>39.64%</b></text>
<text top="318" left="356" width="27" height="10" font="font31" id="p8_t216" reading_order_no="237" segment_no="1" tag_type="figure"><b>182595</b></text>
<text top="327" left="358" width="24" height="10" font="font31" id="p8_t217" reading_order_no="238" segment_no="1" tag_type="figure"><b>90.22%</b></text>
<text top="337" left="360" width="19" height="10" font="font31" id="p8_t218" reading_order_no="239" segment_no="1" tag_type="figure"><b>9.78%</b></text>
<text top="318" left="402" width="22" height="10" font="font31" id="p8_t219" reading_order_no="240" segment_no="1" tag_type="figure"><b>32445</b></text>
<text top="327" left="401" width="24" height="10" font="font31" id="p8_t220" reading_order_no="241" segment_no="1" tag_type="figure"><b>83.76%</b></text>
<text top="337" left="401" width="24" height="10" font="font31" id="p8_t221" reading_order_no="242" segment_no="1" tag_type="figure"><b>16.24%</b></text>
<text top="318" left="444" width="27" height="10" font="font31" id="p8_t222" reading_order_no="243" segment_no="1" tag_type="figure"><b>215040</b></text>
<text top="327" left="445" width="24" height="10" font="font31" id="p8_t223" reading_order_no="244" segment_no="1" tag_type="figure"><b>89.25%</b></text>
<text top="337" left="445" width="24" height="10" font="font31" id="p8_t224" reading_order_no="245" segment_no="1" tag_type="figure"><b>10.75%</b></text>
<text top="356" left="353" width="36" height="8" font="font32" id="p8_t225" reading_order_no="246" segment_no="1" tag_type="figure">background</text>
<text top="367" left="395" width="38" height="10" font="font33" id="p8_t226" reading_order_no="249" segment_no="1" tag_type="figure">True Label</text>
<text top="311" left="332" width="0" height="10" font="font33" id="p8_t227" reading_order_no="208" segment_no="1" tag_type="figure">Pr</text>
<text top="304" left="332" width="0" height="10" font="font33" id="p8_t228" reading_order_no="207" segment_no="1" tag_type="figure">ed</text>
<text top="294" left="332" width="0" height="10" font="font33" id="p8_t229" reading_order_no="206" segment_no="1" tag_type="figure">ic</text>
<text top="289" left="332" width="0" height="10" font="font33" id="p8_t230" reading_order_no="205" segment_no="1" tag_type="figure">te</text>
<text top="281" left="332" width="0" height="10" font="font33" id="p8_t231" reading_order_no="204" segment_no="1" tag_type="figure">d </text>
<text top="274" left="332" width="0" height="10" font="font33" id="p8_t232" reading_order_no="203" segment_no="1" tag_type="figure">La</text>
<text top="266" left="332" width="0" height="10" font="font33" id="p8_t233" reading_order_no="202" segment_no="1" tag_type="figure">be</text>
<text top="257" left="332" width="0" height="10" font="font33" id="p8_t234" reading_order_no="201" segment_no="1" tag_type="figure">l</text>
<text top="381" left="407" width="13" height="12" font="font34" id="p8_t235" reading_order_no="250" segment_no="1" tag_type="figure">ViT</text>
<text top="356" left="397" width="34" height="8" font="font32" id="p8_t236" reading_order_no="247" segment_no="1" tag_type="figure">foreground</text>
<text top="356" left="447" width="23" height="8" font="font32" id="p8_t237" reading_order_no="248" segment_no="1" tag_type="figure">sum-lin</text>
<text top="260" left="344" width="0" height="8" font="font32" id="p8_t238" reading_order_no="213" segment_no="1" tag_type="figure">ba</text>
<text top="253" left="344" width="0" height="8" font="font32" id="p8_t239" reading_order_no="212" segment_no="1" tag_type="figure">ck</text>
<text top="246" left="344" width="0" height="8" font="font32" id="p8_t240" reading_order_no="211" segment_no="1" tag_type="figure">gr</text>
<text top="240" left="344" width="0" height="8" font="font32" id="p8_t241" reading_order_no="210" segment_no="1" tag_type="figure">ou</text>
<text top="232" left="344" width="0" height="8" font="font32" id="p8_t242" reading_order_no="209" segment_no="1" tag_type="figure">nd</text>
<text top="301" left="344" width="0" height="8" font="font32" id="p8_t243" reading_order_no="218" segment_no="1" tag_type="figure">fo</text>
<text top="295" left="344" width="0" height="8" font="font32" id="p8_t244" reading_order_no="217" segment_no="1" tag_type="figure">re</text>
<text top="289" left="344" width="0" height="8" font="font32" id="p8_t245" reading_order_no="216" segment_no="1" tag_type="figure">gr</text>
<text top="283" left="344" width="0" height="8" font="font32" id="p8_t246" reading_order_no="215" segment_no="1" tag_type="figure">ou</text>
<text top="275" left="344" width="0" height="8" font="font32" id="p8_t247" reading_order_no="214" segment_no="1" tag_type="figure">nd</text>
<text top="340" left="344" width="0" height="8" font="font32" id="p8_t248" reading_order_no="222" segment_no="1" tag_type="figure">su</text>
<text top="333" left="344" width="0" height="8" font="font32" id="p8_t249" reading_order_no="221" segment_no="1" tag_type="figure">m</text>
<text top="327" left="344" width="0" height="8" font="font32" id="p8_t250" reading_order_no="220" segment_no="1" tag_type="figure">-c</text>
<text top="320" left="344" width="0" height="8" font="font32" id="p8_t251" reading_order_no="219" segment_no="1" tag_type="figure">ol</text>
<text top="418" left="157" width="35" height="8" font="font20" id="p8_t252" reading_order_no="251" segment_no="3" tag_type="text">Figure 7:</text>
<text top="418" left="196" width="164" height="8" font="font13" id="p8_t253" reading_order_no="252" segment_no="3" tag_type="text">Predict the confusion matrix on test set of</text>
<text top="418" left="363" width="19" height="8" font="font24" id="p8_t254" reading_order_no="253" segment_no="3" tag_type="text">8 × 8</text>
<text top="418" left="385" width="53" height="8" font="font13" id="p8_t255" reading_order_no="254" segment_no="3" tag_type="text">pixels patches</text>
<text top="452" left="51" width="153" height="13" font="font7" id="p8_t256" reading_order_no="255" segment_no="4" tag_type="text">previous work in Section 3.1.3. In Tab</text>
<text top="452" left="206" width="5" height="13" font="font9" id="p8_t257" reading_order_no="256" segment_no="4" tag_type="text"><a href="deeplearning_paper38.html#9">7</a></text>
<text top="452" left="211" width="77" height="13" font="font7" id="p8_t258" reading_order_no="257" segment_no="4" tag_type="text"><a href="deeplearning_paper38.html#9">, </a>we summarize the</text>
<text top="464" left="51" width="164" height="13" font="font7" id="p8_t259" reading_order_no="258" segment_no="4" tag_type="text">classification results on validation set of</text>
<text top="467" left="219" width="42" height="9" font="font23" id="p8_t260" reading_order_no="259" segment_no="4" tag_type="text">224 × 224</text>
<text top="464" left="265" width="24" height="13" font="font7" id="p8_t261" reading_order_no="260" segment_no="4" tag_type="text">pixels</text>
<text top="476" left="51" width="237" height="13" font="font7" id="p8_t262" reading_order_no="261" segment_no="4" tag_type="text">patches for each network model. The highest Pre of classi-</text>
<text top="488" left="51" width="184" height="13" font="font7" id="p8_t263" reading_order_no="262" segment_no="4" tag_type="text">fication foreground is ResNet50 value of 64.6</text>
<text top="491" left="235" width="7" height="9" font="font23" id="p8_t264" reading_order_no="263" segment_no="4" tag_type="text">%</text>
<text top="488" left="243" width="46" height="13" font="font7" id="p8_t265" reading_order_no="264" segment_no="4" tag_type="text">, the lowest</text>
<text top="500" left="51" width="112" height="13" font="font7" id="p8_t266" reading_order_no="265" segment_no="4" tag_type="text">is X-Inception value of 60.8</text>
<text top="503" left="164" width="7" height="9" font="font23" id="p8_t267" reading_order_no="266" segment_no="4" tag_type="text">%</text>
<text top="500" left="171" width="118" height="13" font="font7" id="p8_t268" reading_order_no="267" segment_no="4" tag_type="text">. However, the highest Pre of</text>
<text top="512" left="51" width="211" height="13" font="font7" id="p8_t269" reading_order_no="268" segment_no="4" tag_type="text">background classification is X-Inception value of 97.9</text>
<text top="515" left="262" width="7" height="9" font="font23" id="p8_t270" reading_order_no="269" segment_no="4" tag_type="text">%</text>
<text top="512" left="270" width="19" height="13" font="font7" id="p8_t271" reading_order_no="270" segment_no="4" tag_type="text">, and</text>
<text top="524" left="51" width="119" height="13" font="font7" id="p8_t272" reading_order_no="271" segment_no="4" tag_type="text">the lowest is ViT value of 96.0</text>
<text top="527" left="171" width="7" height="9" font="font23" id="p8_t273" reading_order_no="272" segment_no="4" tag_type="text">%</text>
<text top="524" left="178" width="111" height="13" font="font7" id="p8_t274" reading_order_no="273" segment_no="4" tag_type="text">. The highest Rec of the five</text>
<text top="536" left="51" width="237" height="13" font="font7" id="p8_t275" reading_order_no="274" segment_no="4" tag_type="text">model classification foreground is that the X- Inception value</text>
<text top="548" left="51" width="26" height="13" font="font7" id="p8_t276" reading_order_no="275" segment_no="4" tag_type="text">is 90.4</text>
<text top="551" left="78" width="7" height="9" font="font23" id="p8_t277" reading_order_no="276" segment_no="4" tag_type="text">%</text>
<text top="548" left="85" width="158" height="13" font="font7" id="p8_t278" reading_order_no="277" segment_no="4" tag_type="text">, and the lowest is the ViT value of 80.7</text>
<text top="551" left="243" width="7" height="9" font="font23" id="p8_t279" reading_order_no="278" segment_no="4" tag_type="text">%</text>
<text top="548" left="250" width="39" height="13" font="font7" id="p8_t280" reading_order_no="279" segment_no="4" tag_type="text">. The Spe</text>
<text top="560" left="51" width="237" height="13" font="font7" id="p8_t281" reading_order_no="280" segment_no="4" tag_type="text">results are just the opposite. Overall, the Rec and Spe per-</text>
<text top="572" left="51" width="237" height="13" font="font7" id="p8_t282" reading_order_no="281" segment_no="4" tag_type="text">formance of the five model classification backgrounds are</text>
<text top="584" left="51" width="39" height="13" font="font7" id="p8_t283" reading_order_no="282" segment_no="4" tag_type="text">almost 90</text>
<text top="586" left="91" width="7" height="9" font="font23" id="p8_t284" reading_order_no="283" segment_no="4" tag_type="text">%</text>
<text top="584" left="98" width="191" height="13" font="font7" id="p8_t285" reading_order_no="284" segment_no="4" tag_type="text">. When ResNet50 classifies the foreground and</text>
<text top="596" left="51" width="237" height="13" font="font7" id="p8_t286" reading_order_no="285" segment_no="4" tag_type="text">background of transparent images, F1- Score achieves the</text>
<text top="608" left="51" width="237" height="13" font="font7" id="p8_t287" reading_order_no="286" segment_no="4" tag_type="text">best result. Meanwhile, the Acc of ResNet50 model training</text>
<text top="620" left="51" width="87" height="13" font="font7" id="p8_t288" reading_order_no="287" segment_no="4" tag_type="text">is the highest at 94.99</text>
<text top="622" left="138" width="7" height="9" font="font23" id="p8_t289" reading_order_no="288" segment_no="4" tag_type="text">%</text>
<text top="620" left="146" width="2" height="13" font="font7" id="p8_t290" reading_order_no="289" segment_no="4" tag_type="text">.</text>
<text top="644" left="51" width="110" height="10" font="font28" id="p8_t291" reading_order_no="290" segment_no="8" tag_type="text"><i><b>Comparison on Test set:</b></i></text>
<text top="642" left="167" width="26" height="13" font="font7" id="p8_t292" reading_order_no="291" segment_no="8" tag_type="text">In Tab</text>
<text top="642" left="195" width="5" height="13" font="font9" id="p8_t293" reading_order_no="292" segment_no="8" tag_type="text"><a href="deeplearning_paper38.html#9">8</a></text>
<text top="642" left="203" width="86" height="13" font="font7" id="p8_t294" reading_order_no="293" segment_no="8" tag_type="text">we summarize the re-</text>
<text top="654" left="51" width="237" height="13" font="font7" id="p8_t295" reading_order_no="294" segment_no="8" tag_type="text">sults of these five network predictions. It can be seen that</text>
<text top="666" left="51" width="178" height="13" font="font7" id="p8_t296" reading_order_no="295" segment_no="8" tag_type="text">the prediction Acc of X-Inception is 89.11</text>
<text top="668" left="229" width="7" height="9" font="font23" id="p8_t297" reading_order_no="296" segment_no="8" tag_type="text">%</text>
<text top="666" left="240" width="48" height="13" font="font7" id="p8_t298" reading_order_no="297" segment_no="8" tag_type="text">at the high-</text>
<text top="678" left="51" width="237" height="13" font="font7" id="p8_t299" reading_order_no="298" segment_no="8" tag_type="text">est, and the prediction Acc of Inception-V3 is the lowest at</text>
<text top="689" left="51" width="22" height="13" font="font7" id="p8_t300" reading_order_no="299" segment_no="8" tag_type="text">88.10</text>
<text top="692" left="74" width="7" height="9" font="font23" id="p8_t301" reading_order_no="300" segment_no="8" tag_type="text">%</text>
<text top="689" left="81" width="208" height="13" font="font7" id="p8_t302" reading_order_no="301" segment_no="8" tag_type="text">. However, the highest Pre in predicting transparent</text>
<text top="701" left="51" width="141" height="13" font="font7" id="p8_t303" reading_order_no="302" segment_no="8" tag_type="text">foreground is the ViT value of 60.6</text>
<text top="704" left="192" width="7" height="9" font="font23" id="p8_t304" reading_order_no="303" segment_no="8" tag_type="text">%</text>
<text top="701" left="199" width="2" height="13" font="font7" id="p8_t305" reading_order_no="304" segment_no="8" tag_type="text">.</text>
<text top="713" left="66" width="222" height="13" font="font7" id="p8_t306" reading_order_no="305" segment_no="10" tag_type="text">In order to more intuitively express the classification re-</text>
<text top="725" left="51" width="237" height="13" font="font7" id="p8_t307" reading_order_no="306" segment_no="10" tag_type="text">sults of CNNs and ViT models on transparent image patches,</text>
<text top="458" left="307" width="29" height="8" font="font20" id="p8_t308" reading_order_no="307" segment_no="5" tag_type="title">Table 6</text>
<text top="469" left="307" width="215" height="8" font="font13" id="p8_t309" reading_order_no="308" segment_no="6" tag_type="text">A comparison of the classification results on test set of</text>
<text top="469" left="525" width="19" height="8" font="font24" id="p8_t310" reading_order_no="309" segment_no="6" tag_type="text">8 × 8</text>
<text top="480" left="307" width="237" height="8" font="font13" id="p8_t311" reading_order_no="310" segment_no="6" tag_type="text">pixels patches. MAcc (Max Acc), FG (foreground) and BG</text>
<text top="491" left="307" width="85" height="8" font="font13" id="p8_t312" reading_order_no="311" segment_no="6" tag_type="text">(background)(In [%].)</text>
<text top="509" left="313" width="24" height="8" font="font13" id="p8_t313" reading_order_no="312" segment_no="7" tag_type="table">Model</text>
<text top="509" left="368" width="20" height="8" font="font13" id="p8_t314" reading_order_no="313" segment_no="7" tag_type="table">Class</text>
<text top="509" left="399" width="13" height="8" font="font13" id="p8_t315" reading_order_no="314" segment_no="7" tag_type="table">Pre</text>
<text top="509" left="427" width="14" height="8" font="font13" id="p8_t316" reading_order_no="315" segment_no="7" tag_type="table">Rec</text>
<text top="509" left="456" width="14" height="8" font="font13" id="p8_t317" reading_order_no="316" segment_no="7" tag_type="table">Spe</text>
<text top="509" left="484" width="10" height="8" font="font13" id="p8_t318" reading_order_no="317" segment_no="7" tag_type="table">F1</text>
<text top="509" left="512" width="34" height="8" font="font13" id="p8_t319" reading_order_no="318" segment_no="7" tag_type="table">Max Acc</text>
<text top="531" left="307" width="37" height="8" font="font13" id="p8_t320" reading_order_no="319" segment_no="7" tag_type="table">ResNet50</text>
<text top="525" left="368" width="11" height="8" font="font13" id="p8_t321" reading_order_no="320" segment_no="7" tag_type="table">FG</text>
<text top="525" left="399" width="16" height="8" font="font13" id="p8_t322" reading_order_no="321" segment_no="7" tag_type="table">62.2</text>
<text top="525" left="427" width="16" height="8" font="font13" id="p8_t323" reading_order_no="322" segment_no="7" tag_type="table">87.2</text>
<text top="525" left="456" width="16" height="8" font="font13" id="p8_t324" reading_order_no="323" segment_no="7" tag_type="table">90.6</text>
<text top="525" left="484" width="16" height="8" font="font13" id="p8_t325" reading_order_no="324" segment_no="7" tag_type="table">73.0</text>
<text top="531" left="512" width="16" height="8" font="font13" id="p8_t326" reading_order_no="325" segment_no="7" tag_type="table">90.0</text>
<text top="536" left="368" width="12" height="8" font="font13" id="p8_t327" reading_order_no="326" segment_no="7" tag_type="table">BG</text>
<text top="536" left="399" width="16" height="8" font="font13" id="p8_t328" reading_order_no="327" segment_no="7" tag_type="table">97.5</text>
<text top="536" left="427" width="16" height="8" font="font13" id="p8_t329" reading_order_no="328" segment_no="7" tag_type="table">90.6</text>
<text top="536" left="456" width="16" height="8" font="font13" id="p8_t330" reading_order_no="329" segment_no="7" tag_type="table">87.2</text>
<text top="536" left="484" width="16" height="8" font="font13" id="p8_t331" reading_order_no="330" segment_no="7" tag_type="table">93.4</text>
<text top="553" left="307" width="49" height="8" font="font13" id="p8_t332" reading_order_no="331" segment_no="7" tag_type="table">Inception-V3</text>
<text top="547" left="368" width="11" height="8" font="font13" id="p8_t333" reading_order_no="332" segment_no="7" tag_type="table">FG</text>
<text top="547" left="399" width="16" height="8" font="font13" id="p8_t334" reading_order_no="333" segment_no="7" tag_type="table">52.6</text>
<text top="547" left="427" width="16" height="8" font="font13" id="p8_t335" reading_order_no="334" segment_no="7" tag_type="table">91.5</text>
<text top="547" left="456" width="16" height="8" font="font13" id="p8_t336" reading_order_no="335" segment_no="7" tag_type="table">85.4</text>
<text top="547" left="484" width="16" height="8" font="font13" id="p8_t337" reading_order_no="336" segment_no="7" tag_type="table">72.8</text>
<text top="553" left="512" width="21" height="8" font="font13" id="p8_t338" reading_order_no="337" segment_no="7" tag_type="table">86.29</text>
<text top="558" left="368" width="12" height="8" font="font13" id="p8_t339" reading_order_no="338" segment_no="7" tag_type="table">BG</text>
<text top="558" left="399" width="16" height="8" font="font13" id="p8_t340" reading_order_no="339" segment_no="7" tag_type="table">98.3</text>
<text top="558" left="427" width="16" height="8" font="font13" id="p8_t341" reading_order_no="340" segment_no="7" tag_type="table">85.4</text>
<text top="558" left="456" width="16" height="8" font="font13" id="p8_t342" reading_order_no="341" segment_no="7" tag_type="table">91.5</text>
<text top="558" left="484" width="16" height="8" font="font13" id="p8_t343" reading_order_no="342" segment_no="7" tag_type="table">93.4</text>
<text top="574" left="307" width="30" height="8" font="font13" id="p8_t344" reading_order_no="343" segment_no="7" tag_type="table">VGG-16</text>
<text top="569" left="368" width="11" height="8" font="font13" id="p8_t345" reading_order_no="344" segment_no="7" tag_type="table">FG</text>
<text top="569" left="399" width="16" height="8" font="font13" id="p8_t346" reading_order_no="345" segment_no="7" tag_type="table">60.7</text>
<text top="569" left="427" width="16" height="8" font="font13" id="p8_t347" reading_order_no="346" segment_no="7" tag_type="table">89.4</text>
<text top="569" left="456" width="16" height="8" font="font13" id="p8_t348" reading_order_no="347" segment_no="7" tag_type="table">89.7</text>
<text top="569" left="484" width="16" height="8" font="font13" id="p8_t349" reading_order_no="348" segment_no="7" tag_type="table">73.7</text>
<text top="574" left="512" width="16" height="8" font="font13" id="p8_t350" reading_order_no="349" segment_no="7" tag_type="table">89.6</text>
<text top="580" left="368" width="12" height="8" font="font13" id="p8_t351" reading_order_no="350" segment_no="7" tag_type="table">BG</text>
<text top="580" left="399" width="16" height="8" font="font13" id="p8_t352" reading_order_no="351" segment_no="7" tag_type="table">97.9</text>
<text top="580" left="427" width="16" height="8" font="font13" id="p8_t353" reading_order_no="352" segment_no="7" tag_type="table">89.7</text>
<text top="580" left="456" width="16" height="8" font="font13" id="p8_t354" reading_order_no="353" segment_no="7" tag_type="table">89.4</text>
<text top="580" left="484" width="16" height="8" font="font13" id="p8_t355" reading_order_no="354" segment_no="7" tag_type="table">93.6</text>
<text top="596" left="307" width="44" height="8" font="font13" id="p8_t356" reading_order_no="355" segment_no="7" tag_type="table">X-Inception</text>
<text top="591" left="368" width="11" height="8" font="font13" id="p8_t357" reading_order_no="356" segment_no="7" tag_type="table">FG</text>
<text top="591" left="399" width="16" height="8" font="font13" id="p8_t358" reading_order_no="357" segment_no="7" tag_type="table">51.8</text>
<text top="591" left="427" width="16" height="8" font="font13" id="p8_t359" reading_order_no="358" segment_no="7" tag_type="table">90.7</text>
<text top="591" left="456" width="16" height="8" font="font13" id="p8_t360" reading_order_no="359" segment_no="7" tag_type="table">85.0</text>
<text top="591" left="484" width="16" height="8" font="font13" id="p8_t361" reading_order_no="360" segment_no="7" tag_type="table">66.7</text>
<text top="596" left="512" width="21" height="8" font="font13" id="p8_t362" reading_order_no="361" segment_no="7" tag_type="table">85.85</text>
<text top="602" left="368" width="12" height="8" font="font13" id="p8_t363" reading_order_no="362" segment_no="7" tag_type="table">BG</text>
<text top="602" left="399" width="16" height="8" font="font13" id="p8_t364" reading_order_no="363" segment_no="7" tag_type="table">98.1</text>
<text top="602" left="427" width="16" height="8" font="font13" id="p8_t365" reading_order_no="364" segment_no="7" tag_type="table">85.0</text>
<text top="602" left="456" width="16" height="8" font="font13" id="p8_t366" reading_order_no="365" segment_no="7" tag_type="table">90.7</text>
<text top="602" left="484" width="16" height="8" font="font13" id="p8_t367" reading_order_no="366" segment_no="7" tag_type="table">90.9</text>
<text top="618" left="307" width="15" height="8" font="font13" id="p8_t368" reading_order_no="367" segment_no="7" tag_type="table">ViT</text>
<text top="613" left="368" width="11" height="8" font="font13" id="p8_t369" reading_order_no="368" segment_no="7" tag_type="table">FG</text>
<text top="613" left="399" width="16" height="8" font="font13" id="p8_t370" reading_order_no="369" segment_no="7" tag_type="table">60.4</text>
<text top="613" left="427" width="16" height="8" font="font13" id="p8_t371" reading_order_no="370" segment_no="7" tag_type="table">83.8</text>
<text top="613" left="456" width="16" height="8" font="font13" id="p8_t372" reading_order_no="371" segment_no="7" tag_type="table">90.2</text>
<text top="613" left="484" width="16" height="8" font="font13" id="p8_t373" reading_order_no="372" segment_no="7" tag_type="table">70.2</text>
<text top="618" left="512" width="21" height="8" font="font13" id="p8_t374" reading_order_no="373" segment_no="7" tag_type="table">89.25</text>
<text top="624" left="368" width="12" height="8" font="font13" id="p8_t375" reading_order_no="374" segment_no="7" tag_type="table">BG</text>
<text top="624" left="399" width="16" height="8" font="font13" id="p8_t376" reading_order_no="375" segment_no="7" tag_type="table">96.9</text>
<text top="624" left="427" width="16" height="8" font="font13" id="p8_t377" reading_order_no="376" segment_no="7" tag_type="table">90.2</text>
<text top="624" left="456" width="16" height="8" font="font13" id="p8_t378" reading_order_no="377" segment_no="7" tag_type="table">83.8</text>
<text top="624" left="484" width="16" height="8" font="font13" id="p8_t379" reading_order_no="378" segment_no="7" tag_type="table">93.4</text>
<text top="656" left="307" width="237" height="13" font="font7" id="p8_t380" reading_order_no="379" segment_no="9" tag_type="text">we summarize the confusion matrices predicted by five mod-</text>
<text top="668" left="307" width="83" height="13" font="font7" id="p8_t381" reading_order_no="380" segment_no="9" tag_type="text">els and shown in Fig.</text>
<text top="668" left="396" width="5" height="13" font="font9" id="p8_t382" reading_order_no="381" segment_no="9" tag_type="text"><a href="deeplearning_paper38.html#11">9</a></text>
<text top="668" left="400" width="143" height="13" font="font7" id="p8_t383" reading_order_no="382" segment_no="9" tag_type="text"><a href="deeplearning_paper38.html#11">. </a>We find that the ability of CNNs to</text>
<text top="680" left="307" width="237" height="13" font="font7" id="p8_t384" reading_order_no="383" segment_no="9" tag_type="text">classify foreground patches of transparent images is higher</text>
<text top="692" left="307" width="237" height="13" font="font7" id="p8_t385" reading_order_no="384" segment_no="9" tag_type="text">than that of ViT. Among them, X-Inception is the best in the</text>
<text top="704" left="307" width="238" height="13" font="font7" id="p8_t386" reading_order_no="385" segment_no="9" tag_type="text">CNNs model, which correctly classifies 29559 small patches.</text>
<text top="716" left="307" width="237" height="13" font="font7" id="p8_t387" reading_order_no="386" segment_no="9" tag_type="text">ViT correctly classifies 26285 foreground patches. How-</text>
<text top="728" left="307" width="237" height="13" font="font7" id="p8_t388" reading_order_no="387" segment_no="9" tag_type="text">ever, the highest accuracy of classifying transparent image</text>
<text top="759" left="51" width="78" height="8" font="font13" id="p8_t389" reading_order_no="388" segment_no="11" tag_type="footnote">HeChen Yang et al.:</text>
<text top="759" left="133" width="108" height="8" font="font14" id="p8_t390" reading_order_no="389" segment_no="11" tag_type="footnote"><i>Preprint submitted to Elsevier</i></text>
<text top="759" left="495" width="49" height="8" font="font13" id="p8_t391" reading_order_no="390" segment_no="2" tag_type="text">Page 8 of 12</text>
</page>
<page number="9" position="absolute" top="0" left="0" height="793" width="595">
<text top="37" left="241" width="113" height="8" font="font13" id="p9_t1" reading_order_no="0" segment_no="0" tag_type="text">Leveraging social media news</text>
<text top="61" left="51" width="29" height="8" font="font20" id="p9_t2" reading_order_no="1" segment_no="2" tag_type="title">Table 7</text>
<text top="72" left="51" width="237" height="8" font="font13" id="p9_t3" reading_order_no="2" segment_no="4" tag_type="text">A comparison of the classification results on validation set of</text>
<text top="83" left="51" width="37" height="8" font="font24" id="p9_t4" reading_order_no="3" segment_no="4" tag_type="text">224 × 224</text>
<text top="83" left="92" width="197" height="8" font="font13" id="p9_t5" reading_order_no="4" segment_no="4" tag_type="text">pixels patches. MAcc (Max Acc), FG (foreground)</text>
<text top="94" left="51" width="117" height="8" font="font13" id="p9_t6" reading_order_no="5" segment_no="4" tag_type="text">and BG (background)(In [%].)</text>
<text top="113" left="57" width="24" height="8" font="font13" id="p9_t7" reading_order_no="6" segment_no="5" tag_type="table">Model</text>
<text top="113" left="112" width="20" height="8" font="font13" id="p9_t8" reading_order_no="7" segment_no="5" tag_type="table">Class</text>
<text top="113" left="144" width="13" height="8" font="font13" id="p9_t9" reading_order_no="8" segment_no="5" tag_type="table">Pre</text>
<text top="113" left="172" width="14" height="8" font="font13" id="p9_t10" reading_order_no="9" segment_no="5" tag_type="table">Rec</text>
<text top="113" left="200" width="14" height="8" font="font13" id="p9_t11" reading_order_no="10" segment_no="5" tag_type="table">Spe</text>
<text top="113" left="229" width="10" height="8" font="font13" id="p9_t12" reading_order_no="11" segment_no="5" tag_type="table">F1</text>
<text top="113" left="257" width="34" height="8" font="font13" id="p9_t13" reading_order_no="12" segment_no="5" tag_type="table">Max Acc</text>
<text top="134" left="51" width="37" height="8" font="font13" id="p9_t14" reading_order_no="13" segment_no="5" tag_type="table">ResNet50</text>
<text top="129" left="112" width="11" height="8" font="font13" id="p9_t15" reading_order_no="14" segment_no="5" tag_type="table">FG</text>
<text top="129" left="144" width="16" height="8" font="font13" id="p9_t16" reading_order_no="15" segment_no="5" tag_type="table">64.6</text>
<text top="129" left="172" width="16" height="8" font="font13" id="p9_t17" reading_order_no="16" segment_no="5" tag_type="table">87.6</text>
<text top="129" left="200" width="16" height="8" font="font13" id="p9_t18" reading_order_no="17" segment_no="5" tag_type="table">90.7</text>
<text top="129" left="229" width="16" height="8" font="font13" id="p9_t19" reading_order_no="18" segment_no="5" tag_type="table">74.4</text>
<text top="134" left="257" width="21" height="8" font="font13" id="p9_t20" reading_order_no="19" segment_no="5" tag_type="table">94.99</text>
<text top="140" left="112" width="12" height="8" font="font13" id="p9_t21" reading_order_no="20" segment_no="5" tag_type="table">BG</text>
<text top="140" left="144" width="16" height="8" font="font13" id="p9_t22" reading_order_no="21" segment_no="5" tag_type="table">97.4</text>
<text top="140" left="172" width="16" height="8" font="font13" id="p9_t23" reading_order_no="22" segment_no="5" tag_type="table">90.7</text>
<text top="140" left="200" width="16" height="8" font="font13" id="p9_t24" reading_order_no="23" segment_no="5" tag_type="table">87.6</text>
<text top="140" left="229" width="16" height="8" font="font13" id="p9_t25" reading_order_no="24" segment_no="5" tag_type="table">93.9</text>
<text top="156" left="51" width="49" height="8" font="font13" id="p9_t26" reading_order_no="25" segment_no="5" tag_type="table">Inception-V3</text>
<text top="150" left="112" width="11" height="8" font="font13" id="p9_t27" reading_order_no="26" segment_no="5" tag_type="table">FG</text>
<text top="150" left="144" width="16" height="8" font="font13" id="p9_t28" reading_order_no="27" segment_no="5" tag_type="table">63.0</text>
<text top="150" left="172" width="16" height="8" font="font13" id="p9_t29" reading_order_no="28" segment_no="5" tag_type="table">88.9</text>
<text top="150" left="200" width="16" height="8" font="font13" id="p9_t30" reading_order_no="29" segment_no="5" tag_type="table">89.9</text>
<text top="150" left="229" width="16" height="8" font="font13" id="p9_t31" reading_order_no="30" segment_no="5" tag_type="table">73.7</text>
<text top="156" left="257" width="21" height="8" font="font13" id="p9_t32" reading_order_no="31" segment_no="5" tag_type="table">92.51</text>
<text top="161" left="112" width="12" height="8" font="font13" id="p9_t33" reading_order_no="32" segment_no="5" tag_type="table">BG</text>
<text top="161" left="144" width="16" height="8" font="font13" id="p9_t34" reading_order_no="33" segment_no="5" tag_type="table">97.7</text>
<text top="161" left="172" width="16" height="8" font="font13" id="p9_t35" reading_order_no="34" segment_no="5" tag_type="table">89.9</text>
<text top="161" left="200" width="16" height="8" font="font13" id="p9_t36" reading_order_no="35" segment_no="5" tag_type="table">88.9</text>
<text top="161" left="229" width="16" height="8" font="font13" id="p9_t37" reading_order_no="36" segment_no="5" tag_type="table">93.6</text>
<text top="178" left="51" width="30" height="8" font="font13" id="p9_t38" reading_order_no="37" segment_no="5" tag_type="table">VGG-16</text>
<text top="172" left="112" width="11" height="8" font="font13" id="p9_t39" reading_order_no="38" segment_no="5" tag_type="table">FG</text>
<text top="172" left="144" width="16" height="8" font="font13" id="p9_t40" reading_order_no="39" segment_no="5" tag_type="table">63.2</text>
<text top="172" left="172" width="16" height="8" font="font13" id="p9_t41" reading_order_no="40" segment_no="5" tag_type="table">85.8</text>
<text top="172" left="200" width="16" height="8" font="font13" id="p9_t42" reading_order_no="41" segment_no="5" tag_type="table">90.3</text>
<text top="172" left="229" width="16" height="8" font="font13" id="p9_t43" reading_order_no="42" segment_no="5" tag_type="table">72.8</text>
<text top="178" left="257" width="21" height="8" font="font13" id="p9_t44" reading_order_no="43" segment_no="5" tag_type="table">92.08</text>
<text top="183" left="112" width="12" height="8" font="font13" id="p9_t45" reading_order_no="44" segment_no="5" tag_type="table">BG</text>
<text top="183" left="144" width="16" height="8" font="font13" id="p9_t46" reading_order_no="45" segment_no="5" tag_type="table">97.1</text>
<text top="183" left="172" width="16" height="8" font="font13" id="p9_t47" reading_order_no="46" segment_no="5" tag_type="table">90.3</text>
<text top="183" left="200" width="16" height="8" font="font13" id="p9_t48" reading_order_no="47" segment_no="5" tag_type="table">85.8</text>
<text top="183" left="229" width="16" height="8" font="font13" id="p9_t49" reading_order_no="48" segment_no="5" tag_type="table">93.6</text>
<text top="200" left="51" width="44" height="8" font="font13" id="p9_t50" reading_order_no="49" segment_no="5" tag_type="table">X-Inception</text>
<text top="194" left="112" width="11" height="8" font="font13" id="p9_t51" reading_order_no="50" segment_no="5" tag_type="table">FG</text>
<text top="194" left="144" width="16" height="8" font="font13" id="p9_t52" reading_order_no="51" segment_no="5" tag_type="table">60.8</text>
<text top="194" left="172" width="16" height="8" font="font13" id="p9_t53" reading_order_no="52" segment_no="5" tag_type="table">90.4</text>
<text top="194" left="200" width="16" height="8" font="font13" id="p9_t54" reading_order_no="53" segment_no="5" tag_type="table">88.7</text>
<text top="194" left="229" width="16" height="8" font="font13" id="p9_t55" reading_order_no="54" segment_no="5" tag_type="table">72.7</text>
<text top="200" left="257" width="21" height="8" font="font13" id="p9_t56" reading_order_no="55" segment_no="5" tag_type="table">94.72</text>
<text top="205" left="112" width="12" height="8" font="font13" id="p9_t57" reading_order_no="56" segment_no="5" tag_type="table">BG</text>
<text top="205" left="144" width="16" height="8" font="font13" id="p9_t58" reading_order_no="57" segment_no="5" tag_type="table">97.9</text>
<text top="205" left="172" width="16" height="8" font="font13" id="p9_t59" reading_order_no="58" segment_no="5" tag_type="table">88.7</text>
<text top="205" left="200" width="16" height="8" font="font13" id="p9_t60" reading_order_no="59" segment_no="5" tag_type="table">90.4</text>
<text top="205" left="229" width="16" height="8" font="font13" id="p9_t61" reading_order_no="60" segment_no="5" tag_type="table">93.1</text>
<text top="222" left="51" width="15" height="8" font="font13" id="p9_t62" reading_order_no="61" segment_no="5" tag_type="table">ViT</text>
<text top="216" left="112" width="11" height="8" font="font13" id="p9_t63" reading_order_no="62" segment_no="5" tag_type="table">FG</text>
<text top="216" left="144" width="16" height="8" font="font13" id="p9_t64" reading_order_no="63" segment_no="5" tag_type="table">63.3</text>
<text top="216" left="172" width="16" height="8" font="font13" id="p9_t65" reading_order_no="64" segment_no="5" tag_type="table">80.7</text>
<text top="216" left="200" width="16" height="8" font="font13" id="p9_t66" reading_order_no="65" segment_no="5" tag_type="table">90.9</text>
<text top="216" left="229" width="16" height="8" font="font13" id="p9_t67" reading_order_no="66" segment_no="5" tag_type="table">70.9</text>
<text top="222" left="257" width="21" height="8" font="font13" id="p9_t68" reading_order_no="67" segment_no="5" tag_type="table">89.28</text>
<text top="227" left="112" width="12" height="8" font="font13" id="p9_t69" reading_order_no="68" segment_no="5" tag_type="table">BG</text>
<text top="227" left="144" width="16" height="8" font="font13" id="p9_t70" reading_order_no="69" segment_no="5" tag_type="table">96.0</text>
<text top="227" left="172" width="16" height="8" font="font13" id="p9_t71" reading_order_no="70" segment_no="5" tag_type="table">90.9</text>
<text top="227" left="200" width="16" height="8" font="font13" id="p9_t72" reading_order_no="71" segment_no="5" tag_type="table">80.7</text>
<text top="227" left="229" width="16" height="8" font="font13" id="p9_t73" reading_order_no="72" segment_no="5" tag_type="table">93.4</text>
<text top="257" left="51" width="29" height="8" font="font20" id="p9_t74" reading_order_no="73" segment_no="6" tag_type="title">Table 8</text>
<text top="268" left="51" width="203" height="8" font="font13" id="p9_t75" reading_order_no="74" segment_no="7" tag_type="text">A comparison of the classification results on test set of</text>
<text top="269" left="256" width="33" height="8" font="font24" id="p9_t76" reading_order_no="75" segment_no="7" tag_type="text">224×224</text>
<text top="279" left="51" width="237" height="8" font="font13" id="p9_t77" reading_order_no="76" segment_no="7" tag_type="text">pixels patches. MAcc (Max Acc), FG (foreground) and BG</text>
<text top="290" left="51" width="85" height="8" font="font13" id="p9_t78" reading_order_no="77" segment_no="7" tag_type="text">(background)(In [%].)</text>
<text top="309" left="57" width="24" height="8" font="font13" id="p9_t79" reading_order_no="78" segment_no="9" tag_type="table">Model</text>
<text top="309" left="112" width="20" height="8" font="font13" id="p9_t80" reading_order_no="79" segment_no="9" tag_type="table">Class</text>
<text top="309" left="144" width="13" height="8" font="font13" id="p9_t81" reading_order_no="80" segment_no="9" tag_type="table">Pre</text>
<text top="309" left="172" width="14" height="8" font="font13" id="p9_t82" reading_order_no="81" segment_no="9" tag_type="table">Rec</text>
<text top="309" left="200" width="14" height="8" font="font13" id="p9_t83" reading_order_no="82" segment_no="9" tag_type="table">Spe</text>
<text top="309" left="229" width="10" height="8" font="font13" id="p9_t84" reading_order_no="83" segment_no="9" tag_type="table">F1</text>
<text top="309" left="257" width="34" height="8" font="font13" id="p9_t85" reading_order_no="84" segment_no="9" tag_type="table">Max Acc</text>
<text top="330" left="51" width="37" height="8" font="font13" id="p9_t86" reading_order_no="85" segment_no="9" tag_type="table">ResNet50</text>
<text top="325" left="112" width="11" height="8" font="font13" id="p9_t87" reading_order_no="86" segment_no="9" tag_type="table">FG</text>
<text top="325" left="144" width="16" height="8" font="font13" id="p9_t88" reading_order_no="87" segment_no="9" tag_type="table">59.0</text>
<text top="325" left="172" width="16" height="8" font="font13" id="p9_t89" reading_order_no="88" segment_no="9" tag_type="table">88.7</text>
<text top="325" left="200" width="16" height="8" font="font13" id="p9_t90" reading_order_no="89" segment_no="9" tag_type="table">89.0</text>
<text top="325" left="229" width="16" height="8" font="font13" id="p9_t91" reading_order_no="90" segment_no="9" tag_type="table">73.0</text>
<text top="330" left="257" width="21" height="8" font="font13" id="p9_t92" reading_order_no="91" segment_no="9" tag_type="table">88.92</text>
<text top="336" left="112" width="12" height="8" font="font13" id="p9_t93" reading_order_no="92" segment_no="9" tag_type="table">BG</text>
<text top="336" left="144" width="16" height="8" font="font13" id="p9_t94" reading_order_no="93" segment_no="9" tag_type="table">97.8</text>
<text top="336" left="172" width="16" height="8" font="font13" id="p9_t95" reading_order_no="94" segment_no="9" tag_type="table">89.0</text>
<text top="336" left="200" width="16" height="8" font="font13" id="p9_t96" reading_order_no="95" segment_no="9" tag_type="table">88.7</text>
<text top="336" left="229" width="16" height="8" font="font13" id="p9_t97" reading_order_no="96" segment_no="9" tag_type="table">93.4</text>
<text top="352" left="51" width="49" height="8" font="font13" id="p9_t98" reading_order_no="97" segment_no="9" tag_type="table">Inception-V3</text>
<text top="347" left="112" width="11" height="8" font="font13" id="p9_t99" reading_order_no="98" segment_no="9" tag_type="table">FG</text>
<text top="347" left="144" width="16" height="8" font="font13" id="p9_t100" reading_order_no="99" segment_no="9" tag_type="table">56.8</text>
<text top="347" left="172" width="16" height="8" font="font13" id="p9_t101" reading_order_no="100" segment_no="9" tag_type="table">90.6</text>
<text top="347" left="200" width="16" height="8" font="font13" id="p9_t102" reading_order_no="101" segment_no="9" tag_type="table">87.7</text>
<text top="347" left="229" width="16" height="8" font="font13" id="p9_t103" reading_order_no="102" segment_no="9" tag_type="table">72.8</text>
<text top="352" left="257" width="21" height="8" font="font13" id="p9_t104" reading_order_no="103" segment_no="9" tag_type="table">88.10</text>
<text top="358" left="112" width="12" height="8" font="font13" id="p9_t105" reading_order_no="104" segment_no="9" tag_type="table">BG</text>
<text top="358" left="144" width="16" height="8" font="font13" id="p9_t106" reading_order_no="105" segment_no="9" tag_type="table">98.1</text>
<text top="358" left="172" width="16" height="8" font="font13" id="p9_t107" reading_order_no="106" segment_no="9" tag_type="table">87.7</text>
<text top="358" left="200" width="16" height="8" font="font13" id="p9_t108" reading_order_no="107" segment_no="9" tag_type="table">90.6</text>
<text top="358" left="229" width="16" height="8" font="font13" id="p9_t109" reading_order_no="108" segment_no="9" tag_type="table">93.4</text>
<text top="374" left="51" width="30" height="8" font="font13" id="p9_t110" reading_order_no="109" segment_no="9" tag_type="table">VGG-16</text>
<text top="369" left="112" width="11" height="8" font="font13" id="p9_t111" reading_order_no="110" segment_no="9" tag_type="table">FG</text>
<text top="369" left="144" width="16" height="8" font="font13" id="p9_t112" reading_order_no="111" segment_no="9" tag_type="table">57.1</text>
<text top="369" left="172" width="16" height="8" font="font13" id="p9_t113" reading_order_no="112" segment_no="9" tag_type="table">87.0</text>
<text top="369" left="200" width="16" height="8" font="font13" id="p9_t114" reading_order_no="113" segment_no="9" tag_type="table">88.3</text>
<text top="369" left="229" width="16" height="8" font="font13" id="p9_t115" reading_order_no="114" segment_no="9" tag_type="table">73.7</text>
<text top="374" left="257" width="21" height="8" font="font13" id="p9_t116" reading_order_no="115" segment_no="9" tag_type="table">88.11</text>
<text top="379" left="112" width="12" height="8" font="font13" id="p9_t117" reading_order_no="116" segment_no="9" tag_type="table">BG</text>
<text top="379" left="144" width="16" height="8" font="font13" id="p9_t118" reading_order_no="117" segment_no="9" tag_type="table">97.4</text>
<text top="379" left="172" width="16" height="8" font="font13" id="p9_t119" reading_order_no="118" segment_no="9" tag_type="table">88.3</text>
<text top="379" left="200" width="16" height="8" font="font13" id="p9_t120" reading_order_no="119" segment_no="9" tag_type="table">87.0</text>
<text top="379" left="229" width="16" height="8" font="font13" id="p9_t121" reading_order_no="120" segment_no="9" tag_type="table">93.6</text>
<text top="396" left="51" width="44" height="8" font="font13" id="p9_t122" reading_order_no="121" segment_no="9" tag_type="table">X-Inception</text>
<text top="390" left="112" width="11" height="8" font="font13" id="p9_t123" reading_order_no="122" segment_no="9" tag_type="table">FG</text>
<text top="390" left="144" width="16" height="8" font="font13" id="p9_t124" reading_order_no="123" segment_no="9" tag_type="table">59.6</text>
<text top="390" left="172" width="16" height="8" font="font13" id="p9_t125" reading_order_no="124" segment_no="9" tag_type="table">88.0</text>
<text top="390" left="200" width="16" height="8" font="font13" id="p9_t126" reading_order_no="125" segment_no="9" tag_type="table">89.3</text>
<text top="390" left="229" width="16" height="8" font="font13" id="p9_t127" reading_order_no="126" segment_no="9" tag_type="table">66.7</text>
<text top="396" left="257" width="21" height="8" font="font13" id="p9_t128" reading_order_no="127" segment_no="9" tag_type="table">89.11</text>
<text top="401" left="112" width="12" height="8" font="font13" id="p9_t129" reading_order_no="128" segment_no="9" tag_type="table">BG</text>
<text top="401" left="144" width="16" height="8" font="font13" id="p9_t130" reading_order_no="129" segment_no="9" tag_type="table">97.6</text>
<text top="401" left="172" width="16" height="8" font="font13" id="p9_t131" reading_order_no="130" segment_no="9" tag_type="table">89.3</text>
<text top="401" left="200" width="16" height="8" font="font13" id="p9_t132" reading_order_no="131" segment_no="9" tag_type="table">88.0</text>
<text top="401" left="229" width="16" height="8" font="font13" id="p9_t133" reading_order_no="132" segment_no="9" tag_type="table">90.9</text>
<text top="418" left="51" width="15" height="8" font="font13" id="p9_t134" reading_order_no="133" segment_no="9" tag_type="table">ViT</text>
<text top="412" left="112" width="11" height="8" font="font13" id="p9_t135" reading_order_no="134" segment_no="9" tag_type="table">FG</text>
<text top="412" left="144" width="16" height="8" font="font13" id="p9_t136" reading_order_no="135" segment_no="9" tag_type="table">60.6</text>
<text top="412" left="172" width="16" height="8" font="font13" id="p9_t137" reading_order_no="136" segment_no="9" tag_type="table">80.5</text>
<text top="412" left="200" width="16" height="8" font="font13" id="p9_t138" reading_order_no="137" segment_no="9" tag_type="table">90.6</text>
<text top="412" left="229" width="16" height="8" font="font13" id="p9_t139" reading_order_no="138" segment_no="9" tag_type="table">69.1</text>
<text top="418" left="257" width="21" height="8" font="font13" id="p9_t140" reading_order_no="139" segment_no="9" tag_type="table">89.09</text>
<text top="423" left="112" width="12" height="8" font="font13" id="p9_t141" reading_order_no="140" segment_no="9" tag_type="table">BG</text>
<text top="423" left="144" width="16" height="8" font="font13" id="p9_t142" reading_order_no="141" segment_no="9" tag_type="table">96.3</text>
<text top="423" left="172" width="16" height="8" font="font13" id="p9_t143" reading_order_no="142" segment_no="9" tag_type="table">90.6</text>
<text top="423" left="200" width="16" height="8" font="font13" id="p9_t144" reading_order_no="143" segment_no="9" tag_type="table">80.5</text>
<text top="423" left="229" width="16" height="8" font="font13" id="p9_t145" reading_order_no="144" segment_no="9" tag_type="table">93.4</text>
<text top="454" left="51" width="29" height="8" font="font20" id="p9_t146" reading_order_no="145" segment_no="11" tag_type="title">Table 9</text>
<text top="464" left="51" width="237" height="8" font="font13" id="p9_t147" reading_order_no="146" segment_no="12" tag_type="text">A comparison of the classification results on train and test sets</text>
<text top="475" left="51" width="7" height="8" font="font13" id="p9_t148" reading_order_no="147" segment_no="12" tag_type="text">of</text>
<text top="476" left="63" width="38" height="8" font="font24" id="p9_t149" reading_order_no="148" segment_no="12" tag_type="text">224 × 224</text>
<text top="475" left="104" width="185" height="8" font="font13" id="p9_t150" reading_order_no="149" segment_no="12" tag_type="text">pixels patches. Train (Train times), Test (Test</text>
<text top="486" left="51" width="211" height="8" font="font13" id="p9_t151" reading_order_no="150" segment_no="12" tag_type="text">times) and Avg (Single picture prediction time)(In [s].)</text>
<text top="505" left="65" width="23" height="8" font="font13" id="p9_t152" reading_order_no="151" segment_no="13" tag_type="table">model</text>
<text top="505" left="126" width="20" height="8" font="font13" id="p9_t153" reading_order_no="152" segment_no="13" tag_type="table">Train</text>
<text top="505" left="161" width="16" height="8" font="font13" id="p9_t154" reading_order_no="153" segment_no="13" tag_type="table">Test</text>
<text top="505" left="191" width="15" height="8" font="font13" id="p9_t155" reading_order_no="154" segment_no="13" tag_type="table">Avg</text>
<text top="505" left="229" width="40" height="8" font="font13" id="p9_t156" reading_order_no="155" segment_no="13" tag_type="table">SIZE(MB)</text>
<text top="521" left="65" width="37" height="8" font="font13" id="p9_t157" reading_order_no="156" segment_no="13" tag_type="table">ResNet50</text>
<text top="521" left="126" width="23" height="8" font="font13" id="p9_t158" reading_order_no="157" segment_no="13" tag_type="table">51077</text>
<text top="521" left="161" width="18" height="8" font="font13" id="p9_t159" reading_order_no="158" segment_no="13" tag_type="table">1634</text>
<text top="521" left="191" width="26" height="8" font="font13" id="p9_t160" reading_order_no="159" segment_no="13" tag_type="table">0.0076</text>
<text top="521" left="229" width="14" height="8" font="font13" id="p9_t161" reading_order_no="160" segment_no="13" tag_type="table">114</text>
<text top="532" left="65" width="49" height="8" font="font13" id="p9_t162" reading_order_no="161" segment_no="13" tag_type="table">Inception-V3</text>
<text top="532" left="126" width="23" height="8" font="font13" id="p9_t163" reading_order_no="162" segment_no="13" tag_type="table">66095</text>
<text top="532" left="161" width="18" height="8" font="font13" id="p9_t164" reading_order_no="163" segment_no="13" tag_type="table">1296</text>
<text top="532" left="191" width="26" height="8" font="font13" id="p9_t165" reading_order_no="164" segment_no="13" tag_type="table">0.0060</text>
<text top="532" left="229" width="14" height="8" font="font13" id="p9_t166" reading_order_no="165" segment_no="13" tag_type="table">107</text>
<text top="543" left="65" width="30" height="8" font="font13" id="p9_t167" reading_order_no="166" segment_no="13" tag_type="table">VGG-16</text>
<text top="543" left="126" width="23" height="8" font="font13" id="p9_t168" reading_order_no="167" segment_no="13" tag_type="table">50908</text>
<text top="543" left="161" width="18" height="8" font="font13" id="p9_t169" reading_order_no="168" segment_no="13" tag_type="table">1364</text>
<text top="543" left="191" width="26" height="8" font="font13" id="p9_t170" reading_order_no="169" segment_no="13" tag_type="table">0.0063</text>
<text top="543" left="229" width="16" height="8" font="font13" id="p9_t171" reading_order_no="170" segment_no="13" tag_type="table">62.2</text>
<text top="554" left="65" width="44" height="8" font="font13" id="p9_t172" reading_order_no="171" segment_no="13" tag_type="table">X-inception</text>
<text top="554" left="126" width="23" height="8" font="font13" id="p9_t173" reading_order_no="172" segment_no="13" tag_type="table">73465</text>
<text top="554" left="161" width="18" height="8" font="font13" id="p9_t174" reading_order_no="173" segment_no="13" tag_type="table">1049</text>
<text top="554" left="191" width="26" height="8" font="font13" id="p9_t175" reading_order_no="174" segment_no="13" tag_type="table">0.0049</text>
<text top="554" left="229" width="14" height="8" font="font13" id="p9_t176" reading_order_no="175" segment_no="13" tag_type="table">103</text>
<text top="565" left="65" width="15" height="8" font="font13" id="p9_t177" reading_order_no="176" segment_no="13" tag_type="table">ViT</text>
<text top="565" left="126" width="23" height="8" font="font13" id="p9_t178" reading_order_no="177" segment_no="13" tag_type="table">23102</text>
<text top="565" left="161" width="18" height="8" font="font13" id="p9_t179" reading_order_no="178" segment_no="13" tag_type="table">2156</text>
<text top="565" left="191" width="26" height="8" font="font13" id="p9_t180" reading_order_no="179" segment_no="13" tag_type="table">0.0100</text>
<text top="565" left="229" width="16" height="8" font="font13" id="p9_t181" reading_order_no="180" segment_no="13" tag_type="table">31.2</text>
<text top="597" left="51" width="163" height="13" font="font7" id="p9_t182" reading_order_no="181" segment_no="14" tag_type="text">background is that the ViT value is 90.52</text>
<text top="600" left="214" width="7" height="9" font="font23" id="p9_t183" reading_order_no="182" segment_no="14" tag_type="text">%</text>
<text top="597" left="222" width="67" height="13" font="font7" id="p9_t184" reading_order_no="183" segment_no="14" tag_type="text">, which correctly</text>
<text top="609" left="51" width="237" height="13" font="font7" id="p9_t185" reading_order_no="184" segment_no="14" tag_type="text">classifies 165288 background images. Meanwhile, in order</text>
<text top="621" left="51" width="237" height="13" font="font7" id="p9_t186" reading_order_no="185" segment_no="14" tag_type="text">to better show the classification results, we reconstruct the</text>
<text top="633" left="51" width="151" height="13" font="font7" id="p9_t187" reading_order_no="186" segment_no="14" tag_type="text">transparent images after dicing in Fig.</text>
<text top="633" left="205" width="5" height="13" font="font9" id="p9_t188" reading_order_no="187" segment_no="14" tag_type="text"><a href="deeplearning_paper38.html#10">8</a></text>
<text top="633" left="210" width="2" height="13" font="font7" id="p9_t189" reading_order_no="188" segment_no="14" tag_type="text"><a href="deeplearning_paper38.html#10">.</a></text>
<text top="645" left="66" width="26" height="13" font="font7" id="p9_t190" reading_order_no="189" segment_no="17" tag_type="text">In Tab</text>
<text top="645" left="95" width="5" height="13" font="font9" id="p9_t191" reading_order_no="190" segment_no="17" tag_type="text"><a href="deeplearning_paper38.html#9">9</a></text>
<text top="645" left="102" width="187" height="13" font="font7" id="p9_t192" reading_order_no="191" segment_no="17" tag_type="text">we find that the training time of the ViT model</text>
<text top="657" left="51" width="237" height="13" font="font7" id="p9_t193" reading_order_no="192" segment_no="17" tag_type="text">is still the fastest at 12418 seconds, and the slowest is 73465</text>
<text top="669" left="51" width="237" height="13" font="font7" id="p9_t194" reading_order_no="193" segment_no="17" tag_type="text">seconds for X-Inception. Besides the fastest prediction time</text>
<text top="681" left="51" width="237" height="13" font="font7" id="p9_t195" reading_order_no="194" segment_no="17" tag_type="text">of Inception-V3 is 1049 seconds and the prediction time of</text>
<text top="693" left="51" width="237" height="13" font="font7" id="p9_t196" reading_order_no="195" segment_no="17" tag_type="text">a single picture is 0.0060 second. The slowest time of ViT</text>
<text top="705" left="51" width="237" height="13" font="font7" id="p9_t197" reading_order_no="196" segment_no="17" tag_type="text">is 2156 seconds and the prediction time of a single picture is</text>
<text top="717" left="51" width="60" height="13" font="font7" id="p9_t198" reading_order_no="197" segment_no="17" tag_type="text">0.0100 second.</text>
<text top="58" left="307" width="105" height="10" font="font21" id="p9_t199" reading_order_no="198" segment_no="1" tag_type="title"><b>3.4. In-depth Analysis</b></text>
<text top="68" left="322" width="157" height="13" font="font7" id="p9_t200" reading_order_no="199" segment_no="3" tag_type="text">We compare classification results in Tab</text>
<text top="68" left="480" width="5" height="13" font="font9" id="p9_t201" reading_order_no="200" segment_no="3" tag_type="text"><a href="deeplearning_paper38.html#6">4</a></text>
<text top="68" left="487" width="31" height="13" font="font7" id="p9_t202" reading_order_no="201" segment_no="3" tag_type="text">and Tab</text>
<text top="68" left="520" width="5" height="13" font="font9" id="p9_t203" reading_order_no="202" segment_no="3" tag_type="text"><a href="deeplearning_paper38.html#9">7</a></text>
<text top="68" left="525" width="19" height="13" font="font7" id="p9_t204" reading_order_no="203" segment_no="3" tag_type="text"><a href="deeplearning_paper38.html#9">, </a>and</text>
<text top="80" left="307" width="237" height="13" font="font7" id="p9_t205" reading_order_no="204" segment_no="3" tag_type="text">find that when the transparent image patches of the train-</text>
<text top="92" left="307" width="95" height="13" font="font7" id="p9_t206" reading_order_no="205" segment_no="3" tag_type="text">ing input increase from</text>
<text top="94" left="405" width="22" height="9" font="font23" id="p9_t207" reading_order_no="206" segment_no="3" tag_type="text">8 × 8</text>
<text top="92" left="430" width="8" height="13" font="font7" id="p9_t208" reading_order_no="207" segment_no="3" tag_type="text">to</text>
<text top="94" left="441" width="42" height="9" font="font23" id="p9_t209" reading_order_no="208" segment_no="3" tag_type="text">224 × 224</text>
<text top="92" left="486" width="58" height="13" font="font7" id="p9_t210" reading_order_no="209" segment_no="3" tag_type="text">pixels, the Pre</text>
<text top="104" left="307" width="237" height="13" font="font7" id="p9_t211" reading_order_no="210" segment_no="3" tag_type="text">of the classification foreground of the five models has im-</text>
<text top="116" left="307" width="230" height="13" font="font7" id="p9_t212" reading_order_no="211" segment_no="3" tag_type="text">prove. The biggest improvement is X-Ineption from 53.3</text>
<text top="118" left="537" width="7" height="9" font="font23" id="p9_t213" reading_order_no="212" segment_no="3" tag_type="text">%</text>
<text top="128" left="307" width="29" height="13" font="font7" id="p9_t214" reading_order_no="213" segment_no="3" tag_type="text">to 60.8</text>
<text top="130" left="335" width="7" height="9" font="font23" id="p9_t215" reading_order_no="214" segment_no="3" tag_type="text">%</text>
<text top="128" left="343" width="201" height="13" font="font7" id="p9_t216" reading_order_no="215" segment_no="3" tag_type="text">. This shows that when the image input size be-</text>
<text top="140" left="307" width="237" height="13" font="font7" id="p9_t217" reading_order_no="216" segment_no="3" tag_type="text">comes larger, CNNs can extract more features, thereby im-</text>
<text top="152" left="307" width="237" height="13" font="font7" id="p9_t218" reading_order_no="217" segment_no="3" tag_type="text">proving the model’s classification performance for transpar-</text>
<text top="163" left="307" width="237" height="13" font="font7" id="p9_t219" reading_order_no="218" segment_no="3" tag_type="text">ent images. As the input image size increases, it has little</text>
<text top="175" left="307" width="237" height="13" font="font7" id="p9_t220" reading_order_no="219" segment_no="3" tag_type="text">effect on the performance of the five models to classify the</text>
<text top="187" left="307" width="237" height="13" font="font7" id="p9_t221" reading_order_no="220" segment_no="3" tag_type="text">transparent image background. Among them, the biggest</text>
<text top="199" left="307" width="237" height="13" font="font7" id="p9_t222" reading_order_no="221" segment_no="3" tag_type="text">improvement is X-Inception, which has an Acc increase of</text>
<text top="211" left="307" width="12" height="13" font="font7" id="p9_t223" reading_order_no="222" segment_no="3" tag_type="text">1.2</text>
<text top="214" left="319" width="7" height="9" font="font23" id="p9_t224" reading_order_no="223" segment_no="3" tag_type="text">%</text>
<text top="211" left="326" width="217" height="13" font="font7" id="p9_t225" reading_order_no="224" segment_no="3" tag_type="text">. With the increase in the size of the input image of the</text>
<text top="223" left="307" width="237" height="13" font="font7" id="p9_t226" reading_order_no="225" segment_no="3" tag_type="text">CNNs, the training time of the five models has also increase</text>
<text top="235" left="307" width="17" height="13" font="font7" id="p9_t227" reading_order_no="226" segment_no="3" tag_type="text">by 2</text>
<text top="238" left="323" width="7" height="9" font="font23" id="p9_t228" reading_order_no="227" segment_no="3" tag_type="text">%</text>
<text top="235" left="333" width="15" height="13" font="font7" id="p9_t229" reading_order_no="228" segment_no="3" tag_type="text">to 6</text>
<text top="238" left="348" width="7" height="9" font="font23" id="p9_t230" reading_order_no="229" segment_no="3" tag_type="text">%</text>
<text top="235" left="355" width="189" height="13" font="font7" id="p9_t231" reading_order_no="230" segment_no="3" tag_type="text">, but the Acc of the model has also improve, and</text>
<text top="247" left="307" width="237" height="13" font="font7" id="p9_t232" reading_order_no="231" segment_no="3" tag_type="text">the training Acc of the ResNet50 model is the highest value</text>
<text top="259" left="307" width="33" height="13" font="font7" id="p9_t233" reading_order_no="232" segment_no="3" tag_type="text">of 94.99</text>
<text top="262" left="340" width="7" height="9" font="font23" id="p9_t234" reading_order_no="233" segment_no="3" tag_type="text">%</text>
<text top="259" left="347" width="186" height="13" font="font7" id="p9_t235" reading_order_no="234" segment_no="3" tag_type="text">. VGG-16 and ViT remain basically unchange.</text>
<text top="271" left="322" width="67" height="13" font="font7" id="p9_t236" reading_order_no="235" segment_no="8" tag_type="text">We compare Tab</text>
<text top="271" left="391" width="5" height="13" font="font9" id="p9_t237" reading_order_no="236" segment_no="8" tag_type="text"><a href="deeplearning_paper38.html#8">6</a></text>
<text top="271" left="398" width="32" height="13" font="font7" id="p9_t238" reading_order_no="237" segment_no="8" tag_type="text">and Tab</text>
<text top="271" left="432" width="5" height="13" font="font9" id="p9_t239" reading_order_no="238" segment_no="8" tag_type="text"><a href="deeplearning_paper38.html#9">8</a></text>
<text top="271" left="437" width="107" height="13" font="font7" id="p9_t240" reading_order_no="239" segment_no="8" tag_type="text"><a href="deeplearning_paper38.html#9">. </a>When the transparent im-</text>
<text top="283" left="307" width="113" height="13" font="font7" id="p9_t241" reading_order_no="240" segment_no="8" tag_type="text">age is cropped into pathes of</text>
<text top="286" left="421" width="19" height="9" font="font23" id="p9_t242" reading_order_no="241" segment_no="8" tag_type="text">8 × 8</text>
<text top="283" left="443" width="101" height="13" font="font7" id="p9_t243" reading_order_no="242" segment_no="8" tag_type="text">pixels, the prediction Acc</text>
<text top="295" left="307" width="195" height="13" font="font7" id="p9_t244" reading_order_no="243" segment_no="8" tag_type="text">of the ResNet50 model is the highest value of 90</text>
<text top="298" left="502" width="7" height="9" font="font23" id="p9_t245" reading_order_no="244" segment_no="8" tag_type="text">%</text>
<text top="295" left="510" width="34" height="13" font="font7" id="p9_t246" reading_order_no="245" segment_no="8" tag_type="text">, and the</text>
<text top="307" left="307" width="161" height="13" font="font7" id="p9_t247" reading_order_no="246" segment_no="8" tag_type="text">lowest is the X-Inception value of 85.85</text>
<text top="309" left="467" width="7" height="9" font="font23" id="p9_t248" reading_order_no="247" segment_no="8" tag_type="text">%</text>
<text top="307" left="475" width="69" height="13" font="font7" id="p9_t249" reading_order_no="248" segment_no="8" tag_type="text">. However, when</text>
<text top="319" left="307" width="237" height="13" font="font7" id="p9_t250" reading_order_no="249" segment_no="8" tag_type="text">the transparent image is enlarged and cropped into patches</text>
<text top="331" left="307" width="8" height="13" font="font7" id="p9_t251" reading_order_no="250" segment_no="8" tag_type="text">of</text>
<text top="333" left="318" width="42" height="9" font="font23" id="p9_t252" reading_order_no="251" segment_no="8" tag_type="text">224 × 224</text>
<text top="331" left="362" width="182" height="13" font="font7" id="p9_t253" reading_order_no="252" segment_no="8" tag_type="text">pixels, the X-Inception prediction Acc rate is</text>
<text top="343" left="307" width="67" height="13" font="font7" id="p9_t254" reading_order_no="253" segment_no="8" tag_type="text">the highest 89.11</text>
<text top="345" left="374" width="7" height="9" font="font23" id="p9_t255" reading_order_no="254" segment_no="8" tag_type="text">%</text>
<text top="343" left="381" width="163" height="13" font="font7" id="p9_t256" reading_order_no="255" segment_no="8" tag_type="text">, and the second is that the ViT Acc rate is</text>
<text top="355" left="307" width="22" height="13" font="font7" id="p9_t257" reading_order_no="256" segment_no="8" tag_type="text">89.09</text>
<text top="357" left="329" width="7" height="9" font="font23" id="p9_t258" reading_order_no="257" segment_no="8" tag_type="text">%</text>
<text top="355" left="336" width="208" height="13" font="font7" id="p9_t259" reading_order_no="258" segment_no="8" tag_type="text">. By increasing the size of the input transparent im-</text>
<text top="367" left="307" width="237" height="13" font="font7" id="p9_t260" reading_order_no="259" segment_no="8" tag_type="text">ages patches, the prediction Acc of the ViT model exceeds</text>
<text top="379" left="307" width="237" height="13" font="font7" id="p9_t261" reading_order_no="260" segment_no="8" tag_type="text">that of ResNet50, Inception-V3 and VGG-16. Moreover,</text>
<text top="391" left="307" width="167" height="13" font="font7" id="p9_t262" reading_order_no="261" segment_no="8" tag_type="text">when the input image is a small patches of</text>
<text top="393" left="476" width="39" height="9" font="font23" id="p9_t263" reading_order_no="262" segment_no="8" tag_type="text">224 × 224</text>
<text top="391" left="518" width="26" height="13" font="font7" id="p9_t264" reading_order_no="263" segment_no="8" tag_type="text">pixels,</text>
<text top="403" left="307" width="237" height="13" font="font7" id="p9_t265" reading_order_no="264" segment_no="8" tag_type="text">the Pre of the ViT model to classify the foreground of the</text>
<text top="415" left="307" width="237" height="13" font="font7" id="p9_t266" reading_order_no="265" segment_no="8" tag_type="text">transparent image is higher than that of the CNNs network.</text>
<text top="426" left="307" width="237" height="13" font="font7" id="p9_t267" reading_order_no="266" segment_no="8" tag_type="text">This shows that the advantage of ViT for global information</text>
<text top="438" left="307" width="222" height="13" font="font7" id="p9_t268" reading_order_no="267" segment_no="8" tag_type="text">description is higher than that of some CNNs networks.</text>
<text top="450" left="322" width="222" height="13" font="font7" id="p9_t269" reading_order_no="268" segment_no="10" tag_type="text">In the predicted 215040 patches, we compare the per-</text>
<text top="462" left="307" width="237" height="13" font="font7" id="p9_t270" reading_order_no="269" segment_no="10" tag_type="text">formance of five types of network classification foreground</text>
<text top="474" left="307" width="102" height="13" font="font7" id="p9_t271" reading_order_no="270" segment_no="10" tag_type="text">and background. In Fig.</text>
<text top="474" left="412" width="5" height="13" font="font9" id="p9_t272" reading_order_no="271" segment_no="10" tag_type="text"><a href="deeplearning_paper38.html#8">7</a></text>
<text top="474" left="417" width="127" height="13" font="font7" id="p9_t273" reading_order_no="272" segment_no="10" tag_type="text"><a href="deeplearning_paper38.html#8">, </a>we find that Inception-v3 has</text>
<text top="486" left="307" width="189" height="13" font="font7" id="p9_t274" reading_order_no="273" segment_no="10" tag_type="text">the largest number of correct foregrounds under</text>
<text top="489" left="498" width="20" height="9" font="font23" id="p9_t275" reading_order_no="274" segment_no="10" tag_type="text">8 × 8</text>
<text top="486" left="520" width="24" height="13" font="font7" id="p9_t276" reading_order_no="275" segment_no="10" tag_type="text">pixels</text>
<text top="498" left="307" width="237" height="13" font="font7" id="p9_t277" reading_order_no="276" segment_no="10" tag_type="text">patches. ResNet50 has the largest number of correctly clas-</text>
<text top="510" left="307" width="105" height="13" font="font7" id="p9_t278" reading_order_no="277" segment_no="10" tag_type="text">sify backgrounds. In Fig.</text>
<text top="510" left="415" width="5" height="13" font="font9" id="p9_t279" reading_order_no="278" segment_no="10" tag_type="text"><a href="deeplearning_paper38.html#11">9</a></text>
<text top="510" left="424" width="120" height="13" font="font7" id="p9_t280" reading_order_no="279" segment_no="10" tag_type="text">we find that Inception-v3 has</text>
<text top="522" left="307" width="237" height="13" font="font7" id="p9_t281" reading_order_no="280" segment_no="10" tag_type="text">the largest number of correctly classify foregrounds under</text>
<text top="537" left="307" width="38" height="9" font="font23" id="p9_t282" reading_order_no="281" segment_no="10" tag_type="text">224 × 224</text>
<text top="534" left="347" width="197" height="13" font="font7" id="p9_t283" reading_order_no="282" segment_no="10" tag_type="text">pixels patches, and the largest number of correctly</text>
<text top="546" left="307" width="237" height="13" font="font7" id="p9_t284" reading_order_no="283" segment_no="10" tag_type="text">classify background patches is ViT. In addition, the num-</text>
<text top="558" left="307" width="237" height="13" font="font7" id="p9_t285" reading_order_no="284" segment_no="10" tag_type="text">ber of foreground patches misclassify by the ViT network</text>
<text top="570" left="307" width="237" height="13" font="font7" id="p9_t286" reading_order_no="285" segment_no="10" tag_type="text">model is much smaller than that of the CNNs network. At</text>
<text top="582" left="307" width="237" height="13" font="font7" id="p9_t287" reading_order_no="286" segment_no="10" tag_type="text">the same time, the number of correctly classify foreground</text>
<text top="594" left="307" width="237" height="13" font="font7" id="p9_t288" reading_order_no="287" segment_no="10" tag_type="text">in the CNNs network is greater than that of the ViT network.</text>
<text top="626" left="307" width="164" height="11" font="font8" id="p9_t289" reading_order_no="288" segment_no="15" tag_type="title"><b>4. Conclusion and Future Work</b></text>
<text top="641" left="322" width="222" height="13" font="font7" id="p9_t290" reading_order_no="289" segment_no="16" tag_type="text">In this paper, we aim at the problem that transparent im-</text>
<text top="653" left="307" width="242" height="13" font="font7" id="p9_t291" reading_order_no="290" segment_no="16" tag_type="text">ages are difficult to classify by cropping the image into patches</text>
<text top="665" left="307" width="244" height="13" font="font7" id="p9_t292" reading_order_no="291" segment_no="16" tag_type="text">and classifying the foreground and background. We use CNNs</text>
<text top="677" left="307" width="237" height="13" font="font7" id="p9_t293" reading_order_no="292" segment_no="16" tag_type="text">(ResNet50, Inception-V3, VGG-16, X-Inception) and ViT</text>
<text top="689" left="307" width="237" height="13" font="font7" id="p9_t294" reading_order_no="293" segment_no="16" tag_type="text">deep learning methods to compare the performance of clas-</text>
<text top="701" left="307" width="237" height="13" font="font7" id="p9_t295" reading_order_no="294" segment_no="16" tag_type="text">sifying patches of transparent images. In addition, we also</text>
<text top="713" left="307" width="127" height="13" font="font7" id="p9_t296" reading_order_no="295" segment_no="16" tag_type="text">compare the effects of patches of</text>
<text top="715" left="436" width="17" height="9" font="font23" id="p9_t297" reading_order_no="296" segment_no="16" tag_type="text">8×8</text>
<text top="713" left="454" width="14" height="13" font="font7" id="p9_t298" reading_order_no="297" segment_no="16" tag_type="text">and</text>
<text top="715" left="470" width="37" height="9" font="font23" id="p9_t299" reading_order_no="298" segment_no="16" tag_type="text">224×224</text>
<text top="713" left="509" width="35" height="13" font="font7" id="p9_t300" reading_order_no="299" segment_no="16" tag_type="text">pixels on</text>
<text top="725" left="307" width="237" height="13" font="font7" id="p9_t301" reading_order_no="300" segment_no="16" tag_type="text">the classification performance of deep learning methods. We</text>
<text top="759" left="51" width="78" height="8" font="font13" id="p9_t302" reading_order_no="301" segment_no="18" tag_type="footnote">HeChen Yang et al.:</text>
<text top="759" left="133" width="108" height="8" font="font14" id="p9_t303" reading_order_no="302" segment_no="18" tag_type="footnote"><i>Preprint submitted to Elsevier</i></text>
<text top="759" left="495" width="49" height="8" font="font13" id="p9_t304" reading_order_no="303" segment_no="19" tag_type="text">Page 9 of 12</text>
</page>
<page number="10" position="absolute" top="0" left="0" height="793" width="595">
<text top="37" left="241" width="113" height="8" font="font13" id="p10_t1" reading_order_no="0" segment_no="0" tag_type="text">Leveraging social media news</text>
<text top="66" left="107" width="71" height="9" font="font29" id="p10_t2" reading_order_no="1" segment_no="1" tag_type="figure">Resnet50 Inception-V3</text>
<text top="66" left="193" width="22" height="9" font="font29" id="p10_t3" reading_order_no="2" segment_no="1" tag_type="figure">VGG-16</text>
<text top="66" left="230" width="33" height="9" font="font29" id="p10_t4" reading_order_no="3" segment_no="1" tag_type="figure">X-Inception</text>
<text top="66" left="283" width="9" height="9" font="font29" id="p10_t5" reading_order_no="4" segment_no="1" tag_type="figure">ViT</text>
<text top="64" left="359" width="71" height="9" font="font29" id="p10_t6" reading_order_no="5" segment_no="1" tag_type="figure">Resnet50 Inception-V3</text>
<text top="64" left="445" width="22" height="9" font="font29" id="p10_t7" reading_order_no="6" segment_no="1" tag_type="figure">VGG-16</text>
<text top="64" left="482" width="33" height="9" font="font29" id="p10_t8" reading_order_no="7" segment_no="1" tag_type="figure">X-Inception</text>
<text top="64" left="535" width="9" height="9" font="font29" id="p10_t9" reading_order_no="8" segment_no="1" tag_type="figure">ViT</text>
<text top="474" left="134" width="35" height="8" font="font20" id="p10_t10" reading_order_no="9" segment_no="2" tag_type="text">Figure 8:</text>
<text top="474" left="173" width="68" height="8" font="font13" id="p10_t11" reading_order_no="10" segment_no="2" tag_type="text">Reconstruction of</text>
<text top="475" left="244" width="37" height="8" font="font24" id="p10_t12" reading_order_no="11" segment_no="2" tag_type="text">224 × 224</text>
<text top="474" left="283" width="178" height="8" font="font13" id="p10_t13" reading_order_no="12" segment_no="2" tag_type="text">pixels transparent images classification results.</text>
<text top="509" left="51" width="237" height="13" font="font7" id="p10_t14" reading_order_no="13" segment_no="3" tag_type="text">conclude that CNNs have better classification performance</text>
<text top="521" left="51" width="237" height="13" font="font7" id="p10_t15" reading_order_no="14" segment_no="3" tag_type="text">than ViT in patches of 8×8 pixels. However, the classifica-</text>
<text top="533" left="51" width="237" height="13" font="font7" id="p10_t16" reading_order_no="15" segment_no="3" tag_type="text">tion performance of ViT at 256×256 pixels is better than that</text>
<text top="545" left="51" width="237" height="13" font="font7" id="p10_t17" reading_order_no="16" segment_no="3" tag_type="text">of most CNNs. Therefore, we conclude that CNNs and ViT</text>
<text top="557" left="51" width="237" height="13" font="font7" id="p10_t18" reading_order_no="17" segment_no="3" tag_type="text">network models have more advantages in image classifica-</text>
<text top="569" left="51" width="237" height="13" font="font7" id="p10_t19" reading_order_no="18" segment_no="3" tag_type="text">tion. CNNs are good at extracting local features of images,</text>
<text top="581" left="51" width="210" height="13" font="font7" id="p10_t20" reading_order_no="19" segment_no="3" tag_type="text">and ViT is good at extracting images global features.</text>
<text top="593" left="66" width="222" height="13" font="font7" id="p10_t21" reading_order_no="20" segment_no="7" tag_type="text">In the future, we plan to increase the amount of data to</text>
<text top="605" left="51" width="237" height="13" font="font7" id="p10_t22" reading_order_no="21" segment_no="7" tag_type="text">improve the stability of the comparison. Meanwhile, the im-</text>
<text top="617" left="51" width="237" height="13" font="font7" id="p10_t23" reading_order_no="22" segment_no="7" tag_type="text">ages reconstructed by deep learning classification can be ex-</text>
<text top="629" left="51" width="237" height="13" font="font7" id="p10_t24" reading_order_no="23" segment_no="7" tag_type="text">tended to the positioning, segmentation, recognition and de-</text>
<text top="640" left="51" width="237" height="13" font="font7" id="p10_t25" reading_order_no="24" segment_no="7" tag_type="text">tection of transparent images. We need to further strengthen</text>
<text top="652" left="51" width="101" height="13" font="font7" id="p10_t26" reading_order_no="25" segment_no="7" tag_type="text">the application of results.</text>
<text top="685" left="51" width="113" height="11" font="font8" id="p10_t27" reading_order_no="26" segment_no="11" tag_type="title"><b>5. Acknowledgements</b></text>
<text top="699" left="66" width="226" height="13" font="font7" id="p10_t28" reading_order_no="27" segment_no="13" tag_type="text">This work is supported by National Natural Science Foun-</text>
<text top="711" left="51" width="237" height="13" font="font7" id="p10_t29" reading_order_no="28" segment_no="13" tag_type="text">dation of China (No. 61806047). We thank Miss Zixian Li</text>
<text top="723" left="51" width="202" height="13" font="font7" id="p10_t30" reading_order_no="29" segment_no="13" tag_type="text">and Mr. Guoxian Li for their important discussion.</text>
<text top="513" left="307" width="55" height="11" font="font8" id="p10_t31" reading_order_no="30" segment_no="4" tag_type="title"><b>References</b></text>
<text top="528" left="311" width="233" height="10" font="font4" id="p10_t32" reading_order_no="31" segment_no="5" tag_type="text">[1] Shu-Yuan Liao, Oscar N Aurelio, Kevin Jan, Jan Zavada, and Eric J</text>
<text top="538" left="325" width="219" height="10" font="font4" id="p10_t33" reading_order_no="32" segment_no="5" tag_type="text">Stanbridge. Identification of the mn/ca9 protein as a reliable diagnos-</text>
<text top="548" left="325" width="162" height="10" font="font4" id="p10_t34" reading_order_no="33" segment_no="5" tag_type="text">tic biomarker of clear cell carcinoma of the kidney.</text>
<text top="550" left="489" width="53" height="7" font="font3" id="p10_t35" reading_order_no="34" segment_no="5" tag_type="text"><i>Cancer research</i></text>
<text top="548" left="542" width="2" height="10" font="font4" id="p10_t36" reading_order_no="35" segment_no="5" tag_type="text">,</text>
<text top="558" left="325" width="81" height="10" font="font4" id="p10_t37" reading_order_no="36" segment_no="5" tag_type="text">57(14):2827–2831, 1997.</text>
<text top="568" left="311" width="233" height="10" font="font4" id="p10_t38" reading_order_no="37" segment_no="6" tag_type="text">[2] Zihan Li, Chen Li, Yudong Yao, Jinghua Zhang, Md Mamunur Ra-</text>
<text top="578" left="325" width="219" height="10" font="font4" id="p10_t39" reading_order_no="38" segment_no="6" tag_type="text">haman, Hao Xu, Frank Kulwa, Bolin Lu, Xuemin Zhu, and Tao Jiang.</text>
<text top="588" left="325" width="219" height="10" font="font4" id="p10_t40" reading_order_no="39" segment_no="6" tag_type="text">Emds-5: Environmental microorganism image dataset fifth version</text>
<text top="598" left="325" width="106" height="10" font="font4" id="p10_t41" reading_order_no="40" segment_no="6" tag_type="text">for multiple image analysis tasks.</text>
<text top="600" left="434" width="28" height="7" font="font3" id="p10_t42" reading_order_no="41" segment_no="6" tag_type="text"><i>Plos one</i></text>
<text top="598" left="462" width="77" height="10" font="font4" id="p10_t43" reading_order_no="42" segment_no="6" tag_type="text">, 16(5):e0250631, 2021.</text>
<text top="608" left="311" width="233" height="10" font="font4" id="p10_t44" reading_order_no="43" segment_no="8" tag_type="text">[3] May Phyo Khaing and Mukunoki Masayuki. Transparent object de-</text>
<text top="617" left="325" width="148" height="10" font="font4" id="p10_t45" reading_order_no="44" segment_no="8" tag_type="text">tection using convolutional neural network. In</text>
<text top="620" left="475" width="69" height="7" font="font3" id="p10_t46" reading_order_no="45" segment_no="8" tag_type="text"><i>International Confer-</i></text>
<text top="630" left="325" width="196" height="7" font="font3" id="p10_t47" reading_order_no="46" segment_no="8" tag_type="text"><i>ence on Big Data Analysis and Deep Learning Applications</i></text>
<text top="627" left="521" width="23" height="10" font="font4" id="p10_t48" reading_order_no="47" segment_no="8" tag_type="text">, pages</text>
<text top="637" left="325" width="73" height="10" font="font4" id="p10_t49" reading_order_no="48" segment_no="8" tag_type="text">86–93. Springer, 2018.</text>
<text top="647" left="311" width="233" height="10" font="font4" id="p10_t50" reading_order_no="49" segment_no="9" tag_type="text">[4] Jay Martin Tenenbaum. Accommodation in computer vision. Tech-</text>
<text top="657" left="325" width="205" height="10" font="font4" id="p10_t51" reading_order_no="50" segment_no="9" tag_type="text">nical report, Stanford Univ Ca Dept of Computer Science, 1970.</text>
<text top="667" left="311" width="233" height="10" font="font4" id="p10_t52" reading_order_no="51" segment_no="10" tag_type="text">[5] Michael Isard and Andrew Blake. Contour tracking by stochastic</text>
<text top="677" left="325" width="121" height="10" font="font4" id="p10_t53" reading_order_no="52" segment_no="10" tag_type="text">propagation of conditional density. In</text>
<text top="679" left="448" width="96" height="7" font="font3" id="p10_t54" reading_order_no="53" segment_no="10" tag_type="text"><i>European conference on com-</i></text>
<text top="689" left="325" width="38" height="7" font="font3" id="p10_t55" reading_order_no="54" segment_no="10" tag_type="text"><i>puter vision</i></text>
<text top="687" left="363" width="105" height="10" font="font4" id="p10_t56" reading_order_no="55" segment_no="10" tag_type="text">, pages 343–356. Springer, 1996.</text>
<text top="697" left="311" width="233" height="10" font="font4" id="p10_t57" reading_order_no="56" segment_no="12" tag_type="text">[6] Michael D Kelly. Edge detection in pictures by computer using plan-</text>
<text top="707" left="325" width="219" height="10" font="font4" id="p10_t58" reading_order_no="57" segment_no="12" tag_type="text">ning. Technical report, STANFORD UNIV CALIF DEPT OF COM-</text>
<text top="717" left="325" width="82" height="10" font="font4" id="p10_t59" reading_order_no="58" segment_no="12" tag_type="text">PUTER SCIENCE, 1970.</text>
<text top="727" left="311" width="233" height="10" font="font4" id="p10_t60" reading_order_no="59" segment_no="14" tag_type="text">[7] Vicki Bruce and Andy Young. Understanding face recognition.</text>
<text top="759" left="51" width="78" height="8" font="font13" id="p10_t61" reading_order_no="60" segment_no="15" tag_type="footnote">HeChen Yang et al.:</text>
<text top="759" left="133" width="108" height="8" font="font14" id="p10_t62" reading_order_no="61" segment_no="15" tag_type="footnote"><i>Preprint submitted to Elsevier</i></text>
<text top="759" left="490" width="54" height="8" font="font13" id="p10_t63" reading_order_no="62" segment_no="16" tag_type="text">Page 10 of 12</text>
</page>
<page number="11" position="absolute" top="0" left="0" height="793" width="595">
<text top="37" left="241" width="113" height="8" font="font13" id="p11_t1" reading_order_no="0" segment_no="0" tag_type="text">Leveraging social media news</text>
<text top="72" left="98" width="25" height="10" font="font30" id="p11_t2" reading_order_no="23" segment_no="1" tag_type="figure">162270</text>
<text top="82" left="98" width="24" height="10" font="font31" id="p11_t3" reading_order_no="24" segment_no="1" tag_type="figure"><b>75.46%</b></text>
<text top="72" left="145" width="17" height="10" font="font30" id="p11_t4" reading_order_no="25" segment_no="1" tag_type="figure">3685</text>
<text top="82" left="144" width="19" height="10" font="font31" id="p11_t5" reading_order_no="26" segment_no="1" tag_type="figure"><b>1.71%</b></text>
<text top="67" left="184" width="27" height="10" font="font31" id="p11_t6" reading_order_no="27" segment_no="1" tag_type="figure"><b>165955</b></text>
<text top="77" left="186" width="24" height="10" font="font31" id="p11_t7" reading_order_no="28" segment_no="1" tag_type="figure"><b>97.78%</b></text>
<text top="86" left="188" width="19" height="10" font="font31" id="p11_t8" reading_order_no="29" segment_no="1" tag_type="figure"><b>2.22%</b></text>
<text top="115" left="100" width="21" height="10" font="font30" id="p11_t9" reading_order_no="30" segment_no="1" tag_type="figure">20131</text>
<text top="125" left="101" width="19" height="10" font="font31" id="p11_t10" reading_order_no="31" segment_no="1" tag_type="figure"><b>9.36%</b></text>
<text top="115" left="143" width="21" height="10" font="font30" id="p11_t11" reading_order_no="32" segment_no="1" tag_type="figure">28954</text>
<text top="125" left="142" width="24" height="10" font="font31" id="p11_t12" reading_order_no="33" segment_no="1" tag_type="figure"><b>13.47%</b></text>
<text top="110" left="186" width="22" height="10" font="font31" id="p11_t13" reading_order_no="34" segment_no="1" tag_type="figure"><b>49085</b></text>
<text top="120" left="186" width="24" height="10" font="font31" id="p11_t14" reading_order_no="35" segment_no="1" tag_type="figure"><b>58.99%</b></text>
<text top="129" left="186" width="24" height="10" font="font31" id="p11_t15" reading_order_no="36" segment_no="1" tag_type="figure"><b>41.01%</b></text>
<text top="153" left="97" width="27" height="10" font="font31" id="p11_t16" reading_order_no="37" segment_no="1" tag_type="figure"><b>182401</b></text>
<text top="163" left="98" width="24" height="10" font="font31" id="p11_t17" reading_order_no="38" segment_no="1" tag_type="figure"><b>88.96%</b></text>
<text top="172" left="98" width="24" height="10" font="font31" id="p11_t18" reading_order_no="39" segment_no="1" tag_type="figure"><b>11.04%</b></text>
<text top="153" left="143" width="22" height="10" font="font31" id="p11_t19" reading_order_no="40" segment_no="1" tag_type="figure"><b>32639</b></text>
<text top="163" left="142" width="24" height="10" font="font31" id="p11_t20" reading_order_no="41" segment_no="1" tag_type="figure"><b>88.71%</b></text>
<text top="172" left="142" width="24" height="10" font="font31" id="p11_t21" reading_order_no="42" segment_no="1" tag_type="figure"><b>11.29%</b></text>
<text top="153" left="184" width="27" height="10" font="font31" id="p11_t22" reading_order_no="43" segment_no="1" tag_type="figure"><b>215040</b></text>
<text top="163" left="186" width="24" height="10" font="font31" id="p11_t23" reading_order_no="44" segment_no="1" tag_type="figure"><b>89.93%</b></text>
<text top="172" left="186" width="24" height="10" font="font31" id="p11_t24" reading_order_no="45" segment_no="1" tag_type="figure"><b>10.07%</b></text>
<text top="192" left="93" width="36" height="8" font="font32" id="p11_t25" reading_order_no="46" segment_no="1" tag_type="figure">background</text>
<text top="199" left="133" width="38" height="10" font="font33" id="p11_t26" reading_order_no="49" segment_no="1" tag_type="figure">True Label</text>
<text top="146" left="72" width="0" height="10" font="font33" id="p11_t27" reading_order_no="8" segment_no="1" tag_type="figure">Pr</text>
<text top="138" left="72" width="0" height="10" font="font33" id="p11_t28" reading_order_no="7" segment_no="1" tag_type="figure">ed</text>
<text top="129" left="72" width="0" height="10" font="font33" id="p11_t29" reading_order_no="6" segment_no="1" tag_type="figure">ic</text>
<text top="123" left="72" width="0" height="10" font="font33" id="p11_t30" reading_order_no="5" segment_no="1" tag_type="figure">te</text>
<text top="116" left="72" width="0" height="10" font="font33" id="p11_t31" reading_order_no="4" segment_no="1" tag_type="figure">d </text>
<text top="109" left="72" width="0" height="10" font="font33" id="p11_t32" reading_order_no="3" segment_no="1" tag_type="figure">La</text>
<text top="100" left="72" width="0" height="10" font="font33" id="p11_t33" reading_order_no="2" segment_no="1" tag_type="figure">be</text>
<text top="91" left="72" width="0" height="10" font="font33" id="p11_t34" reading_order_no="1" segment_no="1" tag_type="figure">l</text>
<text top="210" left="135" width="34" height="12" font="font34" id="p11_t35" reading_order_no="50" segment_no="1" tag_type="figure">ResNet50</text>
<text top="191" left="136" width="34" height="8" font="font32" id="p11_t36" reading_order_no="47" segment_no="1" tag_type="figure">foreground</text>
<text top="192" left="186" width="23" height="8" font="font32" id="p11_t37" reading_order_no="48" segment_no="1" tag_type="figure">sum-lin</text>
<text top="95" left="84" width="0" height="8" font="font32" id="p11_t38" reading_order_no="13" segment_no="1" tag_type="figure">ba</text>
<text top="87" left="84" width="0" height="8" font="font32" id="p11_t39" reading_order_no="12" segment_no="1" tag_type="figure">ck</text>
<text top="81" left="84" width="0" height="8" font="font32" id="p11_t40" reading_order_no="11" segment_no="1" tag_type="figure">gr</text>
<text top="74" left="84" width="0" height="8" font="font32" id="p11_t41" reading_order_no="10" segment_no="1" tag_type="figure">ou</text>
<text top="66" left="84" width="0" height="8" font="font32" id="p11_t42" reading_order_no="9" segment_no="1" tag_type="figure">nd</text>
<text top="136" left="84" width="0" height="8" font="font32" id="p11_t43" reading_order_no="18" segment_no="1" tag_type="figure">fo</text>
<text top="130" left="84" width="0" height="8" font="font32" id="p11_t44" reading_order_no="17" segment_no="1" tag_type="figure">re</text>
<text top="124" left="84" width="0" height="8" font="font32" id="p11_t45" reading_order_no="16" segment_no="1" tag_type="figure">gr</text>
<text top="117" left="84" width="0" height="8" font="font32" id="p11_t46" reading_order_no="15" segment_no="1" tag_type="figure">ou</text>
<text top="109" left="84" width="0" height="8" font="font32" id="p11_t47" reading_order_no="14" segment_no="1" tag_type="figure">nd</text>
<text top="174" left="84" width="0" height="8" font="font32" id="p11_t48" reading_order_no="22" segment_no="1" tag_type="figure">su</text>
<text top="167" left="84" width="0" height="8" font="font32" id="p11_t49" reading_order_no="21" segment_no="1" tag_type="figure">m</text>
<text top="161" left="84" width="0" height="8" font="font32" id="p11_t50" reading_order_no="20" segment_no="1" tag_type="figure">-c</text>
<text top="155" left="84" width="0" height="8" font="font32" id="p11_t51" reading_order_no="19" segment_no="1" tag_type="figure">ol</text>
<text top="73" left="267" width="25" height="10" font="font30" id="p11_t52" reading_order_no="73" segment_no="1" tag_type="figure">159906</text>
<text top="82" left="268" width="24" height="10" font="font31" id="p11_t53" reading_order_no="74" segment_no="1" tag_type="figure"><b>74.36%</b></text>
<text top="73" left="315" width="17" height="10" font="font30" id="p11_t54" reading_order_no="75" segment_no="1" tag_type="figure">3080</text>
<text top="82" left="314" width="19" height="10" font="font31" id="p11_t55" reading_order_no="76" segment_no="1" tag_type="figure"><b>1.43%</b></text>
<text top="68" left="354" width="27" height="10" font="font31" id="p11_t56" reading_order_no="77" segment_no="1" tag_type="figure"><b>162986</b></text>
<text top="77" left="355" width="24" height="10" font="font31" id="p11_t57" reading_order_no="78" segment_no="1" tag_type="figure"><b>98.11%</b></text>
<text top="87" left="357" width="19" height="10" font="font31" id="p11_t58" reading_order_no="79" segment_no="1" tag_type="figure"><b>1.89%</b></text>
<text top="116" left="269" width="21" height="10" font="font30" id="p11_t59" reading_order_no="80" segment_no="1" tag_type="figure">22495</text>
<text top="125" left="268" width="24" height="10" font="font31" id="p11_t60" reading_order_no="81" segment_no="1" tag_type="figure"><b>10.46%</b></text>
<text top="116" left="313" width="21" height="10" font="font30" id="p11_t61" reading_order_no="82" segment_no="1" tag_type="figure">29559</text>
<text top="125" left="312" width="24" height="10" font="font31" id="p11_t62" reading_order_no="83" segment_no="1" tag_type="figure"><b>13.75%</b></text>
<text top="111" left="356" width="22" height="10" font="font31" id="p11_t63" reading_order_no="84" segment_no="1" tag_type="figure"><b>52054</b></text>
<text top="120" left="355" width="24" height="10" font="font31" id="p11_t64" reading_order_no="85" segment_no="1" tag_type="figure"><b>56.79%</b></text>
<text top="130" left="355" width="24" height="10" font="font31" id="p11_t65" reading_order_no="86" segment_no="1" tag_type="figure"><b>43.21%</b></text>
<text top="154" left="267" width="27" height="10" font="font31" id="p11_t66" reading_order_no="87" segment_no="1" tag_type="figure"><b>182401</b></text>
<text top="163" left="268" width="24" height="10" font="font31" id="p11_t67" reading_order_no="88" segment_no="1" tag_type="figure"><b>87.67%</b></text>
<text top="173" left="268" width="24" height="10" font="font31" id="p11_t68" reading_order_no="89" segment_no="1" tag_type="figure"><b>12.33%</b></text>
<text top="154" left="312" width="22" height="10" font="font31" id="p11_t69" reading_order_no="90" segment_no="1" tag_type="figure"><b>32639</b></text>
<text top="163" left="312" width="24" height="10" font="font31" id="p11_t70" reading_order_no="91" segment_no="1" tag_type="figure"><b>89.58%</b></text>
<text top="173" left="312" width="24" height="10" font="font31" id="p11_t71" reading_order_no="92" segment_no="1" tag_type="figure"><b>10.42%</b></text>
<text top="154" left="354" width="27" height="10" font="font31" id="p11_t72" reading_order_no="93" segment_no="1" tag_type="figure"><b>215040</b></text>
<text top="163" left="355" width="24" height="10" font="font31" id="p11_t73" reading_order_no="94" segment_no="1" tag_type="figure"><b>88.11%</b></text>
<text top="173" left="355" width="24" height="10" font="font31" id="p11_t74" reading_order_no="95" segment_no="1" tag_type="figure"><b>11.89%</b></text>
<text top="192" left="262" width="36" height="8" font="font32" id="p11_t75" reading_order_no="96" segment_no="1" tag_type="figure">background</text>
<text top="199" left="304" width="38" height="10" font="font33" id="p11_t76" reading_order_no="99" segment_no="1" tag_type="figure">True Label</text>
<text top="146" left="241" width="0" height="10" font="font33" id="p11_t77" reading_order_no="58" segment_no="1" tag_type="figure">Pr</text>
<text top="139" left="241" width="0" height="10" font="font33" id="p11_t78" reading_order_no="57" segment_no="1" tag_type="figure">ed</text>
<text top="130" left="241" width="0" height="10" font="font33" id="p11_t79" reading_order_no="56" segment_no="1" tag_type="figure">ic</text>
<text top="124" left="241" width="0" height="10" font="font33" id="p11_t80" reading_order_no="55" segment_no="1" tag_type="figure">te</text>
<text top="117" left="241" width="0" height="10" font="font33" id="p11_t81" reading_order_no="54" segment_no="1" tag_type="figure">d </text>
<text top="109" left="241" width="0" height="10" font="font33" id="p11_t82" reading_order_no="53" segment_no="1" tag_type="figure">La</text>
<text top="101" left="241" width="0" height="10" font="font33" id="p11_t83" reading_order_no="52" segment_no="1" tag_type="figure">be</text>
<text top="92" left="241" width="0" height="10" font="font33" id="p11_t84" reading_order_no="51" segment_no="1" tag_type="figure">l</text>
<text top="210" left="301" width="46" height="12" font="font34" id="p11_t85" reading_order_no="100" segment_no="1" tag_type="figure">Inception-V3</text>
<text top="192" left="306" width="34" height="8" font="font32" id="p11_t86" reading_order_no="97" segment_no="1" tag_type="figure">foreground</text>
<text top="192" left="356" width="23" height="8" font="font32" id="p11_t87" reading_order_no="98" segment_no="1" tag_type="figure">sum-lin</text>
<text top="95" left="254" width="0" height="8" font="font32" id="p11_t88" reading_order_no="63" segment_no="1" tag_type="figure">ba</text>
<text top="88" left="254" width="0" height="8" font="font32" id="p11_t89" reading_order_no="62" segment_no="1" tag_type="figure">ck</text>
<text top="81" left="254" width="0" height="8" font="font32" id="p11_t90" reading_order_no="61" segment_no="1" tag_type="figure">gr</text>
<text top="75" left="254" width="0" height="8" font="font32" id="p11_t91" reading_order_no="60" segment_no="1" tag_type="figure">ou</text>
<text top="67" left="254" width="0" height="8" font="font32" id="p11_t92" reading_order_no="59" segment_no="1" tag_type="figure">nd</text>
<text top="137" left="254" width="0" height="8" font="font32" id="p11_t93" reading_order_no="68" segment_no="1" tag_type="figure">fo</text>
<text top="131" left="254" width="0" height="8" font="font32" id="p11_t94" reading_order_no="67" segment_no="1" tag_type="figure">re</text>
<text top="125" left="254" width="0" height="8" font="font32" id="p11_t95" reading_order_no="66" segment_no="1" tag_type="figure">gr</text>
<text top="118" left="254" width="0" height="8" font="font32" id="p11_t96" reading_order_no="65" segment_no="1" tag_type="figure">ou</text>
<text top="110" left="254" width="0" height="8" font="font32" id="p11_t97" reading_order_no="64" segment_no="1" tag_type="figure">nd</text>
<text top="175" left="254" width="0" height="8" font="font32" id="p11_t98" reading_order_no="72" segment_no="1" tag_type="figure">su</text>
<text top="168" left="254" width="0" height="8" font="font32" id="p11_t99" reading_order_no="71" segment_no="1" tag_type="figure">m</text>
<text top="162" left="254" width="0" height="8" font="font32" id="p11_t100" reading_order_no="70" segment_no="1" tag_type="figure">-c</text>
<text top="156" left="254" width="0" height="8" font="font32" id="p11_t101" reading_order_no="69" segment_no="1" tag_type="figure">ol</text>
<text top="73" left="429" width="25" height="10" font="font30" id="p11_t102" reading_order_no="123" segment_no="1" tag_type="figure">161057</text>
<text top="82" left="430" width="24" height="10" font="font31" id="p11_t103" reading_order_no="124" segment_no="1" tag_type="figure"><b>74.90%</b></text>
<text top="73" left="477" width="17" height="10" font="font30" id="p11_t104" reading_order_no="125" segment_no="1" tag_type="figure">4235</text>
<text top="82" left="476" width="19" height="10" font="font31" id="p11_t105" reading_order_no="126" segment_no="1" tag_type="figure"><b>1.97%</b></text>
<text top="68" left="516" width="27" height="10" font="font31" id="p11_t106" reading_order_no="127" segment_no="1" tag_type="figure"><b>165292</b></text>
<text top="77" left="517" width="24" height="10" font="font31" id="p11_t107" reading_order_no="128" segment_no="1" tag_type="figure"><b>97.44%</b></text>
<text top="87" left="519" width="19" height="10" font="font31" id="p11_t108" reading_order_no="129" segment_no="1" tag_type="figure"><b>2.56%</b></text>
<text top="116" left="431" width="21" height="10" font="font30" id="p11_t109" reading_order_no="130" segment_no="1" tag_type="figure">21344</text>
<text top="125" left="432" width="19" height="10" font="font31" id="p11_t110" reading_order_no="131" segment_no="1" tag_type="figure"><b>9.93%</b></text>
<text top="116" left="475" width="21" height="10" font="font30" id="p11_t111" reading_order_no="132" segment_no="1" tag_type="figure">28404</text>
<text top="125" left="474" width="24" height="10" font="font31" id="p11_t112" reading_order_no="133" segment_no="1" tag_type="figure"><b>13.20%</b></text>
<text top="111" left="518" width="22" height="10" font="font31" id="p11_t113" reading_order_no="134" segment_no="1" tag_type="figure"><b>49748</b></text>
<text top="120" left="517" width="24" height="10" font="font31" id="p11_t114" reading_order_no="135" segment_no="1" tag_type="figure"><b>57.10%</b></text>
<text top="130" left="517" width="24" height="10" font="font31" id="p11_t115" reading_order_no="136" segment_no="1" tag_type="figure"><b>42.90%</b></text>
<text top="154" left="428" width="27" height="10" font="font31" id="p11_t116" reading_order_no="137" segment_no="1" tag_type="figure"><b>182401</b></text>
<text top="163" left="430" width="24" height="10" font="font31" id="p11_t117" reading_order_no="138" segment_no="1" tag_type="figure"><b>88.30%</b></text>
<text top="173" left="430" width="24" height="10" font="font31" id="p11_t118" reading_order_no="139" segment_no="1" tag_type="figure"><b>11.70%</b></text>
<text top="154" left="474" width="22" height="10" font="font31" id="p11_t119" reading_order_no="140" segment_no="1" tag_type="figure"><b>32639</b></text>
<text top="163" left="474" width="24" height="10" font="font31" id="p11_t120" reading_order_no="141" segment_no="1" tag_type="figure"><b>87.02%</b></text>
<text top="173" left="474" width="24" height="10" font="font31" id="p11_t121" reading_order_no="142" segment_no="1" tag_type="figure"><b>12.92%</b></text>
<text top="154" left="516" width="27" height="10" font="font31" id="p11_t122" reading_order_no="143" segment_no="1" tag_type="figure"><b>215040</b></text>
<text top="163" left="517" width="24" height="10" font="font31" id="p11_t123" reading_order_no="144" segment_no="1" tag_type="figure"><b>88.10%</b></text>
<text top="173" left="517" width="24" height="10" font="font31" id="p11_t124" reading_order_no="145" segment_no="1" tag_type="figure"><b>11.90%</b></text>
<text top="192" left="425" width="36" height="8" font="font32" id="p11_t125" reading_order_no="146" segment_no="1" tag_type="figure">background</text>
<text top="199" left="466" width="38" height="10" font="font33" id="p11_t126" reading_order_no="149" segment_no="1" tag_type="figure">True Label</text>
<text top="147" left="404" width="0" height="10" font="font33" id="p11_t127" reading_order_no="108" segment_no="1" tag_type="figure">Pr</text>
<text top="139" left="404" width="0" height="10" font="font33" id="p11_t128" reading_order_no="107" segment_no="1" tag_type="figure">ed</text>
<text top="130" left="404" width="0" height="10" font="font33" id="p11_t129" reading_order_no="106" segment_no="1" tag_type="figure">ic</text>
<text top="124" left="404" width="0" height="10" font="font33" id="p11_t130" reading_order_no="105" segment_no="1" tag_type="figure">te</text>
<text top="117" left="404" width="0" height="10" font="font33" id="p11_t131" reading_order_no="104" segment_no="1" tag_type="figure">d </text>
<text top="110" left="404" width="0" height="10" font="font33" id="p11_t132" reading_order_no="103" segment_no="1" tag_type="figure">La</text>
<text top="102" left="404" width="0" height="10" font="font33" id="p11_t133" reading_order_no="102" segment_no="1" tag_type="figure">be</text>
<text top="92" left="404" width="0" height="10" font="font33" id="p11_t134" reading_order_no="101" segment_no="1" tag_type="figure">l</text>
<text top="210" left="471" width="30" height="12" font="font34" id="p11_t135" reading_order_no="150" segment_no="1" tag_type="figure">VGG-16</text>
<text top="191" left="469" width="34" height="8" font="font32" id="p11_t136" reading_order_no="147" segment_no="1" tag_type="figure">foreground</text>
<text top="192" left="519" width="23" height="8" font="font32" id="p11_t137" reading_order_no="148" segment_no="1" tag_type="figure">sum-lin</text>
<text top="96" left="416" width="0" height="8" font="font32" id="p11_t138" reading_order_no="113" segment_no="1" tag_type="figure">ba</text>
<text top="88" left="416" width="0" height="8" font="font32" id="p11_t139" reading_order_no="112" segment_no="1" tag_type="figure">ck</text>
<text top="82" left="416" width="0" height="8" font="font32" id="p11_t140" reading_order_no="111" segment_no="1" tag_type="figure">gr</text>
<text top="76" left="416" width="0" height="8" font="font32" id="p11_t141" reading_order_no="110" segment_no="1" tag_type="figure">ou</text>
<text top="68" left="416" width="0" height="8" font="font32" id="p11_t142" reading_order_no="109" segment_no="1" tag_type="figure">nd</text>
<text top="137" left="416" width="0" height="8" font="font32" id="p11_t143" reading_order_no="118" segment_no="1" tag_type="figure">fo</text>
<text top="131" left="416" width="0" height="8" font="font32" id="p11_t144" reading_order_no="117" segment_no="1" tag_type="figure">re</text>
<text top="125" left="416" width="0" height="8" font="font32" id="p11_t145" reading_order_no="116" segment_no="1" tag_type="figure">gr</text>
<text top="119" left="416" width="0" height="8" font="font32" id="p11_t146" reading_order_no="115" segment_no="1" tag_type="figure">ou</text>
<text top="111" left="416" width="0" height="8" font="font32" id="p11_t147" reading_order_no="114" segment_no="1" tag_type="figure">nd</text>
<text top="175" left="416" width="0" height="8" font="font32" id="p11_t148" reading_order_no="122" segment_no="1" tag_type="figure">su</text>
<text top="169" left="416" width="0" height="8" font="font32" id="p11_t149" reading_order_no="121" segment_no="1" tag_type="figure">m</text>
<text top="163" left="416" width="0" height="8" font="font32" id="p11_t150" reading_order_no="120" segment_no="1" tag_type="figure">-c</text>
<text top="156" left="416" width="0" height="8" font="font32" id="p11_t151" reading_order_no="119" segment_no="1" tag_type="figure">ol</text>
<text top="236" left="182" width="25" height="10" font="font30" id="p11_t152" reading_order_no="173" segment_no="1" tag_type="figure">162915</text>
<text top="245" left="183" width="24" height="10" font="font31" id="p11_t153" reading_order_no="174" segment_no="1" tag_type="figure"><b>75.76%</b></text>
<text top="236" left="230" width="17" height="10" font="font30" id="p11_t154" reading_order_no="175" segment_no="1" tag_type="figure">3924</text>
<text top="245" left="229" width="19" height="10" font="font31" id="p11_t155" reading_order_no="176" segment_no="1" tag_type="figure"><b>1.82%</b></text>
<text top="231" left="269" width="27" height="10" font="font31" id="p11_t156" reading_order_no="177" segment_no="1" tag_type="figure"><b>166839</b></text>
<text top="241" left="268" width="28" height="10" font="font31" id="p11_t157" reading_order_no="178" segment_no="1" tag_type="figure"><b>97.655%</b></text>
<text top="250" left="273" width="19" height="10" font="font31" id="p11_t158" reading_order_no="179" segment_no="1" tag_type="figure"><b>2.35%</b></text>
<text top="279" left="184" width="21" height="10" font="font30" id="p11_t159" reading_order_no="180" segment_no="1" tag_type="figure">19486</text>
<text top="288" left="185" width="19" height="10" font="font31" id="p11_t160" reading_order_no="181" segment_no="1" tag_type="figure"><b>9.10%</b></text>
<text top="279" left="228" width="21" height="10" font="font30" id="p11_t161" reading_order_no="182" segment_no="1" tag_type="figure">28715</text>
<text top="288" left="227" width="24" height="10" font="font31" id="p11_t162" reading_order_no="183" segment_no="1" tag_type="figure"><b>13.32%</b></text>
<text top="274" left="271" width="22" height="10" font="font31" id="p11_t163" reading_order_no="184" segment_no="1" tag_type="figure"><b>48201</b></text>
<text top="284" left="270" width="24" height="10" font="font31" id="p11_t164" reading_order_no="185" segment_no="1" tag_type="figure"><b>59.57%</b></text>
<text top="293" left="270" width="24" height="10" font="font31" id="p11_t165" reading_order_no="186" segment_no="1" tag_type="figure"><b>40.43%</b></text>
<text top="317" left="182" width="27" height="10" font="font31" id="p11_t166" reading_order_no="187" segment_no="1" tag_type="figure"><b>182401</b></text>
<text top="327" left="183" width="24" height="10" font="font31" id="p11_t167" reading_order_no="188" segment_no="1" tag_type="figure"><b>89.32%</b></text>
<text top="336" left="183" width="24" height="10" font="font31" id="p11_t168" reading_order_no="189" segment_no="1" tag_type="figure"><b>10.68%</b></text>
<text top="317" left="228" width="22" height="10" font="font31" id="p11_t169" reading_order_no="190" segment_no="1" tag_type="figure"><b>32639</b></text>
<text top="327" left="227" width="24" height="10" font="font31" id="p11_t170" reading_order_no="191" segment_no="1" tag_type="figure"><b>87.98%</b></text>
<text top="336" left="227" width="24" height="10" font="font31" id="p11_t171" reading_order_no="192" segment_no="1" tag_type="figure"><b>12.02%</b></text>
<text top="317" left="269" width="27" height="10" font="font31" id="p11_t172" reading_order_no="193" segment_no="1" tag_type="figure"><b>215040</b></text>
<text top="327" left="270" width="24" height="10" font="font31" id="p11_t173" reading_order_no="194" segment_no="1" tag_type="figure"><b>89.08%</b></text>
<text top="336" left="270" width="24" height="10" font="font31" id="p11_t174" reading_order_no="195" segment_no="1" tag_type="figure"><b>10.92%</b></text>
<text top="355" left="178" width="36" height="8" font="font32" id="p11_t175" reading_order_no="196" segment_no="1" tag_type="figure">background</text>
<text top="367" left="220" width="38" height="10" font="font33" id="p11_t176" reading_order_no="199" segment_no="1" tag_type="figure">True Label</text>
<text top="311" left="157" width="0" height="10" font="font33" id="p11_t177" reading_order_no="158" segment_no="1" tag_type="figure">Pr</text>
<text top="303" left="157" width="0" height="10" font="font33" id="p11_t178" reading_order_no="157" segment_no="1" tag_type="figure">ed</text>
<text top="294" left="157" width="0" height="10" font="font33" id="p11_t179" reading_order_no="156" segment_no="1" tag_type="figure">ic</text>
<text top="288" left="157" width="0" height="10" font="font33" id="p11_t180" reading_order_no="155" segment_no="1" tag_type="figure">te</text>
<text top="281" left="157" width="0" height="10" font="font33" id="p11_t181" reading_order_no="154" segment_no="1" tag_type="figure">d </text>
<text top="274" left="157" width="0" height="10" font="font33" id="p11_t182" reading_order_no="153" segment_no="1" tag_type="figure">La</text>
<text top="265" left="157" width="0" height="10" font="font33" id="p11_t183" reading_order_no="152" segment_no="1" tag_type="figure">be</text>
<text top="256" left="157" width="0" height="10" font="font33" id="p11_t184" reading_order_no="151" segment_no="1" tag_type="figure">l</text>
<text top="381" left="218" width="41" height="12" font="font34" id="p11_t185" reading_order_no="200" segment_no="1" tag_type="figure">X-Inception</text>
<text top="355" left="222" width="34" height="8" font="font32" id="p11_t186" reading_order_no="197" segment_no="1" tag_type="figure">foreground</text>
<text top="355" left="272" width="23" height="8" font="font32" id="p11_t187" reading_order_no="198" segment_no="1" tag_type="figure">sum-lin</text>
<text top="260" left="169" width="0" height="8" font="font32" id="p11_t188" reading_order_no="163" segment_no="1" tag_type="figure">ba</text>
<text top="252" left="169" width="0" height="8" font="font32" id="p11_t189" reading_order_no="162" segment_no="1" tag_type="figure">ck</text>
<text top="246" left="169" width="0" height="8" font="font32" id="p11_t190" reading_order_no="161" segment_no="1" tag_type="figure">gr</text>
<text top="239" left="169" width="0" height="8" font="font32" id="p11_t191" reading_order_no="160" segment_no="1" tag_type="figure">ou</text>
<text top="232" left="169" width="0" height="8" font="font32" id="p11_t192" reading_order_no="159" segment_no="1" tag_type="figure">nd</text>
<text top="301" left="169" width="0" height="8" font="font32" id="p11_t193" reading_order_no="168" segment_no="1" tag_type="figure">fo</text>
<text top="295" left="169" width="0" height="8" font="font32" id="p11_t194" reading_order_no="167" segment_no="1" tag_type="figure">re</text>
<text top="289" left="169" width="0" height="8" font="font32" id="p11_t195" reading_order_no="166" segment_no="1" tag_type="figure">gr</text>
<text top="283" left="169" width="0" height="8" font="font32" id="p11_t196" reading_order_no="165" segment_no="1" tag_type="figure">ou</text>
<text top="275" left="169" width="0" height="8" font="font32" id="p11_t197" reading_order_no="164" segment_no="1" tag_type="figure">nd</text>
<text top="339" left="169" width="0" height="8" font="font32" id="p11_t198" reading_order_no="172" segment_no="1" tag_type="figure">su</text>
<text top="333" left="169" width="0" height="8" font="font32" id="p11_t199" reading_order_no="171" segment_no="1" tag_type="figure">m</text>
<text top="327" left="169" width="0" height="8" font="font32" id="p11_t200" reading_order_no="170" segment_no="1" tag_type="figure">-c</text>
<text top="320" left="169" width="0" height="8" font="font32" id="p11_t201" reading_order_no="169" segment_no="1" tag_type="figure">ol</text>
<text top="237" left="357" width="25" height="10" font="font30" id="p11_t202" reading_order_no="223" segment_no="1" tag_type="figure">165288</text>
<text top="246" left="358" width="24" height="10" font="font31" id="p11_t203" reading_order_no="224" segment_no="1" tag_type="figure"><b>76.86%</b></text>
<text top="237" left="405" width="17" height="10" font="font30" id="p11_t204" reading_order_no="225" segment_no="1" tag_type="figure">6354</text>
<text top="246" left="404" width="19" height="10" font="font31" id="p11_t205" reading_order_no="226" segment_no="1" tag_type="figure"><b>2.95%</b></text>
<text top="232" left="444" width="27" height="10" font="font31" id="p11_t206" reading_order_no="227" segment_no="1" tag_type="figure"><b>171642</b></text>
<text top="242" left="445" width="24" height="10" font="font31" id="p11_t207" reading_order_no="228" segment_no="1" tag_type="figure"><b>96.30%</b></text>
<text top="251" left="447" width="19" height="10" font="font31" id="p11_t208" reading_order_no="229" segment_no="1" tag_type="figure"><b>3.70%</b></text>
<text top="280" left="359" width="21" height="10" font="font30" id="p11_t209" reading_order_no="230" segment_no="1" tag_type="figure">17112</text>
<text top="289" left="360" width="19" height="10" font="font31" id="p11_t210" reading_order_no="231" segment_no="1" tag_type="figure"><b>7.96%</b></text>
<text top="280" left="403" width="21" height="10" font="font30" id="p11_t211" reading_order_no="232" segment_no="1" tag_type="figure">26285</text>
<text top="289" left="401" width="24" height="10" font="font31" id="p11_t212" reading_order_no="233" segment_no="1" tag_type="figure"><b>12.23%</b></text>
<text top="275" left="446" width="22" height="10" font="font31" id="p11_t213" reading_order_no="234" segment_no="1" tag_type="figure"><b>43397</b></text>
<text top="285" left="445" width="24" height="10" font="font31" id="p11_t214" reading_order_no="235" segment_no="1" tag_type="figure"><b>60.57%</b></text>
<text top="294" left="445" width="24" height="10" font="font31" id="p11_t215" reading_order_no="236" segment_no="1" tag_type="figure"><b>39.43%</b></text>
<text top="318" left="356" width="27" height="10" font="font31" id="p11_t216" reading_order_no="237" segment_no="1" tag_type="figure"><b>182401</b></text>
<text top="327" left="358" width="24" height="10" font="font31" id="p11_t217" reading_order_no="238" segment_no="1" tag_type="figure"><b>90.52%</b></text>
<text top="337" left="360" width="19" height="10" font="font31" id="p11_t218" reading_order_no="239" segment_no="1" tag_type="figure"><b>9.47%</b></text>
<text top="318" left="402" width="22" height="10" font="font31" id="p11_t219" reading_order_no="240" segment_no="1" tag_type="figure"><b>32639</b></text>
<text top="327" left="401" width="24" height="10" font="font31" id="p11_t220" reading_order_no="241" segment_no="1" tag_type="figure"><b>80.53%</b></text>
<text top="337" left="401" width="24" height="10" font="font31" id="p11_t221" reading_order_no="242" segment_no="1" tag_type="figure"><b>19.47%</b></text>
<text top="318" left="444" width="27" height="10" font="font31" id="p11_t222" reading_order_no="243" segment_no="1" tag_type="figure"><b>215040</b></text>
<text top="327" left="445" width="24" height="10" font="font31" id="p11_t223" reading_order_no="244" segment_no="1" tag_type="figure"><b>89.09%</b></text>
<text top="337" left="445" width="24" height="10" font="font31" id="p11_t224" reading_order_no="245" segment_no="1" tag_type="figure"><b>10.91%</b></text>
<text top="356" left="353" width="36" height="8" font="font32" id="p11_t225" reading_order_no="246" segment_no="1" tag_type="figure">background</text>
<text top="367" left="395" width="38" height="10" font="font33" id="p11_t226" reading_order_no="249" segment_no="1" tag_type="figure">True Label</text>
<text top="311" left="332" width="0" height="10" font="font33" id="p11_t227" reading_order_no="208" segment_no="1" tag_type="figure">Pr</text>
<text top="304" left="332" width="0" height="10" font="font33" id="p11_t228" reading_order_no="207" segment_no="1" tag_type="figure">ed</text>
<text top="294" left="332" width="0" height="10" font="font33" id="p11_t229" reading_order_no="206" segment_no="1" tag_type="figure">ic</text>
<text top="289" left="332" width="0" height="10" font="font33" id="p11_t230" reading_order_no="205" segment_no="1" tag_type="figure">te</text>
<text top="281" left="332" width="0" height="10" font="font33" id="p11_t231" reading_order_no="204" segment_no="1" tag_type="figure">d </text>
<text top="274" left="332" width="0" height="10" font="font33" id="p11_t232" reading_order_no="203" segment_no="1" tag_type="figure">La</text>
<text top="266" left="332" width="0" height="10" font="font33" id="p11_t233" reading_order_no="202" segment_no="1" tag_type="figure">be</text>
<text top="257" left="332" width="0" height="10" font="font33" id="p11_t234" reading_order_no="201" segment_no="1" tag_type="figure">l</text>
<text top="381" left="407" width="13" height="12" font="font34" id="p11_t235" reading_order_no="250" segment_no="1" tag_type="figure">ViT</text>
<text top="356" left="397" width="34" height="8" font="font32" id="p11_t236" reading_order_no="247" segment_no="1" tag_type="figure">foreground</text>
<text top="356" left="447" width="23" height="8" font="font32" id="p11_t237" reading_order_no="248" segment_no="1" tag_type="figure">sum-lin</text>
<text top="260" left="344" width="0" height="8" font="font32" id="p11_t238" reading_order_no="213" segment_no="1" tag_type="figure">ba</text>
<text top="253" left="344" width="0" height="8" font="font32" id="p11_t239" reading_order_no="212" segment_no="1" tag_type="figure">ck</text>
<text top="246" left="344" width="0" height="8" font="font32" id="p11_t240" reading_order_no="211" segment_no="1" tag_type="figure">gr</text>
<text top="240" left="344" width="0" height="8" font="font32" id="p11_t241" reading_order_no="210" segment_no="1" tag_type="figure">ou</text>
<text top="232" left="344" width="0" height="8" font="font32" id="p11_t242" reading_order_no="209" segment_no="1" tag_type="figure">nd</text>
<text top="301" left="344" width="0" height="8" font="font32" id="p11_t243" reading_order_no="218" segment_no="1" tag_type="figure">fo</text>
<text top="295" left="344" width="0" height="8" font="font32" id="p11_t244" reading_order_no="217" segment_no="1" tag_type="figure">re</text>
<text top="289" left="344" width="0" height="8" font="font32" id="p11_t245" reading_order_no="216" segment_no="1" tag_type="figure">gr</text>
<text top="283" left="344" width="0" height="8" font="font32" id="p11_t246" reading_order_no="215" segment_no="1" tag_type="figure">ou</text>
<text top="275" left="344" width="0" height="8" font="font32" id="p11_t247" reading_order_no="214" segment_no="1" tag_type="figure">nd</text>
<text top="340" left="344" width="0" height="8" font="font32" id="p11_t248" reading_order_no="222" segment_no="1" tag_type="figure">su</text>
<text top="333" left="344" width="0" height="8" font="font32" id="p11_t249" reading_order_no="221" segment_no="1" tag_type="figure">m</text>
<text top="327" left="344" width="0" height="8" font="font32" id="p11_t250" reading_order_no="220" segment_no="1" tag_type="figure">-c</text>
<text top="320" left="344" width="0" height="8" font="font32" id="p11_t251" reading_order_no="219" segment_no="1" tag_type="figure">ol</text>
<text top="418" left="148" width="35" height="8" font="font20" id="p11_t252" reading_order_no="251" segment_no="7" tag_type="text">Figure 9:</text>
<text top="418" left="187" width="164" height="8" font="font13" id="p11_t253" reading_order_no="252" segment_no="7" tag_type="text">Predict the confusion matrix on test set of</text>
<text top="418" left="354" width="37" height="8" font="font24" id="p11_t254" reading_order_no="253" segment_no="7" tag_type="text">224 × 224</text>
<text top="418" left="394" width="53" height="8" font="font13" id="p11_t255" reading_order_no="254" segment_no="7" tag_type="text">pixels patches</text>
<text top="456" left="70" width="93" height="7" font="font3" id="p11_t256" reading_order_no="255" segment_no="8" tag_type="text"><i>British journal of psychology</i></text>
<text top="454" left="163" width="73" height="10" font="font4" id="p11_t257" reading_order_no="256" segment_no="8" tag_type="text">, 77(3):305–327, 1986.</text>
<text top="464" left="55" width="233" height="10" font="font4" id="p11_t258" reading_order_no="257" segment_no="9" tag_type="text">[8] Pierre Baldi and Yves Chauvin. Neural networks for fingerprint recog-</text>
<text top="474" left="70" width="21" height="10" font="font4" id="p11_t259" reading_order_no="258" segment_no="9" tag_type="text">nition.</text>
<text top="476" left="93" width="62" height="7" font="font3" id="p11_t260" reading_order_no="259" segment_no="9" tag_type="text"><i>neural computation</i></text>
<text top="474" left="156" width="69" height="10" font="font4" id="p11_t261" reading_order_no="260" segment_no="9" tag_type="text">, 5(3):402–418, 1993.</text>
<text top="484" left="55" width="233" height="10" font="font4" id="p11_t262" reading_order_no="261" segment_no="11" tag_type="text">[9] Sorin Grigorescu, Bogdan Trasnea, Tiberiu Cocias, and Gigel Mace-</text>
<text top="494" left="70" width="219" height="10" font="font4" id="p11_t263" reading_order_no="262" segment_no="11" tag_type="text">sanu. A survey of deep learning techniques for autonomous driving.</text>
<text top="506" left="70" width="81" height="7" font="font3" id="p11_t264" reading_order_no="263" segment_no="11" tag_type="text"><i>Journal of Field Robotics</i></text>
<text top="504" left="151" width="73" height="10" font="font4" id="p11_t265" reading_order_no="264" segment_no="11" tag_type="text">, 37(3):362–386, 2020.</text>
<text top="514" left="51" width="237" height="10" font="font4" id="p11_t266" reading_order_no="265" segment_no="13" tag_type="text">[10] Dinggang Shen, Guorong Wu, and Heung-Il Suk. Deep learning in</text>
<text top="524" left="70" width="77" height="10" font="font4" id="p11_t267" reading_order_no="266" segment_no="13" tag_type="text">medical image analysis.</text>
<text top="526" left="152" width="134" height="7" font="font3" id="p11_t268" reading_order_no="267" segment_no="13" tag_type="text"><i>Annual review of biomedical engineering</i></text>
<text top="524" left="287" width="2" height="10" font="font4" id="p11_t269" reading_order_no="268" segment_no="13" tag_type="text">,</text>
<text top="534" left="70" width="60" height="10" font="font4" id="p11_t270" reading_order_no="269" segment_no="13" tag_type="text">19:221–248, 2017.</text>
<text top="544" left="51" width="237" height="10" font="font4" id="p11_t271" reading_order_no="270" segment_no="4" tag_type="text">[11] Bernd Jähne and Horst Haußecker. Computer vision and applications.</text>
<text top="554" left="70" width="18" height="10" font="font4" id="p11_t272" reading_order_no="271" segment_no="4" tag_type="text">2000.</text>
<text top="564" left="51" width="237" height="10" font="font4" id="p11_t273" reading_order_no="272" segment_no="15" tag_type="text">[12] Joao Carreira, Henrique Madeira, and Joao Gabriel Silva. Xcep-</text>
<text top="574" left="70" width="219" height="10" font="font4" id="p11_t274" reading_order_no="273" segment_no="15" tag_type="text">tion: A technique for the experimental evaluation of dependability</text>
<text top="584" left="70" width="70" height="10" font="font4" id="p11_t275" reading_order_no="274" segment_no="15" tag_type="text">in modern computers.</text>
<text top="586" left="144" width="143" height="7" font="font3" id="p11_t276" reading_order_no="275" segment_no="15" tag_type="text"><i>IEEE Transactions on Software Engineering</i></text>
<text top="584" left="287" width="2" height="10" font="font4" id="p11_t277" reading_order_no="276" segment_no="15" tag_type="text">,</text>
<text top="594" left="70" width="69" height="10" font="font4" id="p11_t278" reading_order_no="277" segment_no="15" tag_type="text">24(2):125–136, 1998.</text>
<text top="604" left="51" width="237" height="10" font="font4" id="p11_t279" reading_order_no="278" segment_no="17" tag_type="text">[13] Qing Guan, Yunjun Wang, Bo Ping, Duanshu Li, Jiajun Du, Yu Qin,</text>
<text top="614" left="70" width="219" height="10" font="font4" id="p11_t280" reading_order_no="279" segment_no="17" tag_type="text">Hongtao Lu, Xiaochun Wan, and Jun Xiang. Deep convolutional neu-</text>
<text top="624" left="70" width="219" height="10" font="font4" id="p11_t281" reading_order_no="280" segment_no="17" tag_type="text">ral network vgg-16 model for differential diagnosing of papillary thy-</text>
<text top="634" left="70" width="166" height="10" font="font4" id="p11_t282" reading_order_no="281" segment_no="17" tag_type="text">roid carcinomas in cytological images: a pilot study.</text>
<text top="636" left="238" width="51" height="7" font="font3" id="p11_t283" reading_order_no="282" segment_no="17" tag_type="text"><i>Journal of Can-</i></text>
<text top="646" left="70" width="10" height="7" font="font3" id="p11_t284" reading_order_no="283" segment_no="17" tag_type="text"><i>cer</i></text>
<text top="644" left="80" width="65" height="10" font="font4" id="p11_t285" reading_order_no="284" segment_no="17" tag_type="text">, 10(20):4876, 2019.</text>
<text top="653" left="51" width="237" height="10" font="font4" id="p11_t286" reading_order_no="285" segment_no="5" tag_type="text">[14] A Sai Bharadwaj Reddy and D Sujitha Juliet. Transfer learning</text>
<text top="663" left="70" width="187" height="10" font="font4" id="p11_t287" reading_order_no="286" segment_no="5" tag_type="text">with resnet-50 for malaria cell-image classification. In</text>
<text top="666" left="260" width="29" height="7" font="font3" id="p11_t288" reading_order_no="287" segment_no="5" tag_type="text"><i>2019 In-</i></text>
<text top="676" left="70" width="219" height="7" font="font3" id="p11_t289" reading_order_no="288" segment_no="5" tag_type="text"><i>ternational Conference on Communication and Signal Processing</i></text>
<text top="686" left="70" width="27" height="7" font="font3" id="p11_t290" reading_order_no="289" segment_no="5" tag_type="text"><i>(ICCSP)</i></text>
<text top="683" left="97" width="103" height="10" font="font4" id="p11_t291" reading_order_no="290" segment_no="5" tag_type="text">, pages 0945–0949. IEEE, 2019.</text>
<text top="693" left="51" width="237" height="10" font="font4" id="p11_t292" reading_order_no="291" segment_no="20" tag_type="text">[15] Xiaoling Xia, Cui Xu, and Bing Nan. Inception-v3 for flower classi-</text>
<text top="703" left="70" width="35" height="10" font="font4" id="p11_t293" reading_order_no="292" segment_no="20" tag_type="text">fication. In</text>
<text top="706" left="107" width="182" height="7" font="font3" id="p11_t294" reading_order_no="293" segment_no="20" tag_type="text"><i>2017 2nd International Conference on Image, Vision and</i></text>
<text top="716" left="70" width="63" height="7" font="font3" id="p11_t295" reading_order_no="294" segment_no="20" tag_type="text"><i>Computing (ICIVC)</i></text>
<text top="713" left="133" width="95" height="10" font="font4" id="p11_t296" reading_order_no="295" segment_no="20" tag_type="text">, pages 783–787. IEEE, 2017.</text>
<text top="723" left="51" width="237" height="10" font="font4" id="p11_t297" reading_order_no="296" segment_no="21" tag_type="text">[16] Hong-Yen Chen and Chung-Yen Su. An enhanced hybrid mobilenet.</text>
<text top="733" left="70" width="7" height="10" font="font4" id="p11_t298" reading_order_no="297" segment_no="21" tag_type="text">In</text>
<text top="735" left="78" width="211" height="7" font="font3" id="p11_t299" reading_order_no="298" segment_no="21" tag_type="text"><i>2018 9th International Conference on Awareness Science and Tech-</i></text>
<text top="456" left="325" width="50" height="7" font="font3" id="p11_t300" reading_order_no="299" segment_no="3" tag_type="text"><i>nology (iCAST)</i></text>
<text top="454" left="375" width="95" height="10" font="font4" id="p11_t301" reading_order_no="300" segment_no="3" tag_type="text">, pages 308–312. IEEE, 2018.</text>
<text top="464" left="307" width="237" height="10" font="font4" id="p11_t302" reading_order_no="301" segment_no="10" tag_type="text">[17] Fredy Martínez, Fernando Martínez, and Edwar Jacinto. Performance</text>
<text top="474" left="325" width="219" height="10" font="font4" id="p11_t303" reading_order_no="302" segment_no="10" tag_type="text">evaluation of the nasnet convolutional network in the automatic iden-</text>
<text top="484" left="325" width="70" height="10" font="font4" id="p11_t304" reading_order_no="303" segment_no="10" tag_type="text">tification of covid-19.</text>
<text top="486" left="399" width="108" height="7" font="font3" id="p11_t305" reading_order_no="304" segment_no="10" tag_type="text"><i>Int J Adv Sci Eng Inform Technol</i></text>
<text top="484" left="506" width="38" height="10" font="font4" id="p11_t306" reading_order_no="305" segment_no="10" tag_type="text">, 10(2):662,</text>
<text top="494" left="325" width="18" height="10" font="font4" id="p11_t307" reading_order_no="306" segment_no="10" tag_type="text">2020.</text>
<text top="504" left="307" width="237" height="10" font="font4" id="p11_t308" reading_order_no="307" segment_no="12" tag_type="text">[18] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion</text>
<text top="514" left="325" width="219" height="10" font="font4" id="p11_t309" reading_order_no="308" segment_no="12" tag_type="text">Jones, Aidan N Gomez, Lukasz Kaiser, and Illia Polosukhin. Atten-</text>
<text top="524" left="325" width="63" height="10" font="font4" id="p11_t310" reading_order_no="309" segment_no="12" tag_type="text">tion is all you need.</text>
<text top="526" left="390" width="106" height="7" font="font3" id="p11_t311" reading_order_no="310" segment_no="12" tag_type="text"><i>arXiv preprint arXiv:1706.03762</i></text>
<text top="524" left="496" width="22" height="10" font="font4" id="p11_t312" reading_order_no="311" segment_no="12" tag_type="text">, 2017.</text>
<text top="534" left="307" width="237" height="10" font="font4" id="p11_t313" reading_order_no="312" segment_no="14" tag_type="text">[19] Andy Zeng, Kuan-Ting Yu, Shuran Song, Daniel Suo, Ed Walker,</text>
<text top="544" left="325" width="219" height="10" font="font4" id="p11_t314" reading_order_no="313" segment_no="14" tag_type="text">Alberto Rodriguez, and Jianxiong Xiao. Multi-view self-supervised</text>
<text top="554" left="325" width="219" height="10" font="font4" id="p11_t315" reading_order_no="314" segment_no="14" tag_type="text">deep learning for 6d pose estimation in the amazon picking challenge.</text>
<text top="564" left="325" width="7" height="10" font="font4" id="p11_t316" reading_order_no="315" segment_no="14" tag_type="text">In</text>
<text top="566" left="334" width="210" height="7" font="font3" id="p11_t317" reading_order_no="316" segment_no="14" tag_type="text"><i>2017 IEEE international conference on robotics and automation</i></text>
<text top="576" left="325" width="23" height="7" font="font3" id="p11_t318" reading_order_no="317" segment_no="14" tag_type="text"><i>(ICRA)</i></text>
<text top="574" left="348" width="103" height="10" font="font4" id="p11_t319" reading_order_no="318" segment_no="14" tag_type="text">, pages 1386–1383. IEEE, 2017.</text>
<text top="584" left="307" width="237" height="10" font="font4" id="p11_t320" reading_order_no="319" segment_no="16" tag_type="text">[20] Shreeyak Sajjan, Matthew Moore, Mike Pan, Ganesh Nagaraja,</text>
<text top="594" left="325" width="219" height="10" font="font4" id="p11_t321" reading_order_no="320" segment_no="16" tag_type="text">Johnny Lee, Andy Zeng, and Shuran Song. Clear grasp: 3d shape</text>
<text top="604" left="325" width="171" height="10" font="font4" id="p11_t322" reading_order_no="321" segment_no="16" tag_type="text">estimation of transparent objects for manipulation. In</text>
<text top="606" left="497" width="47" height="7" font="font3" id="p11_t323" reading_order_no="322" segment_no="16" tag_type="text"><i>2020 IEEE In-</i></text>
<text top="616" left="325" width="196" height="7" font="font3" id="p11_t324" reading_order_no="323" segment_no="16" tag_type="text"><i>ternational Conference on Robotics and Automation (ICRA)</i></text>
<text top="614" left="521" width="23" height="10" font="font4" id="p11_t325" reading_order_no="324" segment_no="16" tag_type="text">, pages</text>
<text top="624" left="325" width="79" height="10" font="font4" id="p11_t326" reading_order_no="325" segment_no="16" tag_type="text">3634–3642. IEEE, 2020.</text>
<text top="634" left="307" width="237" height="10" font="font4" id="p11_t327" reading_order_no="326" segment_no="18" tag_type="text">[21] Zheng Chunjiao. The application and development of photoelectric</text>
<text top="644" left="325" width="32" height="10" font="font4" id="p11_t328" reading_order_no="327" segment_no="18" tag_type="text">sensor. In</text>
<text top="646" left="359" width="183" height="7" font="font3" id="p11_t329" reading_order_no="328" segment_no="18" tag_type="text"><i>Intelligence Computation and Evolutionary Computation</i></text>
<text top="644" left="542" width="2" height="10" font="font4" id="p11_t330" reading_order_no="329" segment_no="18" tag_type="text">,</text>
<text top="653" left="325" width="101" height="10" font="font4" id="p11_t331" reading_order_no="330" segment_no="18" tag_type="text">pages 671–677. Springer, 2013.</text>
<text top="663" left="307" width="237" height="10" font="font4" id="p11_t332" reading_order_no="331" segment_no="19" tag_type="text">[22] Seiji Hata, Yoko Saitoh, Syoji Kumamura, and Ken’ichi Kaida. Shape</text>
<text top="673" left="325" width="188" height="10" font="font4" id="p11_t333" reading_order_no="332" segment_no="19" tag_type="text">extraction of transparent object using genetic algorithm. In</text>
<text top="676" left="515" width="29" height="7" font="font3" id="p11_t334" reading_order_no="333" segment_no="19" tag_type="text"><i>Proceed-</i></text>
<text top="686" left="325" width="202" height="7" font="font3" id="p11_t335" reading_order_no="334" segment_no="19" tag_type="text"><i>ings of 13th International Conference on Pattern Recognition</i></text>
<text top="683" left="526" width="18" height="10" font="font4" id="p11_t336" reading_order_no="335" segment_no="19" tag_type="text">, vol-</text>
<text top="693" left="325" width="115" height="10" font="font4" id="p11_t337" reading_order_no="336" segment_no="19" tag_type="text">ume 4, pages 684–688. IEEE, 1996.</text>
<text top="703" left="307" width="237" height="10" font="font4" id="p11_t338" reading_order_no="337" segment_no="6" tag_type="text">[23] Yichao Xu, Hajime Nagahara, Atsushi Shimada, and Rin-ichiro</text>
<text top="713" left="325" width="219" height="10" font="font4" id="p11_t339" reading_order_no="338" segment_no="6" tag_type="text">Taniguchi. Transcut: Transparent object segmentation from a light-</text>
<text top="723" left="325" width="47" height="10" font="font4" id="p11_t340" reading_order_no="339" segment_no="6" tag_type="text">field image. In</text>
<text top="725" left="373" width="171" height="7" font="font3" id="p11_t341" reading_order_no="340" segment_no="6" tag_type="text"><i>Proceedings of the IEEE International Conference on</i></text>
<text top="735" left="325" width="54" height="7" font="font3" id="p11_t342" reading_order_no="341" segment_no="6" tag_type="text"><i>Computer Vision</i></text>
<text top="733" left="379" width="82" height="10" font="font4" id="p11_t343" reading_order_no="342" segment_no="6" tag_type="text">, pages 3442–3450, 2015.</text>
<text top="759" left="51" width="78" height="8" font="font13" id="p11_t344" reading_order_no="343" segment_no="22" tag_type="footnote">HeChen Yang et al.:</text>
<text top="759" left="133" width="108" height="8" font="font14" id="p11_t345" reading_order_no="344" segment_no="22" tag_type="footnote"><i>Preprint submitted to Elsevier</i></text>
<text top="759" left="490" width="54" height="8" font="font13" id="p11_t346" reading_order_no="345" segment_no="2" tag_type="text">Page 11 of 12</text>
</page>
<page number="12" position="absolute" top="0" left="0" height="793" width="595">
<text top="37" left="241" width="113" height="8" font="font13" id="p12_t1" reading_order_no="0" segment_no="0" tag_type="text">Leveraging social media news</text>
<text top="58" left="51" width="237" height="10" font="font4" id="p12_t2" reading_order_no="1" segment_no="1" tag_type="text">[24] Yuanhao Guo, Zhan Xiong, and Fons J Verbeek. An efficient and</text>
<text top="68" left="70" width="219" height="10" font="font4" id="p12_t3" reading_order_no="2" segment_no="1" tag_type="text">robust hybrid method for segmentation of zebrafish objects from</text>
<text top="78" left="70" width="103" height="10" font="font4" id="p12_t4" reading_order_no="3" segment_no="1" tag_type="text">bright-field microscope images.</text>
<text top="80" left="179" width="107" height="7" font="font3" id="p12_t5" reading_order_no="4" segment_no="1" tag_type="text"><i>Machine vision and applications</i></text>
<text top="78" left="287" width="2" height="10" font="font4" id="p12_t6" reading_order_no="5" segment_no="1" tag_type="text">,</text>
<text top="88" left="70" width="77" height="10" font="font4" id="p12_t7" reading_order_no="6" segment_no="1" tag_type="text">29(8):1211–1225, 2018.</text>
<text top="98" left="51" width="237" height="10" font="font4" id="p12_t8" reading_order_no="7" segment_no="2" tag_type="text">[25] Abozar Nasirahmadi and Seyed-Hassan Miraei Ashtiani. Bag-of-</text>
<text top="107" left="70" width="180" height="10" font="font4" id="p12_t9" reading_order_no="8" segment_no="2" tag_type="text">feature model for sweet and bitter almond classification.</text>
<text top="110" left="253" width="35" height="7" font="font3" id="p12_t10" reading_order_no="9" segment_no="2" tag_type="text"><i>Biosystems</i></text>
<text top="120" left="70" width="38" height="7" font="font3" id="p12_t11" reading_order_no="10" segment_no="2" tag_type="text"><i>engineering</i></text>
<text top="117" left="108" width="60" height="10" font="font4" id="p12_t12" reading_order_no="11" segment_no="2" tag_type="text">, 156:51–60, 2017.</text>
<text top="127" left="51" width="237" height="10" font="font4" id="p12_t13" reading_order_no="12" segment_no="3" tag_type="text">[26] Yichao Xu, Kazuki Maeno, Hajime Nagahara, Atsushi Shimada, and</text>
<text top="137" left="70" width="219" height="10" font="font4" id="p12_t14" reading_order_no="13" segment_no="3" tag_type="text">Rin-ichiro Taniguchi. Light field distortion feature for transparent</text>
<text top="147" left="70" width="66" height="10" font="font4" id="p12_t15" reading_order_no="14" segment_no="3" tag_type="text">object classification.</text>
<text top="150" left="143" width="144" height="7" font="font3" id="p12_t16" reading_order_no="15" segment_no="3" tag_type="text"><i>Computer Vision and Image Understanding</i></text>
<text top="147" left="287" width="2" height="10" font="font4" id="p12_t17" reading_order_no="16" segment_no="3" tag_type="text">,</text>
<text top="157" left="70" width="64" height="10" font="font4" id="p12_t18" reading_order_no="17" segment_no="3" tag_type="text">139:122–135, 2015.</text>
<text top="167" left="51" width="159" height="10" font="font4" id="p12_t19" reading_order_no="18" segment_no="4" tag_type="text">[27] Karen Simonyan and Andrew Zisserman.</text>
<text top="167" left="222" width="67" height="10" font="font4" id="p12_t20" reading_order_no="19" segment_no="4" tag_type="text">Very deep convolu-</text>
<text top="177" left="70" width="164" height="10" font="font4" id="p12_t21" reading_order_no="20" segment_no="4" tag_type="text">tional networks for large-scale image recognition.</text>
<text top="179" left="242" width="47" height="7" font="font3" id="p12_t22" reading_order_no="21" segment_no="4" tag_type="text"><i>arXiv preprint</i></text>
<text top="189" left="70" width="54" height="7" font="font3" id="p12_t23" reading_order_no="22" segment_no="4" tag_type="text"><i>arXiv:1409.1556</i></text>
<text top="187" left="124" width="22" height="10" font="font4" id="p12_t24" reading_order_no="23" segment_no="4" tag_type="text">, 2014.</text>
<text top="197" left="51" width="237" height="10" font="font4" id="p12_t25" reading_order_no="24" segment_no="5" tag_type="text">[28] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep</text>
<text top="207" left="70" width="137" height="10" font="font4" id="p12_t26" reading_order_no="25" segment_no="5" tag_type="text">residual learning for image recognition. In</text>
<text top="209" left="209" width="79" height="7" font="font3" id="p12_t27" reading_order_no="26" segment_no="5" tag_type="text"><i>Proceedings of the IEEE</i></text>
<text top="219" left="70" width="178" height="7" font="font3" id="p12_t28" reading_order_no="27" segment_no="5" tag_type="text"><i>conference on computer vision and pattern recognition</i></text>
<text top="217" left="248" width="41" height="10" font="font4" id="p12_t29" reading_order_no="28" segment_no="5" tag_type="text">, pages 770–</text>
<text top="227" left="70" width="34" height="10" font="font4" id="p12_t30" reading_order_no="29" segment_no="5" tag_type="text">778, 2016.</text>
<text top="237" left="51" width="237" height="10" font="font4" id="p12_t31" reading_order_no="30" segment_no="6" tag_type="text">[29] Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott</text>
<text top="247" left="70" width="219" height="10" font="font4" id="p12_t32" reading_order_no="31" segment_no="6" tag_type="text">Reed, Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, and</text>
<text top="257" left="70" width="178" height="10" font="font4" id="p12_t33" reading_order_no="32" segment_no="6" tag_type="text">Andrew Rabinovich. Going deeper with convolutions. In</text>
<text top="259" left="249" width="40" height="7" font="font3" id="p12_t34" reading_order_no="33" segment_no="6" tag_type="text"><i>Proceedings</i></text>
<text top="269" left="70" width="217" height="7" font="font3" id="p12_t35" reading_order_no="34" segment_no="6" tag_type="text"><i>of the IEEE conference on computer vision and pattern recognition</i></text>
<text top="267" left="287" width="2" height="10" font="font4" id="p12_t36" reading_order_no="35" segment_no="6" tag_type="text">,</text>
<text top="277" left="70" width="54" height="10" font="font4" id="p12_t37" reading_order_no="36" segment_no="6" tag_type="text">pages 1–9, 2015.</text>
<text top="287" left="51" width="237" height="10" font="font4" id="p12_t38" reading_order_no="37" segment_no="7" tag_type="text">[30] Sergey Ioffe and Christian Szegedy. Batch normalization: Accelerat-</text>
<text top="297" left="70" width="208" height="10" font="font4" id="p12_t39" reading_order_no="38" segment_no="7" tag_type="text">ing deep network training by reducing internal covariate shift. In</text>
<text top="299" left="279" width="9" height="7" font="font3" id="p12_t40" reading_order_no="39" segment_no="7" tag_type="text"><i>In-</i></text>
<text top="309" left="70" width="140" height="7" font="font3" id="p12_t41" reading_order_no="40" segment_no="7" tag_type="text"><i>ternational conference on machine learning</i></text>
<text top="307" left="209" width="79" height="10" font="font4" id="p12_t42" reading_order_no="41" segment_no="7" tag_type="text">, pages 448–456. PMLR,</text>
<text top="317" left="70" width="18" height="10" font="font4" id="p12_t43" reading_order_no="42" segment_no="7" tag_type="text">2015.</text>
<text top="327" left="51" width="237" height="10" font="font4" id="p12_t44" reading_order_no="43" segment_no="8" tag_type="text">[31] Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jon Shlens, and</text>
<text top="337" left="70" width="219" height="10" font="font4" id="p12_t45" reading_order_no="44" segment_no="8" tag_type="text">Zbigniew Wojna. Rethinking the inception architecture for computer</text>
<text top="347" left="70" width="33" height="10" font="font4" id="p12_t46" reading_order_no="45" segment_no="8" tag_type="text">vision. In</text>
<text top="349" left="106" width="183" height="7" font="font3" id="p12_t47" reading_order_no="46" segment_no="8" tag_type="text"><i>Proceedings of the IEEE conference on computer vision</i></text>
<text top="359" left="70" width="76" height="7" font="font3" id="p12_t48" reading_order_no="47" segment_no="8" tag_type="text"><i>and pattern recognition</i></text>
<text top="357" left="145" width="82" height="10" font="font4" id="p12_t49" reading_order_no="48" segment_no="8" tag_type="text">, pages 2818–2826, 2016.</text>
<text top="367" left="51" width="237" height="10" font="font4" id="p12_t50" reading_order_no="49" segment_no="9" tag_type="text">[32] François Chollet. Xception: Deep learning with depthwise separable</text>
<text top="376" left="70" width="55" height="10" font="font4" id="p12_t51" reading_order_no="50" segment_no="9" tag_type="text">convolutions. In</text>
<text top="379" left="127" width="162" height="7" font="font3" id="p12_t52" reading_order_no="51" segment_no="9" tag_type="text"><i>Proceedings of the IEEE conference on computer</i></text>
<text top="389" left="70" width="97" height="7" font="font3" id="p12_t53" reading_order_no="52" segment_no="9" tag_type="text"><i>vision and pattern recognition</i></text>
<text top="386" left="166" width="82" height="10" font="font4" id="p12_t54" reading_order_no="53" segment_no="9" tag_type="text">, pages 1251–1258, 2017.</text>
<text top="396" left="51" width="237" height="10" font="font4" id="p12_t55" reading_order_no="54" segment_no="10" tag_type="text">[33] Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weis-</text>
<text top="406" left="70" width="219" height="10" font="font4" id="p12_t56" reading_order_no="55" segment_no="10" tag_type="text">senborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani,</text>
<text top="416" left="70" width="219" height="10" font="font4" id="p12_t57" reading_order_no="56" segment_no="10" tag_type="text">Matthias Minderer, Georg Heigold, Sylvain Gelly, et al. An image</text>
<text top="426" left="70" width="219" height="10" font="font4" id="p12_t58" reading_order_no="57" segment_no="10" tag_type="text">is worth 16x16 words: Transformers for image recognition at scale.</text>
<text top="438" left="70" width="106" height="7" font="font3" id="p12_t59" reading_order_no="58" segment_no="10" tag_type="text"><i>arXiv preprint arXiv:2010.11929</i></text>
<text top="436" left="175" width="22" height="10" font="font4" id="p12_t60" reading_order_no="59" segment_no="10" tag_type="text">, 2020.</text>
<text top="759" left="51" width="78" height="8" font="font13" id="p12_t61" reading_order_no="60" segment_no="11" tag_type="footnote">HeChen Yang et al.:</text>
<text top="759" left="133" width="108" height="8" font="font14" id="p12_t62" reading_order_no="61" segment_no="11" tag_type="footnote"><i>Preprint submitted to Elsevier</i></text>
<text top="759" left="490" width="54" height="8" font="font13" id="p12_t63" reading_order_no="62" segment_no="12" tag_type="text">Page 12 of 12</text>
</page>
</pdf2xml>
