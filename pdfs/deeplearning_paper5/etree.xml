<!DOCTYPE pdf2xml SYSTEM "pdf2xml.dtd">
<pdf2xml producer="poppler" version="23.04.0">
<page number="1" position="absolute" top="0" left="0" height="792" width="612">
	<fontspec id="font0" size="17" family="NimbusRomNo9L-Medi" color="#000000"/>
	<fontspec id="font1" size="10" family="NimbusRomNo9L-Medi" color="#000000"/>
	<fontspec id="font2" size="10" family="SFTT1000" color="#000000"/>
	<fontspec id="font3" size="12" family="NimbusRomNo9L-Medi" color="#000000"/>
	<fontspec id="font4" size="10" family="NimbusRomNo9L-Regu" color="#000000"/>
	<fontspec id="font5" size="10" family="NimbusRomNo9L-ReguItal" color="#000000"/>
	<fontspec id="font6" size="9" family="NimbusRomNo9L-Regu" color="#000000"/>
	<fontspec id="font7" size="20" family="Times" color="#7f7f7f"/>
<text top="101" left="163" width="285" height="15" font="font0" id="p1_t1" reading_order_no="1" segment_no="0" tag_type="title">A Deep Latent Space Model for Graph</text>
<text top="121" left="214" width="184" height="15" font="font0" id="p1_t2" reading_order_no="2" segment_no="0" tag_type="title">Representation Learning</text>
<text top="182" left="153" width="64" height="9" font="font1" id="p1_t3" reading_order_no="3" segment_no="1" tag_type="text">Hanxuan Yang</text>
<text top="194" left="120" width="125" height="8" font="font2" id="p1_t4" reading_order_no="4" segment_no="1" tag_type="text">yanghanxuan2020@ia.ac.cn</text>
<text top="182" left="288" width="66" height="9" font="font1" id="p1_t5" reading_order_no="5" segment_no="2" tag_type="text">Qingchao Kong</text>
<text top="194" left="264" width="115" height="8" font="font2" id="p1_t6" reading_order_no="6" segment_no="2" tag_type="text">qingchao.kong@ia.ac.cn</text>
<text top="182" left="421" width="47" height="9" font="font1" id="p1_t7" reading_order_no="7" segment_no="3" tag_type="text">Wenji Mao</text>
<text top="194" left="398" width="94" height="8" font="font2" id="p1_t8" reading_order_no="8" segment_no="3" tag_type="text">wenji.mao@ia.ac.cn</text>
<text top="233" left="284" width="44" height="11" font="font3" id="p1_t9" reading_order_no="9" segment_no="4" tag_type="title">Abstract</text>
<text top="258" left="144" width="324" height="9" font="font4" id="p1_t10" reading_order_no="10" segment_no="5" tag_type="text">Graph representation learning is a fundamental problem for modeling relational</text>
<text top="269" left="144" width="324" height="9" font="font4" id="p1_t11" reading_order_no="11" segment_no="5" tag_type="text">data and benefits a number of downstream applications. Traditional Bayesian-based</text>
<text top="280" left="144" width="326" height="9" font="font4" id="p1_t12" reading_order_no="12" segment_no="5" tag_type="text">graph models and recent deep learning based GNN either suffer from impracticabil-</text>
<text top="291" left="144" width="324" height="9" font="font4" id="p1_t13" reading_order_no="13" segment_no="5" tag_type="text">ity or lack interpretability, thus combined models for undirected graphs have been</text>
<text top="302" left="144" width="324" height="9" font="font4" id="p1_t14" reading_order_no="14" segment_no="5" tag_type="text">proposed to overcome the weaknesses. As a large portion of real-world graphs are</text>
<text top="313" left="144" width="324" height="9" font="font4" id="p1_t15" reading_order_no="15" segment_no="5" tag_type="text">directed graphs (of which undirected graphs are special cases), in this paper, we</text>
<text top="324" left="144" width="324" height="9" font="font4" id="p1_t16" reading_order_no="16" segment_no="5" tag_type="text">propose a Deep Latent Space Model (DLSM) for directed graphs to incorporate the</text>
<text top="335" left="144" width="326" height="9" font="font4" id="p1_t17" reading_order_no="17" segment_no="5" tag_type="text">traditional latent variable based generative model into deep learning frameworks.</text>
<text top="346" left="144" width="324" height="9" font="font4" id="p1_t18" reading_order_no="18" segment_no="5" tag_type="text">Our proposed model consists of a graph convolutional network (GCN) encoder</text>
<text top="356" left="144" width="326" height="9" font="font4" id="p1_t19" reading_order_no="19" segment_no="5" tag_type="text">and a stochastic decoder, which are layer-wise connected by a hierarchical varia-</text>
<text top="367" left="144" width="325" height="9" font="font4" id="p1_t20" reading_order_no="20" segment_no="5" tag_type="text">tional auto-encoder architecture. By specifically modeling the degree heterogeneity</text>
<text top="378" left="144" width="324" height="9" font="font4" id="p1_t21" reading_order_no="21" segment_no="5" tag_type="text">using node random factors, our model possesses better interpretability in both</text>
<text top="389" left="144" width="324" height="9" font="font4" id="p1_t22" reading_order_no="22" segment_no="5" tag_type="text">community structure and degree heterogeneity. For fast inference, the stochastic</text>
<text top="400" left="144" width="324" height="9" font="font4" id="p1_t23" reading_order_no="23" segment_no="5" tag_type="text">gradient variational Bayes (SGVB) is adopted using a non-iterative recognition</text>
<text top="411" left="144" width="324" height="9" font="font4" id="p1_t24" reading_order_no="24" segment_no="5" tag_type="text">model, which is much more scalable than traditional MCMC-based methods. The</text>
<text top="422" left="144" width="324" height="9" font="font4" id="p1_t25" reading_order_no="25" segment_no="5" tag_type="text">experiments on real-world datasets show that the proposed model achieves the</text>
<text top="433" left="144" width="324" height="9" font="font4" id="p1_t26" reading_order_no="26" segment_no="5" tag_type="text">state-of-the-art performances on both link prediction and community detection</text>
<text top="444" left="144" width="324" height="9" font="font4" id="p1_t27" reading_order_no="27" segment_no="5" tag_type="text">tasks while learning interpretable node embeddings. The source code is available</text>
<text top="455" left="144" width="168" height="9" font="font4" id="p1_t28" reading_order_no="28" segment_no="5" tag_type="text">at . https://github.com/upperr/DLSM</text>
<text top="488" left="108" width="6" height="11" font="font3" id="p1_t29" reading_order_no="29" segment_no="6" tag_type="title">1<a href="https://github.com/upperr/DLSM">https://github.com/upperr/DLSM</a></text>
<text top="488" left="126" width="65" height="11" font="font3" id="p1_t30" reading_order_no="30" segment_no="6" tag_type="title">Introduction<a href="https://github.com/upperr/DLSM">.</a></text>
<text top="513" left="108" width="396" height="9" font="font4" id="p1_t31" reading_order_no="31" segment_no="7" tag_type="text">Graph representation learning is a fundamental problem for graph analysis and benefits a number</text>
<text top="524" left="108" width="398" height="9" font="font4" id="p1_t32" reading_order_no="32" segment_no="7" tag_type="text">of downstream applications, such as link prediction, community detection and node classification.</text>
<text top="535" left="108" width="396" height="9" font="font4" id="p1_t33" reading_order_no="33" segment_no="7" tag_type="text">Traditionally, a plethora of Bayesian-based random graph models have been proposed for learning</text>
<text top="546" left="108" width="396" height="9" font="font4" id="p1_t34" reading_order_no="34" segment_no="7" tag_type="text">graph representations [11, 10, 13, 28]. Despite the ideal theoretical properties of these methods, they</text>
<text top="557" left="108" width="398" height="9" font="font4" id="p1_t35" reading_order_no="35" segment_no="7" tag_type="text">are impractical to model large-scale networks due to the expensive iterative inference procedures.</text>
<text top="568" left="108" width="396" height="9" font="font4" id="p1_t36" reading_order_no="36" segment_no="7" tag_type="text">Taking advantage of the powerful representation learning ability of deep learning, the graph neural<a href="deeplearning_paper5.html#10">[11, 10, 13, </a><a href="deeplearning_paper5.html#11">28]. </a>Despite the ideal theoretical properties of these methods, they</text>
<text top="579" left="108" width="398" height="9" font="font4" id="p1_t37" reading_order_no="37" segment_no="7" tag_type="text">networks (GNN) have been proposed to learn the topology of graph-structured data [17, 8, 33, 32].</text>
<text top="590" left="108" width="338" height="9" font="font4" id="p1_t38" reading_order_no="38" segment_no="7" tag_type="text">However, these deep learning methods usually bring about the interpretability issues.</text>
<text top="606" left="108" width="396" height="9" font="font4" id="p1_t39" reading_order_no="39" segment_no="9" tag_type="text">To take the advantages of both Bayesian-based and deep learning based graph models and foster their<a href="deeplearning_paper5.html#10">[17, 8, </a><a href="deeplearning_paper5.html#11">33, 32].</a></text>
<text top="617" left="108" width="397" height="9" font="font4" id="p1_t40" reading_order_no="40" segment_no="9" tag_type="text">mutual facilitation, recently, some research attempts to combine the Bayesian methods with GNN,</text>
<text top="628" left="108" width="398" height="9" font="font4" id="p1_t41" reading_order_no="41" segment_no="9" tag_type="text">and designs deep latent variable based generative models for graph-structured data [16, 6, 23, 26].</text>
<text top="639" left="108" width="397" height="9" font="font4" id="p1_t42" reading_order_no="42" segment_no="9" tag_type="text">Although these combined models can preserve the effective representation ability and achieve better</text>
<text top="650" left="108" width="396" height="9" font="font4" id="p1_t43" reading_order_no="43" segment_no="9" tag_type="text">performances on downstream tasks, they are all designed for undirected graphs. In contrast, a large<a href="deeplearning_paper5.html#10">[16, 6, </a><a href="deeplearning_paper5.html#11">23, 26].</a></text>
<text top="661" left="108" width="396" height="9" font="font4" id="p1_t44" reading_order_no="44" segment_no="9" tag_type="text">portion of real-world graphs, such as retweet and citation networks, are directed graphs, of which</text>
<text top="671" left="108" width="398" height="9" font="font4" id="p1_t45" reading_order_no="45" segment_no="9" tag_type="text">undirected graphs are special cases (i.e. an undirected edge can be seen as a two-way directed edge).</text>
<text top="682" left="108" width="396" height="9" font="font4" id="p1_t46" reading_order_no="46" segment_no="9" tag_type="text">The representation learning of directed graphs is particularly challenging since not only the existence</text>
<text top="693" left="108" width="396" height="9" font="font4" id="p1_t47" reading_order_no="47" segment_no="9" tag_type="text">but also the direction of edges need to be learned. Moreover, existing combined models for undirected</text>
<text top="704" left="108" width="396" height="9" font="font4" id="p1_t48" reading_order_no="48" segment_no="9" tag_type="text">graphs only consider the community structure but ignore another important graph characteristic</text>
<text top="734" left="108" width="31" height="8" font="font6" id="p1_t49" reading_order_no="49" segment_no="10" tag_type="footnote">Preprint.</text>
<text top="546" left="32" width="0" height="18" font="font7" id="p1_t50" reading_order_no="0" segment_no="8" tag_type="title">arXiv:2106.11721v1  [cs.LG]  22 Jun 2021</text>
</page>
<page number="2" position="absolute" top="0" left="0" height="792" width="612">
<text top="75" left="108" width="396" height="9" font="font4" id="p2_t1" reading_order_no="0" segment_no="0" tag_type="text">commonly observed in complex networks – the degree heterogeneity , which measures the skewness</text>
<text top="86" left="108" width="168" height="9" font="font4" id="p2_t2" reading_order_no="1" segment_no="0" tag_type="text">of the distributions of out- and in-degrees.</text>
<text top="103" left="108" width="396" height="9" font="font4" id="p2_t3" reading_order_no="2" segment_no="1" tag_type="text">In this paper, we focus on directed graphs and better modeling various graph properties with nice</text>
<text top="113" left="108" width="396" height="9" font="font4" id="p2_t4" reading_order_no="3" segment_no="1" tag_type="text">interpretability, including community structure and degree heterogeneity. To this end, we propose the</text>
<text top="124" left="108" width="396" height="9" font="font4" id="p2_t5" reading_order_no="4" segment_no="1" tag_type="text">Deep Latent Space Model (DLSM) by marrying the graph convolutional networks (GCN) with the</text>
<text top="135" left="108" width="396" height="9" font="font4" id="p2_t6" reading_order_no="5" segment_no="1" tag_type="text">classic latent space approaches. Specifically, to generate an asymmetric adjacency matrix, the degree</text>
<text top="146" left="108" width="396" height="9" font="font4" id="p2_t7" reading_order_no="6" segment_no="1" tag_type="text">discrepancy of the two ends in each directed edge is utilized, which is measured by the pairwise</text>
<text top="157" left="108" width="396" height="9" font="font4" id="p2_t8" reading_order_no="7" segment_no="1" tag_type="text">node random factors as distance scales. Moreover, to accommodate an overlapping community</text>
<text top="168" left="108" width="396" height="9" font="font4" id="p2_t9" reading_order_no="8" segment_no="1" tag_type="text">structure, where nodes may belong to one or more communities, we use a binary latent vector to</text>
<text top="179" left="108" width="396" height="9" font="font4" id="p2_t10" reading_order_no="9" segment_no="1" tag_type="text">denote the membership of a node pertaining to each community. All latent variables are generated by</text>
<text top="190" left="108" width="396" height="9" font="font4" id="p2_t11" reading_order_no="10" segment_no="1" tag_type="text">a hierarchical variational auto-encoder (VAE) architecture, which consists of a GCN deterministic</text>
<text top="201" left="108" width="396" height="9" font="font4" id="p2_t12" reading_order_no="11" segment_no="1" tag_type="text">encoder and a stochastic decoder. For fast inference, the reparameterization trick of each latent</text>
<text top="212" left="108" width="397" height="9" font="font4" id="p2_t13" reading_order_no="12" segment_no="1" tag_type="text">variable is leveraged to perform the stochastic gradient variational Bayes (SGVB) [14] algorithm,</text>
<text top="223" left="108" width="389" height="9" font="font4" id="p2_t14" reading_order_no="13" segment_no="1" tag_type="text">which is far more efficient and scalable compared with the traditional iterative inference methods.</text>
<text top="239" left="108" width="255" height="9" font="font4" id="p2_t15" reading_order_no="14" segment_no="2" tag_type="text">The main contributions of this work are summarized as follows:</text>
<text top="260" left="131" width="373" height="9" font="font4" id="p2_t16" reading_order_no="15" segment_no="3" tag_type="list">1. We propose the DLSM to incorporate the classic Bayesian latent space approaches into deep</text>
<text top="271" left="144" width="360" height="9" font="font4" id="p2_t17" reading_order_no="16" segment_no="3" tag_type="list">learning frameworks and generate interpretable representations involving the community<a href="deeplearning_paper5.html#10">[14] </a>algorithm,</text>
<text top="282" left="144" width="214" height="9" font="font4" id="p2_t18" reading_order_no="17" segment_no="3" tag_type="list">structure and degree heterogeneity of directed graphs.</text>
<text top="297" left="131" width="373" height="9" font="font4" id="p2_t19" reading_order_no="18" segment_no="4" tag_type="list">2. A hierarchical VAE architecture is established to layer-wise connect a GCN encoder and a</text>
<text top="308" left="144" width="360" height="9" font="font4" id="p2_t20" reading_order_no="19" segment_no="4" tag_type="list">stochastic decoder, which enables the variational posteriors to depend on the approximate</text>
<text top="319" left="144" width="194" height="9" font="font4" id="p2_t21" reading_order_no="20" segment_no="4" tag_type="list">likelihood as well as priors from previous layers.</text>
<text top="335" left="131" width="373" height="9" font="font4" id="p2_t22" reading_order_no="21" segment_no="5" tag_type="list">3. For fast inference, the SGVB algorithm using a recognition model is adopted as a more</text>
<text top="346" left="144" width="271" height="9" font="font4" id="p2_t23" reading_order_no="22" segment_no="5" tag_type="list">efficient and scalable alternative of the expensive MCMC inference.</text>
<text top="361" left="131" width="373" height="9" font="font4" id="p2_t24" reading_order_no="23" segment_no="6" tag_type="list">4. Our experiments on five real world network datasets show that the learned representations are</text>
<text top="372" left="144" width="360" height="9" font="font4" id="p2_t25" reading_order_no="24" segment_no="6" tag_type="list">readily to be employed in downstream applications and achieve state-of-the-art performances</text>
<text top="383" left="144" width="175" height="9" font="font4" id="p2_t26" reading_order_no="25" segment_no="6" tag_type="list">in link prediction and community detection.</text>
<text top="411" left="108" width="6" height="11" font="font3" id="p2_t27" reading_order_no="26" segment_no="7" tag_type="title">2</text>
<text top="411" left="126" width="71" height="11" font="font3" id="p2_t28" reading_order_no="27" segment_no="7" tag_type="title">Related Work</text>
<text top="436" left="108" width="396" height="9" font="font4" id="p2_t29" reading_order_no="28" segment_no="8" tag_type="text">In this section, we briefly review the traditional Bayesian-based random graph models and deep</text>
<text top="447" left="108" width="224" height="9" font="font4" id="p2_t30" reading_order_no="29" segment_no="8" tag_type="text">learning based generative graph representation methods.</text>
<text top="472" left="108" width="12" height="9" font="font1" id="p2_t31" reading_order_no="30" segment_no="9" tag_type="title">2.1</text>
<text top="472" left="130" width="162" height="9" font="font1" id="p2_t32" reading_order_no="31" segment_no="9" tag_type="title">Bayesian-based random graph models</text>
<text top="493" left="108" width="396" height="9" font="font4" id="p2_t33" reading_order_no="32" segment_no="10" tag_type="text">Classic Bayesian-based random graph models have developed for decades and are still valued</text>
<text top="504" left="108" width="396" height="9" font="font4" id="p2_t34" reading_order_no="33" segment_no="10" tag_type="text">in modeling relational data. One of the most well-known methods is the stochastic blockmodel</text>
<text top="515" left="108" width="398" height="9" font="font4" id="p2_t35" reading_order_no="34" segment_no="10" tag_type="text">(SBM) [11], which generates a latent variable indicating the community membership of each node.</text>
<text top="526" left="108" width="396" height="9" font="font4" id="p2_t36" reading_order_no="35" segment_no="10" tag_type="text">Following SBM, a large number of variants have been proposed, such as allowing an overlapping</text>
<text top="537" left="108" width="396" height="9" font="font4" id="p2_t37" reading_order_no="36" segment_no="10" tag_type="text">community structure [24] and involving degree heterogeneity [13, 27]. Another stream of research is</text>
<text top="547" left="108" width="396" height="9" font="font4" id="p2_t38" reading_order_no="37" segment_no="10" tag_type="text">the latent space models (LSM) [10], which endows each node with a low-dimensional latent variable</text>
<text top="558" left="108" width="396" height="9" font="font4" id="p2_t39" reading_order_no="38" segment_no="10" tag_type="text">to represent the node’s position in a network. The most significant difference between these two<a href="deeplearning_paper5.html#10">[11], </a>which generates a latent variable indicating the community membership of each node.</text>
<text top="569" left="108" width="396" height="9" font="font4" id="p2_t40" reading_order_no="39" segment_no="10" tag_type="text">methods is that LSM use the node similarity to measure the divergences between nodes, rather than</text>
<text top="580" left="108" width="396" height="9" font="font4" id="p2_t41" reading_order_no="40" segment_no="10" tag_type="text">communities, and thus can easily adapt to the complex directed networks. More recently, [9] involves<a href="deeplearning_paper5.html#11">[24] </a>and involving degree heterogeneity <a href="deeplearning_paper5.html#10">[13, </a><a href="deeplearning_paper5.html#11">27]. </a>Another stream of research is</text>
<text top="591" left="108" width="397" height="9" font="font4" id="p2_t42" reading_order_no="41" segment_no="10" tag_type="text">the community structure within LSM using mixture Normal priors of latent positions. Furthermore,<a href="deeplearning_paper5.html#10">[10], </a>which endows each node with a low-dimensional latent variable</text>
<text top="602" left="108" width="396" height="9" font="font4" id="p2_t43" reading_order_no="42" segment_no="10" tag_type="text">[18] and [28] introduce a pair of random variables in each link to model the degree heterogeneity of</text>
<text top="613" left="108" width="396" height="9" font="font4" id="p2_t44" reading_order_no="43" segment_no="10" tag_type="text">nodes. Although these above methods provide good theoretical properties and learn interpretable node</text>
<text top="624" left="108" width="396" height="9" font="font4" id="p2_t45" reading_order_no="44" segment_no="10" tag_type="text">embeddings, they rely on either the MCMC posterior sampling or mean-field variational inference<a href="deeplearning_paper5.html#10">[9] </a>involves</text>
<text top="635" left="108" width="396" height="9" font="font4" id="p2_t46" reading_order_no="45" segment_no="10" tag_type="text">with dramatically high computational complexity, and thus are usually unfeasible when modeling</text>
<text top="646" left="108" width="84" height="9" font="font4" id="p2_t47" reading_order_no="46" segment_no="10" tag_type="text">large scale networks.<a href="deeplearning_paper5.html#10">[18] </a>and <a href="deeplearning_paper5.html#11">[28] </a>introduce a pair of random variables in each link to model the degree heterogeneity of</text>
<text top="671" left="108" width="12" height="9" font="font1" id="p2_t48" reading_order_no="47" segment_no="11" tag_type="title">2.2</text>
<text top="671" left="130" width="147" height="9" font="font1" id="p2_t49" reading_order_no="48" segment_no="11" tag_type="title">Deep learning based graph models</text>
<text top="691" left="108" width="396" height="9" font="font4" id="p2_t50" reading_order_no="49" segment_no="12" tag_type="text">The intriguing achievements of deep learning models for learning representations of Euclidean data</text>
<text top="702" left="108" width="396" height="9" font="font4" id="p2_t51" reading_order_no="50" segment_no="12" tag_type="text">have encouraged efforts to employ them on graph-structured data. The earliest attempts include</text>
<text top="713" left="108" width="396" height="9" font="font4" id="p2_t52" reading_order_no="51" segment_no="12" tag_type="text">DeepWalk [25] and node2vec [5], both of which encode local relations as node representations by</text>
<text top="743" left="304" width="5" height="9" font="font4" id="p2_t53" reading_order_no="52" segment_no="13" tag_type="text">2</text>
</page>
<page number="3" position="absolute" top="0" left="0" height="792" width="612">
	<fontspec id="font8" size="10" family="CMMI10" color="#000000"/>
	<fontspec id="font9" size="10" family="CMR10" color="#000000"/>
	<fontspec id="font10" size="7" family="CMMI7" color="#000000"/>
	<fontspec id="font11" size="10" family="CMSY10" color="#000000"/>
	<fontspec id="font12" size="7" family="CMSY7" color="#000000"/>
	<fontspec id="font13" size="10" family="MSBM10" color="#000000"/>
	<fontspec id="font14" size="10" family="CMMIB10" color="#000000"/>
<text top="75" left="108" width="396" height="9" font="font4" id="p3_t1" reading_order_no="0" segment_no="0" tag_type="text">conducting random walks on a graph. More recently, many GNN-based deep generative models</text>
<text top="86" left="108" width="396" height="9" font="font4" id="p3_t2" reading_order_no="1" segment_no="0" tag_type="text">have been proposed. [17] first leverages the spectral GCN to generate node embeddings using the<a href="deeplearning_paper5.html#10">[17] </a>first leverages the spectral GCN to generate node embeddings using the</text>
<text top="97" left="108" width="396" height="9" font="font4" id="p3_t3" reading_order_no="2" segment_no="0" tag_type="text">global topology of a graph. GraphSAGE [8] samples a fixed-size neighborhood of each node for<a href="deeplearning_paper5.html#10">[8] </a>samples a fixed-size neighborhood of each node for</text>
<text top="108" left="108" width="398" height="9" font="font4" id="p3_t4" reading_order_no="3" segment_no="0" tag_type="text">the inductive representation learning, which allows unseen nodes to be excluded during training.</text>
<text top="119" left="108" width="396" height="9" font="font4" id="p3_t5" reading_order_no="4" segment_no="0" tag_type="text">Later, GraphGAN [33] unifies a generator and a discriminator to learn node embeddings by playing a<a href="deeplearning_paper5.html#11">[33] </a>unifies a generator and a discriminator to learn node embeddings by playing a</text>
<text top="130" left="108" width="396" height="9" font="font4" id="p3_t6" reading_order_no="5" segment_no="0" tag_type="text">minimax game. The graph attention networks [32] introduce the attention mechanism to aggregate<a href="deeplearning_paper5.html#11">[32] </a>introduce the attention mechanism to aggregate</text>
<text top="141" left="108" width="128" height="9" font="font4" id="p3_t7" reading_order_no="6" segment_no="0" tag_type="text">the information from neighbors.</text>
<text top="157" left="108" width="398" height="9" font="font4" id="p3_t8" reading_order_no="7" segment_no="1" tag_type="text">To take advantage of the nice theoretical properties of Bayesian methods and the powerful representa-</text>
<text top="168" left="108" width="396" height="9" font="font4" id="p3_t9" reading_order_no="8" segment_no="1" tag_type="text">tion ability of deep learning methods, some research work tries to combine these two approaches</text>
<text top="179" left="108" width="396" height="9" font="font4" id="p3_t10" reading_order_no="9" segment_no="1" tag_type="text">for graph representation learning. The variational graph auto-encoders (VGAE) [16] first generates<a href="deeplearning_paper5.html#10">[16] </a>first generates</text>
<text top="190" left="108" width="396" height="9" font="font4" id="p3_t11" reading_order_no="10" segment_no="1" tag_type="text">Normal node embeddings using the variational auto-encoder (VAE) [15], which is then modified<a href="deeplearning_paper5.html#10">[15], </a>which is then modified</text>
<text top="201" left="108" width="396" height="9" font="font4" id="p3_t12" reading_order_no="11" segment_no="1" tag_type="text">by Graphite [6] with a perception component based on GCN. [23] combines the classic SBM with<a href="deeplearning_paper5.html#10">[6] </a>with a perception component based on GCN. <a href="deeplearning_paper5.html#11">[23] </a>combines the classic SBM with</text>
<text top="212" left="108" width="396" height="9" font="font4" id="p3_t13" reading_order_no="12" segment_no="1" tag_type="text">GCN to learn a sparse real-valued node embedding interpreted as the memberships and strengths of</text>
<text top="223" left="108" width="396" height="9" font="font4" id="p3_t14" reading_order_no="13" segment_no="1" tag_type="text">each node belonging to different communities. Furthermore, [26] builds a sparse ladder VAE [29]<a href="deeplearning_paper5.html#11">[26] </a>builds a sparse ladder VAE <a href="deeplearning_paper5.html#11">[29]</a></text>
<text top="233" left="108" width="396" height="9" font="font4" id="p3_t15" reading_order_no="14" segment_no="1" tag_type="text">architecture to discover the communities at multiple levels of granularities. All of the existing deep</text>
<text top="244" left="108" width="396" height="9" font="font4" id="p3_t16" reading_order_no="15" segment_no="1" tag_type="text">learning based graph models, to the best of our knowledge, are only designed for undirected graphs</text>
<text top="255" left="108" width="396" height="9" font="font4" id="p3_t17" reading_order_no="16" segment_no="1" tag_type="text">without considering graph characteristics, such as degree heterogeneity. In this paper, we design a</text>
<text top="266" left="108" width="396" height="9" font="font4" id="p3_t18" reading_order_no="17" segment_no="1" tag_type="text">novel hierarchical variational auto-encoder architecture which combines the LSM and GCN to learn</text>
<text top="277" left="108" width="364" height="9" font="font4" id="p3_t19" reading_order_no="18" segment_no="1" tag_type="text">directed graph representations involving the community structure and degree heterogeneity.</text>
<text top="305" left="108" width="6" height="11" font="font3" id="p3_t20" reading_order_no="19" segment_no="2" tag_type="title">3</text>
<text top="305" left="126" width="69" height="11" font="font3" id="p3_t21" reading_order_no="20" segment_no="2" tag_type="title">Preliminaries</text>
<text top="330" left="108" width="396" height="9" font="font4" id="p3_t22" reading_order_no="21" segment_no="3" tag_type="text">This section provides a formal definition of the graph representation learning problem concerned in</text>
<text top="341" left="108" width="347" height="9" font="font4" id="p3_t23" reading_order_no="22" segment_no="3" tag_type="text">this paper, followed by a brief introduction of the VAE method leveraged in our model.</text>
<text top="366" left="108" width="12" height="9" font="font1" id="p3_t24" reading_order_no="23" segment_no="4" tag_type="title">3.1</text>
<text top="366" left="130" width="79" height="9" font="font1" id="p3_t25" reading_order_no="24" segment_no="4" tag_type="title">Problem definition</text>
<text top="387" left="108" width="396" height="9" font="font4" id="p3_t26" reading_order_no="25" segment_no="5" tag_type="text">Consider a directed network containing n nodes. The data to be modeled include an asymmetric</text>
<text top="396" left="108" width="396" height="11" font="font4" id="p3_t27" reading_order_no="26" segment_no="5" tag_type="text">adjacency matrix A = ( a ij ) ∈ { 0 , 1 } n × n , where each binary element a ij denotes the presence ( 1 ) or</text>
<text top="407" left="108" width="396" height="12" font="font4" id="p3_t28" reading_order_no="27" segment_no="5" tag_type="text">not ( 0 ) of the directed edge from node i to j , and a node attribute matrix X ∈ R n × p . Throughout</text>
<text top="419" left="108" width="398" height="10" font="font4" id="p3_t29" reading_order_no="28" segment_no="5" tag_type="text">this paper we assume all edges to be conditionally independent and satisfy a ij | Θ ∼ Bernoulli ( p ij ) ,</text>
<text top="430" left="108" width="396" height="10" font="font4" id="p3_t30" reading_order_no="29" segment_no="5" tag_type="text">where Θ is the collection of latent representations. The problem concerned is to learn the node</text>
<text top="442" left="108" width="314" height="9" font="font4" id="p3_t31" reading_order_no="30" segment_no="5" tag_type="text">representations (embeddings) which can best reconstruct the adjacency matrix.</text>
<text top="467" left="108" width="12" height="9" font="font1" id="p3_t32" reading_order_no="31" segment_no="6" tag_type="title">3.2</text>
<text top="467" left="130" width="106" height="9" font="font1" id="p3_t33" reading_order_no="32" segment_no="6" tag_type="title">Variational auto-encoder</text>
<text top="487" left="108" width="396" height="9" font="font4" id="p3_t34" reading_order_no="33" segment_no="7" tag_type="text">The objective of VAE is to train a generative model (decoder) p ( X | Θ) which can generate X given</text>
<text top="498" left="108" width="396" height="9" font="font4" id="p3_t35" reading_order_no="34" segment_no="7" tag_type="text">latent variables Θ . However, due to the complex non-linearity of neural networks, the true posteriors</text>
<text top="508" left="108" width="397" height="10" font="font8" id="p3_t36" reading_order_no="35" segment_no="7" tag_type="text">p (Θ | X ) are typically intractable and need to be approximated by the variational posteriors q (Θ | X )</text>
<text top="520" left="108" width="147" height="9" font="font4" id="p3_t37" reading_order_no="36" segment_no="7" tag_type="text">using a recognition model (encoder).</text>
<text top="536" left="108" width="396" height="9" font="font4" id="p3_t38" reading_order_no="37" segment_no="8" tag_type="text">One of the problems for the vanilla VAE is that the latent variables generated at deep layers tend to</text>
<text top="547" left="108" width="398" height="9" font="font4" id="p3_t39" reading_order_no="38" segment_no="8" tag_type="text">collapse into priors because of the noises accumulated during the multiple Monte Carlo sampling.</text>
<text top="558" left="108" width="396" height="9" font="font4" id="p3_t40" reading_order_no="39" segment_no="8" tag_type="text">Enlightened by the ladder VAE [29], which employs a bidirectional structure to layer-wise connect</text>
<text top="569" left="108" width="396" height="9" font="font4" id="p3_t41" reading_order_no="40" segment_no="8" tag_type="text">the encoder and decoder, here we propose a hierarchical architecture, as illustrated in Fig 1. The</text>
<text top="580" left="108" width="396" height="9" font="font4" id="p3_t42" reading_order_no="41" segment_no="8" tag_type="text">encoder block takes the adjacency A and attribute matrices X , if available, as inputs and learns a</text>
<text top="591" left="108" width="396" height="9" font="font4" id="p3_t43" reading_order_no="42" segment_no="8" tag_type="text">hidden state for each node using a directed GCN. Then, the decoder block recursively generates</text>
<text top="602" left="108" width="396" height="9" font="font4" id="p3_t44" reading_order_no="43" segment_no="8" tag_type="text">expressive latent variables from variational posteriors depending on not only the priors passed from</text>
<text top="613" left="108" width="396" height="9" font="font4" id="p3_t45" reading_order_no="44" segment_no="8" tag_type="text">previous layers of the decoder, but also the approximate likelihood learned by the encoder, which</text>
<text top="624" left="108" width="193" height="9" font="font4" id="p3_t46" reading_order_no="45" segment_no="8" tag_type="text">enables a deep hierarchy of the proposed model.</text>
<text top="649" left="108" width="12" height="9" font="font1" id="p3_t47" reading_order_no="46" segment_no="9" tag_type="title">3.3</text>
<text top="649" left="130" width="82" height="9" font="font1" id="p3_t48" reading_order_no="47" segment_no="9" tag_type="title">Latent space model</text>
<text top="670" left="108" width="398" height="9" font="font4" id="p3_t49" reading_order_no="48" segment_no="10" tag_type="text">The proposed model learns interpretable node representations based on the classic LSM framework.</text>
<text top="680" left="108" width="396" height="10" font="font4" id="p3_t50" reading_order_no="49" segment_no="10" tag_type="text">Assume each node correspond to a latent position in an unobservable D -dimensional space, denoted</text>
<text top="690" left="108" width="396" height="12" font="font4" id="p3_t51" reading_order_no="50" segment_no="10" tag_type="text">as z i ∈ R D . The distances between latent positions indicate the relationships of nodes. The closer the</text>
<text top="702" left="108" width="396" height="9" font="font4" id="p3_t52" reading_order_no="51" segment_no="10" tag_type="text">latent positions are, the more possible the edge will exist. To accommodate the degree heterogeneity</text>
<text top="713" left="108" width="396" height="9" font="font4" id="p3_t53" reading_order_no="52" segment_no="10" tag_type="text">of directed networks, we propose a generalized form of LSM by involving two node-specific random</text>
<text top="743" left="304" width="5" height="9" font="font4" id="p3_t54" reading_order_no="53" segment_no="11" tag_type="text">3</text>
</page>
<page number="4" position="absolute" top="0" left="0" height="792" width="612">
	<fontspec id="font15" size="6" family="TimesNewRomanPSMT" color="#000000"/>
	<fontspec id="font16" size="7" family="CMR7" color="#000000"/>
	<fontspec id="font17" size="5" family="CMMI5" color="#000000"/>
	<fontspec id="font18" size="5" family="CMSY5" color="#000000"/>
	<fontspec id="font19" size="5" family="CMR5" color="#000000"/>
<text top="167" left="191" width="72" height="7" font="font15" id="p4_t1" reading_order_no="0" segment_no="0" tag_type="figure">GCN Deterministic Encoder</text>
<text top="167" left="348" width="63" height="7" font="font15" id="p4_t2" reading_order_no="1" segment_no="0" tag_type="figure">LSM Stochastic Decoder</text>
<text top="184" left="108" width="397" height="9" font="font4" id="p4_t3" reading_order_no="2" segment_no="1" tag_type="text">Figure 1: The architecture of hierarchical variational auto-encoder. The deterministic GNN (blue)</text>
<text top="194" left="108" width="396" height="11" font="font4" id="p4_t4" reading_order_no="3" segment_no="1" tag_type="text">encodes the adjacency matrix and attribute (if available) inputs as hidden states H ( l ) , which are then</text>
<text top="207" left="108" width="397" height="10" font="font4" id="p4_t5" reading_order_no="4" segment_no="1" tag_type="text">passed to the LSM decoder to generate the interpretable latent representations Θ ( l ) . For inference,</text>
<text top="219" left="108" width="396" height="9" font="font4" id="p4_t6" reading_order_no="5" segment_no="1" tag_type="text">the posterior variational distributions are also dependent on the GNN likelihood of the corresponding</text>
<text top="230" left="108" width="92" height="9" font="font4" id="p4_t7" reading_order_no="6" segment_no="1" tag_type="text">layers (orange arrows).</text>
<text top="263" left="108" width="318" height="9" font="font4" id="p4_t8" reading_order_no="7" segment_no="2" tag_type="text">factors, which serve as distance scales at each dimension of the latent space, i.e.</text>
<text top="279" left="171" width="90" height="11" font="font8" id="p4_t9" reading_order_no="8" segment_no="3" tag_type="formula">p ij = σ ( β 0 − β out k γ i</text>
<text top="279" left="273" width="84" height="10" font="font9" id="p4_t10" reading_order_no="9" segment_no="3" tag_type="formula">( z i − z j ) k − β in k δ j</text>
<text top="279" left="370" width="52" height="10" font="font9" id="p4_t11" reading_order_no="10" segment_no="3" tag_type="formula">( z i − z j ) k ) ,</text>
<text top="280" left="492" width="12" height="9" font="font4" id="p4_t12" reading_order_no="11" segment_no="3" tag_type="text">(1)</text>
<text top="298" left="108" width="24" height="9" font="font4" id="p4_t13" reading_order_no="12" segment_no="4" tag_type="text">where</text>
<text top="296" left="145" width="359" height="12" font="font4" id="p4_t14" reading_order_no="13" segment_no="4" tag_type="text">denotes the element-wise multiplication and σ ( · ) is the sigmoid function. γ i and δ i ∈ R D</text>
<text top="309" left="108" width="396" height="9" font="font4" id="p4_t15" reading_order_no="14" segment_no="4" tag_type="text">are the activity and popularity factors, the reverse of which represent the tendencies for a node to</text>
<text top="320" left="108" width="397" height="9" font="font4" id="p4_t16" reading_order_no="15" segment_no="4" tag_type="text">send and receive edges, respectively. The latent positions z i are involved as Euclidean distances,</text>
<text top="330" left="108" width="396" height="10" font="font4" id="p4_t17" reading_order_no="16" segment_no="4" tag_type="text">indicating the relationships between the nodes. The global weights β out and β in are to measure the</text>
<text top="341" left="108" width="323" height="10" font="font4" id="p4_t18" reading_order_no="17" segment_no="4" tag_type="text">importance of out-degrees (activity) and in-degrees (popularity), and β 0 is a bias.</text>
<text top="364" left="108" width="54" height="9" font="font1" id="p4_t19" reading_order_no="18" segment_no="5" tag_type="text">Special cases</text>
<text top="364" left="172" width="332" height="9" font="font4" id="p4_t20" reading_order_no="19" segment_no="5" tag_type="text">Though Eq. (1) is designed for directed networks due to the asymmetric structures of</text>
<text top="375" left="108" width="396" height="11" font="font8" id="p4_t21" reading_order_no="20" segment_no="5" tag_type="text">p ij and p ji , it can be easily degraded to a symmetric structure by setting γ i = δ i and β out = β in for</text>
<text top="386" left="108" width="83" height="9" font="font4" id="p4_t22" reading_order_no="21" segment_no="5" tag_type="text">undirected networks.</text>
<text top="413" left="108" width="6" height="11" font="font3" id="p4_t23" reading_order_no="22" segment_no="6" tag_type="title">4</text>
<text top="413" left="126" width="131" height="11" font="font3" id="p4_t24" reading_order_no="23" segment_no="6" tag_type="title">Deep Latent Space Model</text>
<text top="437" left="108" width="396" height="9" font="font4" id="p4_t25" reading_order_no="24" segment_no="7" tag_type="text">We propose a hierarchical VAE architecture composed of a GCN encoder and an LSM decoder, as</text>
<text top="448" left="108" width="358" height="9" font="font4" id="p4_t26" reading_order_no="25" segment_no="7" tag_type="text">shown in Fig. 1, to generate interpretable node representations via Monte Carlo sampling.</text>
<text top="473" left="108" width="12" height="9" font="font1" id="p4_t27" reading_order_no="26" segment_no="8" tag_type="title">4.1</text>
<text top="473" left="130" width="58" height="9" font="font1" id="p4_t28" reading_order_no="27" segment_no="8" tag_type="title">LSM decoder</text>
<text top="492" left="108" width="396" height="10" font="font4" id="p4_t29" reading_order_no="28" segment_no="9" tag_type="text">We first introduce the hierarchical architecture of the stochastic decoder. Denoting G l as the size of</text>
<text top="503" left="108" width="365" height="12" font="font4" id="p4_t30" reading_order_no="29" segment_no="9" tag_type="text">the l − th decoder layer, there are four latent variables to generate, i.e. the latent positions z ( l )</text>
<text top="511" left="465" width="3" height="6" font="font10" id="p4_t31" reading_order_no="30" segment_no="9" tag_type="text">i</text>
<text top="504" left="477" width="28" height="12" font="font11" id="p4_t32" reading_order_no="31" segment_no="9" tag_type="text">∈ R G l ,</text>
<text top="517" left="108" width="116" height="12" font="font4" id="p4_t33" reading_order_no="32" segment_no="9" tag_type="text">community memberships s ( l )</text>
<text top="525" left="216" width="3" height="6" font="font10" id="p4_t34" reading_order_no="33" segment_no="9" tag_type="text">i</text>
<text top="517" left="228" width="157" height="14" font="font11" id="p4_t35" reading_order_no="34" segment_no="9" tag_type="text">∈ R G l and node random factors γ i , δ ( l )</text>
<text top="525" left="377" width="3" height="6" font="font10" id="p4_t36" reading_order_no="35" segment_no="9" tag_type="text">i</text>
<text top="519" left="389" width="115" height="11" font="font11" id="p4_t37" reading_order_no="36" segment_no="9" tag_type="text">∈ R G l . All of these variables</text>
<text top="531" left="108" width="396" height="9" font="font4" id="p4_t38" reading_order_no="37" segment_no="9" tag_type="text">are randomly sampled from the variational distributions. At the first layer ( l = 1 ), the parameters of</text>
<text top="541" left="108" width="396" height="10" font="font4" id="p4_t39" reading_order_no="38" segment_no="9" tag_type="text">variational distributions are defined by priors solely, while for other layers ( l = 2 , . . . , L − 1 ), the</text>
<text top="553" left="108" width="396" height="9" font="font4" id="p4_t40" reading_order_no="39" segment_no="9" tag_type="text">parameters are obtained by the feedforward representations generated from previous layers as well as</text>
<text top="564" left="108" width="26" height="9" font="font4" id="p4_t41" reading_order_no="40" segment_no="9" tag_type="text">priors.</text>
<text top="589" left="108" width="69" height="9" font="font1" id="p4_t42" reading_order_no="41" segment_no="10" tag_type="text">Latent positions</text>
<text top="586" left="187" width="98" height="13" font="font4" id="p4_t43" reading_order_no="42" segment_no="10" tag_type="text">The latent positions z ( l )</text>
<text top="594" left="277" width="3" height="6" font="font10" id="p4_t44" reading_order_no="43" segment_no="10" tag_type="text">i</text>
<text top="590" left="289" width="217" height="9" font="font4" id="p4_t45" reading_order_no="44" segment_no="10" tag_type="text">measure the relationship between nodes through dis-</text>
<text top="600" left="108" width="79" height="9" font="font4" id="p4_t46" reading_order_no="45" segment_no="10" tag_type="text">tances, generated as</text>
<text top="618" left="201" width="15" height="12" font="font14" id="p4_t47" reading_order_no="46" segment_no="11" tag_type="formula">z ( l )</text>
<text top="626" left="207" width="3" height="6" font="font10" id="p4_t48" reading_order_no="47" segment_no="11" tag_type="formula">i</text>
<text top="618" left="219" width="59" height="12" font="font11" id="p4_t49" reading_order_no="48" segment_no="11" tag_type="formula">∼ Normal ( s ( l )</text>
<text top="626" left="269" width="3" height="6" font="font10" id="p4_t50" reading_order_no="49" segment_no="11" tag_type="formula">i</text>
<text top="618" left="291" width="38" height="12" font="font8" id="p4_t51" reading_order_no="50" segment_no="11" tag_type="formula">f ( W ( l − 1)</text>
<text top="625" left="310" width="4" height="6" font="font10" id="p4_t52" reading_order_no="51" segment_no="11" tag_type="formula">z</text>
<text top="617" left="330" width="25" height="13" font="font14" id="p4_t53" reading_order_no="52" segment_no="11" tag_type="formula">z ( l − 1)</text>
<text top="626" left="336" width="3" height="6" font="font10" id="p4_t54" reading_order_no="53" segment_no="11" tag_type="formula">i</text>
<text top="619" left="355" width="20" height="12" font="font9" id="p4_t55" reading_order_no="54" segment_no="11" tag_type="formula">) , σ 2 i</text>
<text top="617" left="375" width="16" height="13" font="font9" id="p4_t56" reading_order_no="55" segment_no="11" tag_type="formula">( l ) ) ,</text>
<text top="621" left="492" width="12" height="9" font="font4" id="p4_t57" reading_order_no="56" segment_no="11" tag_type="text">(2)</text>
<text top="640" left="108" width="258" height="12" font="font4" id="p4_t58" reading_order_no="57" segment_no="12" tag_type="text">where f ( · ) is a nonlinear activation function (e.g. leaky ReLU), σ 2 i</text>
<text top="638" left="367" width="137" height="14" font="font11" id="p4_t59" reading_order_no="58" segment_no="12" tag_type="text">( l ) ∈ R G l is the prior variance to be</text>
<text top="652" left="108" width="85" height="12" font="font4" id="p4_t60" reading_order_no="59" segment_no="12" tag_type="text">specified, and W ( l − 1)</text>
<text top="659" left="174" width="4" height="6" font="font10" id="p4_t61" reading_order_no="60" segment_no="12" tag_type="text">z</text>
<text top="653" left="196" width="308" height="12" font="font11" id="p4_t62" reading_order_no="61" segment_no="12" tag_type="text">∈ R G l × G l − 1 is a weight matrix to transform the variable from dimension G l − 1</text>
<text top="666" left="108" width="396" height="9" font="font4" id="p4_t63" reading_order_no="62" segment_no="12" tag_type="text">to G l . For the convenience of notations, here the parameters of Normal distribution are symbolized</text>
<text top="677" left="108" width="195" height="9" font="font4" id="p4_t64" reading_order_no="63" segment_no="12" tag_type="text">as vectors, meaning the element-wise operations.</text>
<text top="700" left="108" width="110" height="9" font="font1" id="p4_t65" reading_order_no="64" segment_no="13" tag_type="text">Community memberships</text>
<text top="700" left="228" width="276" height="9" font="font4" id="p4_t66" reading_order_no="65" segment_no="13" tag_type="text">The latent positions in Eq. (2) are separated into different communities</text>
<text top="710" left="108" width="135" height="12" font="font4" id="p4_t67" reading_order_no="66" segment_no="13" tag_type="text">by the sparse binary variables s ( l )</text>
<text top="718" left="234" width="3" height="6" font="font10" id="p4_t68" reading_order_no="67" segment_no="13" tag_type="text">i</text>
<text top="711" left="246" width="258" height="12" font="font9" id="p4_t69" reading_order_no="68" segment_no="13" tag_type="text">= ( s i 1 , . . . , s iG l ) 0 , thus an overlapping community structure can</text>
<text top="743" left="304" width="5" height="9" font="font4" id="p4_t70" reading_order_no="69" segment_no="14" tag_type="text">4</text>
</page>
<page number="5" position="absolute" top="0" left="0" height="792" width="612">
	<fontspec id="font20" size="10" family="CMEX10" color="#000000"/>
<text top="72" left="108" width="347" height="13" font="font4" id="p5_t1" reading_order_no="0" segment_no="0" tag_type="text">be adapted. Referring to [24], we employ the Indian buffet process (IBP) prior on s ( l )<a href="deeplearning_paper5.html#11">[24], </a>we employ the Indian buffet process (IBP) prior on</text>
<text top="80" left="447" width="3" height="6" font="font10" id="p5_t2" reading_order_no="1" segment_no="0" tag_type="text">i</text>
<text top="76" left="458" width="46" height="9" font="font4" id="p5_t3" reading_order_no="2" segment_no="0" tag_type="text">to learn the</text>
<text top="86" left="108" width="348" height="10" font="font4" id="p5_t4" reading_order_no="3" segment_no="0" tag_type="text">effective number of communities given a sufficiently large truncation parameter G l , i.e.</text>
<text top="106" left="246" width="15" height="13" font="font8" id="p5_t5" reading_order_no="4" segment_no="1" tag_type="formula">π ( l )</text>
<text top="114" left="252" width="7" height="6" font="font10" id="p5_t6" reading_order_no="5" segment_no="1" tag_type="formula">ig</text>
<text top="110" left="271" width="8" height="9" font="font9" id="p5_t7" reading_order_no="6" segment_no="1" tag_type="formula">=</text>
<text top="110" left="289" width="22" height="9" font="font4" id="p5_t8" reading_order_no="7" segment_no="1" tag_type="formula">logit (</text>
<text top="99" left="316" width="4" height="6" font="font10" id="p5_t9" reading_order_no="8" segment_no="1" tag_type="formula">g</text>
<text top="107" left="312" width="13" height="4" font="font20" id="p5_t10" reading_order_no="9" segment_no="1" tag_type="formula">Y</text>
<text top="124" left="311" width="15" height="6" font="font10" id="p5_t11" reading_order_no="10" segment_no="1" tag_type="formula">h =1</text>
<text top="106" left="327" width="14" height="13" font="font8" id="p5_t12" reading_order_no="11" segment_no="1" tag_type="formula">v ( l )</text>
<text top="110" left="332" width="17" height="11" font="font9" id="p5_t13" reading_order_no="12" segment_no="1" tag_type="formula">ih ) ,</text>
<text top="110" left="492" width="12" height="9" font="font4" id="p5_t14" reading_order_no="13" segment_no="1" tag_type="text">(3)</text>
<text top="134" left="247" width="14" height="12" font="font8" id="p5_t15" reading_order_no="14" segment_no="2" tag_type="formula">s ( l )</text>
<text top="142" left="252" width="7" height="6" font="font10" id="p5_t16" reading_order_no="15" segment_no="2" tag_type="formula">ig</text>
<text top="136" left="271" width="8" height="9" font="font11" id="p5_t17" reading_order_no="16" segment_no="2" tag_type="formula">∼</text>
<text top="134" left="289" width="66" height="12" font="font4" id="p5_t18" reading_order_no="17" segment_no="2" tag_type="formula">Bernoulli ( σ ( π ( l )</text>
<text top="137" left="346" width="20" height="11" font="font9" id="p5_t19" reading_order_no="18" segment_no="2" tag_type="formula">ig )) .</text>
<text top="137" left="492" width="12" height="9" font="font4" id="p5_t20" reading_order_no="19" segment_no="2" tag_type="text">(4)</text>
<text top="152" left="108" width="105" height="13" font="font4" id="p5_t21" reading_order_no="20" segment_no="3" tag_type="text">Typically, the log odds π ( l )</text>
<text top="152" left="204" width="243" height="14" font="font4" id="p5_t22" reading_order_no="21" segment_no="3" tag_type="text">ig is generated using a stick-breaking construction, where v ( l )</text>
<text top="156" left="438" width="66" height="11" font="font4" id="p5_t23" reading_order_no="22" segment_no="3" tag_type="text">ih is drawn from</text>
<text top="167" left="108" width="396" height="9" font="font4" id="p5_t24" reading_order_no="23" segment_no="3" tag_type="text">a Beta distribution [30]. In our model we simplify such hierarchical prior structure by specifying</text>
<text top="177" left="108" width="296" height="12" font="font4" id="p5_t25" reading_order_no="24" segment_no="3" tag_type="text">a global v for all nodes. At each layer, the community membership s ( l )</text>
<text top="180" left="395" width="109" height="11" font="font4" id="p5_t26" reading_order_no="25" segment_no="3" tag_type="text">ig denotes whether node i</text>
<text top="192" left="108" width="396" height="10" font="font4" id="p5_t27" reading_order_no="26" segment_no="3" tag_type="text">belongs to community g , hence the size of each decoder layer G l can be explained as the number of</text>
<text top="203" left="108" width="396" height="9" font="font4" id="p5_t28" reading_order_no="27" segment_no="3" tag_type="text">communities. Additionally, the proposed HVAE architecture enables our model to detect community</text>
<text top="214" left="108" width="396" height="9" font="font4" id="p5_t29" reading_order_no="28" segment_no="3" tag_type="text">structures at multiple levels of granularities. Letting the layer sizes G l be downward increasing, the</text>
<text top="225" left="108" width="396" height="9" font="font4" id="p5_t30" reading_order_no="29" segment_no="3" tag_type="text">top layers indicate the coarse-grained communities and the bottom layers indicate the fine-grained</text>
<text top="236" left="108" width="54" height="9" font="font4" id="p5_t31" reading_order_no="30" segment_no="3" tag_type="text">communities.</text>
<text top="258" left="108" width="90" height="9" font="font1" id="p5_t32" reading_order_no="31" segment_no="4" tag_type="text">Node random factors</text>
<text top="258" left="208" width="296" height="9" font="font4" id="p5_t33" reading_order_no="32" segment_no="4" tag_type="text">Considering the prevalent power-law of degrees, we propose the Dirichlet</text>
<text top="268" left="108" width="99" height="13" font="font4" id="p5_t34" reading_order_no="33" segment_no="4" tag_type="text">node random factors γ ( l )</text>
<text top="268" left="198" width="29" height="14" font="font4" id="p5_t35" reading_order_no="34" segment_no="4" tag_type="text">i , δ ( l )</text>
<text top="276" left="218" width="3" height="6" font="font10" id="p5_t36" reading_order_no="35" segment_no="4" tag_type="text">i</text>
<text top="270" left="230" width="275" height="12" font="font11" id="p5_t37" reading_order_no="36" segment_no="4" tag_type="text">∈ R G l , so the sparse distributions of degrees can be modeled flexibly,</text>
<text top="283" left="108" width="12" height="9" font="font4" id="p5_t38" reading_order_no="37" segment_no="4" tag_type="text">i.e.</text>
<text top="293" left="199" width="15" height="12" font="font14" id="p5_t39" reading_order_no="38" segment_no="5" tag_type="formula">γ ( l )</text>
<text top="301" left="206" width="3" height="6" font="font10" id="p5_t40" reading_order_no="39" segment_no="5" tag_type="formula">i</text>
<text top="296" left="225" width="8" height="9" font="font11" id="p5_t41" reading_order_no="40" segment_no="5" tag_type="formula">∼</text>
<text top="293" left="243" width="53" height="13" font="font4" id="p5_t42" reading_order_no="41" segment_no="5" tag_type="formula">Dirichlet ( ξ ( l )</text>
<text top="301" left="287" width="3" height="6" font="font10" id="p5_t43" reading_order_no="42" segment_no="5" tag_type="formula">i</text>
<text top="293" left="299" width="24" height="12" font="font9" id="p5_t44" reading_order_no="43" segment_no="5" tag_type="formula">+ s ( l )</text>
<text top="301" left="314" width="3" height="6" font="font10" id="p5_t45" reading_order_no="44" segment_no="5" tag_type="formula">i</text>
<text top="294" left="335" width="39" height="12" font="font8" id="p5_t46" reading_order_no="45" segment_no="5" tag_type="formula">f ( W ( l − 1)</text>
<text top="301" left="355" width="4" height="6" font="font10" id="p5_t47" reading_order_no="46" segment_no="5" tag_type="formula">γ</text>
<text top="293" left="375" width="25" height="12" font="font14" id="p5_t48" reading_order_no="47" segment_no="5" tag_type="formula">γ ( l − 1)</text>
<text top="301" left="381" width="3" height="6" font="font10" id="p5_t49" reading_order_no="48" segment_no="5" tag_type="formula">i</text>
<text top="296" left="401" width="10" height="9" font="font9" id="p5_t50" reading_order_no="49" segment_no="5" tag_type="formula">)) ,</text>
<text top="297" left="492" width="12" height="9" font="font4" id="p5_t51" reading_order_no="50" segment_no="5" tag_type="text">(5)</text>
<text top="312" left="200" width="14" height="12" font="font14" id="p5_t52" reading_order_no="51" segment_no="6" tag_type="formula">δ ( l )</text>
<text top="320" left="206" width="3" height="6" font="font10" id="p5_t53" reading_order_no="52" segment_no="6" tag_type="formula">i</text>
<text top="314" left="225" width="8" height="9" font="font11" id="p5_t54" reading_order_no="53" segment_no="6" tag_type="formula">∼</text>
<text top="312" left="243" width="55" height="12" font="font4" id="p5_t55" reading_order_no="54" segment_no="6" tag_type="formula">Dirichlet ( ψ ( l )</text>
<text top="320" left="290" width="3" height="6" font="font10" id="p5_t56" reading_order_no="55" segment_no="6" tag_type="formula">i</text>
<text top="312" left="301" width="24" height="12" font="font9" id="p5_t57" reading_order_no="56" segment_no="6" tag_type="formula">+ s ( l )</text>
<text top="320" left="317" width="3" height="6" font="font10" id="p5_t58" reading_order_no="57" segment_no="6" tag_type="formula">i</text>
<text top="311" left="338" width="39" height="13" font="font8" id="p5_t59" reading_order_no="58" segment_no="6" tag_type="formula">f ( W ( l − 1)</text>
<text top="320" left="358" width="4" height="6" font="font10" id="p5_t60" reading_order_no="59" segment_no="6" tag_type="formula">δ</text>
<text top="311" left="377" width="25" height="13" font="font14" id="p5_t61" reading_order_no="60" segment_no="6" tag_type="formula">δ ( l − 1)</text>
<text top="320" left="383" width="3" height="6" font="font10" id="p5_t62" reading_order_no="61" segment_no="6" tag_type="formula">i</text>
<text top="315" left="402" width="11" height="9" font="font9" id="p5_t63" reading_order_no="62" segment_no="6" tag_type="formula">)) ,<a href="deeplearning_paper5.html#11">[30]. </a>In our model we simplify such hierarchical prior structure by specifying</text>
<text top="315" left="492" width="12" height="9" font="font4" id="p5_t64" reading_order_no="63" segment_no="6" tag_type="text">(6)</text>
<text top="329" left="108" width="40" height="12" font="font4" id="p5_t65" reading_order_no="64" segment_no="7" tag_type="text">where ξ ( l )</text>
<text top="337" left="139" width="3" height="6" font="font10" id="p5_t66" reading_order_no="65" segment_no="7" tag_type="text">i</text>
<text top="329" left="151" width="33" height="12" font="font4" id="p5_t67" reading_order_no="66" segment_no="7" tag_type="text">and ψ ( l )</text>
<text top="337" left="175" width="3" height="6" font="font10" id="p5_t68" reading_order_no="67" segment_no="7" tag_type="text">i</text>
<text top="329" left="187" width="186" height="12" font="font4" id="p5_t69" reading_order_no="68" segment_no="7" tag_type="text">are prior parameters to be specified, and W ( l − 1)</text>
<text top="337" left="354" width="4" height="6" font="font10" id="p5_t70" reading_order_no="69" segment_no="7" tag_type="text">γ</text>
<text top="329" left="374" width="33" height="12" font="font4" id="p5_t71" reading_order_no="70" segment_no="7" tag_type="text">, W ( l − 1)</text>
<text top="337" left="388" width="4" height="6" font="font10" id="p5_t72" reading_order_no="71" segment_no="7" tag_type="text">δ</text>
<text top="330" left="411" width="93" height="12" font="font11" id="p5_t73" reading_order_no="72" segment_no="7" tag_type="text">∈ R G l × G l − 1 are weight</text>
<text top="344" left="108" width="364" height="13" font="font4" id="p5_t74" reading_order_no="73" segment_no="7" tag_type="text">matrices. Note that the social reach factors are dependent on the community membership s ( l )</text>
<text top="352" left="464" width="3" height="6" font="font10" id="p5_t75" reading_order_no="74" segment_no="7" tag_type="text">i</text>
<text top="348" left="475" width="30" height="9" font="font4" id="p5_t76" reading_order_no="75" segment_no="7" tag_type="text">as well,</text>
<text top="358" left="108" width="396" height="9" font="font4" id="p5_t77" reading_order_no="76" segment_no="7" tag_type="text">which can be explained as only the random effects within the communities the node belongs to are</text>
<text top="369" left="108" width="149" height="9" font="font4" id="p5_t78" reading_order_no="77" segment_no="7" tag_type="text">involved in the latent representations.</text>
<text top="385" left="108" width="225" height="12" font="font4" id="p5_t79" reading_order_no="78" segment_no="8" tag_type="text">At the output layer ( l = L ), the latent positions z ( L )</text>
<text top="393" left="321" width="3" height="6" font="font10" id="p5_t80" reading_order_no="79" segment_no="8" tag_type="text">i</text>
<text top="385" left="337" width="126" height="12" font="font4" id="p5_t81" reading_order_no="80" segment_no="8" tag_type="text">and node random factors γ ( L )</text>
<text top="393" left="451" width="3" height="6" font="font10" id="p5_t82" reading_order_no="81" segment_no="8" tag_type="text">i</text>
<text top="385" left="464" width="23" height="12" font="font4" id="p5_t83" reading_order_no="82" segment_no="8" tag_type="text">, δ ( L )</text>
<text top="393" left="476" width="3" height="6" font="font10" id="p5_t84" reading_order_no="83" segment_no="8" tag_type="text">i</text>
<text top="388" left="492" width="12" height="9" font="font4" id="p5_t85" reading_order_no="84" segment_no="8" tag_type="text">are</text>
<text top="399" left="108" width="397" height="10" font="font4" id="p5_t86" reading_order_no="85" segment_no="8" tag_type="text">transformed from dimension G L − 1 to D through a full connection layer, where weights are column-</text>
<text top="410" left="108" width="396" height="9" font="font4" id="p5_t87" reading_order_no="86" segment_no="8" tag_type="text">wise summing to one. Such transformation also changes the interpretation of the layer size, from</text>
<text top="421" left="108" width="396" height="9" font="font4" id="p5_t88" reading_order_no="87" segment_no="8" tag_type="text">the number of communities to the dimension of the latent space. Last, the adjacency matrix is</text>
<text top="432" left="108" width="110" height="9" font="font4" id="p5_t89" reading_order_no="88" segment_no="8" tag_type="text">reconstructed using Eq. (1).</text>
<text top="456" left="108" width="12" height="9" font="font1" id="p5_t90" reading_order_no="89" segment_no="9" tag_type="title">4.2</text>
<text top="456" left="130" width="58" height="9" font="font1" id="p5_t91" reading_order_no="90" segment_no="9" tag_type="title">GCN encoder</text>
<text top="476" left="108" width="396" height="9" font="font4" id="p5_t92" reading_order_no="91" segment_no="10" tag_type="text">The proposed DLSM employs a deep encoder as a non-iterative recognition model to infer the</text>
<text top="487" left="108" width="396" height="9" font="font4" id="p5_t93" reading_order_no="92" segment_no="10" tag_type="text">parameters of posterior distributions. Assuming the mean-field approximation of the variational</text>
<text top="497" left="108" width="396" height="10" font="font4" id="p5_t94" reading_order_no="93" segment_no="10" tag_type="text">distributions, the true joint posterior of the latent variables p θ (Θ | A , X ) can be approximated by a</text>
<text top="505" left="108" width="225" height="14" font="font4" id="p5_t95" reading_order_no="94" segment_no="10" tag_type="text">variational posterior q φ (Θ) , where Θ = { z i , s i , γ i , δ i } n</text>
<text top="508" left="328" width="176" height="11" font="font4" id="p5_t96" reading_order_no="95" segment_no="10" tag_type="text">i =1 , θ and φ denote the generative (decoder)</text>
<text top="519" left="108" width="396" height="9" font="font4" id="p5_t97" reading_order_no="96" segment_no="10" tag_type="text">and inference (encoder) parameters to be trained, respectively. Then, the variational posterior is given</text>
<text top="530" left="108" width="8" height="9" font="font4" id="p5_t98" reading_order_no="97" segment_no="10" tag_type="text">as</text>
<text top="553" left="180" width="64" height="9" font="font8" id="p5_t99" reading_order_no="98" segment_no="11" tag_type="formula">q φ ( z , s , γ , δ ) =</text>
<text top="542" left="250" width="5" height="6" font="font10" id="p5_t100" reading_order_no="99" segment_no="11" tag_type="formula">n</text>
<text top="550" left="246" width="13" height="4" font="font20" id="p5_t101" reading_order_no="100" segment_no="11" tag_type="formula">Y</text>
<text top="566" left="246" width="13" height="6" font="font10" id="p5_t102" reading_order_no="101" segment_no="11" tag_type="formula">i =1</text>
<text top="542" left="264" width="5" height="6" font="font10" id="p5_t103" reading_order_no="102" segment_no="11" tag_type="formula">L</text>
<text top="550" left="261" width="13" height="4" font="font20" id="p5_t104" reading_order_no="103" segment_no="11" tag_type="formula">Y</text>
<text top="567" left="261" width="12" height="6" font="font10" id="p5_t105" reading_order_no="104" segment_no="11" tag_type="formula">l =1</text>
<text top="549" left="275" width="28" height="13" font="font8" id="p5_t106" reading_order_no="105" segment_no="11" tag_type="formula">q φ ( z ( l )</text>
<text top="549" left="295" width="27" height="14" font="font11" id="p5_t107" reading_order_no="106" segment_no="11" tag_type="formula">i | h ( l )</text>
<text top="557" left="313" width="3" height="6" font="font10" id="p5_t108" reading_order_no="107" segment_no="11" tag_type="formula">i</text>
<text top="549" left="323" width="29" height="13" font="font8" id="p5_t109" reading_order_no="108" segment_no="11" tag_type="formula">, z ( l − 1)</text>
<text top="557" left="333" width="3" height="6" font="font10" id="p5_t110" reading_order_no="109" segment_no="11" tag_type="formula">i</text>
<text top="549" left="352" width="45" height="13" font="font9" id="p5_t111" reading_order_no="110" segment_no="11" tag_type="formula">) q φ ( s i | h ( l )</text>
<text top="549" left="388" width="40" height="14" font="font8" id="p5_t112" reading_order_no="111" segment_no="11" tag_type="formula">i , π ( l − 1)</text>
<text top="557" left="409" width="3" height="6" font="font10" id="p5_t113" reading_order_no="112" segment_no="11" tag_type="formula">i</text>
<text top="553" left="428" width="4" height="9" font="font9" id="p5_t114" reading_order_no="113" segment_no="11" tag_type="formula">)</text>
<text top="577" left="244" width="42" height="13" font="font8" id="p5_t115" reading_order_no="114" segment_no="11" tag_type="formula">q φ ( γ i | h ( l )</text>
<text top="585" left="277" width="3" height="6" font="font10" id="p5_t116" reading_order_no="115" segment_no="11" tag_type="formula">i</text>
<text top="576" left="287" width="29" height="13" font="font8" id="p5_t117" reading_order_no="116" segment_no="11" tag_type="formula">, γ ( l − 1)</text>
<text top="585" left="298" width="3" height="6" font="font10" id="p5_t118" reading_order_no="117" segment_no="11" tag_type="formula">i</text>
<text top="577" left="317" width="44" height="13" font="font9" id="p5_t119" reading_order_no="118" segment_no="11" tag_type="formula">) q φ ( δ i | h ( l )</text>
<text top="576" left="353" width="38" height="15" font="font8" id="p5_t120" reading_order_no="119" segment_no="11" tag_type="formula">i , δ ( l − 1)</text>
<text top="585" left="372" width="3" height="6" font="font10" id="p5_t121" reading_order_no="120" segment_no="11" tag_type="formula">i</text>
<text top="580" left="392" width="6" height="9" font="font9" id="p5_t122" reading_order_no="121" segment_no="11" tag_type="formula">) ,</text>
<text top="580" left="492" width="12" height="9" font="font4" id="p5_t123" reading_order_no="122" segment_no="11" tag_type="text">(7)</text>
<text top="595" left="108" width="42" height="12" font="font4" id="p5_t124" reading_order_no="123" segment_no="12" tag_type="text">where h ( l )</text>
<text top="603" left="141" width="3" height="6" font="font10" id="p5_t125" reading_order_no="124" segment_no="12" tag_type="text">i</text>
<text top="596" left="153" width="301" height="12" font="font11" id="p5_t126" reading_order_no="125" segment_no="12" tag_type="text">∈ R K l is the output of the encoder and K l denotes the size of the l -th layer.</text>
<text top="614" left="108" width="396" height="9" font="font4" id="p5_t127" reading_order_no="126" segment_no="13" tag_type="text">GCN has been proved effective in learning the topology of non-Euclidean data, and thus is an ideal</text>
<text top="625" left="108" width="386" height="9" font="font4" id="p5_t128" reading_order_no="127" segment_no="13" tag_type="text">choice for the encoder of our model. Referring to [17], we propose the directed GCN operator as</text>
<text top="638" left="228" width="136" height="12" font="font1" id="p5_t129" reading_order_no="128" segment_no="14" tag_type="formula">H ( l +1) = f ( ˜ D out ˜ A ˜ D in H ( l ) W ( l ) ) .</text>
<text top="641" left="492" width="12" height="9" font="font4" id="p5_t130" reading_order_no="129" segment_no="14" tag_type="text">(8)</text>
<text top="654" left="108" width="396" height="12" font="font4" id="p5_t131" reading_order_no="130" segment_no="15" tag_type="text">Here ˜ A = A + I n and I n is the n -dimensional identity matrix. ˜ D out and ˜ D in are diagonal matrices</text>
<text top="667" left="108" width="396" height="12" font="font4" id="p5_t132" reading_order_no="131" segment_no="15" tag_type="text">with elements as the out- and in-degrees of ˜ A , respectively. H (0) = X if X is available and H (0) = I n</text>
<text top="681" left="108" width="396" height="9" font="font4" id="p5_t133" reading_order_no="132" segment_no="15" tag_type="text">if not. During inference, the hidden states are passed to the corresponding layer of the decoder</text>
<text top="691" left="108" width="396" height="9" font="font4" id="p5_t134" reading_order_no="133" segment_no="15" tag_type="text">and then combined with the prior information from previous layers to generate the parameters of</text>
<text top="702" left="108" width="396" height="9" font="font4" id="p5_t135" reading_order_no="134" segment_no="15" tag_type="text">variational distributions. Note that the vanilla GCN used here can be substituted by any other GNN</text>
<text top="713" left="108" width="88" height="9" font="font4" id="p5_t136" reading_order_no="135" segment_no="15" tag_type="text">for directed networks.</text>
<text top="743" left="304" width="5" height="9" font="font4" id="p5_t137" reading_order_no="136" segment_no="16" tag_type="text">5</text>
</page>
<page number="6" position="absolute" top="0" left="0" height="792" width="612">
	<fontspec id="font21" size="10" family="CMBX10" color="#000000"/>
<text top="74" left="108" width="6" height="11" font="font3" id="p6_t1" reading_order_no="0" segment_no="0" tag_type="title">5</text>
<text top="74" left="126" width="48" height="11" font="font3" id="p6_t2" reading_order_no="1" segment_no="0" tag_type="title">Inference</text>
<text top="101" left="108" width="397" height="9" font="font4" id="p6_t3" reading_order_no="2" segment_no="1" tag_type="text">We now introduce our fast inference method using the stochastic gradient variational Bayes (SGVB)</text>
<text top="112" left="108" width="396" height="9" font="font4" id="p6_t4" reading_order_no="3" segment_no="1" tag_type="text">algorithm [14]. Compared with the iterative methods such as MCMC adopted by traditional Bayesian<a href="deeplearning_paper5.html#10">[14]. </a>Compared with the iterative methods such as MCMC adopted by traditional Bayesian</text>
<text top="123" left="108" width="396" height="9" font="font4" id="p6_t5" reading_order_no="4" segment_no="1" tag_type="text">random graph approaches, SGVB is much more efficient and scalable. Such method requires</text>
<text top="134" left="108" width="396" height="9" font="font4" id="p6_t6" reading_order_no="5" segment_no="1" tag_type="text">differential Monte Carlo expectations to perform backpropagation, thus the reparameterization trick</text>
<text top="145" left="108" width="173" height="9" font="font4" id="p6_t7" reading_order_no="6" segment_no="1" tag_type="text">for each of the latent variables is leveraged.</text>
<text top="159" left="108" width="44" height="11" font="font4" id="p6_t8" reading_order_no="7" segment_no="2" tag_type="text">Letting z ∗</text>
<text top="159" left="159" width="345" height="12" font="font11" id="p6_t9" reading_order_no="8" segment_no="2" tag_type="text">∈ R G l denote a vector with standard Normal elements, the latent positions are</text>
<text top="171" left="108" width="95" height="13" font="font4" id="p6_t10" reading_order_no="9" segment_no="2" tag_type="text">reparametrized as z ( l )</text>
<text top="179" left="194" width="3" height="6" font="font10" id="p6_t11" reading_order_no="10" segment_no="2" tag_type="text">i</text>
<text top="174" left="212" width="8" height="9" font="font9" id="p6_t12" reading_order_no="11" segment_no="2" tag_type="text">=</text>
<text top="171" left="228" width="16" height="12" font="font9" id="p6_t13" reading_order_no="12" segment_no="2" tag_type="text">ˆ µ ( l )</text>
<text top="179" left="235" width="3" height="6" font="font10" id="p6_t14" reading_order_no="13" segment_no="2" tag_type="text">i</text>
<text top="171" left="245" width="28" height="12" font="font9" id="p6_t15" reading_order_no="14" segment_no="2" tag_type="text">( z ( l − 1)</text>
<text top="179" left="254" width="3" height="6" font="font10" id="p6_t16" reading_order_no="15" segment_no="2" tag_type="text">i</text>
<text top="171" left="274" width="28" height="12" font="font8" id="p6_t17" reading_order_no="16" segment_no="2" tag_type="text">, s ( l − 1)</text>
<text top="179" left="284" width="3" height="6" font="font10" id="p6_t18" reading_order_no="17" segment_no="2" tag_type="text">i</text>
<text top="171" left="303" width="20" height="12" font="font8" id="p6_t19" reading_order_no="18" segment_no="2" tag_type="text">, h ( l )</text>
<text top="171" left="314" width="46" height="14" font="font9" id="p6_t20" reading_order_no="19" segment_no="2" tag_type="text">i ) + ˆ σ ( l )</text>
<text top="171" left="351" width="38" height="14" font="font9" id="p6_t21" reading_order_no="20" segment_no="2" tag_type="text">i ( z ( l − 1)</text>
<text top="179" left="370" width="3" height="6" font="font10" id="p6_t22" reading_order_no="21" segment_no="2" tag_type="text">i</text>
<text top="171" left="390" width="28" height="12" font="font8" id="p6_t23" reading_order_no="22" segment_no="2" tag_type="text">, s ( l − 1)</text>
<text top="179" left="399" width="3" height="6" font="font10" id="p6_t24" reading_order_no="23" segment_no="2" tag_type="text">i</text>
<text top="171" left="419" width="20" height="12" font="font8" id="p6_t25" reading_order_no="24" segment_no="2" tag_type="text">, h ( l )</text>
<text top="174" left="430" width="13" height="11" font="font9" id="p6_t26" reading_order_no="25" segment_no="2" tag_type="text">i )</text>
<text top="172" left="460" width="44" height="12" font="font14" id="p6_t27" reading_order_no="26" segment_no="2" tag_type="text">z ∗ , where</text>
<text top="185" left="108" width="16" height="13" font="font9" id="p6_t28" reading_order_no="27" segment_no="2" tag_type="text">ˆ µ ( l )</text>
<text top="185" left="115" width="38" height="14" font="font9" id="p6_t29" reading_order_no="28" segment_no="2" tag_type="text">i ( z ( l − 1)</text>
<text top="193" left="134" width="3" height="6" font="font10" id="p6_t30" reading_order_no="29" segment_no="2" tag_type="text">i</text>
<text top="185" left="154" width="28" height="13" font="font8" id="p6_t31" reading_order_no="30" segment_no="2" tag_type="text">, s ( l − 1)</text>
<text top="193" left="163" width="3" height="6" font="font10" id="p6_t32" reading_order_no="31" segment_no="2" tag_type="text">i</text>
<text top="185" left="183" width="20" height="13" font="font8" id="p6_t33" reading_order_no="32" segment_no="2" tag_type="text">, h ( l )</text>
<text top="185" left="194" width="34" height="14" font="font9" id="p6_t34" reading_order_no="33" segment_no="2" tag_type="text">i ) , ˆ σ ( l )</text>
<text top="193" left="219" width="3" height="6" font="font10" id="p6_t35" reading_order_no="34" segment_no="2" tag_type="text">i</text>
<text top="185" left="229" width="28" height="13" font="font9" id="p6_t36" reading_order_no="35" segment_no="2" tag_type="text">( z ( l − 1)</text>
<text top="193" left="238" width="3" height="6" font="font10" id="p6_t37" reading_order_no="36" segment_no="2" tag_type="text">i</text>
<text top="185" left="258" width="28" height="13" font="font8" id="p6_t38" reading_order_no="37" segment_no="2" tag_type="text">, s ( l − 1)</text>
<text top="193" left="268" width="3" height="6" font="font10" id="p6_t39" reading_order_no="38" segment_no="2" tag_type="text">i</text>
<text top="185" left="287" width="20" height="13" font="font8" id="p6_t40" reading_order_no="39" segment_no="2" tag_type="text">, h ( l )</text>
<text top="189" left="298" width="160" height="10" font="font9" id="p6_t41" reading_order_no="40" segment_no="2" tag_type="text">i ) are variational posterior parameters.</text>
<text top="205" left="108" width="183" height="13" font="font4" id="p6_t42" reading_order_no="41" segment_no="3" tag_type="text">Following [23], the Bernoulli posterior p θ ( s ( l )</text>
<text top="208" left="282" width="222" height="11" font="font9" id="p6_t43" reading_order_no="42" segment_no="3" tag_type="text">ig ) is approximated by the Binary Concrete distribution</text>
<text top="219" left="108" width="34" height="9" font="font4" id="p6_t44" reading_order_no="43" segment_no="3" tag_type="text">[22], i.e.</text>
<text top="248" left="224" width="13" height="12" font="font9" id="p6_t45" reading_order_no="44" segment_no="4" tag_type="formula">˜ ( l )</text>
<text top="251" left="228" width="21" height="11" font="font9" id="p6_t46" reading_order_no="45" segment_no="4" tag_type="formula">ig =</text>
<text top="240" left="252" width="15" height="12" font="font9" id="p6_t47" reading_order_no="46" segment_no="4" tag_type="formula">ˆ π ( l )</text>
<text top="239" left="258" width="38" height="15" font="font9" id="p6_t48" reading_order_no="47" segment_no="4" tag_type="formula">ig ( s ( l − 1)</text>
<text top="248" left="277" width="3" height="6" font="font10" id="p6_t49" reading_order_no="48" segment_no="4" tag_type="formula">i</text>
<text top="240" left="296" width="20" height="12" font="font8" id="p6_t50" reading_order_no="49" segment_no="4" tag_type="formula">, h ( l )</text>
<text top="248" left="307" width="3" height="6" font="font10" id="p6_t51" reading_order_no="50" segment_no="4" tag_type="formula">i</text>
<text top="243" left="317" width="47" height="9" font="font9" id="p6_t52" reading_order_no="51" segment_no="4" tag_type="formula">) + logit ( u )</text>
<text top="258" left="305" width="6" height="9" font="font8" id="p6_t53" reading_order_no="52" segment_no="4" tag_type="formula">λ</text>
<text top="251" left="366" width="3" height="9" font="font8" id="p6_t54" reading_order_no="53" segment_no="4" tag_type="formula">,</text>
<text top="251" left="492" width="12" height="9" font="font4" id="p6_t55" reading_order_no="54" segment_no="4" tag_type="text">(9)</text>
<text top="277" left="108" width="95" height="12" font="font4" id="p6_t56" reading_order_no="55" segment_no="5" tag_type="text">where u ∼ U (0 , 1) , ˆ π ( l )</text>
<text top="277" left="194" width="37" height="14" font="font9" id="p6_t57" reading_order_no="56" segment_no="5" tag_type="text">ig ( s ( l − 1)</text>
<text top="285" left="212" width="3" height="6" font="font10" id="p6_t58" reading_order_no="57" segment_no="5" tag_type="text">i</text>
<text top="277" left="232" width="20" height="12" font="font8" id="p6_t59" reading_order_no="58" segment_no="5" tag_type="text">, h ( l )</text>
<text top="278" left="243" width="261" height="13" font="font9" id="p6_t60" reading_order_no="59" segment_no="5" tag_type="text">i ) is a variational posterior parameter, λ ∈ R + is the temperature</text>
<text top="292" left="108" width="112" height="13" font="font4" id="p6_t61" reading_order_no="60" segment_no="5" tag_type="text">to be specified, and then s ( l )</text>
<text top="292" left="212" width="46" height="14" font="font9" id="p6_t62" reading_order_no="61" segment_no="5" tag_type="text">ig = σ (˜ s ( l )</text>
<text top="296" left="249" width="15" height="10" font="font9" id="p6_t63" reading_order_no="62" segment_no="5" tag_type="text">ig ) .</text>
<text top="312" left="108" width="396" height="9" font="font4" id="p6_t64" reading_order_no="63" segment_no="6" tag_type="text">Referring to the recent literature [12], we use multiple normalized Gamma variables with unified rate</text>
<text top="322" left="108" width="228" height="13" font="font4" id="p6_t65" reading_order_no="64" segment_no="6" tag_type="text">parameters to compose the Dirichlet distributions p θ ( γ ( l )</text>
<text top="322" left="327" width="60" height="14" font="font9" id="p6_t66" reading_order_no="65" segment_no="6" tag_type="text">i ) and p θ ( δ ( l )</text>
<text top="330" left="378" width="3" height="6" font="font10" id="p6_t67" reading_order_no="66" segment_no="6" tag_type="text">i</text>
<text top="326" left="388" width="21" height="9" font="font9" id="p6_t68" reading_order_no="67" segment_no="6" tag_type="text">) , i.e.</text>
<text top="349" left="207" width="15" height="12" font="font9" id="p6_t69" reading_order_no="68" segment_no="7" tag_type="formula">˜ γ ( l )</text>
<text top="357" left="213" width="3" height="6" font="font10" id="p6_t70" reading_order_no="69" segment_no="7" tag_type="formula">i</text>
<text top="352" left="232" width="8" height="9" font="font11" id="p6_t71" reading_order_no="70" segment_no="7" tag_type="formula">∼</text>
<text top="352" left="250" width="44" height="11" font="font4" id="p6_t72" reading_order_no="71" segment_no="7" tag_type="formula">Gamma ( ˆ ξ i</text>
<text top="347" left="294" width="39" height="14" font="font9" id="p6_t73" reading_order_no="72" segment_no="7" tag_type="formula">( l ) ( γ ( l − 1)</text>
<text top="357" left="314" width="3" height="6" font="font10" id="p6_t74" reading_order_no="73" segment_no="7" tag_type="formula">i</text>
<text top="349" left="333" width="29" height="12" font="font8" id="p6_t75" reading_order_no="74" segment_no="7" tag_type="formula">, s ( l − 1)</text>
<text top="357" left="343" width="3" height="6" font="font10" id="p6_t76" reading_order_no="75" segment_no="7" tag_type="formula">i</text>
<text top="349" left="363" width="19" height="12" font="font8" id="p6_t77" reading_order_no="76" segment_no="7" tag_type="formula">, h ( l )</text>
<text top="352" left="374" width="30" height="11" font="font9" id="p6_t78" reading_order_no="77" segment_no="7" tag_type="formula">i ) , 1 ) ,</text>
<text top="353" left="487" width="17" height="9" font="font4" id="p6_t79" reading_order_no="78" segment_no="7" tag_type="text">(10)</text>
<text top="367" left="208" width="14" height="14" font="font9" id="p6_t80" reading_order_no="79" segment_no="8" tag_type="formula">˜ δ ( l )</text>
<text top="376" left="213" width="3" height="6" font="font10" id="p6_t81" reading_order_no="80" segment_no="8" tag_type="formula">i</text>
<text top="371" left="232" width="8" height="9" font="font11" id="p6_t82" reading_order_no="81" segment_no="8" tag_type="formula">∼</text>
<text top="372" left="250" width="44" height="9" font="font4" id="p6_t83" reading_order_no="82" segment_no="8" tag_type="formula">Gamma ( ˆ</text>
<text top="372" left="286" width="11" height="10" font="font14" id="p6_t84" reading_order_no="83" segment_no="8" tag_type="formula">ψ i</text>
<text top="367" left="297" width="37" height="14" font="font9" id="p6_t85" reading_order_no="84" segment_no="8" tag_type="formula">( l ) ( δ ( l − 1)</text>
<text top="376" left="316" width="3" height="6" font="font10" id="p6_t86" reading_order_no="85" segment_no="8" tag_type="formula">i</text>
<text top="368" left="335" width="29" height="13" font="font8" id="p6_t87" reading_order_no="86" segment_no="8" tag_type="formula">, s ( l − 1)</text>
<text top="376" left="345" width="3" height="6" font="font10" id="p6_t88" reading_order_no="87" segment_no="8" tag_type="formula">i</text>
<text top="368" left="364" width="20" height="13" font="font8" id="p6_t89" reading_order_no="88" segment_no="8" tag_type="formula">, h ( l )</text>
<text top="376" left="375" width="3" height="6" font="font10" id="p6_t90" reading_order_no="89" segment_no="8" tag_type="formula">i</text>
<text top="372" left="385" width="21" height="9" font="font9" id="p6_t91" reading_order_no="90" segment_no="8" tag_type="formula">) , 1 ) ,</text>
<text top="372" left="487" width="17" height="9" font="font4" id="p6_t92" reading_order_no="91" segment_no="8" tag_type="text">(11)</text>
<text top="396" left="108" width="35" height="13" font="font4" id="p6_t93" reading_order_no="92" segment_no="9" tag_type="text">where ˆ ξ i</text>
<text top="393" left="143" width="39" height="14" font="font9" id="p6_t94" reading_order_no="93" segment_no="9" tag_type="text">( l ) ( γ ( l − 1)</text>
<text top="403" left="163" width="3" height="6" font="font10" id="p6_t95" reading_order_no="94" segment_no="9" tag_type="text">i</text>
<text top="395" left="183" width="28" height="12" font="font8" id="p6_t96" reading_order_no="95" segment_no="9" tag_type="text">, s ( l − 1)</text>
<text top="403" left="192" width="3" height="6" font="font10" id="p6_t97" reading_order_no="96" segment_no="9" tag_type="text">i</text>
<text top="395" left="212" width="19" height="12" font="font8" id="p6_t98" reading_order_no="97" segment_no="9" tag_type="text">, h ( l )</text>
<text top="396" left="223" width="43" height="13" font="font9" id="p6_t99" reading_order_no="98" segment_no="9" tag_type="text">i ) and ˆ ψ i</text>
<text top="393" left="267" width="37" height="14" font="font9" id="p6_t100" reading_order_no="99" segment_no="9" tag_type="text">( l ) ( δ ( l − 1)</text>
<text top="403" left="285" width="3" height="6" font="font10" id="p6_t101" reading_order_no="100" segment_no="9" tag_type="text">i</text>
<text top="395" left="305" width="29" height="12" font="font8" id="p6_t102" reading_order_no="101" segment_no="9" tag_type="text">, s ( l − 1)</text>
<text top="403" left="315" width="3" height="6" font="font10" id="p6_t103" reading_order_no="102" segment_no="9" tag_type="text">i</text>
<text top="395" left="334" width="20" height="12" font="font8" id="p6_t104" reading_order_no="103" segment_no="9" tag_type="text">, h ( l )</text>
<text top="403" left="345" width="3" height="6" font="font10" id="p6_t105" reading_order_no="104" segment_no="9" tag_type="text">i</text>
<text top="398" left="355" width="151" height="10" font="font9" id="p6_t106" reading_order_no="105" segment_no="9" tag_type="text">) are variational posterior parameters.</text>
<text top="411" left="108" width="215" height="12" font="font4" id="p6_t107" reading_order_no="106" segment_no="9" tag_type="text">The node random factors are then derived from γ ( l )</text>
<text top="419" left="315" width="3" height="6" font="font10" id="p6_t108" reading_order_no="107" segment_no="9" tag_type="text">i</text>
<text top="411" left="328" width="27" height="12" font="font9" id="p6_t109" reading_order_no="108" segment_no="9" tag_type="text">= ˜ γ ( l )</text>
<text top="411" left="347" width="31" height="14" font="font8" id="p6_t110" reading_order_no="109" segment_no="9" tag_type="text">i / P n</text>
<text top="411" left="373" width="23" height="14" font="font9" id="p6_t111" reading_order_no="110" segment_no="9" tag_type="text">j ˜ γ ( l )</text>
<text top="411" left="387" width="29" height="14" font="font4" id="p6_t112" reading_order_no="111" segment_no="9" tag_type="text">j , δ ( l )</text>
<text top="419" left="408" width="3" height="6" font="font10" id="p6_t113" reading_order_no="112" segment_no="9" tag_type="text">i</text>
<text top="410" left="421" width="27" height="13" font="font9" id="p6_t114" reading_order_no="113" segment_no="9" tag_type="text">= ˜ δ ( l )</text>
<text top="411" left="439" width="31" height="14" font="font8" id="p6_t115" reading_order_no="114" segment_no="9" tag_type="text">i / P n</text>
<text top="419" left="465" width="3" height="6" font="font10" id="p6_t116" reading_order_no="115" segment_no="9" tag_type="text">j</text>
<text top="410" left="473" width="14" height="13" font="font9" id="p6_t117" reading_order_no="116" segment_no="9" tag_type="text">˜ δ ( l )</text>
<text top="414" left="478" width="26" height="11" font="font4" id="p6_t118" reading_order_no="117" segment_no="9" tag_type="text">j . In</text>
<text top="427" left="108" width="361" height="12" font="font4" id="p6_t119" reading_order_no="118" segment_no="9" tag_type="text">practice, the Dirichlet variables are magnified by n times to avoid too small values of γ ( l )</text>
<text top="435" left="460" width="3" height="6" font="font10" id="p6_t120" reading_order_no="119" segment_no="9" tag_type="text">i</text>
<text top="427" left="472" width="31" height="12" font="font4" id="p6_t121" reading_order_no="120" segment_no="9" tag_type="text">and δ ( l )</text>
<text top="435" left="495" width="3" height="6" font="font10" id="p6_t122" reading_order_no="121" segment_no="9" tag_type="text">i</text>
<text top="441" left="108" width="63" height="9" font="font4" id="p6_t123" reading_order_no="122" segment_no="9" tag_type="text">when n is large.</text>
<text top="457" left="108" width="396" height="9" font="font4" id="p6_t124" reading_order_no="123" segment_no="10" tag_type="text">In particular, the initial variational posterior parameters ( l = 0 ) are set as nonlinear combinations of</text>
<text top="468" left="108" width="17" height="12" font="font14" id="p6_t125" reading_order_no="124" segment_no="10" tag_type="text">h (1)</text>
<text top="476" left="115" width="3" height="6" font="font10" id="p6_t126" reading_order_no="125" segment_no="10" tag_type="text">i</text>
<text top="467" left="128" width="45" height="13" font="font4" id="p6_t127" reading_order_no="126" segment_no="10" tag_type="text">and h ( L − 1)</text>
<text top="476" left="151" width="3" height="6" font="font10" id="p6_t128" reading_order_no="127" segment_no="10" tag_type="text">i</text>
<text top="471" left="174" width="94" height="9" font="font4" id="p6_t129" reading_order_no="128" segment_no="10" tag_type="text">, as illustrated in Fig. 1.</text>
<text top="487" left="108" width="364" height="9" font="font4" id="p6_t130" reading_order_no="129" segment_no="11" tag_type="text">The loss function is defined by minimizing the negative evidence lower bound (ELBO), i.e.</text>
<text top="519" left="134" width="17" height="9" font="font11" id="p6_t131" reading_order_no="130" segment_no="12" tag_type="formula">L =</text>
<text top="509" left="157" width="5" height="6" font="font10" id="p6_t132" reading_order_no="131" segment_no="12" tag_type="formula">n</text>
<text top="517" left="153" width="14" height="4" font="font20" id="p6_t133" reading_order_no="132" segment_no="12" tag_type="formula">X</text>
<text top="533" left="153" width="13" height="6" font="font10" id="p6_t134" reading_order_no="133" segment_no="12" tag_type="formula">i =1</text>
<text top="509" left="173" width="5" height="6" font="font10" id="p6_t135" reading_order_no="134" segment_no="12" tag_type="formula">L<a href="deeplearning_paper5.html#11">[23], </a>the Bernoulli posterior</text>
<text top="517" left="169" width="14" height="4" font="font20" id="p6_t136" reading_order_no="135" segment_no="12" tag_type="formula">X</text>
<text top="534" left="170" width="12" height="6" font="font10" id="p6_t137" reading_order_no="136" segment_no="12" tag_type="formula">l =1</text>
<text top="516" left="183" width="48" height="13" font="font9" id="p6_t138" reading_order_no="137" segment_no="12" tag_type="formula">( KL [ q φ ( z ( l )</text>
<text top="516" left="223" width="46" height="14" font="font9" id="p6_t139" reading_order_no="138" segment_no="12" tag_type="formula">i ) k p θ ( z ( l )</text>
<text top="516" left="260" width="72" height="14" font="font9" id="p6_t140" reading_order_no="139" segment_no="12" tag_type="formula">i )] + KL [ q φ ( s ( l )</text>
<text top="524" left="323" width="3" height="6" font="font10" id="p6_t141" reading_order_no="140" segment_no="12" tag_type="formula">i</text>
<text top="516" left="333" width="36" height="13" font="font9" id="p6_t142" reading_order_no="141" segment_no="12" tag_type="formula">) k p θ ( s ( l )</text>
<text top="516" left="360" width="73" height="14" font="font9" id="p6_t143" reading_order_no="142" segment_no="12" tag_type="formula">i )] + KL [ q φ ( γ ( l )</text>
<text top="524" left="424" width="3" height="6" font="font10" id="p6_t144" reading_order_no="143" segment_no="12" tag_type="formula">i</text>
<text top="516" left="434" width="37" height="13" font="font9" id="p6_t145" reading_order_no="144" segment_no="12" tag_type="formula">) k p θ ( γ ( l )</text>
<text top="524" left="462" width="3" height="6" font="font10" id="p6_t146" reading_order_no="145" segment_no="12" tag_type="formula">i<a href="deeplearning_paper5.html#11">[22], </a>i.e.</text>
<text top="519" left="472" width="7" height="9" font="font9" id="p6_t147" reading_order_no="146" segment_no="12" tag_type="formula">)]</text>
<text top="550" left="153" width="54" height="12" font="font9" id="p6_t148" reading_order_no="147" segment_no="12" tag_type="formula">+ KL [ q φ ( δ ( l )</text>
<text top="550" left="199" width="45" height="14" font="font9" id="p6_t149" reading_order_no="148" segment_no="12" tag_type="formula">i ) k p θ ( δ ( l )</text>
<text top="552" left="236" width="30" height="12" font="font9" id="p6_t150" reading_order_no="149" segment_no="12" tag_type="formula">i )]) −</text>
<text top="543" left="272" width="5" height="6" font="font10" id="p6_t151" reading_order_no="150" segment_no="12" tag_type="formula">n</text>
<text top="550" left="268" width="14" height="4" font="font20" id="p6_t152" reading_order_no="151" segment_no="12" tag_type="formula">X</text>
<text top="567" left="268" width="13" height="6" font="font10" id="p6_t153" reading_order_no="152" segment_no="12" tag_type="formula">i =1</text>
<text top="543" left="288" width="5" height="6" font="font10" id="p6_t154" reading_order_no="153" segment_no="12" tag_type="formula">n</text>
<text top="550" left="284" width="14" height="4" font="font20" id="p6_t155" reading_order_no="154" segment_no="12" tag_type="formula">X</text>
<text top="567" left="284" width="14" height="6" font="font10" id="p6_t156" reading_order_no="155" segment_no="12" tag_type="formula">j =1</text>
<text top="551" left="300" width="80" height="12" font="font13" id="p6_t157" reading_order_no="156" segment_no="12" tag_type="formula">E q [ log p θ ( a ij | Θ ( L ) ] ,</text>
<text top="553" left="487" width="17" height="9" font="font4" id="p6_t158" reading_order_no="157" segment_no="12" tag_type="text">(12)</text>
<text top="586" left="108" width="396" height="9" font="font4" id="p6_t159" reading_order_no="158" segment_no="13" tag_type="text">where KL [ q ( · ) || p ( · )] denotes the Kullback-Leibler (KL) divergence between q ( · ) and p ( · ) . The</text>
<text top="597" left="108" width="396" height="9" font="font4" id="p6_t160" reading_order_no="159" segment_no="13" tag_type="text">second term is the cross entropy of adjacency matrix reconstruction. Here all of the true posteriors</text>
<text top="608" left="108" width="396" height="11" font="font8" id="p6_t161" reading_order_no="160" segment_no="13" tag_type="text">p θ (Θ ( l ) ) and variational posteriors q φ (Θ ( l ) ) , except for the input layer ( l = 1 ), are conditioned on</text>
<text top="620" left="108" width="172" height="11" font="font9" id="p6_t162" reading_order_no="161" segment_no="13" tag_type="text">Θ ( l − 1) , which is omitted for simplification.</text>
<text top="653" left="108" width="6" height="11" font="font3" id="p6_t163" reading_order_no="162" segment_no="14" tag_type="title">6</text>
<text top="653" left="126" width="65" height="11" font="font3" id="p6_t164" reading_order_no="163" segment_no="14" tag_type="title">Experiments</text>
<text top="681" left="108" width="396" height="9" font="font4" id="p6_t165" reading_order_no="164" segment_no="15" tag_type="text">To evaluate the performances of the proposed method, we conduct a series of experiments on</text>
<text top="691" left="108" width="396" height="9" font="font4" id="p6_t166" reading_order_no="165" segment_no="15" tag_type="text">real datasets. Two important downstream applications of graph analysis, i.e. link prediction and</text>
<text top="702" left="108" width="396" height="9" font="font4" id="p6_t167" reading_order_no="166" segment_no="15" tag_type="text">community detection, are considered in our experiments. Results show that the latent embeddings</text>
<text top="713" left="108" width="398" height="9" font="font4" id="p6_t168" reading_order_no="167" segment_no="15" tag_type="text">learned by DLSM can better represent directed graphs and significantly outperform baseline methods.</text>
<text top="743" left="304" width="5" height="9" font="font4" id="p6_t169" reading_order_no="168" segment_no="16" tag_type="text">6</text>
</page>
<page number="7" position="absolute" top="0" left="0" height="792" width="612">
<text top="79" left="108" width="396" height="10" font="font4" id="p7_t1" reading_order_no="0" segment_no="0" tag_type="text">Table 1: Descriptive statistics of the real network datasets. |V| and |E| are the numbers of nodes</text>
<text top="89" left="108" width="267" height="11" font="font4" id="p7_t2" reading_order_no="1" segment_no="0" tag_type="text">and edges, respectively, CC is the clustering coefficient [3], d out</text>
<text top="89" left="363" width="50" height="12" font="font4" id="p7_t3" reading_order_no="2" segment_no="0" tag_type="text">max and d in</text>
<text top="91" left="405" width="101" height="10" font="font4" id="p7_t4" reading_order_no="3" segment_no="0" tag_type="text">max are the maximal in-</text>
<text top="102" left="108" width="396" height="9" font="font4" id="p7_t5" reading_order_no="4" segment_no="0" tag_type="text">degree and out-degree of all nodes, respectively, d avg is the average degree of all nodes (average</text>
<text top="109" left="108" width="203" height="13" font="font4" id="p7_t6" reading_order_no="5" segment_no="0" tag_type="text">in-degree equals to average out-degree), ED = P n<a href="deeplearning_paper5.html#10">[3],</a></text>
<text top="109" left="306" width="31" height="14" font="font20" id="p7_t7" reading_order_no="6" segment_no="0" tag_type="text">i =1 P n</text>
<text top="112" left="332" width="172" height="11" font="font8" id="p7_t8" reading_order_no="7" segment_no="0" tag_type="text">j =1 a ij / ( n ( n − 1)) is the edge density, and</text>
<text top="123" left="108" width="42" height="12" font="font4" id="p7_t9" reading_order_no="8" segment_no="0" tag_type="text">RR = P n</text>
<text top="123" left="145" width="31" height="14" font="font20" id="p7_t10" reading_order_no="9" segment_no="0" tag_type="text">i =1 P n</text>
<text top="123" left="171" width="62" height="14" font="font8" id="p7_t11" reading_order_no="10" segment_no="0" tag_type="text">j =1 a ij a ji / P n</text>
<text top="123" left="228" width="31" height="14" font="font20" id="p7_t12" reading_order_no="11" segment_no="0" tag_type="text">i =1 P n</text>
<text top="126" left="254" width="115" height="11" font="font8" id="p7_t13" reading_order_no="12" segment_no="0" tag_type="text">j =1 a ij is the reciprocal rate.</text>
<text top="142" left="128" width="30" height="9" font="font4" id="p7_t14" reading_order_no="13" segment_no="1" tag_type="table">Dataset</text>
<text top="142" left="204" width="12" height="9" font="font11" id="p7_t15" reading_order_no="14" segment_no="1" tag_type="table">|V|</text>
<text top="142" left="247" width="12" height="9" font="font11" id="p7_t16" reading_order_no="15" segment_no="1" tag_type="table">|E|</text>
<text top="142" left="288" width="13" height="9" font="font4" id="p7_t17" reading_order_no="16" segment_no="1" tag_type="table">CC</text>
<text top="141" left="320" width="17" height="10" font="font8" id="p7_t18" reading_order_no="17" segment_no="1" tag_type="table">d out</text>
<text top="147" left="325" width="16" height="6" font="font10" id="p7_t19" reading_order_no="18" segment_no="1" tag_type="table">max</text>
<text top="141" left="354" width="13" height="10" font="font8" id="p7_t20" reading_order_no="19" segment_no="1" tag_type="table">d in</text>
<text top="147" left="359" width="16" height="6" font="font10" id="p7_t21" reading_order_no="20" segment_no="1" tag_type="table">max</text>
<text top="142" left="387" width="17" height="10" font="font8" id="p7_t22" reading_order_no="21" segment_no="1" tag_type="table">d avg</text>
<text top="142" left="425" width="13" height="9" font="font4" id="p7_t23" reading_order_no="22" segment_no="1" tag_type="table">ED</text>
<text top="142" left="464" width="13" height="9" font="font4" id="p7_t24" reading_order_no="23" segment_no="1" tag_type="table">RR</text>
<text top="158" left="128" width="57" height="9" font="font4" id="p7_t25" reading_order_no="24" segment_no="1" tag_type="table">Political blogs</text>
<text top="158" left="200" width="22" height="9" font="font4" id="p7_t26" reading_order_no="25" segment_no="1" tag_type="table">1,222</text>
<text top="158" left="239" width="27" height="9" font="font4" id="p7_t27" reading_order_no="26" segment_no="1" tag_type="table">19,021</text>
<text top="158" left="281" width="27" height="9" font="font4" id="p7_t28" reading_order_no="27" segment_no="1" tag_type="table">0.2459</text>
<text top="158" left="323" width="15" height="9" font="font4" id="p7_t29" reading_order_no="28" segment_no="1" tag_type="table">256</text>
<text top="158" left="357" width="15" height="9" font="font4" id="p7_t30" reading_order_no="29" segment_no="1" tag_type="table">337</text>
<text top="158" left="388" width="17" height="9" font="font4" id="p7_t31" reading_order_no="30" segment_no="1" tag_type="table">15.6</text>
<text top="158" left="417" width="27" height="9" font="font4" id="p7_t32" reading_order_no="31" segment_no="1" tag_type="table">0.0127</text>
<text top="158" left="457" width="27" height="9" font="font4" id="p7_t33" reading_order_no="32" segment_no="1" tag_type="table">0.2426</text>
<text top="169" left="128" width="36" height="9" font="font4" id="p7_t34" reading_order_no="33" segment_no="1" tag_type="table">Kohonen</text>
<text top="169" left="200" width="22" height="9" font="font4" id="p7_t35" reading_order_no="34" segment_no="1" tag_type="table">3,772</text>
<text top="169" left="239" width="27" height="9" font="font4" id="p7_t36" reading_order_no="35" segment_no="1" tag_type="table">12,731</text>
<text top="169" left="281" width="27" height="9" font="font4" id="p7_t37" reading_order_no="36" segment_no="1" tag_type="table">0.1530</text>
<text top="169" left="326" width="10" height="9" font="font4" id="p7_t38" reading_order_no="37" segment_no="1" tag_type="table">51</text>
<text top="169" left="357" width="15" height="9" font="font4" id="p7_t39" reading_order_no="38" segment_no="1" tag_type="table">735</text>
<text top="169" left="390" width="12" height="9" font="font4" id="p7_t40" reading_order_no="39" segment_no="1" tag_type="table">3.4</text>
<text top="169" left="417" width="27" height="9" font="font4" id="p7_t41" reading_order_no="40" segment_no="1" tag_type="table">0.0013</text>
<text top="169" left="457" width="27" height="9" font="font4" id="p7_t42" reading_order_no="41" segment_no="1" tag_type="table">0.0017</text>
<text top="180" left="128" width="40" height="9" font="font4" id="p7_t43" reading_order_no="42" segment_no="1" tag_type="table">CiaoDVD</text>
<text top="180" left="200" width="22" height="9" font="font4" id="p7_t44" reading_order_no="43" segment_no="1" tag_type="table">4,658</text>
<text top="180" left="239" width="27" height="9" font="font4" id="p7_t45" reading_order_no="44" segment_no="1" tag_type="table">40,133</text>
<text top="180" left="281" width="27" height="9" font="font4" id="p7_t46" reading_order_no="45" segment_no="1" tag_type="table">0.1492</text>
<text top="180" left="323" width="15" height="9" font="font4" id="p7_t47" reading_order_no="46" segment_no="1" tag_type="table">100</text>
<text top="180" left="357" width="15" height="9" font="font4" id="p7_t48" reading_order_no="47" segment_no="1" tag_type="table">361</text>
<text top="180" left="390" width="12" height="9" font="font4" id="p7_t49" reading_order_no="48" segment_no="1" tag_type="table">8.6</text>
<text top="180" left="417" width="27" height="9" font="font4" id="p7_t50" reading_order_no="49" segment_no="1" tag_type="table">0.0019</text>
<text top="180" left="457" width="27" height="9" font="font4" id="p7_t51" reading_order_no="50" segment_no="1" tag_type="table">0.3497</text>
<text top="191" left="128" width="38" height="9" font="font4" id="p7_t52" reading_order_no="51" segment_no="1" tag_type="table">WikiVote</text>
<text top="191" left="200" width="22" height="9" font="font4" id="p7_t53" reading_order_no="52" segment_no="1" tag_type="table">7,115</text>
<text top="191" left="236" width="32" height="9" font="font4" id="p7_t54" reading_order_no="53" segment_no="1" tag_type="table">103,689</text>
<text top="191" left="281" width="27" height="9" font="font4" id="p7_t55" reading_order_no="54" segment_no="1" tag_type="table">0.0896</text>
<text top="191" left="323" width="15" height="9" font="font4" id="p7_t56" reading_order_no="55" segment_no="1" tag_type="table">893</text>
<text top="191" left="357" width="15" height="9" font="font4" id="p7_t57" reading_order_no="56" segment_no="1" tag_type="table">457</text>
<text top="191" left="388" width="17" height="9" font="font4" id="p7_t58" reading_order_no="57" segment_no="1" tag_type="table">14.6</text>
<text top="191" left="417" width="27" height="9" font="font4" id="p7_t59" reading_order_no="58" segment_no="1" tag_type="table">0.0020</text>
<text top="191" left="457" width="27" height="9" font="font4" id="p7_t60" reading_order_no="59" segment_no="1" tag_type="table">0.0565</text>
<text top="202" left="128" width="25" height="9" font="font4" id="p7_t61" reading_order_no="60" segment_no="1" tag_type="table">DBLP</text>
<text top="202" left="197" width="27" height="9" font="font4" id="p7_t62" reading_order_no="61" segment_no="1" tag_type="table">12,590</text>
<text top="202" left="239" width="27" height="9" font="font4" id="p7_t63" reading_order_no="62" segment_no="1" tag_type="table">49,744</text>
<text top="202" left="281" width="27" height="9" font="font4" id="p7_t64" reading_order_no="63" segment_no="1" tag_type="table">0.0983</text>
<text top="202" left="323" width="15" height="9" font="font4" id="p7_t65" reading_order_no="64" segment_no="1" tag_type="table">617</text>
<text top="202" left="357" width="15" height="9" font="font4" id="p7_t66" reading_order_no="65" segment_no="1" tag_type="table">227</text>
<text top="202" left="390" width="12" height="9" font="font4" id="p7_t67" reading_order_no="66" segment_no="1" tag_type="table">4.0</text>
<text top="202" left="417" width="27" height="9" font="font4" id="p7_t68" reading_order_no="67" segment_no="1" tag_type="table">0.0003</text>
<text top="202" left="457" width="27" height="9" font="font4" id="p7_t69" reading_order_no="68" segment_no="1" tag_type="table">0.0043</text>
<text top="213" left="128" width="28" height="9" font="font4" id="p7_t70" reading_order_no="69" segment_no="1" tag_type="table">Emails</text>
<text top="213" left="203" width="15" height="9" font="font4" id="p7_t71" reading_order_no="70" segment_no="1" tag_type="table">986</text>
<text top="213" left="239" width="27" height="9" font="font4" id="p7_t72" reading_order_no="71" segment_no="1" tag_type="table">24,929</text>
<text top="213" left="281" width="27" height="9" font="font4" id="p7_t73" reading_order_no="72" segment_no="1" tag_type="table">0.4124</text>
<text top="213" left="323" width="15" height="9" font="font4" id="p7_t74" reading_order_no="73" segment_no="1" tag_type="table">333</text>
<text top="213" left="357" width="15" height="9" font="font4" id="p7_t75" reading_order_no="74" segment_no="1" tag_type="table">211</text>
<text top="213" left="388" width="17" height="9" font="font4" id="p7_t76" reading_order_no="75" segment_no="1" tag_type="table">25.3</text>
<text top="213" left="417" width="27" height="9" font="font4" id="p7_t77" reading_order_no="76" segment_no="1" tag_type="table">0.0257</text>
<text top="213" left="457" width="27" height="9" font="font4" id="p7_t78" reading_order_no="77" segment_no="1" tag_type="table">0.7112</text>
<text top="224" left="128" width="44" height="9" font="font4" id="p7_t79" reading_order_no="78" segment_no="1" tag_type="table">British MP</text>
<text top="224" left="203" width="15" height="9" font="font4" id="p7_t80" reading_order_no="79" segment_no="1" tag_type="table">418</text>
<text top="224" left="239" width="27" height="9" font="font4" id="p7_t81" reading_order_no="80" segment_no="1" tag_type="table">27,340</text>
<text top="224" left="281" width="27" height="9" font="font4" id="p7_t82" reading_order_no="81" segment_no="1" tag_type="table">0.5314</text>
<text top="224" left="323" width="15" height="9" font="font4" id="p7_t83" reading_order_no="82" segment_no="1" tag_type="table">201</text>
<text top="224" left="357" width="15" height="9" font="font4" id="p7_t84" reading_order_no="83" segment_no="1" tag_type="table">303</text>
<text top="224" left="388" width="17" height="9" font="font4" id="p7_t85" reading_order_no="84" segment_no="1" tag_type="table">65.4</text>
<text top="224" left="417" width="27" height="9" font="font4" id="p7_t86" reading_order_no="85" segment_no="1" tag_type="table">0.1569</text>
<text top="224" left="457" width="27" height="9" font="font4" id="p7_t87" reading_order_no="86" segment_no="1" tag_type="table">0.5406</text>
<text top="259" left="108" width="12" height="9" font="font1" id="p7_t88" reading_order_no="87" segment_no="2" tag_type="title">6.1</text>
<text top="259" left="130" width="39" height="9" font="font1" id="p7_t89" reading_order_no="88" segment_no="2" tag_type="title">Baselines</text>
<text top="279" left="108" width="396" height="9" font="font4" id="p7_t90" reading_order_no="89" segment_no="3" tag_type="text">We compare the proposed DLSM with a variant of our model by changing the Euclidean distance</text>
<text top="291" left="108" width="326" height="11" font="font4" id="p7_t91" reading_order_no="90" segment_no="3" tag_type="text">reconstruction layer to a inner product generator, i.e. P ( a ij = 1 | Θ) = σ (( β out γ i</text>
<text top="288" left="447" width="46" height="13" font="font14" id="p7_t92" reading_order_no="91" segment_no="3" tag_type="text">z i ) &gt; ( β in δ j</text>
<text top="303" left="108" width="243" height="9" font="font14" id="p7_t93" reading_order_no="92" segment_no="3" tag_type="text">z j )) following [23] and [26], which we refer to as DLSM-IP.</text>
<text top="319" left="108" width="396" height="9" font="font4" id="p7_t94" reading_order_no="93" segment_no="4" tag_type="text">Other baselines include a traditional Bayesian random graph model, i.e. the popularity-scaled latent</text>
<text top="330" left="108" width="398" height="9" font="font4" id="p7_t95" reading_order_no="94" segment_no="4" tag_type="text">space model (PSLSM) [28], and four recent deep learning graph models, i.e. the variational auto-</text>
<text top="341" left="108" width="396" height="9" font="font4" id="p7_t96" reading_order_no="95" segment_no="4" tag_type="text">encoder on graphs (VGAE) [16], Graphite [6], the deep generative latent feature relational model</text>
<text top="352" left="108" width="363" height="9" font="font4" id="p7_t97" reading_order_no="96" segment_no="4" tag_type="text">(DGLFRM) [23], and the ladder Gamma variational auto-encoder for graphs (LGVG) [26].</text>
<text top="376" left="108" width="12" height="9" font="font1" id="p7_t98" reading_order_no="97" segment_no="5" tag_type="title">6.2</text>
<text top="376" left="130" width="36" height="9" font="font1" id="p7_t99" reading_order_no="98" segment_no="5" tag_type="title">Datasets</text>
<text top="396" left="108" width="396" height="9" font="font4" id="p7_t100" reading_order_no="99" segment_no="6" tag_type="text">The experiments of link prediction are conducted on five real world datasets. Specifically, Political</text>
<text top="407" left="108" width="398" height="9" font="font4" id="p7_t101" reading_order_no="100" segment_no="6" tag_type="text">blogs is a well-studied social network composed of U.S. political blog nodes and webpage links [1].</text>
<text top="418" left="108" width="396" height="9" font="font4" id="p7_t102" reading_order_no="101" segment_no="6" tag_type="text">Kohonen is a citation network related to the self-organizing maps [2], where each node and directed</text>
<text top="429" left="108" width="396" height="9" font="font4" id="p7_t103" reading_order_no="102" segment_no="6" tag_type="text">edge represent a paper and a citation, respectively. CiaoDVD is a user–user trust network of an online</text>
<text top="440" left="108" width="396" height="9" font="font4" id="p7_t104" reading_order_no="103" segment_no="6" tag_type="text">DVD website in Britain [7]. WikiVote is a network of Wikipedia users, where each directed edge</text>
<text top="451" left="108" width="396" height="9" font="font4" id="p7_t105" reading_order_no="104" segment_no="6" tag_type="text">represents a user voting on another to become the administrator [19]. DBLP is a citation network</text>
<text top="462" left="108" width="282" height="9" font="font4" id="p7_t106" reading_order_no="105" segment_no="6" tag_type="text">within an authoritative database of computer science publications [21].</text>
<text top="478" left="108" width="396" height="9" font="font4" id="p7_t107" reading_order_no="106" segment_no="7" tag_type="text">For community detection, we consider three datasets with ground-truth community labels. The nodes</text>
<text top="489" left="108" width="396" height="9" font="font4" id="p7_t108" reading_order_no="107" segment_no="7" tag_type="text">of political blogs have been labeled as “liberal” and “conservative”. The Emails network consists</text>
<text top="500" left="108" width="396" height="9" font="font4" id="p7_t109" reading_order_no="108" segment_no="7" tag_type="text">of the members from 42 departments (communities) of a European research institution [20]. For</text>
<text top="511" left="108" width="396" height="9" font="font4" id="p7_t110" reading_order_no="109" segment_no="7" tag_type="text">this dataset, the communities with less than 30 nodes are excluded and finally 10 communities are</text>
<text top="522" left="108" width="396" height="9" font="font4" id="p7_t111" reading_order_no="110" segment_no="7" tag_type="text">retained. Lastly, the British MP is a network of politicians divided into 4 communities according to</text>
<text top="533" left="108" width="64" height="9" font="font4" id="p7_t112" reading_order_no="111" segment_no="7" tag_type="text">their parties [4].</text>
<text top="549" left="108" width="397" height="9" font="font4" id="p7_t113" reading_order_no="112" segment_no="8" tag_type="text">All of the networks have been preprocessed by omitting the isolated nodes and loops. In our</text>
<text top="560" left="108" width="397" height="9" font="font4" id="p7_t114" reading_order_no="113" segment_no="8" tag_type="text">experiments, they are randomly splitted as 85% edges for training, 10% edges for testing, and 5%</text>
<text top="571" left="108" width="352" height="9" font="font4" id="p7_t115" reading_order_no="114" segment_no="8" tag_type="text">edges for validation. The descriptive statistics of the datasets are summarized in Table 1.</text>
<text top="595" left="108" width="12" height="9" font="font1" id="p7_t116" reading_order_no="115" segment_no="9" tag_type="title">6.3</text>
<text top="595" left="130" width="67" height="9" font="font1" id="p7_t117" reading_order_no="116" segment_no="9" tag_type="title">Link Prediction</text>
<text top="615" left="108" width="396" height="9" font="font4" id="p7_t118" reading_order_no="117" segment_no="10" tag_type="text">For link prediction, we use the area under the ROC curve (AUC) and average precision (AP) as</text>
<text top="626" left="108" width="396" height="9" font="font4" id="p7_t119" reading_order_no="118" segment_no="10" tag_type="text">evaluation metric. All baselines designed for undirected graphs are slightly modified by altering the</text>
<text top="637" left="108" width="396" height="9" font="font4" id="p7_t120" reading_order_no="119" segment_no="10" tag_type="text">original encoder to the proposed directed GCN given in Eq 8. The experimental results of DLSM</text>
<text top="648" left="108" width="396" height="9" font="font4" id="p7_t121" reading_order_no="120" segment_no="10" tag_type="text">and the baselines are presented in Table 2 and Table 3, where the results are reported as the means</text>
<text top="659" left="108" width="396" height="9" font="font4" id="p7_t122" reading_order_no="121" segment_no="10" tag_type="text">and standard deviations of 10 independent random splits. Our model significantly outperforms the</text>
<text top="670" left="108" width="396" height="9" font="font4" id="p7_t123" reading_order_no="122" segment_no="10" tag_type="text">baselines on all datasets, especially the citation networks such as Kohonen and DBLP. The reason for</text>
<text top="681" left="108" width="396" height="9" font="font4" id="p7_t124" reading_order_no="123" segment_no="10" tag_type="text">this is that, these networks are almost unidirectional (i.e. the reciprocal rates are close to 0 as shown</text>
<text top="691" left="108" width="396" height="9" font="font4" id="p7_t125" reading_order_no="124" segment_no="10" tag_type="text">in Table 1), since most publications can only be cited by later ones. The Bayesian PSLSM model</text>
<text top="702" left="108" width="396" height="9" font="font4" id="p7_t126" reading_order_no="125" segment_no="10" tag_type="text">is unpractical to fit large networks such as WikiVote and DBLP because of the high computational</text>
<text top="713" left="108" width="396" height="9" font="font4" id="p7_t127" reading_order_no="126" segment_no="10" tag_type="text">complexity of MCMC-based inference methods, while the SGVB method adopted by our model</text>
<text top="743" left="304" width="5" height="9" font="font4" id="p7_t128" reading_order_no="127" segment_no="11" tag_type="text">7</text>
</page>
<page number="8" position="absolute" top="0" left="0" height="792" width="612">
	<fontspec id="font22" size="9" family="CMR10" color="#000000"/>
	<fontspec id="font23" size="9" family="CMMI10" color="#000000"/>
	<fontspec id="font24" size="9" family="CMSY10" color="#000000"/>
	<fontspec id="font25" size="9" family="CMBX10" color="#000000"/>
	<fontspec id="font26" size="9" family="CMMIB10" color="#000000"/>
	<fontspec id="font27" size="9" family="CMBSY10" color="#000000"/>
	<fontspec id="font28" size="10" family="CMBSY10" color="#000000"/>
<text top="80" left="241" width="130" height="9" font="font4" id="p8_t1" reading_order_no="0" segment_no="0" tag_type="title">Table 2: AUC of link prediction.</text>
<text top="94" left="167" width="51" height="8" font="font6" id="p8_t2" reading_order_no="1" segment_no="1" tag_type="table">Political blogs</text>
<text top="94" left="245" width="32" height="8" font="font6" id="p8_t3" reading_order_no="2" segment_no="1" tag_type="table">Kohonen</text>
<text top="94" left="312" width="35" height="8" font="font6" id="p8_t4" reading_order_no="3" segment_no="1" tag_type="table">CiaoDVD</text>
<text top="94" left="382" width="33" height="8" font="font6" id="p8_t5" reading_order_no="4" segment_no="1" tag_type="table">WikiVote</text>
<text top="94" left="456" width="22" height="8" font="font6" id="p8_t6" reading_order_no="5" segment_no="1" tag_type="table">DBLP</text>
<text top="108" left="115" width="28" height="8" font="font6" id="p8_t7" reading_order_no="6" segment_no="1" tag_type="table">PSLSM</text>
<text top="108" left="166" width="51" height="8" font="font22" id="p8_t8" reading_order_no="7" segment_no="1" tag_type="table">0 . 887 ± 0 . 005</text>
<text top="108" left="235" width="51" height="8" font="font22" id="p8_t9" reading_order_no="8" segment_no="1" tag_type="table">0 . 903 ± 0 . 002</text>
<text top="108" left="304" width="51" height="8" font="font22" id="p8_t10" reading_order_no="9" segment_no="1" tag_type="table">0 . 942 ± 0 . 002</text>
<text top="108" left="391" width="15" height="8" font="font6" id="p8_t11" reading_order_no="10" segment_no="1" tag_type="table">N/A</text>
<text top="108" left="460" width="15" height="8" font="font6" id="p8_t12" reading_order_no="11" segment_no="1" tag_type="table">N/A</text>
<text top="118" left="115" width="24" height="8" font="font6" id="p8_t13" reading_order_no="12" segment_no="1" tag_type="table">VGAE</text>
<text top="117" left="166" width="51" height="9" font="font22" id="p8_t14" reading_order_no="13" segment_no="1" tag_type="table">0 . 848 ± 0 . 006</text>
<text top="117" left="235" width="51" height="9" font="font22" id="p8_t15" reading_order_no="14" segment_no="1" tag_type="table">0 . 755 ± 0 . 008</text>
<text top="117" left="304" width="51" height="9" font="font22" id="p8_t16" reading_order_no="15" segment_no="1" tag_type="table">0 . 846 ± 0 . 003</text>
<text top="117" left="373" width="51" height="9" font="font22" id="p8_t17" reading_order_no="16" segment_no="1" tag_type="table">0 . 786 ± 0 . 002</text>
<text top="117" left="442" width="51" height="9" font="font22" id="p8_t18" reading_order_no="17" segment_no="1" tag_type="table">0 . 707 ± 0 . 000</text>
<text top="127" left="115" width="31" height="8" font="font6" id="p8_t19" reading_order_no="18" segment_no="1" tag_type="table">Graphite</text>
<text top="127" left="166" width="51" height="8" font="font22" id="p8_t20" reading_order_no="19" segment_no="1" tag_type="table">0 . 800 ± 0 . 011</text>
<text top="127" left="235" width="51" height="8" font="font22" id="p8_t21" reading_order_no="20" segment_no="1" tag_type="table">0 . 819 ± 0 . 006</text>
<text top="127" left="304" width="51" height="8" font="font22" id="p8_t22" reading_order_no="21" segment_no="1" tag_type="table">0 . 752 ± 0 . 003</text>
<text top="127" left="373" width="51" height="8" font="font22" id="p8_t23" reading_order_no="22" segment_no="1" tag_type="table">0 . 735 ± 0 . 003</text>
<text top="127" left="442" width="51" height="8" font="font22" id="p8_t24" reading_order_no="23" segment_no="1" tag_type="table">0 . 458 ± 0 . 019</text>
<text top="137" left="115" width="37" height="8" font="font6" id="p8_t25" reading_order_no="24" segment_no="1" tag_type="table">DGLFRM</text>
<text top="136" left="166" width="51" height="9" font="font22" id="p8_t26" reading_order_no="25" segment_no="1" tag_type="table">0 . 889 ± 0 . 006</text>
<text top="136" left="235" width="51" height="9" font="font22" id="p8_t27" reading_order_no="26" segment_no="1" tag_type="table">0 . 783 ± 0 . 007</text>
<text top="136" left="304" width="51" height="9" font="font22" id="p8_t28" reading_order_no="27" segment_no="1" tag_type="table">0 . 895 ± 0 . 002</text>
<text top="136" left="373" width="51" height="9" font="font22" id="p8_t29" reading_order_no="28" segment_no="1" tag_type="table">0 . 887 ± 0 . 001</text>
<text top="136" left="442" width="51" height="9" font="font22" id="p8_t30" reading_order_no="29" segment_no="1" tag_type="table">0 . 778 ± 0 . 000</text>
<text top="147" left="115" width="24" height="8" font="font6" id="p8_t31" reading_order_no="30" segment_no="1" tag_type="table">LGVG</text>
<text top="146" left="166" width="51" height="8" font="font22" id="p8_t32" reading_order_no="31" segment_no="1" tag_type="table">0 . 921 ± 0 . 005</text>
<text top="146" left="235" width="51" height="8" font="font22" id="p8_t33" reading_order_no="32" segment_no="1" tag_type="table">0 . 855 ± 0 . 007</text>
<text top="146" left="304" width="51" height="8" font="font22" id="p8_t34" reading_order_no="33" segment_no="1" tag_type="table">0 . 932 ± 0 . 002</text>
<text top="146" left="373" width="51" height="8" font="font22" id="p8_t35" reading_order_no="34" segment_no="1" tag_type="table">0 . 943 ± 0 . 000</text>
<text top="146" left="442" width="51" height="8" font="font22" id="p8_t36" reading_order_no="35" segment_no="1" tag_type="table">0 . 882 ± 0 . 000</text>
<text top="161" left="115" width="35" height="8" font="font6" id="p8_t37" reading_order_no="36" segment_no="1" tag_type="table">DLSM-IP</text>
<text top="160" left="166" width="51" height="9" font="font22" id="p8_t38" reading_order_no="37" segment_no="1" tag_type="table">0 . 894 ± 0 . 005</text>
<text top="160" left="235" width="51" height="9" font="font22" id="p8_t39" reading_order_no="38" segment_no="1" tag_type="table">0 . 881 ± 0 . 007</text>
<text top="160" left="304" width="51" height="9" font="font22" id="p8_t40" reading_order_no="39" segment_no="1" tag_type="table">0 . 964 ± 0 . 002</text>
<text top="160" left="373" width="51" height="9" font="font22" id="p8_t41" reading_order_no="40" segment_no="1" tag_type="table">0 . 965 ± 0 . 001</text>
<text top="160" left="442" width="51" height="9" font="font22" id="p8_t42" reading_order_no="41" segment_no="1" tag_type="table">0 . 920 ± 0 . 000</text>
<text top="170" left="115" width="24" height="8" font="font6" id="p8_t43" reading_order_no="42" segment_no="1" tag_type="table">DLSM</text>
<text top="170" left="163" width="58" height="8" font="font25" id="p8_t44" reading_order_no="43" segment_no="1" tag_type="table">0 . 944 ± 0 . 004</text>
<text top="170" left="231" width="59" height="8" font="font25" id="p8_t45" reading_order_no="44" segment_no="1" tag_type="table">0 . 917 ± 0 . 005</text>
<text top="170" left="300" width="59" height="8" font="font25" id="p8_t46" reading_order_no="45" segment_no="1" tag_type="table">0 . 970 ± 0 . 002</text>
<text top="170" left="369" width="58" height="8" font="font25" id="p8_t47" reading_order_no="46" segment_no="1" tag_type="table">0 . 967 ± 0 . 002</text>
<text top="170" left="438" width="58" height="8" font="font25" id="p8_t48" reading_order_no="47" segment_no="1" tag_type="table">0 . 946 ± 0 . 009</text>
<text top="210" left="245" width="122" height="9" font="font4" id="p8_t49" reading_order_no="48" segment_no="2" tag_type="title">Table 3: AP of link prediction.</text>
<text top="224" left="167" width="51" height="8" font="font6" id="p8_t50" reading_order_no="49" segment_no="3" tag_type="table">Political blogs</text>
<text top="224" left="245" width="32" height="8" font="font6" id="p8_t51" reading_order_no="50" segment_no="3" tag_type="table">Kohonen</text>
<text top="224" left="312" width="35" height="8" font="font6" id="p8_t52" reading_order_no="51" segment_no="3" tag_type="table">CiaoDVD</text>
<text top="224" left="382" width="33" height="8" font="font6" id="p8_t53" reading_order_no="52" segment_no="3" tag_type="table">WikiVote</text>
<text top="224" left="456" width="22" height="8" font="font6" id="p8_t54" reading_order_no="53" segment_no="3" tag_type="table">DBLP</text>
<text top="238" left="115" width="28" height="8" font="font6" id="p8_t55" reading_order_no="54" segment_no="3" tag_type="table">PSLSM</text>
<text top="237" left="166" width="51" height="9" font="font22" id="p8_t56" reading_order_no="55" segment_no="3" tag_type="table">0 . 887 ± 0 . 005</text>
<text top="237" left="235" width="51" height="9" font="font22" id="p8_t57" reading_order_no="56" segment_no="3" tag_type="table">0 . 903 ± 0 . 002</text>
<text top="237" left="304" width="51" height="9" font="font22" id="p8_t58" reading_order_no="57" segment_no="3" tag_type="table">0 . 943 ± 0 . 002</text>
<text top="238" left="391" width="15" height="8" font="font6" id="p8_t59" reading_order_no="58" segment_no="3" tag_type="table">N/A</text>
<text top="238" left="460" width="15" height="8" font="font6" id="p8_t60" reading_order_no="59" segment_no="3" tag_type="table">N/A</text>
<text top="247" left="115" width="24" height="8" font="font6" id="p8_t61" reading_order_no="60" segment_no="3" tag_type="table">VGAE</text>
<text top="247" left="166" width="51" height="8" font="font22" id="p8_t62" reading_order_no="61" segment_no="3" tag_type="table">0 . 830 ± 0 . 006</text>
<text top="247" left="235" width="51" height="8" font="font22" id="p8_t63" reading_order_no="62" segment_no="3" tag_type="table">0 . 783 ± 0 . 007</text>
<text top="247" left="304" width="51" height="8" font="font22" id="p8_t64" reading_order_no="63" segment_no="3" tag_type="table">0 . 846 ± 0 . 003</text>
<text top="247" left="373" width="51" height="8" font="font22" id="p8_t65" reading_order_no="64" segment_no="3" tag_type="table">0 . 778 ± 0 . 000</text>
<text top="247" left="442" width="51" height="8" font="font22" id="p8_t66" reading_order_no="65" segment_no="3" tag_type="table">0 . 640 ± 0 . 000</text>
<text top="257" left="115" width="31" height="8" font="font6" id="p8_t67" reading_order_no="66" segment_no="3" tag_type="table">Graphite</text>
<text top="256" left="166" width="51" height="9" font="font22" id="p8_t68" reading_order_no="67" segment_no="3" tag_type="table">0 . 752 ± 0 . 011</text>
<text top="256" left="235" width="51" height="9" font="font22" id="p8_t69" reading_order_no="68" segment_no="3" tag_type="table">0 . 839 ± 0 . 007</text>
<text top="256" left="304" width="51" height="9" font="font22" id="p8_t70" reading_order_no="69" segment_no="3" tag_type="table">0 . 728 ± 0 . 003</text>
<text top="256" left="373" width="51" height="9" font="font22" id="p8_t71" reading_order_no="70" segment_no="3" tag_type="table">0 . 735 ± 0 . 002</text>
<text top="256" left="442" width="51" height="9" font="font22" id="p8_t72" reading_order_no="71" segment_no="3" tag_type="table">0 . 549 ± 0 . 001</text>
<text top="267" left="115" width="37" height="8" font="font6" id="p8_t73" reading_order_no="72" segment_no="3" tag_type="table">DGLFRM</text>
<text top="266" left="166" width="51" height="9" font="font22" id="p8_t74" reading_order_no="73" segment_no="3" tag_type="table">0 . 887 ± 0 . 006</text>
<text top="266" left="235" width="51" height="9" font="font22" id="p8_t75" reading_order_no="74" segment_no="3" tag_type="table">0 . 833 ± 0 . 005</text>
<text top="266" left="304" width="51" height="9" font="font22" id="p8_t76" reading_order_no="75" segment_no="3" tag_type="table">0 . 924 ± 0 . 002</text>
<text top="266" left="373" width="51" height="9" font="font22" id="p8_t77" reading_order_no="76" segment_no="3" tag_type="table">0 . 901 ± 0 . 001</text>
<text top="266" left="442" width="51" height="9" font="font22" id="p8_t78" reading_order_no="77" segment_no="3" tag_type="table">0 . 835 ± 0 . 000</text>
<text top="276" left="115" width="24" height="8" font="font6" id="p8_t79" reading_order_no="78" segment_no="3" tag_type="table">LGVG</text>
<text top="276" left="166" width="51" height="8" font="font22" id="p8_t80" reading_order_no="79" segment_no="3" tag_type="table">0 . 915 ± 0 . 005</text>
<text top="276" left="235" width="51" height="8" font="font22" id="p8_t81" reading_order_no="80" segment_no="3" tag_type="table">0 . 859 ± 0 . 004</text>
<text top="276" left="304" width="51" height="8" font="font22" id="p8_t82" reading_order_no="81" segment_no="3" tag_type="table">0 . 945 ± 0 . 002</text>
<text top="276" left="373" width="51" height="8" font="font22" id="p8_t83" reading_order_no="82" segment_no="3" tag_type="table">0 . 948 ± 0 . 000</text>
<text top="276" left="442" width="51" height="8" font="font22" id="p8_t84" reading_order_no="83" segment_no="3" tag_type="table">0 . 909 ± 0 . 000</text>
<text top="291" left="115" width="35" height="8" font="font6" id="p8_t85" reading_order_no="84" segment_no="3" tag_type="table">DLSM-IP</text>
<text top="290" left="166" width="51" height="8" font="font22" id="p8_t86" reading_order_no="85" segment_no="3" tag_type="table">0 . 882 ± 0 . 005</text>
<text top="290" left="235" width="51" height="8" font="font22" id="p8_t87" reading_order_no="86" segment_no="3" tag_type="table">0 . 884 ± 0 . 005</text>
<text top="290" left="304" width="51" height="8" font="font22" id="p8_t88" reading_order_no="87" segment_no="3" tag_type="table">0 . 965 ± 0 . 003</text>
<text top="290" left="373" width="51" height="8" font="font22" id="p8_t89" reading_order_no="88" segment_no="3" tag_type="table">0 . 964 ± 0 . 000</text>
<text top="290" left="442" width="51" height="8" font="font22" id="p8_t90" reading_order_no="89" segment_no="3" tag_type="table">0 . 933 ± 0 . 000</text>
<text top="300" left="115" width="24" height="8" font="font6" id="p8_t91" reading_order_no="90" segment_no="3" tag_type="table">DLSM</text>
<text top="300" left="163" width="58" height="8" font="font25" id="p8_t92" reading_order_no="91" segment_no="3" tag_type="table">0 . 932 ± 0 . 009</text>
<text top="300" left="231" width="59" height="8" font="font25" id="p8_t93" reading_order_no="92" segment_no="3" tag_type="table">0 . 924 ± 0 . 006</text>
<text top="300" left="300" width="59" height="8" font="font25" id="p8_t94" reading_order_no="93" segment_no="3" tag_type="table">0 . 967 ± 0 . 002</text>
<text top="300" left="369" width="58" height="8" font="font25" id="p8_t95" reading_order_no="94" segment_no="3" tag_type="table">0 . 967 ± 0 . 002</text>
<text top="300" left="438" width="58" height="8" font="font25" id="p8_t96" reading_order_no="95" segment_no="3" tag_type="table">0 . 944 ± 0 . 010</text>
<text top="343" left="108" width="396" height="9" font="font4" id="p8_t97" reading_order_no="96" segment_no="4" tag_type="text">can handle large scale graphs efficiently. The experimental results also show that, the variant of our</text>
<text top="353" left="108" width="396" height="9" font="font4" id="p8_t98" reading_order_no="97" segment_no="4" tag_type="text">model, i.e. DLSM-IP, outperforms deep learning based methods on most datasets, demonstrating the</text>
<text top="364" left="108" width="258" height="9" font="font4" id="p8_t99" reading_order_no="98" segment_no="4" tag_type="text">importance of modeling degree heterogeneity of directed graphs.</text>
<text top="398" left="108" width="12" height="9" font="font1" id="p8_t100" reading_order_no="99" segment_no="5" tag_type="title">6.4</text>
<text top="398" left="130" width="94" height="9" font="font1" id="p8_t101" reading_order_no="100" segment_no="5" tag_type="title">Community Detection</text>
<text top="422" left="108" width="126" height="9" font="font1" id="p8_t102" reading_order_no="101" segment_no="6" tag_type="text">Community detection results</text>
<text top="422" left="244" width="260" height="9" font="font4" id="p8_t103" reading_order_no="102" segment_no="6" tag_type="text">We further conduct community detection on three real world</text>
<text top="433" left="108" width="396" height="9" font="font4" id="p8_t104" reading_order_no="103" segment_no="6" tag_type="text">datasets, i.e. Political blogs, Emails and British MP. Specially, we adopt K-means method with</text>
<text top="444" left="108" width="396" height="9" font="font4" id="p8_t105" reading_order_no="104" segment_no="6" tag_type="text">ground-truth community numbers for clustering using the learned node embeddings (the latent</text>
<text top="454" left="108" width="396" height="10" font="font4" id="p8_t106" reading_order_no="105" segment_no="6" tag_type="text">positions z i for DLSM) of all methods. The accuracy is used as the evaluation metric, which is</text>
<text top="465" left="108" width="396" height="9" font="font4" id="p8_t107" reading_order_no="106" segment_no="6" tag_type="text">computed as the percentage of correctly clustered samples using most likely mappings between true</text>
<text top="476" left="108" width="396" height="9" font="font4" id="p8_t108" reading_order_no="107" segment_no="6" tag_type="text">and predicted clusters. Table 4 shows that our proposed model significantly outperforms all other</text>
<text top="487" left="108" width="396" height="9" font="font4" id="p8_t109" reading_order_no="108" segment_no="6" tag_type="text">baseline methods. Such results verify that the sparse latent positions learned by DLSM can naturally</text>
<text top="498" left="108" width="245" height="9" font="font4" id="p8_t110" reading_order_no="109" segment_no="6" tag_type="text">capture the community structure in a high dimensional space.</text>
<text top="530" left="108" width="150" height="9" font="font1" id="p8_t111" reading_order_no="110" segment_no="7" tag_type="text">Visualizations of node embeddings</text>
<text top="530" left="268" width="236" height="9" font="font4" id="p8_t112" reading_order_no="111" segment_no="7" tag_type="text">We leverage a 2D t-SNE projection [31] to visualize the</text>
<text top="541" left="108" width="398" height="9" font="font4" id="p8_t113" reading_order_no="112" segment_no="7" tag_type="text">learned latent positions for the Emails dataset. As comparisons, we also illustrate the node represen-</text>
<text top="552" left="108" width="396" height="9" font="font4" id="p8_t114" reading_order_no="113" segment_no="7" tag_type="text">tations learned by DGLFRM and LGVG, both of which only consider the community structure but</text>
<text top="563" left="108" width="396" height="9" font="font4" id="p8_t115" reading_order_no="114" segment_no="7" tag_type="text">overlook the degree heterogeneity of networks. The transformed latent variables learned by the three</text>
<text top="574" left="108" width="396" height="9" font="font4" id="p8_t116" reading_order_no="115" segment_no="7" tag_type="text">models are plotted in Fig. 2. It is clearly seen that our model performs best in fitting such directed</text>
<text top="585" left="108" width="39" height="9" font="font4" id="p8_t117" reading_order_no="116" segment_no="7" tag_type="text">networks.</text>
<text top="628" left="216" width="180" height="9" font="font4" id="p8_t118" reading_order_no="117" segment_no="8" tag_type="title">Table 4: Accuracies of community detection.</text>
<text top="642" left="241" width="28" height="9" font="font4" id="p8_t119" reading_order_no="118" segment_no="9" tag_type="table">Emails</text>
<text top="642" left="304" width="57" height="9" font="font4" id="p8_t120" reading_order_no="119" segment_no="9" tag_type="table">Political blogs</text>
<text top="642" left="389" width="44" height="9" font="font4" id="p8_t121" reading_order_no="120" segment_no="9" tag_type="table">British MP</text>
<text top="659" left="168" width="28" height="9" font="font4" id="p8_t122" reading_order_no="121" segment_no="9" tag_type="table">VGAE</text>
<text top="658" left="226" width="57" height="9" font="font9" id="p8_t123" reading_order_no="122" segment_no="9" tag_type="table">0 . 423 ± 0 . 015</text>
<text top="658" left="304" width="58" height="9" font="font9" id="p8_t124" reading_order_no="123" segment_no="9" tag_type="table">0 . 523 ± 0 . 002</text>
<text top="658" left="382" width="58" height="9" font="font9" id="p8_t125" reading_order_no="124" segment_no="9" tag_type="table">0 . 593 ± 0 . 002</text>
<text top="669" left="168" width="35" height="9" font="font4" id="p8_t126" reading_order_no="125" segment_no="9" tag_type="table">Graphite</text>
<text top="669" left="226" width="57" height="9" font="font9" id="p8_t127" reading_order_no="126" segment_no="9" tag_type="table">0 . 672 ± 0 . 012</text>
<text top="669" left="304" width="58" height="9" font="font9" id="p8_t128" reading_order_no="127" segment_no="9" tag_type="table">0 . 514 ± 0 . 002</text>
<text top="669" left="382" width="58" height="9" font="font9" id="p8_t129" reading_order_no="128" segment_no="9" tag_type="table">0 . 593 ± 0 . 002</text>
<text top="680" left="168" width="42" height="9" font="font4" id="p8_t130" reading_order_no="129" segment_no="9" tag_type="table">DGLFRM</text>
<text top="680" left="226" width="57" height="9" font="font9" id="p8_t131" reading_order_no="130" segment_no="9" tag_type="table">0 . 607 ± 0 . 010</text>
<text top="680" left="304" width="58" height="9" font="font9" id="p8_t132" reading_order_no="131" segment_no="9" tag_type="table">0 . 505 ± 0 . 001</text>
<text top="680" left="382" width="58" height="9" font="font9" id="p8_t133" reading_order_no="132" segment_no="9" tag_type="table">0 . 572 ± 0 . 003</text>
<text top="691" left="168" width="28" height="9" font="font4" id="p8_t134" reading_order_no="133" segment_no="9" tag_type="table">LGVG</text>
<text top="691" left="226" width="57" height="9" font="font9" id="p8_t135" reading_order_no="134" segment_no="9" tag_type="table">0 . 638 ± 0 . 013</text>
<text top="691" left="304" width="58" height="9" font="font9" id="p8_t136" reading_order_no="135" segment_no="9" tag_type="table">0 . 739 ± 0 . 013</text>
<text top="691" left="378" width="66" height="9" font="font21" id="p8_t137" reading_order_no="136" segment_no="9" tag_type="table">0 . 823 ± 0 . 017</text>
<text top="707" left="168" width="28" height="9" font="font4" id="p8_t138" reading_order_no="137" segment_no="9" tag_type="table">DLSM</text>
<text top="707" left="221" width="66" height="9" font="font21" id="p8_t139" reading_order_no="138" segment_no="9" tag_type="table">0 . 816 ± 0 . 010</text>
<text top="707" left="300" width="66" height="9" font="font21" id="p8_t140" reading_order_no="139" segment_no="9" tag_type="table">0 . 879 ± 0 . 007</text>
<text top="707" left="382" width="58" height="9" font="font9" id="p8_t141" reading_order_no="140" segment_no="9" tag_type="table">0 . 811 ± 0 . 005</text>
<text top="743" left="304" width="5" height="9" font="font4" id="p8_t142" reading_order_no="141" segment_no="10" tag_type="text">8</text>
</page>
<page number="9" position="absolute" top="0" left="0" height="792" width="612">
	<fontspec id="font29" size="6" family="DejaVuSans" color="#000000"/>
	<fontspec id="font30" size="5" family="DejaVuSans,Italic" color="#000000"/>
	<fontspec id="font31" size="4" family="DejaVuSans" color="#000000"/>
	<fontspec id="font32" size="4" family="Helvetica" color="#4d4d4d"/>
	<fontspec id="font33" size="4" family="Helvetica" color="#000000"/>
	<fontspec id="font34" size="5" family="Helvetica" color="#000000"/>
	<fontspec id="font35" size="5" family="Symbol" color="#000000"/>
	<fontspec id="font36" size="6" family="DejaVuSans" color="#000000"/>
	<fontspec id="font37" size="9" family="DejaVuSans" color="#000000"/>
<text top="173" left="142" width="5" height="7" font="font29" id="p9_t1" reading_order_no="8" segment_no="0" tag_type="figure">60</text>
<text top="173" left="157" width="5" height="7" font="font29" id="p9_t2" reading_order_no="9" segment_no="0" tag_type="figure">40</text>
<text top="173" left="172" width="5" height="7" font="font29" id="p9_t3" reading_order_no="10" segment_no="0" tag_type="figure">20</text>
<text top="173" left="187" width="2" height="7" font="font29" id="p9_t4" reading_order_no="11" segment_no="0" tag_type="figure">0</text>
<text top="173" left="201" width="5" height="7" font="font29" id="p9_t5" reading_order_no="12" segment_no="0" tag_type="figure">20</text>
<text top="173" left="216" width="5" height="7" font="font29" id="p9_t6" reading_order_no="13" segment_no="0" tag_type="figure">40</text>
<text top="173" left="232" width="5" height="7" font="font29" id="p9_t7" reading_order_no="14" segment_no="0" tag_type="figure">60</text>
<text top="179" left="182" width="4" height="6" font="font30" id="p9_t8" reading_order_no="15" segment_no="0" tag_type="figure">z 1<i>z</i></text>
<text top="165" left="126" width="5" height="7" font="font29" id="p9_t9" reading_order_no="7" segment_no="0" tag_type="figure">60</text>
<text top="154" left="126" width="5" height="7" font="font29" id="p9_t10" reading_order_no="6" segment_no="0" tag_type="figure">40</text>
<text top="143" left="126" width="5" height="7" font="font29" id="p9_t11" reading_order_no="5" segment_no="0" tag_type="figure">20</text>
<text top="132" left="128" width="2" height="7" font="font29" id="p9_t12" reading_order_no="4" segment_no="0" tag_type="figure">0</text>
<text top="122" left="126" width="5" height="7" font="font29" id="p9_t13" reading_order_no="3" segment_no="0" tag_type="figure">20</text>
<text top="111" left="126" width="5" height="7" font="font29" id="p9_t14" reading_order_no="2" segment_no="0" tag_type="figure">40</text>
<text top="100" left="126" width="5" height="7" font="font29" id="p9_t15" reading_order_no="1" segment_no="0" tag_type="figure">60</text>
<text top="130" left="120" width="1" height="7" font="font30" id="p9_t16" reading_order_no="0" segment_no="0" tag_type="figure">z 2</text>
<text top="191" left="157" width="50" height="8" font="font6" id="p9_t17" reading_order_no="16" segment_no="0" tag_type="figure">(a) DGLFRM<i>z</i></text>
<text top="173" left="262" width="5" height="7" font="font29" id="p9_t18" reading_order_no="25" segment_no="0" tag_type="figure">60</text>
<text top="173" left="275" width="5" height="7" font="font29" id="p9_t19" reading_order_no="26" segment_no="0" tag_type="figure">40</text>
<text top="173" left="289" width="5" height="7" font="font29" id="p9_t20" reading_order_no="27" segment_no="0" tag_type="figure">20</text>
<text top="173" left="302" width="2" height="7" font="font29" id="p9_t21" reading_order_no="28" segment_no="0" tag_type="figure">0</text>
<text top="173" left="315" width="5" height="7" font="font29" id="p9_t22" reading_order_no="29" segment_no="0" tag_type="figure">20</text>
<text top="173" left="329" width="5" height="7" font="font29" id="p9_t23" reading_order_no="30" segment_no="0" tag_type="figure">40</text>
<text top="173" left="343" width="5" height="7" font="font29" id="p9_t24" reading_order_no="31" segment_no="0" tag_type="figure">60</text>
<text top="179" left="306" width="4" height="6" font="font30" id="p9_t25" reading_order_no="32" segment_no="0" tag_type="figure">z 1</text>
<text top="161" left="250" width="5" height="7" font="font29" id="p9_t26" reading_order_no="24" segment_no="0" tag_type="figure">60</text>
<text top="151" left="250" width="5" height="7" font="font29" id="p9_t27" reading_order_no="23" segment_no="0" tag_type="figure">40<i>z</i></text>
<text top="140" left="250" width="5" height="7" font="font29" id="p9_t28" reading_order_no="22" segment_no="0" tag_type="figure">20</text>
<text top="130" left="252" width="2" height="7" font="font29" id="p9_t29" reading_order_no="21" segment_no="0" tag_type="figure">0</text>
<text top="119" left="250" width="5" height="7" font="font29" id="p9_t30" reading_order_no="20" segment_no="0" tag_type="figure">20</text>
<text top="109" left="250" width="5" height="7" font="font29" id="p9_t31" reading_order_no="19" segment_no="0" tag_type="figure">40</text>
<text top="98" left="250" width="5" height="7" font="font29" id="p9_t32" reading_order_no="18" segment_no="0" tag_type="figure">60</text>
<text top="130" left="244" width="1" height="7" font="font30" id="p9_t33" reading_order_no="17" segment_no="0" tag_type="figure">z 2</text>
<text top="191" left="287" width="37" height="8" font="font6" id="p9_t34" reading_order_no="33" segment_no="0" tag_type="figure">(b) LGVG</text>
<text top="173" left="391" width="5" height="7" font="font29" id="p9_t35" reading_order_no="42" segment_no="0" tag_type="figure">60</text>
<text top="173" left="404" width="5" height="7" font="font29" id="p9_t36" reading_order_no="43" segment_no="0" tag_type="figure">40<i>z</i></text>
<text top="173" left="418" width="5" height="7" font="font29" id="p9_t37" reading_order_no="44" segment_no="0" tag_type="figure">20</text>
<text top="173" left="432" width="2" height="7" font="font29" id="p9_t38" reading_order_no="45" segment_no="0" tag_type="figure">0</text>
<text top="173" left="445" width="5" height="7" font="font29" id="p9_t39" reading_order_no="46" segment_no="0" tag_type="figure">20</text>
<text top="173" left="459" width="5" height="7" font="font29" id="p9_t40" reading_order_no="47" segment_no="0" tag_type="figure">40</text>
<text top="173" left="472" width="5" height="7" font="font29" id="p9_t41" reading_order_no="48" segment_no="0" tag_type="figure">60</text>
<text top="179" left="430" width="4" height="6" font="font30" id="p9_t42" reading_order_no="49" segment_no="0" tag_type="figure">z 1</text>
<text top="166" left="374" width="5" height="7" font="font29" id="p9_t43" reading_order_no="41" segment_no="0" tag_type="figure">80</text>
<text top="154" left="374" width="5" height="7" font="font29" id="p9_t44" reading_order_no="40" segment_no="0" tag_type="figure">60</text>
<text top="143" left="374" width="5" height="7" font="font29" id="p9_t45" reading_order_no="39" segment_no="0" tag_type="figure">40</text>
<text top="131" left="374" width="5" height="7" font="font29" id="p9_t46" reading_order_no="38" segment_no="0" tag_type="figure">20<i>z</i></text>
<text top="120" left="376" width="2" height="7" font="font29" id="p9_t47" reading_order_no="37" segment_no="0" tag_type="figure">0</text>
<text top="108" left="374" width="5" height="7" font="font29" id="p9_t48" reading_order_no="36" segment_no="0" tag_type="figure">20</text>
<text top="97" left="374" width="5" height="7" font="font29" id="p9_t49" reading_order_no="35" segment_no="0" tag_type="figure">40</text>
<text top="130" left="368" width="1" height="7" font="font30" id="p9_t50" reading_order_no="34" segment_no="0" tag_type="figure">z 2</text>
<text top="191" left="411" width="37" height="8" font="font6" id="p9_t51" reading_order_no="50" segment_no="0" tag_type="figure">(c) DLSM</text>
<text top="208" left="108" width="396" height="9" font="font4" id="p9_t52" reading_order_no="51" segment_no="1" tag_type="text">Figure 2: Visualizations of the node embeddings learned on the Email network using a 2D t-SNE</text>
<text top="219" left="108" width="226" height="9" font="font4" id="p9_t53" reading_order_no="52" segment_no="1" tag_type="text">projection. Colors denote the ground-truth communities.</text>
<text top="260" left="108" width="12" height="9" font="font1" id="p9_t54" reading_order_no="53" segment_no="2" tag_type="title">6.5</text>
<text top="260" left="130" width="162" height="9" font="font1" id="p9_t55" reading_order_no="54" segment_no="2" tag_type="title">Interpretation of node random factors<i>z</i></text>
<text top="283" left="108" width="396" height="11" font="font4" id="p9_t56" reading_order_no="55" segment_no="3" tag_type="text">The pairwise node random factors γ i and δ i are supposed to measure the heterogeneity of out-degrees</text>
<text top="294" left="108" width="396" height="9" font="font4" id="p9_t57" reading_order_no="56" segment_no="3" tag_type="text">and in-degrees, respectively, which typically follow the power-law. Fig. 3(a) and (b) present the</text>
<text top="305" left="108" width="396" height="9" font="font4" id="p9_t58" reading_order_no="57" segment_no="3" tag_type="text">probability density distributions (PDD) of the node degrees and reverse random factors learned by</text>
<text top="316" left="108" width="396" height="9" font="font4" id="p9_t59" reading_order_no="58" segment_no="3" tag_type="text">DLSM on the political blogs network. It seems that the degree distributions are well fitted by the</text>
<text top="327" left="108" width="396" height="9" font="font4" id="p9_t60" reading_order_no="59" segment_no="3" tag_type="text">reverse node random factors, indicating that our DLSM can ideally represent the degree heterogeneity</text>
<text top="338" left="108" width="398" height="9" font="font4" id="p9_t61" reading_order_no="60" segment_no="3" tag_type="text">via these latent variables. Furthermore, Fig. 3(c) illustrates the complementary cumulative distri-</text>
<text top="348" left="108" width="396" height="11" font="font4" id="p9_t62" reading_order_no="61" segment_no="3" tag_type="text">butions (CCD) of the random factors. As can be seen, the logarithm CCD of both γ i and δ i are</text>
<text top="360" left="108" width="396" height="9" font="font4" id="p9_t63" reading_order_no="62" segment_no="3" tag_type="text">approximately linear, with different slopes though. This shows that the proposed Dirichlet latent</text>
<text top="370" left="108" width="336" height="9" font="font4" id="p9_t64" reading_order_no="63" segment_no="3" tag_type="text">variables are flexible enough to accommodate the power-law distribution of degrees.</text>
<text top="500" left="118" width="9" height="3" font="font32" id="p9_t65" reading_order_no="69" segment_no="4" tag_type="figure">0.000</text>
<text top="478" left="118" width="9" height="3" font="font32" id="p9_t66" reading_order_no="68" segment_no="4" tag_type="figure">0.005</text>
<text top="456" left="118" width="9" height="3" font="font32" id="p9_t67" reading_order_no="67" segment_no="4" tag_type="figure">0.010</text>
<text top="434" left="118" width="9" height="3" font="font32" id="p9_t68" reading_order_no="66" segment_no="4" tag_type="figure">0.015</text>
<text top="413" left="118" width="9" height="3" font="font32" id="p9_t69" reading_order_no="65" segment_no="4" tag_type="figure">0.020<a href="deeplearning_paper5.html#9">3(a) </a>and (b) present the</text>
<text top="508" left="133" width="2" height="3" font="font32" id="p9_t70" reading_order_no="70" segment_no="4" tag_type="figure">0</text>
<text top="508" left="157" width="6" height="3" font="font32" id="p9_t71" reading_order_no="71" segment_no="4" tag_type="figure">200</text>
<text top="508" left="184" width="6" height="3" font="font32" id="p9_t72" reading_order_no="72" segment_no="4" tag_type="figure">400</text>
<text top="508" left="210" width="6" height="3" font="font32" id="p9_t73" reading_order_no="73" segment_no="4" tag_type="figure">600<a href="deeplearning_paper5.html#9">3(c) </a>illustrates the complementary cumulative distri-</text>
<text top="462" left="116" width="0" height="4" font="font33" id="p9_t74" reading_order_no="64" segment_no="4" tag_type="figure">density</text>
<text top="426" left="189" width="7" height="7" font="font34" id="p9_t75" reading_order_no="74" segment_no="4" tag_type="figure">1 γ</text>
<text top="428" left="207" width="28" height="5" font="font34" id="p9_t76" reading_order_no="75" segment_no="4" tag_type="figure">out−degree</text>
<text top="518" left="134" width="84" height="8" font="font6" id="p9_t77" reading_order_no="76" segment_no="4" tag_type="figure">(a) PDD of out-degrees</text>
<text top="500" left="248" width="9" height="3" font="font32" id="p9_t78" reading_order_no="82" segment_no="4" tag_type="figure">0.000</text>
<text top="479" left="248" width="9" height="3" font="font32" id="p9_t79" reading_order_no="81" segment_no="4" tag_type="figure">0.005</text>
<text top="457" left="248" width="9" height="3" font="font32" id="p9_t80" reading_order_no="80" segment_no="4" tag_type="figure">0.010</text>
<text top="435" left="248" width="9" height="3" font="font32" id="p9_t81" reading_order_no="79" segment_no="4" tag_type="figure">0.015</text>
<text top="413" left="248" width="9" height="3" font="font32" id="p9_t82" reading_order_no="78" segment_no="4" tag_type="figure">0.020</text>
<text top="508" left="263" width="2" height="3" font="font32" id="p9_t83" reading_order_no="83" segment_no="4" tag_type="figure">0</text>
<text top="508" left="290" width="6" height="3" font="font32" id="p9_t84" reading_order_no="84" segment_no="4" tag_type="figure">100</text>
<text top="508" left="320" width="6" height="3" font="font32" id="p9_t85" reading_order_no="85" segment_no="4" tag_type="figure">200</text>
<text top="508" left="350" width="6" height="3" font="font32" id="p9_t86" reading_order_no="86" segment_no="4" tag_type="figure">300</text>
<text top="462" left="246" width="0" height="4" font="font33" id="p9_t87" reading_order_no="77" segment_no="4" tag_type="figure">density</text>
<text top="426" left="320" width="9" height="7" font="font34" id="p9_t88" reading_order_no="87" segment_no="4" tag_type="figure">1 δ</text>
<text top="428" left="338" width="24" height="5" font="font34" id="p9_t89" reading_order_no="88" segment_no="4" tag_type="figure">in−degree</text>
<text top="518" left="266" width="80" height="8" font="font6" id="p9_t90" reading_order_no="89" segment_no="4" tag_type="figure">(b) PDD of in-degrees</text>
<text top="500" left="390" width="2" height="7" font="font29" id="p9_t91" reading_order_no="95" segment_no="4" tag_type="figure">1</text>
<text top="500" left="403" width="5" height="7" font="font29" id="p9_t92" reading_order_no="96" segment_no="4" tag_type="figure">10</text>
<text top="500" left="416" width="7" height="7" font="font29" id="p9_t93" reading_order_no="97" segment_no="4" tag_type="figure">10 2</text>
<text top="500" left="430" width="7" height="7" font="font29" id="p9_t94" reading_order_no="98" segment_no="4" tag_type="figure">10 3</text>
<text top="500" left="444" width="7" height="7" font="font29" id="p9_t95" reading_order_no="99" segment_no="4" tag_type="figure">10 4</text>
<text top="500" left="458" width="7" height="7" font="font29" id="p9_t96" reading_order_no="100" segment_no="4" tag_type="figure">10 5</text>
<text top="500" left="472" width="7" height="7" font="font29" id="p9_t97" reading_order_no="101" segment_no="4" tag_type="figure">10 6</text>
<text top="490" left="375" width="9" height="7" font="font29" id="p9_t98" reading_order_no="94" segment_no="4" tag_type="figure">10 3</text>
<text top="466" left="375" width="9" height="7" font="font29" id="p9_t99" reading_order_no="93" segment_no="4" tag_type="figure">10 2</text>
<text top="442" left="375" width="9" height="7" font="font29" id="p9_t100" reading_order_no="92" segment_no="4" tag_type="figure">10 1</text>
<text top="418" left="382" width="2" height="7" font="font29" id="p9_t101" reading_order_no="91" segment_no="4" tag_type="figure">1</text>
<text top="460" left="373" width="0" height="7" font="font36" id="p9_t102" reading_order_no="90" segment_no="4" tag_type="figure">CCDF</text>
<text top="421" left="474" width="5" height="11" font="font37" id="p9_t103" reading_order_no="102" segment_no="4" tag_type="figure">1/</text>
<text top="430" left="474" width="5" height="11" font="font37" id="p9_t104" reading_order_no="103" segment_no="4" tag_type="figure">1/</text>
<text top="518" left="387" width="97" height="8" font="font6" id="p9_t105" reading_order_no="104" segment_no="4" tag_type="figure">(c) CCD of random factors</text>
<text top="535" left="108" width="396" height="9" font="font4" id="p9_t106" reading_order_no="105" segment_no="5" tag_type="text">Figure 3: Probability density distributions of the degrees and node random factors learned by DLSM.</text>
<text top="585" left="108" width="6" height="11" font="font3" id="p9_t107" reading_order_no="106" segment_no="6" tag_type="title">7</text>
<text top="585" left="126" width="57" height="11" font="font3" id="p9_t108" reading_order_no="107" segment_no="6" tag_type="title">Conclusion</text>
<text top="615" left="108" width="396" height="9" font="font4" id="p9_t109" reading_order_no="108" segment_no="7" tag_type="text">We establish a hierarchical VAE architecture to incorporate the classic LSM into deep learning</text>
<text top="626" left="108" width="396" height="9" font="font4" id="p9_t110" reading_order_no="109" segment_no="7" tag_type="text">frameworks. The proposed model, dubbed DLSM, is comprised of a deterministic GNN encoder and</text>
<text top="637" left="108" width="396" height="9" font="font4" id="p9_t111" reading_order_no="110" segment_no="7" tag_type="text">a stochastic Bayesian decoder, which is devised for the networks with degree heterogeneity. Series of</text>
<text top="648" left="108" width="398" height="9" font="font4" id="p9_t112" reading_order_no="111" segment_no="7" tag_type="text">experiments have shown that the model is valuable in fitting directed networks and achieves the state-</text>
<text top="659" left="108" width="396" height="9" font="font4" id="p9_t113" reading_order_no="112" segment_no="7" tag_type="text">of-the-art performance on link prediction and community detection. In addition, the interpretable</text>
<text top="670" left="108" width="396" height="9" font="font4" id="p9_t114" reading_order_no="113" segment_no="7" tag_type="text">node embeddings learned by the model can naturally represent both the community structure and</text>
<text top="681" left="108" width="396" height="9" font="font4" id="p9_t115" reading_order_no="114" segment_no="7" tag_type="text">degree heterogeneity of complex directed graphs. In the future, we shall extend our model for the</text>
<text top="691" left="108" width="396" height="9" font="font4" id="p9_t116" reading_order_no="115" segment_no="7" tag_type="text">more complicated scenes such as weighted or dynamic networks. While the former with multi-valued</text>
<text top="702" left="108" width="396" height="9" font="font4" id="p9_t117" reading_order_no="116" segment_no="7" tag_type="text">edges can be simply achieved, the latter demands for a more efficient method to learn the evolutionary</text>
<text top="713" left="108" width="78" height="9" font="font4" id="p9_t118" reading_order_no="117" segment_no="7" tag_type="text">topology of graphs.</text>
<text top="743" left="304" width="5" height="9" font="font4" id="p9_t119" reading_order_no="118" segment_no="8" tag_type="text">9</text>
</page>
<page number="10" position="absolute" top="0" left="0" height="792" width="612">
<text top="74" left="108" width="56" height="11" font="font3" id="p10_t1" reading_order_no="0" segment_no="0" tag_type="title">References</text>
<text top="95" left="113" width="392" height="9" font="font4" id="p10_t2" reading_order_no="1" segment_no="1" tag_type="text">[1] Lada A Adamic and Natalie Glance. The political blogosphere and the 2004 US election:</text>
<text top="106" left="130" width="338" height="9" font="font4" id="p10_t3" reading_order_no="2" segment_no="1" tag_type="text">divided they blog. In International Workshop on Link Discovery , pages 36–43, 2005.</text>
<text top="121" left="113" width="392" height="9" font="font4" id="p10_t4" reading_order_no="3" segment_no="2" tag_type="text">[2] Vladimir Batagelj and Andrej Mrvar. Pajek datasets. http://vlado.fmf.uni-lj.si/pub/</text>
<text top="132" left="130" width="100" height="9" font="font2" id="p10_t5" reading_order_no="4" segment_no="2" tag_type="text">networks/data/ , 2006.</text>
<text top="147" left="113" width="392" height="9" font="font4" id="p10_t6" reading_order_no="5" segment_no="3" tag_type="text">[3] Giorgio Fagiolo. Clustering in complex directed networks. Physical Review E , 76(2):026107,</text>
<text top="158" left="130" width="22" height="9" font="font4" id="p10_t7" reading_order_no="6" segment_no="3" tag_type="text">2007.<a href="http://vlado.fmf.uni-lj.si/pub/networks/data/">http://vlado.fmf.uni-lj.si/pub/</a></text>
<text top="173" left="113" width="391" height="9" font="font4" id="p10_t8" reading_order_no="7" segment_no="4" tag_type="text">[4] Derek Greene and Pádraig Cunningham. Producing a unified graph representation from multiple<a href="http://vlado.fmf.uni-lj.si/pub/networks/data/">networks/data/</a></text>
<text top="184" left="130" width="344" height="9" font="font4" id="p10_t9" reading_order_no="8" segment_no="4" tag_type="text">social network views. In Annual ACM Web Science Conference , pages 118–121, 2013.<a href="http://vlado.fmf.uni-lj.si/pub/networks/data/">, </a>2006.</text>
<text top="199" left="113" width="391" height="9" font="font4" id="p10_t10" reading_order_no="9" segment_no="5" tag_type="text">[5] Aditya Grover and Jure Leskovec. node2vec: Scalable feature learning for networks. In ACM</text>
<text top="210" left="129" width="377" height="9" font="font5" id="p10_t11" reading_order_no="10" segment_no="5" tag_type="text">SIGKDD International Conference on Knowledge Discovery and Data Mining , pages 855–864,</text>
<text top="221" left="130" width="22" height="9" font="font4" id="p10_t12" reading_order_no="11" segment_no="5" tag_type="text">2016.</text>
<text top="236" left="113" width="391" height="9" font="font4" id="p10_t13" reading_order_no="12" segment_no="6" tag_type="text">[6] Aditya Grover, Aaron Zweig, and Stefano Ermon. Graphite: Iterative generative modeling of</text>
<text top="247" left="130" width="334" height="9" font="font4" id="p10_t14" reading_order_no="13" segment_no="6" tag_type="text">graphs. In International Conference on Machine Learning , pages 2434–2444, 2019.</text>
<text top="262" left="113" width="391" height="9" font="font4" id="p10_t15" reading_order_no="14" segment_no="7" tag_type="text">[7] Guibing Guo, Jie Zhang, Daniel Thalmann, and Neil Yorke-Smith. Etaf: An extended trust</text>
<text top="273" left="130" width="374" height="9" font="font4" id="p10_t16" reading_order_no="15" segment_no="7" tag_type="text">antecedents framework for trust prediction. In IEEE/ACM International Conference on Advances</text>
<text top="284" left="130" width="252" height="9" font="font5" id="p10_t17" reading_order_no="16" segment_no="7" tag_type="text">in Social Networks Analysis and Mining , pages 540–547, 2014.</text>
<text top="299" left="113" width="391" height="9" font="font4" id="p10_t18" reading_order_no="17" segment_no="8" tag_type="text">[8] William L Hamilton, Rex Ying, and Jure Leskovec. Inductive representation learning on</text>
<text top="310" left="130" width="374" height="9" font="font4" id="p10_t19" reading_order_no="18" segment_no="8" tag_type="text">large graphs. In International Conference on Neural Information Processing Systems , pages</text>
<text top="321" left="129" width="72" height="9" font="font4" id="p10_t20" reading_order_no="19" segment_no="8" tag_type="text">1025–1035, 2017.</text>
<text top="336" left="113" width="391" height="9" font="font4" id="p10_t21" reading_order_no="20" segment_no="9" tag_type="text">[9] Mark S Handcock, Adrian E Raftery, and Jeremy M Tantrum. Model-based clustering for</text>
<text top="347" left="130" width="376" height="9" font="font4" id="p10_t22" reading_order_no="21" segment_no="9" tag_type="text">social networks. Journal of the Royal Statistical Society: Series A (Statistics in Society) ,</text>
<text top="358" left="129" width="92" height="9" font="font4" id="p10_t23" reading_order_no="22" segment_no="9" tag_type="text">170(2):301–354, 2007.</text>
<text top="373" left="108" width="396" height="9" font="font4" id="p10_t24" reading_order_no="23" segment_no="10" tag_type="text">[10] Peter D Hoff, Adrian E Raftery, and Mark S Handcock. Latent space approaches to social</text>
<text top="384" left="130" width="373" height="9" font="font4" id="p10_t25" reading_order_no="24" segment_no="10" tag_type="text">network analysis. Journal of the American Statistical Association , 97(460):1090–1098, 2002.</text>
<text top="399" left="108" width="398" height="9" font="font4" id="p10_t26" reading_order_no="25" segment_no="11" tag_type="text">[11] Paul W Holland, Kathryn B Laskey, and Samuel Leinhardt. Stochastic blockmodels: First steps.</text>
<text top="410" left="129" width="152" height="9" font="font5" id="p10_t27" reading_order_no="26" segment_no="11" tag_type="text">Social Networks , 5(2):109–137, 1983.</text>
<text top="425" left="108" width="398" height="9" font="font4" id="p10_t28" reading_order_no="27" segment_no="12" tag_type="text">[12] Weonyoung Joo, Wonsung Lee, Sungrae Park, and Il-Chul Moon. Dirichlet variational autoen-</text>
<text top="436" left="130" width="187" height="9" font="font4" id="p10_t29" reading_order_no="28" segment_no="12" tag_type="text">coder. Pattern Recognition , 107:107514, 2020.</text>
<text top="451" left="108" width="396" height="9" font="font4" id="p10_t30" reading_order_no="29" segment_no="13" tag_type="text">[13] Brian Karrer and Mark EJ Newman. Stochastic blockmodels and community structure in</text>
<text top="462" left="130" width="203" height="9" font="font4" id="p10_t31" reading_order_no="30" segment_no="13" tag_type="text">networks. Physical Review E , 83(1):016107, 2011.</text>
<text top="477" left="108" width="396" height="9" font="font4" id="p10_t32" reading_order_no="31" segment_no="14" tag_type="text">[14] Diederik Kingma and Max Welling. Efficient gradient-based inference through transformations</text>
<text top="488" left="130" width="374" height="9" font="font4" id="p10_t33" reading_order_no="32" segment_no="14" tag_type="text">between Bayes nets and neural nets. In International Conference on Machine Learning , pages</text>
<text top="499" left="129" width="72" height="9" font="font4" id="p10_t34" reading_order_no="33" segment_no="14" tag_type="text">1782–1790, 2014.</text>
<text top="514" left="108" width="396" height="9" font="font4" id="p10_t35" reading_order_no="34" segment_no="15" tag_type="text">[15] Diederik P Kingma and Max Welling. Auto-encoding variational Bayes. In International</text>
<text top="525" left="129" width="191" height="9" font="font5" id="p10_t36" reading_order_no="35" segment_no="15" tag_type="text">Conference on Learning Representations , 2014.</text>
<text top="540" left="108" width="396" height="9" font="font4" id="p10_t37" reading_order_no="36" segment_no="16" tag_type="text">[16] Thomas N Kipf and Max Welling. Variational graph auto-encoders. In NIPS Workshop on</text>
<text top="551" left="129" width="126" height="9" font="font5" id="p10_t38" reading_order_no="37" segment_no="16" tag_type="text">Bayesian Deep Learning , 2016.</text>
<text top="566" left="108" width="396" height="9" font="font4" id="p10_t39" reading_order_no="38" segment_no="17" tag_type="text">[17] Thomas N Kipf and Max Welling. Semi-supervised classification with graph convolutional</text>
<text top="577" left="130" width="298" height="9" font="font4" id="p10_t40" reading_order_no="39" segment_no="17" tag_type="text">networks. In International Conference on Learning Representations , 2017.</text>
<text top="592" left="108" width="396" height="9" font="font4" id="p10_t41" reading_order_no="40" segment_no="18" tag_type="text">[18] Pavel N Krivitsky, Mark S Handcock, Adrian E Raftery, and Peter D Hoff. Representing degree</text>
<text top="603" left="130" width="374" height="9" font="font4" id="p10_t42" reading_order_no="41" segment_no="18" tag_type="text">distributions, clustering, and homophily in social networks with latent cluster random effects</text>
<text top="613" left="130" width="191" height="10" font="font4" id="p10_t43" reading_order_no="42" segment_no="18" tag_type="text">models. Social Networks , 31(3):204–213, 2009.</text>
<text top="629" left="108" width="396" height="9" font="font4" id="p10_t44" reading_order_no="43" segment_no="19" tag_type="text">[19] Jure Leskovec, Daniel Huttenlocher, and Jon Kleinberg. Predicting positive and negative links</text>
<text top="639" left="130" width="375" height="10" font="font4" id="p10_t45" reading_order_no="44" segment_no="19" tag_type="text">in online social networks. In International Conference on World Wide Web , pages 641–650,</text>
<text top="650" left="130" width="22" height="9" font="font4" id="p10_t46" reading_order_no="45" segment_no="19" tag_type="text">2010.</text>
<text top="665" left="108" width="396" height="9" font="font4" id="p10_t47" reading_order_no="46" segment_no="20" tag_type="text">[20] Jure Leskovec, Jon Kleinberg, and Christos Faloutsos. Graph evolution: Densification and</text>
<text top="676" left="130" width="375" height="9" font="font4" id="p10_t48" reading_order_no="47" segment_no="20" tag_type="text">shrinking diameters. ACM Transactions on Knowledge Discovery from Data , 1(1):2–es, 2007.</text>
<text top="691" left="108" width="398" height="9" font="font4" id="p10_t49" reading_order_no="48" segment_no="21" tag_type="text">[21] Michael Ley. The DBLP computer science bibliography: Evolution, research issues, perspec-</text>
<text top="702" left="130" width="375" height="9" font="font4" id="p10_t50" reading_order_no="49" segment_no="21" tag_type="text">tives. In International Symposium on String Processing and Information Retrieval , pages 1–10,</text>
<text top="713" left="130" width="22" height="9" font="font4" id="p10_t51" reading_order_no="50" segment_no="21" tag_type="text">2002.</text>
<text top="743" left="301" width="10" height="9" font="font4" id="p10_t52" reading_order_no="51" segment_no="22" tag_type="text">10</text>
</page>
<page number="11" position="absolute" top="0" left="0" height="792" width="612">
<text top="75" left="108" width="398" height="9" font="font4" id="p11_t1" reading_order_no="0" segment_no="0" tag_type="text">[22] Chris J Maddison, Andriy Mnih, and Yee W Teh. The concrete distribution: A continuous relax-</text>
<text top="86" left="130" width="376" height="9" font="font4" id="p11_t2" reading_order_no="1" segment_no="0" tag_type="text">ation of discrete random variables. In International Conference on Learning Representations ,</text>
<text top="97" left="130" width="22" height="9" font="font4" id="p11_t3" reading_order_no="2" segment_no="0" tag_type="text">2017.</text>
<text top="112" left="108" width="396" height="9" font="font4" id="p11_t4" reading_order_no="3" segment_no="1" tag_type="text">[23] Nikhil Mehta, Lawrence C Duke, and Piyush Rai. Stochastic blockmodels meet graph neural</text>
<text top="123" left="130" width="344" height="9" font="font4" id="p11_t5" reading_order_no="4" segment_no="1" tag_type="text">networks. In International Conference on Machine Learning , pages 4466–4474, 2019.</text>
<text top="138" left="108" width="396" height="9" font="font4" id="p11_t6" reading_order_no="5" segment_no="2" tag_type="text">[24] Kurt Miller, Michael Jordan, and Thomas Griffiths. Nonparametric latent feature models for</text>
<text top="149" left="130" width="363" height="9" font="font4" id="p11_t7" reading_order_no="6" segment_no="2" tag_type="text">link prediction. Advances in Neural Information Processing Systems , 22:1276–1284, 2009.</text>
<text top="164" left="108" width="396" height="9" font="font4" id="p11_t8" reading_order_no="7" segment_no="3" tag_type="text">[25] Bryan Perozzi, Rami Al-Rfou, and Steven Skiena. Deepwalk: Online learning of social</text>
<text top="174" left="130" width="374" height="10" font="font4" id="p11_t9" reading_order_no="8" segment_no="3" tag_type="text">representations. In ACM SIGKDD International Conference on Knowledge Discovery and Data</text>
<text top="185" left="129" width="121" height="9" font="font5" id="p11_t10" reading_order_no="9" segment_no="3" tag_type="text">Mining , pages 701–710, 2014.</text>
<text top="200" left="108" width="396" height="9" font="font4" id="p11_t11" reading_order_no="10" segment_no="4" tag_type="text">[26] Arindam Sarkar, Nikhil Mehta, and Piyush Rai. Graph representation learning via ladder Gamma</text>
<text top="211" left="129" width="376" height="9" font="font4" id="p11_t12" reading_order_no="11" segment_no="4" tag_type="text">variational autoencoders. In AAAI Conference on Artificial Intelligence , pages 5604–5611,</text>
<text top="222" left="130" width="22" height="9" font="font4" id="p11_t13" reading_order_no="12" segment_no="4" tag_type="text">2020.</text>
<text top="237" left="108" width="396" height="9" font="font4" id="p11_t14" reading_order_no="13" segment_no="5" tag_type="text">[27] Srijan Sengupta and Yuguo Chen. A block model for node popularity in networks with</text>
<text top="248" left="130" width="375" height="9" font="font4" id="p11_t15" reading_order_no="14" segment_no="5" tag_type="text">community structure. Journal of the Royal Statistical Society: Series B (Statistical Methodology) ,</text>
<text top="259" left="130" width="87" height="9" font="font4" id="p11_t16" reading_order_no="15" segment_no="5" tag_type="text">80(2):365–386, 2018.</text>
<text top="274" left="108" width="396" height="9" font="font4" id="p11_t17" reading_order_no="16" segment_no="6" tag_type="text">[28] Daniel K Sewell and Yuguo Chen. Latent space models for dynamic networks. Journal of the</text>
<text top="285" left="129" width="247" height="9" font="font5" id="p11_t18" reading_order_no="17" segment_no="6" tag_type="text">American Statistical Association , 110(512):1646–1657, 2015.</text>
<text top="299" left="108" width="396" height="9" font="font4" id="p11_t19" reading_order_no="18" segment_no="7" tag_type="text">[29] Casper K Sønderby, Tapani Raiko, Lars Maaløe, Søren K Sønderby, and Ole Winther. Ladder</text>
<text top="310" left="129" width="375" height="9" font="font4" id="p11_t20" reading_order_no="19" segment_no="7" tag_type="text">variational autoencoders. In International Conference on Neural Information Processing</text>
<text top="321" left="129" width="134" height="9" font="font5" id="p11_t21" reading_order_no="20" segment_no="7" tag_type="text">Systems , pages 3745–3753, 2016.</text>
<text top="336" left="108" width="396" height="9" font="font4" id="p11_t22" reading_order_no="21" segment_no="8" tag_type="text">[30] Yee W Teh, Dilan Grür, and Zoubin Ghahramani. Stick-breaking construction for the Indian</text>
<text top="347" left="130" width="305" height="9" font="font4" id="p11_t23" reading_order_no="22" segment_no="8" tag_type="text">buffet process. In Artificial Intelligence and Statistics , pages 556–563, 2007.</text>
<text top="362" left="108" width="396" height="9" font="font4" id="p11_t24" reading_order_no="23" segment_no="9" tag_type="text">[31] Laurens Van der Maaten and Geoffrey Hinton. Visualizing data using t-SNE. Journal of</text>
<text top="373" left="129" width="167" height="9" font="font5" id="p11_t25" reading_order_no="24" segment_no="9" tag_type="text">Machine Learning Research , 9(11), 2008.</text>
<text top="388" left="108" width="396" height="9" font="font4" id="p11_t26" reading_order_no="25" segment_no="10" tag_type="text">[32] Petar Veliˇckovi´c, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Lio, and Yoshua</text>
<text top="399" left="130" width="376" height="9" font="font4" id="p11_t27" reading_order_no="26" segment_no="10" tag_type="text">Bengio. Graph attention networks. In International Conference on Learning Representations ,</text>
<text top="410" left="130" width="22" height="9" font="font4" id="p11_t28" reading_order_no="27" segment_no="10" tag_type="text">2018.</text>
<text top="424" left="108" width="397" height="9" font="font4" id="p11_t29" reading_order_no="28" segment_no="11" tag_type="text">[33] Hongwei Wang, Jia Wang, Jialin Wang, Miao Zhao, Weinan Zhang, Fuzheng Zhang, Xing Xie,</text>
<text top="435" left="130" width="374" height="9" font="font4" id="p11_t30" reading_order_no="29" segment_no="11" tag_type="text">and Minyi Guo. GraphGAN: Graph representation learning with generative adversarial nets. In</text>
<text top="446" left="129" width="244" height="9" font="font5" id="p11_t31" reading_order_no="30" segment_no="11" tag_type="text">AAAI Conference on Artificial Intelligence , volume 32, 2018.</text>
<text top="743" left="301" width="10" height="9" font="font4" id="p11_t32" reading_order_no="31" segment_no="12" tag_type="text">11</text>
</page>
<outline>
<item page="1">1 Introduction</item>
<item page="2">2 Related Work</item>
<outline>
<item page="2">2.1 Bayesian-based random graph models</item>
<item page="2">2.2 Deep learning based graph models</item>
</outline>
<item page="3">3 Preliminaries</item>
<outline>
<item page="3">3.1 Problem definition</item>
<item page="3">3.2 Variational auto-encoder</item>
<item page="3">3.3 Latent space model</item>
</outline>
<item page="4">4 Deep Latent Space Model</item>
<outline>
<item page="4">4.1 LSM decoder</item>
<item page="5">4.2 GCN encoder</item>
</outline>
<item page="6">5 Inference</item>
<item page="6">6 Experiments</item>
<outline>
<item page="7">6.1 Baselines</item>
<item page="7">6.2 Datasets</item>
<item page="7">6.3 Link Prediction</item>
<item page="8">6.4 Community Detection</item>
<item page="9">6.5 Interpretation of node random factors</item>
</outline>
<item page="9">7 Conclusion</item>
</outline>
</pdf2xml>
